{
    "DVD-by-mail": "| E-commerce |\n|---|\n| Digital content |\n| Retail goods and services |\n| Online shopping |\n| Mobile commerce |\n| Customer service |\n| E-procurement |\n| Purchase-to-pay |\n| Super-apps |\nDVD-by-mail is a business model in which customers order DVDs and similar discs containing films, television shows, video games, and other media to rent, which are then delivery to the customer by mail. Generally, all interaction between the renter and the rental company takes place through the company's website, using an e-commerce model. Typically, a customer chooses from a list of titles online and adds titles to a queue. As a customer's requested titles become available, the company sends them out. When the customer is finished with the disc, they mail it back to the company.\nDVD-by-mail arrived in time to compete with video rental shops, but both have largely been overtaken in developed countries by video on demand (online streaming) services. As a result, formerly operating DVD-by-mail services, (e.g. Redbox) are now defunct.\nMost companies operate on the following model:\n- The customer joins the rental service, typically through an online e-commerce system and a website, and agrees to abide by a list of conditions, and provides some form of electronic payment (e.g., a credit card number).\n- Once the customer has registered, they create a list of titles they wish to watch, which are ranked by the customer by priority.\n- Titles from the list are mailed to the customer as they become available.\n- The customer watches the films or uses the media and then sends the discs back to the rental company using the mail.\nMost companies let customers keep the films for as long as they want; customers are, however, limited to a set number of discs out at any one time. Commonly, once a disc is returned, another is sent out. Some companies or plans may have a limit on the total number of movies rented in a month. Memberships are usually billed monthly, and includes postage both ways.\nVariations exist; for example, some companies also offer video game rentals while others offer music. Redbox allowed users to reserve DVDs or Blu-ray discs online to retrieve and return the DVD at interactive kiosks located in various retail establishments.\nGiven sufficiently fast mail delivery, customers on \"unlimited\" plans who return their discs quickly enough can receive enough shipments in a month that the company's cost of delivery exceeds the fixed monthly subscription fee, making this type of customer unprofitable. Even below this point, higher volume customers are less profitable than customers who receive fewer discs per month. If these customers become too numerous, there are various measures which the rental company can take.\nOne is the so-called \"throttling\" approach, which received significant publicity with regard to Netflix (which refers to the practice as a \"fairness algorithm\").[1] In this case, high-volume customers may experience a greater likelihood of (slower) shipments from alternative warehouses, when the nearest shipment center does not have the requested disc. Also, if there is a high demand for a particular disc, it is more likely that an infrequent renter will get priority over the frequent renters, with the latter receiving a movie further down on their list.[2] They are also less likely to receive replacement shipments on the same day a disc is received. Similar \"fair use\" caveats can be found in the terms and conditions of leading UK companies such as LOVEFiLM. In Canada, Zip.ca switched to \"capped\" plans (with additional shipping charges for rentals over the cap) in part to avoid implementing throttling.[citation needed]\nLOVEFiLM came under scrutiny from users over its claim to offer \"unlimited\" movie rentals. Some users reportedly found the company used long delays at the shipping stage to reduce the number of films a month a customer can rent. The company was subject to a dispute by the Advertising Standards Authority over the use of the word \"unlimited\" in their advertising. It was revealed that they practised throttling.[3] The company itself claimed that this \"fair usage\" policy means all customers get a similar service.\nOn March 2, 2006, Blockbuster announced that their service does not implement throttling.[4] \"We don't prioritize our customers' movie fulfillment based on how often they use our service, and we don't limit the number of movies a subscriber receives each month,\" according to Senior Vice-President Shayne Evangelist. However, the terms and conditions each customer has to agree to in order to subscribe to the service states, \"Blockbuster Online reserves the right to determine product allocation among members in its sole discretion. In determining product allocation, we use various factors including, but not limited to, (i) the historical rental volume for each subscriber, (ii) historical number of outstanding rentals relative to the maximum number of outstanding Blockbuster Online Rentals allowed under a subscriber's plan, and (iii) the average rental queue position of Blockbuster Online rentals that have shipped to a subscriber in the past.\"[5]\nThis article needs to be updated.(September 2019) |\nThe following is a summary of the major DVD-by-mail markets.\nNetflix ended 2008 with 9.39 million customers.[6] Around 4.2 million individuals in the U.S. still rented DVDs via mail from the company as of 2017.[7] Netflix announced on April 18, 2023, that their DVD subscription services would be closed and the last DVDs sent via mail was on September 29, 2023.[8]\nBlockbuster claimed 1 million online customers in August 2005, 2 million by March 2006, and finished the first quarter of 2007 with 3 million.[9] By the end of 2013, Blockbuster had withdrawn from the DVD-by-mail market.[10] Walmart briefly entered the market as well, but withdrew in 2005 and then went into a cross-promotional agreement with Netflix.[11] There have been a number of smaller companies, some of which target specific niches: eHit,[12] the first such niche company, came online in 2000 targeting fans of Asian films; specifically Japan, China, and Korea, expanding to include other countries' films over time.\nEstimates put the number of Canadian subscribers at 70–80,000, with Zip.ca having had around 50,000 before ceasing operations.[citation needed] Other competitors include Kaku.ca and DVDlink.ca. Cinemail.ca announced it would cease operations at the end of June 2013.\nBlockbuster Online started DVD rentals in Mexico during 2007, after the chain acquired a local startup called MovieNet.[citation needed]\nBlockbuster Online started DVD rentals in Brazil during 2006 and now offers Blu-ray plans as well. The 3-disc unlimited rental plan costs R$49.90/month with unlimited exchanges.[13]\nGiven the relatively small geographical area and high population density of the UK, online DVD rentals have some differences from the US, as a single shipping facility can serve the entire country. In-Movies.com launched the UK's first subscription service in May 2000 at £14.99 per month for a 3 disc plan and merged with Screen Select in December 2003. In April 2006, LoveFilm merged with its major rival Video Island, which had operated ScreenSelect and other brands,[14] and in February 2008, LoveFilm acquired Amazon's DVD rental business in the UK and German markets. In return, Amazon became the largest shareholder of LoveFilm.[15][16][17] LoveFilm ceased operating on 31st October 2017. Cinema Paradiso is now the only remaining supplier of rental DVDs in the UK.\nThe most prominent Australian provider was Quickflix, which provided the service alongside online streaming of movies until it ceased operations in 2021. Other companies which operated in Australia included HomeScreen, which Quickflix acquired in 2005, and BigPond Movies, which sold their library of 50,000 titles to Quickflix in 2011.\nThere were three online DVD rental companies in New Zealand, all offering flat-rate packages. The three companies were DVD Unlimited, Fatso and Movieshack. On June 7, 2008, all three companies merged into Fatso, owned by SKY Network Television. Fatso ceased operations on 23 November 2017 due to declining membership.\nHollywoodclicks and Videohub are the two most established online DVD rental services in Singapore. Hollywoodclicks was the first to market, followed by Video Ezy Online. Video Ezy Online rental service was shut down at the start of 2009 and was converted to a home delivery service.\nThere are several online DVD rental services in India, all running their own delivery systems and logistics. Unlike online DVD rental companies in other countries, online DVD rental services in India do not use the postal service as a means of delivery or exchange. India's first online DVD rental service Clixflix started in August 2004.[18] Cinesprite, Seventymm and Reliance BigFlix have closed their operations.[citation needed] Clixflix (the oldest) is still in operation in Mumbai.\nMajor online rental Blu-ray Disc and DVD companies are Tsutaya Discas, Posren, and DMM.com.[citation needed]\n- [1] Archived April 3, 2007, at the Wayback Machine\n- What is \"throttling\" and does Netflix \"throttle\" its members? Archived 2007-10-14 at the Wayback Machine, Netflix, September 10, 2007, Retrieved 2007-09-12.\n- \"Advertising Standards Authority adjudication upholding a complaint against LOVEFiLM\". Asa.org.uk. August 9, 2006. Archived from the original on September 28, 2007.\n- \"BLOCKBUSTER Online Doesn't Throttle Customers!\". Blockbuster Inc. 2007-03-02. Archived from the original on April 23, 2007. Retrieved 2007-03-28.\n- \"Blockbuster Online - Terms and Conditions\". Blockbuster Online. 2007-11-03. Archived from the original on 2007-03-22. Retrieved 2007-03-28.\n- \"Netflix 2008 Annual Report\". Netflix. 2009-05-28. Archived from the original on 2009-08-08. Retrieved 2009-08-06.\n- Ghoshal, Abhimanyu (2017-01-04). \"Netflix is still renting out DVDs to millions of customers in 2017\". The Next Web. Archived from the original on 2017-02-04. Retrieved 2017-06-01.\n- Associated Press (18 April 2023). \"Netflix will end its DVD-by-mail service\". NPR. Archived from the original on 19 April 2023. Retrieved 19 April 2023.\n- \"Blockbuster reports First Quarter 2007 results\"\n- Whitney, Lance. \"Blockbuster throws in the towel\". cnet. Archived from the original on 2 April 2018. Retrieved 16 April 2018.\n- \"Walmart.com and Netflix Announce New Promotional Agreement\". Netflix. 2005-05-19. Archived from the original on 2007-02-06. Retrieved 2007-03-28.\n- \"eHit.com - Rent Chinese and English Dvds Online. Watch it Now\". Archived from the original on 27 July 2007.\n- \"Bem vindo a Blockbuster\". Máquina de Cinema Blockbuster. Archived from the original on 2018-09-29. Retrieved 2019-04-12.\n- \"LoveFilm and Video Island merge to create Europe's leading online home entertainment group\". LoveFilm. 2006-04-06. Archived from the original on 2007-09-27. Retrieved 2007-03-28.\n- \"LoveFilm to Acquire Amazon's European DVD Rental Business - Amazon to become largest shareholder of LoveFilm\". Lovefilm.co.uk. 2010-05-24. Archived from the original on 2008-09-26. Retrieved 2013-03-24.\n- \"LoveFilm website\". Lovefilm.com. 2010-05-24. Archived from the original on 2008-10-23. Retrieved 2013-03-24.\n- Williams, Christopher (2008-02-05). \"Amazon buys into Lovefilm\". Theregister.co.uk. Archived from the original on 2017-08-10. Retrieved 2013-03-24.\n- \"Day 1: Clixflix\". Hindustan Times. 30 June 2008. Archived from the original on 12 June 2018. Retrieved 11 June 2018.",
    "IT performance management": "In a business or IT Management context, IT performance management is concerned with measuring the expenditure of capital and human resources on Information Technology projects. This allows the business to determine how these expenditures improve strategic and operational capabilities of the firm in designing and developing products and services for maximum customer satisfaction, corporate productivity, profitability, and competitiveness.[1] This type of IT Performance Management is usually of interest to executive level IT personnel, all the way up to the Chief Information Officer (CIO), and is related to IT Portfolio Management.[2]\n- Focuses IT resources on projects that grow sales\n- Focuses IT resources on projects that reduce costs\n- Aligns IT organization directly behind corporate financial goals\n- Demonstrates the direct business value of each IT project or operation\n- Helps audit and comply with legislative requirements\n- Allows reallocation of IT resources to projects of most importance to the corporation\n- Facilitates the elimination of IT projects that are not delivering on expected benefits\n- M.K. Badawy (1998), Technology Management Education: Alternative Models. California Management Review. 40 (4), pp. 94–115\n- \"CIO vs CTO: What's the difference? | McKinsey\". www.mckinsey.com. Retrieved 2025-03-04.",
    "IT service management": "Information technology service management (ITSM) are the activities performed by an organization to design, build, deliver, operate and control IT services offered to customers.[1]\nDiffering from more technology-oriented IT management approaches like network management and IT systems management,[2] IT service management is characterized by adopting a process approach towards management, focusing on customer needs and IT services for customers rather than IT systems, and stressing continual improvement. The CIO WaterCooler's 2017 ITSM report states that business uses ITSM \"mostly in support of customer experience (35%) and service quality (48%).\"[3]\nExecution of ITSM processes in an organization, especially those processes that are more workflow-driven, can benefit significantly from being supported with specialized software tools.[4]\nA service desk is a primary IT function within the discipline of IT service management (ITSM) as defined by ITIL. It is intended to provide a Single Point of Contact (SPOC) to meet the communication needs of both users and IT staff,[5] and also to satisfy both Customer and IT Provider objectives. User refers to the actual user of the service, while customer refers to the entity that is paying for the service. ITSM tools are frequently applied to other aspects of business; this practice is often called enterprise service management (ESM).[6] A key initiative in ITSM is the automation of routine tasks, enabling personnel to focus on higher-priority responsibilities; this is known as IT process automation.\nThe ITIL approach considers the service desk to be the central point of contact between service providers and users/customers on a day-to-day basis. It is also a focal point for reporting incidents (disruptions or potential disruptions in service availability or quality) and for users making service requests (routine requests for services).[7]\nITIL regards a call centre or help desk as similar kinds of tech support which provide only a portion of what a service desk can offer. A service desk has a more broad and user-centered approach which is designed to provide the user with an informed single point of contact for all IT requirements. A service desk seeks to facilitate the integration of business processes into the service management infrastructure. In addition to actively monitoring and owning incidents and user questions, and providing the communications channel for other service management disciplines with the user community, a service desk also provides an interface for other activities such as customer change requests, third parties (e.g. maintenance contracts), and software licensing.[7] Computer emergency response teams (CERT) are specifically dedicated to computer security incidents.\nAs a discipline, ITSM has ties and common interests with other IT and general management approaches, information security management and software engineering. Consequently, IT service management frameworks have been influenced by other standards and adopted concepts from them, e.g. CMMI, ISO 9000, or ISO/IEC 27000.[8]\nVarious frameworks for ITSM and overlapping disciplines include:\n- ITIL (Information Technology Infrastructure Library) is a set of detailed practices for IT activities such as IT service management (ITSM) and IT asset management (ITAM) that focus on aligning IT services with the needs of business.[9][2]\n- TOGAF is a framework and methodology that aims to define business goals while aligning them with architecture objectives related to software development.\n- Business Process Framework (eTOM) is a process framework for telecommunications service providers.\n- COBIT (Control Objectives for Information and Related Technologies) is an IT Governance framework that specifies control objectives, metrics and maturity models. Recent versions have aligned the naming of select control objectives to established ITSM process names.\n- FitSM[10] is a standard for lightweight service management. It contains several parts, including e.g. auditable requirements and document templates, which are published under Creative Common licenses. Its basic process framework is in large parts aligned to that of ISO/IEC 20000.\n- CMMI, guides all types of service providers to establish, manage, and improve services to meet business goals.\n- ASL's goal is the professional development of application management. This is achieved by offering a framework within which the processes of application management are brought in relation to each other.\n- USM,[11] the principle-based USM method provides a standardized management system for a service organization to manage its people, its processes, its technology, and its services, based on an explicit service management architecture.USM specifies the management system that supports the practice-based frameworks and standards and is adopted by Dutch government[12] for its management architecture.\n- ISO/IEC 20000 is an international standard for managing and delivering IT services. Its process model bears many similarities to that of ITIL version 2, since BS 15000 (precursor of ISO/IEC 20000) and ITIL were mutually aligned up to version 2 of ITIL. ISO/IEC 20000 defines minimum requirements for an effective \"service management system\" (SMS). Conformance of the SMS to ISO/IEC can be audited and organizations can achieve an ISO/IEC 20000 certification of their SMS for a defined scope.\n- BiSL is a framework of best practices for the Information Management domain.\n- MOF[13] (Microsoft Operations Framework) includes, in addition to a general framework of service management functions, guidance on managing services based on Microsoft technologies.\nThere are international, chapter-based professional associations, such as the IT Service Management Forum (itSMF),[14] and HDI. The main goal of these organizations is to foster the exchange of experiences and ideas between users of ITSM frameworks. To this end, national and local itSMF and HDI chapters (LIGs or local interest groups for itSMF) organize conferences and workshops. Some of them also contribute to the translations of ITSM framework documents into their respective languages or publish their own ITSM guides. There are several certifications for service management like ITILv4, TOGAF or COBIT.[15]\n- Customer service\n- Network and service management taxonomy\n- ISO/IEC 33001 Information technology -- Process assessment -- Concepts and terminology (software development)\n- Incident management § IT service management\n- \"FitSM Part 0: Overview and vocabulary\". Itemo. 24 August 2016. Archived from the original on 18 April 2019. Retrieved 27 November 2018.\n- Brenner, Michael; Garschhammer, Markus; Hegering, Heinz-Gerd (15 August 2006). \"When Infrastructure Management Just Won't Do - The Trend Towards Organizational IT Service Management\". In Eva-Maria Kern; Heinz-Gerd Hegering; Bernd Brügge (eds.). Managing Development and Application of Digital Technologies: Research Insights in the Munich Center for Digital Technology & Management. Springer Science & Business Media. pp. 131–146. ISBN 978-3-540-34129-1.\n- \"The IT Service Management Survey 2017\". Retrieved 28 November 2017.\n- \"Brenner, M. Classifying ITIL Processes - A Taxonomy under Tool Support Aspects\" (PDF). IEEE. 2006.\n- ITIL Service Design (2011), p. 22.\n- \"Enterprise Service Management\". Gartner. Retrieved 17 January 2023.\n- ITIL Service Design. The Stationery Office. 2011. ISBN 9780113313051.ITIL Service Operation. The Stationery Office. 2011. ISBN 978-0113313075.\n- \"FitSM Foundation slides handout\". Itemo.org. 1 May 2015. Archived from the original on 18 April 2019. Retrieved 30 July 2015.\n- \"(crowdsourced list of) Alternatives to ITIL\". list.ly, Jan van Bon. 3 February 2016. Retrieved 3 February 2016.\n- \"FitSM\". Itemo. Archived from the original on 9 August 2018. Retrieved 27 November 2018.\n- \"USM Wiki\". SURVUZfoundation. Retrieved 13 February 2024.\n- \"USM en het Dienstverleningsconcept\". NORA. Retrieved 13 February 2024.\n- \"Microsoft Operations Framework\". Microsoft.com. Retrieved 7 October 2012.\n- \"itSMF International\".\n- Shiff, Laura. \"Popular IT Service Management (ITSM) Frameworks\". BMC Blogs. Retrieved 12 December 2021.\n- Media related to IT Service Management at Wikimedia Commons",
    "International Standard Industrial Classification": "The International Standard Industrial Classification of All Economic Activities (ISIC) is a United Nations industry classification system. Wide use has been made of ISIC in classifying data according to kind of economic activity in the fields of employment and health data.\nIt is maintained by the United Nations Statistics Division.[1]\nISIC classifies entities by activity. The most detailed categories are defined by combinations of activities described in statistical units, considering the relative importance of the activities included in these classes.\nISIC Rev.4 continues to use criteria such as input, output and use of the products produced, but places additional emphasis on production processes.\nThe United Nations Statistics Division has published the following revisions of the ISIC standard:\n- Revision 1 – Published in 1958[2]\n- Revision 2 – Published in 1968[2]\n- Revision 3 – Published in 1989[2]\n- Revision 3.1 – Published in 2002[3]\n- Revision 4 – Published by the United Nations in 2008[4]\n- Revision 5 – Endorsed in 2023, but not yet fully published.[5]\n- Section A – Agriculture, forestry and fishing\n- Section B – Mining and quarrying\n- Section C – Manufacturing\n- Section D – Electricity, gas, steam and air conditioning supply\n- Section E – Water supply; sewerage, waste management and remediation activities\n- Section F – Construction\n- Section G – Wholesale and retail trade; repair and selling of motor vehicles and motorcycles\n- Section H – Transportation and storage\n- Section I – Accommodation and food service activities\n- Section J – Information and communication\n- Section K – Financial and insurance activities\n- Section L – Real estate activities\n- Section M – Professional, scientific and technical activities\n- Section N – Administrative and support service activities\n- Section O – Public administration and defence; compulsory social security\n- Section P – Education\n- Section Q – Human health and social work activities\n- Section R – Arts, entertainment and recreation\n- Section S – Other service activities\n- Section T – Activities of households as employers; undifferentiated goods- and services-producing activities of households for own use\n- Section U – Activities of extraterritorial organizations and bodies\n- Standard Industrial Classification (United States)\n- Trade Map, HS products by hierarchy (International Trade Centre)[6]\n- North American Industry Classification System\n- United Kingdom Standard Industrial Classification of Economic Activities\n- Russian Economic Activities Classification System (OKVED) (in Russian)\n- Australian and New Zealand Standard Industrial Classification\n- Industry Classification Benchmark (ICB)\n- Global Industry Classification Standard\n- Statistical classification of economic activities in the European Community (NACE)\n- Industry information (industry classifications)\n- French classification of economic activities, named NAF code or APE code (in French)\n- German classification of economic sectors, currently used version from 2008 (in German)\n- USND\n- International Trade Center Investment Map\n- International Standard Industrial Classification of All Economic Activities (ISIC) Revision 3.1, United Nations, New York, 2002\n- International Standard Industrial Classification of All Economic Activities (ISIC) Revision 4, United Nations, New York, 2008\n- Introduction (2024)\n- http://www.trademap.org/AdvancedProductSearch_h.aspx?nvpm=1%7C%7C%7C%7C%7C%7C%7C%7C%7C1%7C%7C1%7C%7C%7C%7C%7C",
    "analytics": "Analytics is the systematic computational analysis of data or statistics.[1] It is used for the discovery, interpretation, and communication of meaningful patterns in data, which also falls under and directly relates to the umbrella term, data science.[2] Analytics also entails applying data patterns toward effective decision-making. It can be valuable in areas rich with recorded information; analytics relies on the simultaneous application of statistics, computer programming, and operations research to quantify performance.\nOrganizations may apply analytics to business data to describe, predict, and improve business performance. Specifically, areas within analytics include descriptive analytics, diagnostic analytics, predictive analytics, prescriptive analytics, and cognitive analytics.[3] Analytics may apply to a variety of fields such as marketing, management, finance, online systems, information security, and software services. Since analytics can require extensive computation (see big data), the algorithms and software used for analytics harness the most current methods in computer science, statistics, and mathematics.[4] According to International Data Corporation, global spending on big data and business analytics (BDA) solutions is estimated to reach $215.7 billion in 2021.[5][6] As per Gartner, the overall analytic platforms software market grew by $25.5 billion in 2020.[7]\nData analysis focuses on the process of examining past data through business understanding, data understanding, data preparation, modeling and evaluation, and deployment.[8] It is a subset of data analytics, which takes multiple data analysis processes to focus on why an event happened and what may happen in the future based on the previous data.[9][unreliable source?] Data analytics is used to formulate larger organizational decisions. [citation needed]\nData analytics is a multidisciplinary field. There is extensive use of computer skills, mathematics, statistics, the use of descriptive techniques and predictive models to gain valuable knowledge from data through analytics.[citation needed] There is increasing use of the term advanced analytics, typically used to describe the technical aspects of analytics, especially in the emerging fields such as the use of machine learning techniques like neural networks, decision trees, logistic regression, linear to multiple regression analysis, and classification to do predictive modeling.[10][8] It also includes unsupervised machine learning techniques like cluster analysis, principal component analysis, segmentation profile analysis and association analysis.[citation needed]\nMarketing organizations use analytics to determine the outcomes of campaigns or efforts, and to guide decisions for investment and consumer targeting. Demographic studies, customer segmentation, conjoint analysis and other techniques allow marketers to use large amounts of consumer purchase, survey and panel data to understand and communicate marketing strategy.[11]\nMarketing analytics consists of both qualitative and quantitative, structured and unstructured data used to drive strategic decisions about brand and revenue outcomes. The process involves predictive modelling, marketing experimentation, automation and real-time sales communications. The data enables companies to make predictions and alter strategic execution to maximize performance results.[11]\nWeb analytics allows marketers to collect session-level information about interactions on a website using an operation called sessionization. Google Analytics is an example of a popular free analytics tool that marketers use for this purpose.[12] Those interactions provide web analytics information systems with the information necessary to track the referrer, search keywords, identify the IP address,[13] and track the activities of the visitor. With this information, a marketer can improve marketing campaigns, website creative content, and information architecture.[14]\nAnalysis techniques frequently used in marketing include marketing mix modeling, pricing and promotion analyses, sales force optimization and customer analytics, e.g., segmentation. Web analytics and optimization of websites and online campaigns now frequently work hand in hand with the more traditional marketing analysis techniques. A focus on digital media has slightly changed the vocabulary so that marketing mix modeling is commonly referred to as attribution modeling in the digital or marketing mix modeling context.[citation needed]\nThese tools and techniques support both strategic marketing decisions (such as how much overall to spend on marketing, how to allocate budgets across a portfolio of brands and the marketing mix) and more tactical campaign support, in terms of targeting the best potential customer with the optimal message in the most cost-effective medium at the ideal time.\nPeople analytics uses behavioral data to understand how people work and change how companies are managed.[15] It can be referred to by various names, depending on the context, the purpose of the analytics, or the specific focus of the analysis. Some examples include workforce analytics, HR analytics, talent analytics, people insights, talent insights, colleague insights, human capital analytics, and human resources information system (HRIS) analytics. HR analytics is the application of analytics to help companies manage human resources.[16]\nHR analytics has become a strategic tool in analyzing and forecasting human-related trends in the changing labor markets, using career analytics tools.[17] The aim is to discern which employees to hire, which to reward or promote, what responsibilities to assign, and similar human resource problems.[18] For example, inspection of the strategic phenomenon of employee turnover utilizing people analytics tools may serve as an important analysis at times of disruption.[19]\nIt has been suggested that people analytics is a separate discipline to HR analytics, with a greater focus on addressing business issues, while HR Analytics is more concerned with metrics related to HR processes.[20] Additionally, people analytics may now extend beyond the human resources function in organizations.[21] However, experts find that many HR departments are burdened by operational tasks and need to prioritize people analytics and automation to become a more strategic and capable business function in the evolving world of work, rather than producing basic reports that offer limited long-term value.[22] Some experts argue that a change in the way HR departments operate is essential. Although HR functions were traditionally centered on administrative tasks, they are now evolving with a new generation of data-driven HR professionals who serve as strategic business partners.[23]\nExamples of HR analytic metrics include employee lifetime value (ELTV), labour cost expense percent, union percentage, etc.[citation needed]\nA common application of business analytics is portfolio analysis. In this, a bank or lending agency has a collection of accounts of varying value and risk. The accounts may differ by the social status (wealthy, middle-class, poor, etc.) of the holder, the geographical location, its net value, and many other factors. The lender must balance the return on the loan with the risk of default for each loan. The question is then how to evaluate the portfolio as a whole.[24]\nThe least risk loan may be to the very wealthy, but there are a very limited number of wealthy people. On the other hand, there are many poor that can be lent to, but at greater risk. Some balance must be struck that maximizes return and minimizes risk. The analytics solution may combine time series analysis with many other issues in order to make decisions on when to lend money to these different borrower segments, or decisions on the interest rate charged to members of a portfolio segment to cover any losses among members in that segment.[citation needed]\nPredictive models in the banking industry are developed to bring certainty across the risk scores for individual customers. Credit scores are built to predict an individual's delinquency behavior and are widely used to evaluate the credit worthiness of each applicant.[25] Furthermore, risk analyses are carried out in the scientific world[26] and the insurance industry.[27] It is also extensively used in financial institutions like online payment gateway companies to analyse if a transaction was genuine or fraud.[28] For this purpose, they use the transaction history of the customer. This is more commonly used in Credit Card purchases, when there is a sudden spike in the customer transaction volume the customer gets a call of confirmation if the transaction was initiated by him/her. This helps in reducing loss due to such circumstances.[29]\nDigital analytics is a set of business and technical activities that define, create, collect, verify or transform digital data into reporting, research, analyses, recommendations, optimizations, predictions, and automation.[30] This also includes the SEO (search engine optimization) where the keyword search is tracked and that data is used for marketing purposes.[31] Banner ads, clicks, and social media metrics track by social media analytics, a part of digital analytics.[32] A growing number of brands and marketing firms rely on digital analytics for their digital marketing assignments, where marketing return on investment (MROI) is an important key performance indicator (KPI).[citation needed]\nSecurity analytics refers to information technology (IT) to gather security events to understand and analyze events that pose the greatest security risks.[33][34] Products in this area include security information and event management and user behavior analytics.\nSoftware analytics is the process of collecting information about the way a piece of software is used and produced.[35]\nIn the industry of commercial analytics software, an emphasis has emerged on solving the challenges of analyzing massive, complex data sets, often when such data is in a constant state of change. Such data sets are commonly referred to as big data.[36] Whereas once the problems posed by big data were only found in the scientific community, today big data is a problem for many businesses that operate transactional systems online and, as a result, amass large volumes of data quickly.[37][36]\nThe analysis of unstructured data types is another challenge getting attention in the industry. Unstructured data differs from structured data in that its format varies widely and cannot be stored in traditional relational databases without significant effort at data transformation.[38] Sources of unstructured data, such as email, the contents of word processor documents, PDFs, geospatial data, etc., are rapidly becoming a relevant source of business intelligence for businesses, governments and universities.[39][40] For example, in Britain the discovery that one company was illegally selling fraudulent doctor's notes in order to assist people in defrauding employers and insurance companies[41] is an opportunity for insurance firms to increase the vigilance of their unstructured data analysis.[42][original research?]\nThese challenges are the current inspiration for much of the innovation in modern analytics information systems, giving birth to relatively new machine analysis concepts such as complex event processing,[43] full text search and analysis, and even new ideas in presentation. One such innovation is the introduction of grid-like architecture in machine analysis, allowing increases in the speed of massively parallel processing by distributing the workload to many computers all with equal access to the complete data set.[44]\nAnalytics is increasingly used in education, particularly at the district and government office levels. However, the complexity of student performance measures presents challenges when educators try to understand and use analytics to discern patterns in student performance, predict graduation likelihood, improve chances of student success, etc.[45] For example, in a study involving districts known for strong data use, 48% of teachers had difficulty posing questions prompted by data, 36% did not comprehend given data, and 52% incorrectly interpreted data.[46] To combat this, some analytics tools for educators adhere to an over-the-counter data format (embedding labels, supplemental documentation, and a help system, and making key package/display and content decisions) to improve educators' understanding and use of the analytics being displayed.[47]\nRisks for the general population include discrimination on the basis of characteristics such as gender, skin colour, ethnic origin or political opinions, through mechanisms such as price discrimination or statistical discrimination.[48]\n- Analysis\n- Analytic applications\n- Architectural analytics\n- Behavioral analytics\n- Business analytics\n- Business intelligence\n- Cloud analytics\n- Complex event processing\n- Continuous analytics\n- Cultural analytics\n- Customer analytics\n- Dashboard (business)\n- Data mining\n- Data presentation architecture\n- Embedded analytics\n- Learning analytics\n- List of software engineering topics\n- Mobile Location Analytics\n- News analytics\n- Online analytical processing\n- Online video analytics\n- Operational reporting\n- Operations research\n- Prediction\n- Predictive analytics\n- Predictive engineering analytics\n- Prescriptive analytics\n- Semantic analytics\n- Smart grid\n- Social analytics\n- Software analytics\n- Speech analytics\n- Statistics\n- User behavior analytics\n- Visual analytics\n- Web analytics\n- Win–loss analytics\n- \"Oxford definition of analytics\". Archived from the original on August 10, 2020.\n- Agarwal, Ritu; Dhar, Vasant (2014). \"Editorial—Big Data, Data Science, and Analytics: The Opportunity and Challenge for IS Research\". Information Systems Research. 25 (3): 443–448. doi:10.1287/isre.2014.0546.\n- \"Cognitive Analytics - combining Artificial Intelligence (AI) and Data Analytics\". www.ulster.ac.uk. March 8, 2017. Archived from the original on January 10, 2022. Retrieved January 7, 2022.\n- Kohavi, Ron; Rothleder, Neal J.; Simoudis, Evangelos (2002). \"Emerging trends in business analytics\". Communications of the ACM. 45 (8): 45–48. doi:10.1145/545151.545177.\n- \"Global Spending on Big Data and Analytics Solutions Will Reach $215.7 Billion in 2021, According to a New IDC Spending Guide\". Archived from the original on July 23, 2022. Retrieved July 24, 2022.\n- \"Big data and business analytics revenue 2022\". Archived from the original on July 20, 2022. Retrieved July 24, 2022.\n- \"Market Share: Data and Analytics Software, Worldwide, 2020\". Archived from the original on October 3, 2022. Retrieved July 24, 2022.\n- Kelleher, John D. (2020). Fundamentals of machine learning for predictive data analytics : algorithms, worked examples, and case studies. Brian Mac Namee, Aoife D'Arcy (2 ed.). Cambridge, Massachusetts. p. 16. ISBN 978-0-262-36110-1. OCLC 1162184998.\n{{cite book}}\n: CS1 maint: location missing publisher (link) - Park, David (August 28, 2017). \"Analysis vs. Analytics: Past vs. Future\". EE Times. Archived from the original on January 29, 2021. Retrieved January 20, 2021.\n- \"AI, Big Data & Advanced Analytics In The Supply Chain\". Forbes.com. Archived from the original on June 23, 2022. Retrieved April 16, 2020.\n- Wedel, Michel; Kannan, P.K. (2016). \"Marketing Analytics for Data-Rich Environments\". Journal of Marketing. 80 (6): 97–121. doi:10.1509/jm.15.0413.\n- \"Session - Analytics Help\". support.google.com. Archived from the original on January 10, 2022. Retrieved January 9, 2022.\n- \"IP address - Analytics Help\". support.google.com. Archived from the original on January 10, 2022. Retrieved January 9, 2022.\n- \"Analytics Tools & Solutions for Your Business - Google Analytics\". Google Marketing Platform. Archived from the original on October 2, 2022. Retrieved January 9, 2022.\n- lukem (November 4, 2016). \"People Analytics: Transforming Management with Behavioral Data\". Programs for Professionals | MIT Professional Education. Archived from the original on September 8, 2018. Retrieved April 3, 2018.\n- Chalutz Ben-Gal, Hila (2019). \"An ROI-based review of HR analytics: Practical implementation tools\". Personnel Review. 48 (6): 1429–1448. doi:10.1108/PR-11-2017-0362.\n- Sela, Alon; Ben-Gal, Hila Chalutz (2018). \"Big Data Analysis of Employee Turnover in Global Media Companies, Google, Facebook and Others\". 2018 IEEE International Conference on the Science of Electrical Engineering in Israel (ICSEE). pp. 1–5. doi:10.1109/ICSEE.2018.8645991. ISBN 978-1-5386-6378-3.\n- \"People analytics - University of Pennsylvania\". Coursera. Archived from the original on April 19, 2019. Retrieved May 3, 2017.\n- Avrahami, Dan; Pessach, Dana; Singer, Gonen; Chalutz Ben-Gal, Hila (2022). \"A human resources analytics and machine-learning examination of turnover: Implications for theory and practice\". International Journal of Manpower. 43 (6): 1405–1424. doi:10.1108/IJM-12-2020-0548.\n- \"People Analytics: MIT July 24, 2017\". HR Examiner. August 2, 2017. Archived from the original on April 28, 2019. Retrieved April 3, 2018.\nWaber makes a key distinction between People Analytics and HR Analytics. \"People Analytics solves business problems. HR Analytics solves HR problems,\" he says. People Analytics looks at the work and its social organization. HR Analytics measures and integrates data about HR administrative processes.\n- Bersin, Josh. \"The Geeks Arrive In HR: People Analytics Is Here\". Forbes. Archived from the original on September 20, 2019. Retrieved April 3, 2018.\n- \"The CEO's guide to competing through HR\". Archived from the original on July 24, 2020. Retrieved July 24, 2020.\n- McNulty, Keith. \"It's Time for HR 3.0\". Talent Economy. Archived from the original on July 3, 2020. Retrieved July 24, 2020.\n- Pilbeam, Keith (2005). \"Portfolio Analysis: Risk and Return in Financial Markets\". Finance and Financial Markets. pp. 156–187. doi:10.1007/978-1-349-26273-1_7. ISBN 978-0-333-62945-1.\n- \"Credit Reports and Scores | USAGov\". www.usa.gov. Archived from the original on January 8, 2022. Retrieved January 9, 2022.\n- Mayernik, Matthew S.; Breseman, Kelsey; Downs, Robert R.; Duerr, Ruth; Garretson, Alexis; Hou, Chung-Yi (Sophie) (2020). \"Risk Assessment for Scientific Data\". Data Science Journal. 19 10. doi:10.5334/dsj-2020-010.\n- \"Predictive Analytics in Insurance: Types, Tools, and the Future\". Maryville Online. October 28, 2020. Archived from the original on January 10, 2022. Retrieved January 9, 2022.\n- Liébana-Cabanillas, Francisco; Singh, Nidhi; Kalinic, Zoran; Carvajal-Trujillo, Elena (2021). \"Examining the determinants of continuance intention to use and the moderating effect of the gender and age of users of NFC mobile payments: A multi-analytical approach\". Information Technology and Management. 22 (2): 133–161. doi:10.1007/s10799-021-00328-6.\n- Crail, Chauncey (March 9, 2021). \"How to Enable Mobile Credit Card Alerts for Purchases and Fraud\". Forbes Advisor. Archived from the original on January 10, 2022. Retrieved January 9, 2022.\n- Phillips, Judah \"Building a Digital Analytics Organization\" Financial Times Press, 2013, pp 7–8.\n- \"SEO Starter Guide: The Basics | Google Search Central\". Google Developers. Archived from the original on January 12, 2022. Retrieved January 9, 2022.\n- \"Clickthrough rate (CTR): Definition - Google Ads Help\". support.google.com. Archived from the original on January 10, 2022. Retrieved January 9, 2022.\n- \"Security analytics shores up hope for breach detection\". Enterprise Innovation. Archived from the original on February 12, 2019. Retrieved April 27, 2015.\n- Talabis, Mark Ryan M. (2015). Information security analytics : finding security insights, patterns, and anomalies in big data. Robert McPherson, I Miyamoto, Jason L. Martin. Waltham, MA. p. 1. ISBN 978-0-12-800506-4. OCLC 910911974.\n{{cite book}}\n: CS1 maint: location missing publisher (link)[page needed] - Zhang, Dongmei; Xie, Tao (2016). \"Software analytics and its application in practice\". Perspectives on Data Science for Software Engineering. pp. 7–11. doi:10.1016/B978-0-12-804206-9.00002-7. ISBN 978-0-12-804206-9.\n- \"2.3 Ten common characteristics of big data\". www.bitbybitbook.com. Archived from the original on March 31, 2022. Retrieved January 10, 2022.\n- Naone, Erica. \"The New Big Data\". Technology Review, MIT. Archived from the original on May 20, 2022. Retrieved August 22, 2011.\n- Inmon, Bill; Nesavich, Anthony (2007). Tapping Into Unstructured Data. Prentice-Hall. ISBN 978-0-13-236029-6.\n- Wise, Lyndsay. \"Data Analysis and Unstructured Data\". Dashboard Insight. Archived from the original on January 5, 2014. Retrieved February 14, 2011.\n- \"Tapping the power of unstructured data\". MIT Sloan. February 2021. Archived from the original on January 10, 2022. Retrieved January 10, 2022.\n- \"Fake doctors' sick notes for Sale for £25, NHS fraud squad warns\". The Telegraph. London. August 26, 2008. Archived from the original on January 12, 2022. Retrieved September 16, 2011.\n- \"Big Data: The next frontier for innovation, competition and productivity as reported in Building with Big Data\". The Economist. May 26, 2011. Archived from the original on June 3, 2011.\n- Flouris, Ioannis; Giatrakos, Nikos; Deligiannakis, Antonios; Garofalakis, Minos; Kamp, Michael; Mock, Michael (2017). \"Issues in complex event processing: Status and prospects in the Big Data era\". Journal of Systems and Software. 127: 217–236. doi:10.1016/j.jss.2016.06.011.\n- Yang, Ning; Liu, Diyou; Feng, Quanlong; Xiong, Quan; Zhang, Lin; Ren, Tianwei; Zhao, Yuanyuan; Zhu, Dehai; Huang, Jianxi (2019). \"Large-Scale Crop Mapping Based on Machine Learning and Parallel Computation with Grids\". Remote Sensing. 11 (12): 1500. Bibcode:2019RemS...11.1500Y. doi:10.3390/rs11121500.\n- Prinsloo, Paul; Slade, Sharon (2017). \"An elephant in the learning analytics room: The obligation to act\". Proceedings of the Seventh International Learning Analytics & Knowledge Conference. pp. 46–55. doi:10.1145/3027385.3027406. ISBN 978-1-4503-4870-6.\n- U.S. Department of Education Office of Planning, Evaluation and Policy Development (2009). Implementing data-informed decision making in schools: Teacher access, supports and use. United States Department of Education (ERIC Document Reproduction Service No. ED504191)\n- Rankin, J. (March 28, 2013). How data Systems & reports can either fight or propagate the data analysis error epidemic, and how educator leaders can help. Archived March 26, 2019, at the Wayback Machine Presentation conducted from Technology Information Center for Administrative Leadership (TICAL) School Leadership Summit.\n- Favaretto, Maddalena; De Clercq, Eva; Elger, Bernice Simone (2019). \"Big Data and discrimination: Perils, promises and solutions. A systematic review\". Journal of Big Data. 6 12. doi:10.1186/s40537-019-0177-4.\n- The dictionary definition of analytics at Wiktionary",
    "artificial intelligence": "| Part of a series on |\n| Artificial intelligence (AI) |\n|---|\nArtificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that is enableb on machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.[1]\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., language models and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"[2][3]\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics.[a] To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics.[b] AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.[4] Some companies, such as OpenAI, Google DeepMind and Meta,[5] aim to create artificial general intelligence (AGI)—AI that can complete virtually any cognitive task at least as well as a human.\nArtificial intelligence was founded as an academic discipline in 1956,[6] and the field went through multiple cycles of optimism throughout its history,[7][8] followed by periods of disappointment and loss of funding, known as AI winters.[9][10] Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks, and deep learning outperformed previous AI techniques.[11] This growth accelerated further after 2017 with the transformer architecture.[12] In the 2020s, an ongoing period of rapid progress in advanced generative AI became known as the AI boom. Generative AI's ability to create and modify content has led to several unintended consequences and harms. Ethical concerns have been raised about AI's long-term effects and potential existential risks, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\nGoals\nThe general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.[a]\nReasoning and problem-solving\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions.[13] By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.[14]\nMany of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": They become exponentially slower as the problems grow.[15] Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.[16] Accurate and efficient reasoning is an unsolved problem.\nKnowledge representation\nKnowledge representation and knowledge engineering[17] allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval,[18] scene interpretation,[19] clinical decision support,[20] knowledge discovery (mining \"interesting\" and actionable inferences from large databases),[21] and other areas.[22]\nA knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge.[23] Knowledge bases need to represent things such as objects, properties, categories, and relations between objects;[24] situations, events, states, and time;[25] causes and effects;[26] knowledge about knowledge (what we know about what other people know);[27] default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing);[28] and many other aspects and domains of knowledge.\nAmong the most difficult problems in knowledge representation are the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous);[29] and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \"facts\" or \"statements\" that they could express verbally).[16] There is also the difficulty of knowledge acquisition, the problem of obtaining knowledge for AI applications.[c]\nPlanning and decision-making\nAn \"agent\" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen.[d][32] In automated planning, the agent has a specific goal.[33] In automated decision-making, the agent has preferences—there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision-making agent assigns a number to each situation (called the \"utility\") that measures how much the agent prefers it. For each possible action, it can calculate the \"expected utility\": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.[34]\nIn classical planning, the agent knows exactly what the effect of any action will be.[35] In most real-world problems, however, the agent may not be certain about the situation they are in (it is \"unknown\" or \"unobservable\") and it may not know for certain what will happen after each possible action (it is not \"deterministic\"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.[36]\nIn some problems, the agent's preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with inverse reinforcement learning), or the agent can seek information to improve its preferences.[37] Information value theory can be used to weigh the value of exploratory or experimental actions.[38] The space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain of what the outcome will be.\nA Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way and a reward function that supplies the utility of each state and the cost of each action. A policy associates a decision with each possible state. The policy could be calculated (e.g., by iteration), be heuristic, or it can be learned.[39]\nGame theory describes the rational behavior of multiple interacting agents and is used in AI programs that make decisions that involve other agents.[40]\nLearning\nMachine learning is the study of programs that can improve their performance on a given task automatically.[41] It has been a part of AI from the beginning.[e]\nThere are several kinds of machine learning. Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance.[44] Supervised learning requires labeling the training data with the expected answers, and comes in two main varieties: classification (where the program must learn to predict what category the input belongs in) and regression (where the program must deduce a numeric function based on numeric input).[45]\nIn reinforcement learning, the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as \"good\".[46] Transfer learning is when the knowledge gained from one problem is applied to a new problem.[47] Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning.[48]\nComputational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.[49]\nNatural language processing\nNatural language processing (NLP) allows programs to read, write and communicate in human languages.[50] Specific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval and question answering.[51]\nEarly work, based on Noam Chomsky's generative grammar and semantic networks, had difficulty with word-sense disambiguation[f] unless restricted to small domains called \"micro-worlds\" (due to the common sense knowledge problem[29]). Margaret Masterman believed that it was meaning and not grammar that was the key to understanding languages, and that thesauri and not dictionaries should be the basis of computational language structure.\nModern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning),[52] transformers (a deep learning architecture using an attention mechanism),[53] and others.[54] In 2019, generative pre-trained transformer (or \"GPT\") language models began to generate coherent text,[55][56] and by 2023, these models were able to get human-level scores on the bar exam, SAT test, GRE test, and many other real-world applications.[57]\nPerception\nMachine perception is the ability to use input from sensors (such as cameras, microphones, wireless signals, active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Computer vision is the ability to analyze visual input.[58]\nThe field includes speech recognition,[59] image classification,[60] facial recognition, object recognition,[61] object tracking,[62] and robotic perception.[63]\nSocial intelligence\nAffective computing is a field that comprises systems that recognize, interpret, process, or simulate human feeling, emotion, and mood.[65] For example, some virtual assistants are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human–computer interaction.\nHowever, this tends to give naïve users an unrealistic conception of the intelligence of existing computer agents.[66] Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal sentiment analysis, wherein AI classifies the effects displayed by a videotaped subject.[67]\nGeneral intelligence\nA machine with artificial general intelligence would be able to solve a wide variety of problems with breadth and versatility similar to human intelligence.[68]\nTechniques\nAI research uses a wide variety of techniques to accomplish the goals above.[b]\nSearch and optimization\nAI can solve many problems by intelligently searching through many possible solutions.[69] There are two very different kinds of search used in AI: state space search and local search.\nState space search\nState space search searches through a tree of possible states to try to find a goal state.[70] For example, planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis.[71]\nSimple exhaustive searches[72] are rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes.[15] \"Heuristics\" or \"rules of thumb\" can help prioritize choices that are more likely to reach a goal.[73]\nAdversarial search is used for game-playing programs, such as chess or Go. It searches through a tree of possible moves and countermoves, looking for a winning position.[74]\nLocal search\nLocal search uses mathematical optimization to find a solution to a problem. It begins with some form of guess and refines it incrementally.[75]\nGradient descent is a type of local search that optimizes a set of numerical parameters by incrementally adjusting them to minimize a loss function. Variants of gradient descent are commonly used to train neural networks,[76] through the backpropagation algorithm.\nAnother type of local search is evolutionary computation, which aims to iteratively improve a set of candidate solutions by \"mutating\" and \"recombining\" them, selecting only the fittest to survive each generation.[77]\nDistributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking) and ant colony optimization (inspired by ant trails).[78]\nLogic\nFormal logic is used for reasoning and knowledge representation.[79] Formal logic comes in two main forms: propositional logic (which operates on statements that are true or false and uses logical connectives such as \"and\", \"or\", \"not\" and \"implies\")[80] and predicate logic (which also operates on objects, predicates and relations and uses quantifiers such as \"Every X is a Y\" and \"There are some Xs that are Ys\").[81]\nDeductive reasoning in logic is the process of proving a new statement (conclusion) from other statements that are given and assumed to be true (the premises).[82] Proofs can be structured as proof trees, in which nodes are labelled by sentences, and children nodes are connected to parent nodes by inference rules.\nGiven a problem and a set of premises, problem-solving reduces to searching for a proof tree whose root node is labelled by a solution of the problem and whose leaf nodes are labelled by premises or axioms. In the case of Horn clauses, problem-solving search can be performed by reasoning forwards from the premises or backwards from the problem.[83] In the more general case of the clausal form of first-order logic, resolution is a single, axiom-free rule of inference, in which a problem is solved by proving a contradiction from premises that include the negation of the problem to be solved.[84]\nInference in both Horn clause logic and first-order logic is undecidable, and therefore intractable. However, backward reasoning with Horn clauses, which underpins computation in the logic programming language Prolog, is Turing complete. Moreover, its efficiency is competitive with computation in other symbolic programming languages.[85]\nFuzzy logic assigns a \"degree of truth\" between 0 and 1. It can therefore handle propositions that are vague and partially true.[86]\nNon-monotonic logics, including logic programming with negation as failure, are designed to handle default reasoning.[28] Other specialized versions of logic have been developed to describe many complex domains.\nProbabilistic methods for uncertain reasoning\nMany problems in AI (including reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods from probability theory and economics.[87] Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis,[88] and information value theory.[89] These tools include models such as Markov decision processes,[90] dynamic decision networks,[91] game theory and mechanism design.[92]\nBayesian networks[93] are a tool that can be used for reasoning (using the Bayesian inference algorithm),[g][95] learning (using the expectation–maximization algorithm),[h][97] planning (using decision networks)[98] and perception (using dynamic Bayesian networks).[91]\nProbabilistic algorithms can also be used for filtering, prediction, smoothing, and finding explanations for streams of data, thus helping perception systems analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).[91]\nClassifiers and statistical learning methods\nThe simplest AI applications can be divided into two types: classifiers (e.g., \"if shiny then diamond\"), on one hand, and controllers (e.g., \"if diamond then pick up\"), on the other hand. Classifiers[99] are functions that use pattern matching to determine the closest match. They can be fine-tuned based on chosen examples using supervised learning. Each pattern (also called an \"observation\") is labeled with a certain predefined class. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.[45]\nThere are many kinds of classifiers in use.[100] The decision tree is the simplest and most widely used symbolic machine learning algorithm.[101] K-nearest neighbor algorithm was the most widely used analogical AI until the mid-1990s, and Kernel methods such as the support vector machine (SVM) displaced k-nearest neighbor in the 1990s.[102] The naive Bayes classifier is reportedly the \"most widely used learner\"[103] at Google, due in part to its scalability.[104] Neural networks are also used as classifiers.[105]\nArtificial neural networks\nAn artificial neural network is based on a collection of nodes also known as artificial neurons, which loosely model the neurons in a biological brain. It is trained to recognise patterns; once trained, it can recognise those patterns in fresh data. There is an input, at least one hidden layer of nodes and an output. Each node applies a function and once the weight crosses its specified threshold, the data is transmitted to the next layer. A network is typically called a deep neural network if it has at least 2 hidden layers.[105]\nLearning algorithms for neural networks use local search to choose the weights that will get the right output for each input during training. The most common training technique is the backpropagation algorithm.[106] Neural networks learn to model complex relationships between inputs and outputs and find patterns in data. In theory, a neural network can learn any function.[107]\nIn feedforward neural networks the signal passes in only one direction.[108] The term perceptron typically refers to a single-layer neural network.[109] In contrast, deep learning uses many layers.[110] Recurrent neural networks (RNNs) feed the output signal back into the input, which allows short-term memories of previous input events. Long short-term memory networks (LSTMs) are recurrent neural networks that better preserve longterm dependencies and are less sensitive to the vanishing gradient problem.[111] Convolutional neural networks (CNNs) use layers of kernels to more efficiently process local patterns. This local processing is especially important in image processing, where the early CNN layers typically identify simple local patterns such as edges and curves, with subsequent layers detecting more complex patterns like textures, and eventually whole objects.[112]\nDeep learning\nDeep learning uses several layers of neurons between the network's inputs and outputs.[110] The multiple layers can progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits, letters, or faces.[114]\nDeep learning has profoundly improved the performance of programs in many important subfields of artificial intelligence, including computer vision, speech recognition, natural language processing, image classification,[115] and others. The reason that deep learning performs so well in so many applications is not known as of 2021.[116] The sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s)[i] but because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching to GPUs) and the availability of vast amounts of training data, especially the giant curated datasets used for benchmark testing, such as ImageNet.[j]\nGPT\nGenerative pre-trained transformers (GPT) are large language models (LLMs) that generate text based on the semantic relationships between words in sentences. Text-based GPT models are pre-trained on a large corpus of text that can be from the Internet. The pretraining consists of predicting the next token (a token being usually a word, subword, or punctuation). Throughout this pretraining, GPT models accumulate knowledge about the world and can then generate human-like text by repeatedly predicting the next token. Typically, a subsequent training phase makes the model more truthful, useful, and harmless, usually with a technique called reinforcement learning from human feedback (RLHF). Current GPT models are prone to generating falsehoods called \"hallucinations\". These can be reduced with RLHF and quality data, but the problem has been getting worse for reasoning systems.[124] Such systems are used in chatbots, which allow people to ask a question or request a task in simple text.[125][126]\nCurrent models and services include ChatGPT, Claude, Gemini, Copilot, and Meta AI.[127] Multimodal GPT models can process different types of data (modalities) such as images, videos, sound, and text.[128]\nHardware and software\nIn the late 2010s, graphics processing units (GPUs) that were increasingly designed with AI-specific enhancements and used with specialized TensorFlow software had replaced previously used central processing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine learning models' training.[129] Specialized programming languages such as Prolog were used in early AI research,[130] but general-purpose programming languages like Python have become predominant.[131]\nThe transistor density in integrated circuits has been observed to roughly double every 18 months—a trend known as Moore's law, named after the Intel co-founder Gordon Moore, who first identified it. Improvements in GPUs have been even faster,[132] a trend sometimes called Huang's law,[133] named after Nvidia co-founder and CEO Jensen Huang.\nApplications\nAI and machine learning technology is used in most of the essential applications of the 2020s, including: search engines (such as Google Search), targeting online advertisements, recommendation systems (offered by Netflix, YouTube or Amazon), driving internet traffic, targeted advertising (AdSense, Facebook), virtual assistants (such as Siri or Alexa), autonomous vehicles (including drones, ADAS and self-driving cars), automatic language translation (Microsoft Translator, Google Translate), facial recognition (Apple's FaceID or Microsoft's DeepFace and Google's FaceNet) and image labeling (used by Facebook, Apple's Photos and TikTok). The deployment of AI may be overseen by a chief automation officer (CAO).\nHealth and medicine\nThe application of AI in medicine and medical research has the potential to increase patient care and quality of life.[134] Through the lens of the Hippocratic Oath, medical professionals are ethically compelled to use AI, if applications can more accurately diagnose and treat patients.[135][136]\nFor medical research, AI is an important tool for processing and integrating big data. This is particularly important for organoid and tissue engineering development which use microscopy imaging as a key technique in fabrication.[137] It has been suggested that AI can overcome discrepancies in funding allocated to different fields of research.[137][138] New AI tools can deepen the understanding of biomedically relevant pathways. For example, AlphaFold 2 (2021) demonstrated the ability to approximate, in hours rather than months, the 3D structure of a protein.[139] In 2023, it was reported that AI-guided drug discovery helped find a class of antibiotics capable of killing two different types of drug-resistant bacteria.[140] In 2024, researchers used machine learning to accelerate the search for Parkinson's disease drug treatments. Their aim was to identify compounds that block the clumping, or aggregation, of alpha-synuclein (the protein that characterises Parkinson's disease). They were able to speed up the initial screening process ten-fold and reduce the cost by a thousand-fold.[141][142]\nGames\nGame playing programs have been used since the 1950s to demonstrate and test AI's most advanced techniques.[143] Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997.[144] In 2011, in a Jeopardy! quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin.[145] In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps. Then, in 2017, it defeated Ke Jie, who was the best Go player in the world.[146] Other programs handle imperfect-information games, such as the poker-playing program Pluribus.[147] DeepMind developed increasingly generalistic reinforcement learning models, such as with MuZero, which could be trained to play chess, Go, or Atari games.[148] In 2019, DeepMind's AlphaStar achieved grandmaster level in StarCraft II, a particularly challenging real-time strategy game that involves incomplete knowledge of what happens on the map.[149] In 2021, an AI agent competed in a PlayStation Gran Turismo competition, winning against four of the world's best Gran Turismo drivers using deep reinforcement learning.[150] In 2024, Google DeepMind introduced SIMA, a type of AI capable of autonomously playing nine previously unseen open-world video games by observing screen output, as well as executing short, specific tasks in response to natural language instructions.[151]\nMathematics\nLarge language models, such as GPT-4, Gemini, Claude, Llama or Mistral, are increasingly used in mathematics. These probabilistic models are versatile, but can also produce wrong answers in the form of hallucinations. They sometimes need a large database of mathematical problems to learn from, but also methods such as supervised fine-tuning[152] or trained classifiers with human-annotated data to improve answers for new problems and learn from corrections.[153] A February 2024 study showed that the performance of some language models for reasoning capabilities in solving math problems not included in their training data was low, even for problems with only minor deviations from trained data.[154] One technique to improve their performance involves training the models to produce correct reasoning steps, rather than just the correct result.[155] The Alibaba Group developed a version of its Qwen models called Qwen2-Math, that achieved state-of-the-art performance on several mathematical benchmarks, including 84% accuracy on the MATH dataset of competition mathematics problems.[156] In January 2025, Microsoft proposed the technique rStar-Math that leverages Monte Carlo tree search and step-by-step reasoning, enabling a relatively small language model like Qwen-7B to solve 53% of the AIME 2024 and 90% of the MATH benchmark problems.[157]\nAlternatively, dedicated models for mathematical problem solving with higher precision for the outcome including proof of theorems have been developed such as AlphaTensor, AlphaGeometry, AlphaProof and AlphaEvolve[158] all from Google DeepMind,[159] Llemma from EleutherAI[160] or Julius.[161]\nWhen natural language is used to describe mathematical problems, converters can transform such prompts into a formal language such as Lean to define mathematical tasks. The experimental model Gemini Deep Think accepts natural language prompts directly and achieved gold medal results in the International Math Olympiad of 2025.[162]\nSome models have been developed to solve challenging problems and reach good results in benchmark tests, others to serve as educational tools in mathematics.[163]\nTopological deep learning integrates various topological approaches.\nFinance\nFinance is one of the fastest growing sectors where applied AI tools are being deployed: from retail online banking to investment advice and insurance, where automated \"robot advisers\" have been in use for some years.[164]\nAccording to Nicolas Firzli, director of the World Pensions & Investments Forum, it may be too early to see the emergence of highly innovative AI-informed financial products and services. He argues that \"the deployment of AI tools will simply further automatise things: destroying tens of thousands of jobs in banking, financial planning, and pension advice in the process, but I'm not sure it will unleash a new wave of [e.g., sophisticated] pension innovation.\"[165]\nMilitary\nVarious countries are deploying AI military applications.[166] The main applications enhance command and control, communications, sensors, integration and interoperability.[167] Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles.[166] AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition, coordination and deconfliction of distributed Joint Fires between networked combat vehicles, both human-operated and autonomous.[167]\nAI has been used in military operations in Iraq, Syria, Israel and Ukraine.[166][168][169][170]\nGenerative AI\nGenerative artificial intelligence (Generative AI, GenAI,[171] or GAI) is a subfield of artificial intelligence that uses generative models to produce text, images, videos, audio, software code or other forms of data.[172][173] These models learn the underlying patterns and structures of their training data and use them to produce new data[174][175] based on the input, which often comes in the form of natural language prompts.[176][177]\nGenerative AI tools have become more common since the AI boom in the 2020s. This boom was made possible by improvements in transformer-based deep neural networks, particularly large language models (LLMs). Major tools include chatbots such as ChatGPT, Copilot, Gemini, Claude, Grok, and DeepSeek; text-to-image models such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video models such as Veo and Sora.[178][179][180] Technology companies developing generative AI include OpenAI, xAI, Anthropic, Meta AI, Microsoft, Google, Mistral AI, DeepSeek, Baidu[181] and Yandex.[182]\nGenerative AI is used across many industries, including software development,[183] healthcare,[184] finance,[185] entertainment,[186] customer service,[187] sales and marketing,[188] art, writing,[189] fashion,[190] and product design.[191] The production of generative AI systems requires large scale data centers using specialized chips which require a lot of electricity for processing and water for cooling.[192]Agents\nAI agents are software entities designed to perceive their environment, make decisions, and take actions autonomously to achieve specific goals. These agents can interact with users, their environment, or other agents. AI agents are used in various applications, including virtual assistants, chatbots, autonomous vehicles, game-playing systems, and industrial robotics. AI agents operate within the constraints of their programming, available computational resources, and hardware limitations. This means they are restricted to performing tasks within their defined scope and have finite memory and processing capabilities. In real-world applications, AI agents often face time constraints for decision-making and action execution. Many AI agents incorporate learning algorithms, enabling them to improve their performance over time through experience or training. Using machine learning, AI agents can adapt to new situations and optimise their behaviour for their designated tasks.[193][194][195]\nWeb search\nMicrosoft introduced Copilot Search in February 2023 under the name Bing Chat, as a built-in feature for Microsoft Edge and Bing mobile app. Copilot Search provides AI-generated summaries[196] and step-by-step reasoning based of information from web publishers, ranked in Bing Search.[197] For safety, Copilot uses AI-based classifiers and filters to reduce potentially harmful content.[198]\nGoogle officially pushed its AI Search at its Google I/O event on 20 May 2025.[199] It keeps people looking at Google instead of clicking on a search result. AI Overviews uses Gemini 2.5 to provide contextual answers to user queries based on web content.[200]\nSexuality\nApplications of AI in this domain include AI-enabled menstruation and fertility trackers that analyze user data to offer predictions,[201] AI-integrated sex toys (e.g., teledildonics),[202] AI-generated sexual education content,[203] and AI agents that simulate sexual and romantic partners (e.g., Replika).[204] AI is also used for the production of non-consensual deepfake pornography, raising significant ethical and legal concerns.[205]\nAI technologies have also been used to attempt to identify online gender-based violence and online sexual grooming of minors.[206][207]\nOther industry-specific tasks\nThere are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported having incorporated \"AI\" in some offerings or processes.[208] A few examples are energy storage, medical diagnosis, military logistics, applications that predict the result of judicial decisions, foreign policy, or supply chain management.\nAI applications for evacuation and disaster management are growing. AI has been used to investigate patterns in large-scale and small-scale evacuations using historical data from GPS, videos or social media. Furthermore, AI can provide real-time information on the evacuation conditions.[209][210][211]\nIn agriculture, AI has helped farmers to increase yield and identify areas that need irrigation, fertilization, pesticide treatments. Agronomists use AI to conduct research and development. AI has been used to predict the ripening time for crops such as tomatoes, monitor soil moisture, operate agricultural robots, conduct predictive analytics, classify livestock pig call emotions, automate greenhouses, detect diseases and pests, and save water.\nArtificial intelligence is used in astronomy to analyze increasing amounts of available data and applications, mainly for \"classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights.\" For example, it is used for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy. Additionally, it could be used for activities in space, such as space exploration, including the analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance, and more autonomous operation.\nDuring the 2024 Indian elections, US$50 million was spent on authorized AI-generated content, notably by creating deepfakes of allied (including sometimes deceased) politicians to better engage with voters, and by translating speeches to various local languages.[212]\nEthics\nAI has potential benefits and potential risks.[215] AI may be able to advance science and find solutions for serious problems: Demis Hassabis of DeepMind hopes to \"solve intelligence, and then use that to solve everything else\".[216] However, as the use of AI has become widespread, several unintended consequences and risks have been identified.[217][218] In-production systems can sometimes not factor ethics and bias into their AI training processes, especially when the AI algorithms are inherently unexplainable in deep learning.[219]\nRisks and harm\nPrivacy and copyright\nMachine learning algorithms require large amounts of data. The techniques used to acquire this data have raised concerns about privacy, surveillance and copyright.\nAI-powered devices and services, such as virtual assistants and IoT products, continuously collect personal information, raising concerns about intrusive data gathering and unauthorized access by third parties. The loss of privacy is further exacerbated by AI's ability to process and combine vast amounts of data, potentially leading to a surveillance society where individual activities are constantly monitored and analyzed without adequate safeguards or transparency.\nSensitive user data collected may include online activity records, geolocation data, video, or audio.[220] For example, in order to build speech recognition algorithms, Amazon has recorded millions of private conversations and allowed temporary workers to listen to and transcribe some of them.[221] Opinions about this widespread surveillance range from those who see it as a necessary evil to those for whom it is clearly unethical and a violation of the right to privacy.[222]\nAI developers argue that this is the only way to deliver valuable applications and have developed several techniques that attempt to preserve privacy while still obtaining the data, such as data aggregation, de-identification and differential privacy.[223] Since 2016, some privacy experts, such as Cynthia Dwork, have begun to view privacy in terms of fairness. Brian Christian wrote that experts have pivoted \"from the question of 'what they know' to the question of 'what they're doing with it'.\"[224]\nGenerative AI is often trained on unlicensed copyrighted works, including in domains such as images or computer code; the output is then used under the rationale of \"fair use\". Experts disagree about how well and under what circumstances this rationale will hold up in courts of law; relevant factors may include \"the purpose and character of the use of the copyrighted work\" and \"the effect upon the potential market for the copyrighted work\".[225][226] Website owners can indicate that they do not want their content scraped via a \"robots.txt\" file.[227] However, some companies will scrape content regardless[228][229] because the robots.txt file has no real authority. In 2023, leading authors (including John Grisham and Jonathan Franzen) sued AI companies for using their work to train generative AI.[230][231] Another discussed approach is to envision a separate sui generis system of protection for creations generated by AI to ensure fair attribution and compensation for human authors.[232]\nDominance by tech giants\nThe commercial AI scene is dominated by Big Tech companies such as Alphabet Inc., Amazon, Apple Inc., Meta Platforms, and Microsoft.[233][234][235] Some of these players already own the vast majority of existing cloud infrastructure and computing power from data centers, allowing them to entrench further in the marketplace.[236][237]\nPower needs and environmental impacts\nIn January 2024, the International Energy Agency (IEA) released Electricity 2024, Analysis and Forecast to 2026, forecasting electric power use.[238] This is the first IEA report to make projections for data centers and power consumption for artificial intelligence and cryptocurrency. The report states that power demand for these uses might double by 2026, with additional electric power usage equal to electricity used by the whole Japanese nation.[239]\nProdigious power consumption by AI is responsible for the growth of fossil fuel use, and might delay closings of obsolete, carbon-emitting coal energy facilities. There is a feverish rise in the construction of data centers throughout the US, making large technology firms (e.g., Microsoft, Meta, Google, Amazon) into voracious consumers of electric power. Projected electric consumption is so immense that there is concern that it will be fulfilled no matter the source. A ChatGPT search involves the use of 10 times the electrical energy as a Google search. The large firms are in haste to find power sources – from nuclear energy to geothermal to fusion. The tech firms argue that – in the long view – AI will be eventually kinder to the environment, but they need the energy now. AI makes the power grid more efficient and \"intelligent\", will assist in the growth of nuclear power, and track overall carbon emissions, according to technology firms.[240]\nA 2024 Goldman Sachs Research Paper, AI Data Centers and the Coming US Power Demand Surge, found \"US power demand (is) likely to experience growth not seen in a generation....\" and forecasts that, by 2030, US data centers will consume 8% of US power, as opposed to 3% in 2022, presaging growth for the electrical power generation industry by a variety of means.[241] Data centers' need for more and more electrical power is such that they might max out the electrical grid. The Big Tech companies counter that AI can be used to maximize the utilization of the grid by all.[242]\nIn 2024, the Wall Street Journal reported that big AI companies have begun negotiations with the US nuclear power providers to provide electricity to the data centers. In March 2024 Amazon purchased a Pennsylvania nuclear-powered data center for US$650 million.[243] Nvidia CEO Jensen Huang said nuclear power is a good option for the data centers.[244]\nIn September 2024, Microsoft announced an agreement with Constellation Energy to re-open the Three Mile Island nuclear power plant to provide Microsoft with 100% of all electric power produced by the plant for 20 years. Reopening the plant, which suffered a partial nuclear meltdown of its Unit 2 reactor in 1979, will require Constellation to get through strict regulatory processes which will include extensive safety scrutiny from the US Nuclear Regulatory Commission. If approved (this will be the first ever US re-commissioning of a nuclear plant), over 835 megawatts of power – enough for 800,000 homes – of energy will be produced. The cost for re-opening and upgrading is estimated at US$1.6 billion and is dependent on tax breaks for nuclear power contained in the 2022 US Inflation Reduction Act.[245] The US government and the state of Michigan are investing almost US$2 billion to reopen the Palisades Nuclear reactor on Lake Michigan. Closed since 2022, the plant is planned to be reopened in October 2025. The Three Mile Island facility will be renamed the Crane Clean Energy Center after Chris Crane, a nuclear proponent and former CEO of Exelon who was responsible for Exelon's spinoff of Constellation.[246]\nAfter the last approval in September 2023, Taiwan suspended the approval of data centers north of Taoyuan with a capacity of more than 5 MW in 2024, due to power supply shortages.[247] Taiwan aims to phase out nuclear power by 2025.[247] On the other hand, Singapore imposed a ban on the opening of data centers in 2019 due to electric power, but in 2022, lifted this ban.[247]\nAlthough most nuclear plants in Japan have been shut down after the 2011 Fukushima nuclear accident, according to an October 2024 Bloomberg article in Japanese, cloud gaming services company Ubitus, in which Nvidia has a stake, is looking for land in Japan near a nuclear power plant for a new data center for generative AI.[248] Ubitus CEO Wesley Kuo said nuclear power plants are the most efficient, cheap and stable power for AI.[248]\nOn 1 November 2024, the Federal Energy Regulatory Commission (FERC) rejected an application submitted by Talen Energy for approval to supply some electricity from the nuclear power station Susquehanna to Amazon's data center.[249] According to the Commission Chairman Willie L. Phillips, it is a burden on the electricity grid as well as a significant cost shifting concern to households and other business sectors.[249]\nIn 2025, a report prepared by the International Energy Agency estimated the greenhouse gas emissions from the energy consumption of AI at 180 million tons. By 2035, these emissions could rise to 300–500 million tonnes depending on what measures will be taken. This is below 1.5% of the energy sector emissions. The emissions reduction potential of AI was estimated at 5% of the energy sector emissions, but rebound effects (for example if people switch from public transport to autonomous cars) can reduce it.[250]\nMisinformation\nYouTube, Facebook and others use recommender systems to guide users to more content. These AI programs were given the goal of maximizing user engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choose misinformation, conspiracy theories, and extreme partisan content, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people into filter bubbles where they received multiple versions of the same misinformation.[251] This convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government.[252] The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took some steps to mitigate the problem.[253]\nIn the early 2020s, generative AI began to create images, audio, and texts that are virtually indistinguishable from real photographs, recordings, or human writing,[254] while realistic AI-generated videos became feasible in the mid-2020s.[255][256][257] It is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda;[258] one such potential malicious use is deepfakes for computational propaganda.[259] AI pioneer Geoffrey Hinton expressed concern about AI enabling \"authoritarian leaders to manipulate their electorates\" on a large scale, among other risks.[260]\nAI researchers at Microsoft, OpenAI, universities and other organisations have suggested using \"personhood credentials\" as a way to overcome online deception enabled by AI models.[261]\nAlgorithmic bias and fairness\nMachine learning applications can be biased[k] if they learn from biased data.[263] The developers may not be aware that the bias exists.[264] Discriminatory behavior by some LLMs can be observed in their output.[265] Bias can be introduced by the way training data is selected and by the way a model is deployed.[266][263] If a biased algorithm is used to make decisions that can seriously harm people (as it can in medicine, finance, recruitment, housing or policing) then the algorithm may cause discrimination.[267] The field of fairness studies how to prevent harms from algorithmic biases.\nOn 28 June 2015, Google Photos's new image labeling feature mistakenly identified Jacky Alcine and a friend as \"gorillas\" because they were black. The system was trained on a dataset that contained very few images of black people,[268] a problem called \"sample size disparity\".[269] Google \"fixed\" this problem by preventing the system from labelling anything as a \"gorilla\". Eight years later, in 2023, Google Photos still could not identify a gorilla, and neither could similar products from Apple, Facebook, Microsoft and Amazon.[270]\nCOMPAS is a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist. In 2016, Julia Angwin at ProPublica discovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61%, the errors for each race were different—the system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend.[271] In 2017, several researchers[l] showed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data.[273]\nA program can make biased decisions even if the data does not explicitly mention a problematic feature (such as \"race\" or \"gender\"). The feature will correlate with other features (like \"address\", \"shopping history\" or \"first name\"), and the program will make the same decisions based on these features as it would on \"race\" or \"gender\".[274] Moritz Hardt said \"the most robust fact in this research area is that fairness through blindness doesn't work.\"[275]\nCriticism of COMPAS highlighted that machine learning models are designed to make \"predictions\" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. If an application then uses these predictions as recommendations, some of these \"recommendations\" will likely be racist.[276] Thus, machine learning is not well suited to help make decisions in areas where there is hope that the future will be better than the past. It is descriptive rather than prescriptive.[m]\nBias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4% are black and 20% are women.[269]\nThere are various conflicting definitions and mathematical models of fairness. These notions depend on ethical assumptions, and are influenced by beliefs about society. One broad category is distributive fairness, which focuses on the outcomes, often identifying groups and seeking to compensate for statistical disparities. Representational fairness tries to ensure that AI systems do not reinforce negative stereotypes or render certain groups invisible. Procedural fairness focuses on the decision process rather than the outcome. The most relevant notions of fairness may depend on the context, notably the type of AI application and the stakeholders. The subjectivity in the notions of bias and fairness makes it difficult for companies to operationalize them. Having access to sensitive attributes such as race or gender is also considered by many AI ethicists to be necessary in order to compensate for biases, but it may conflict with anti-discrimination laws.[262]\nAt its 2022 Conference on Fairness, Accountability, and Transparency (ACM FAccT 2022), the Association for Computing Machinery, in Seoul, South Korea, presented and published findings that recommend that until AI and robotics systems are demonstrated to be free of bias mistakes, they are unsafe, and the use of self-learning neural networks trained on vast, unregulated sources of flawed internet data should be curtailed.[dubious – discuss][278]\nLack of transparency\nMany AI systems are so complex that their designers cannot explain how they reach their decisions.[279] Particularly with deep neural networks, in which there are many non-linear relationships between inputs and outputs. But some popular explainability techniques exist.[280]\nIt is impossible to be certain that a program is operating correctly if no one knows how exactly it works. There have been many cases where a machine learning program passed rigorous tests, but nevertheless learned something different than what the programmers intended. For example, a system that could identify skin diseases better than medical professionals was found to actually have a strong tendency to classify images with a ruler as \"cancerous\", because pictures of malignancies typically include a ruler to show the scale.[281] Another machine learning system designed to help effectively allocate medical resources was found to classify patients with asthma as being at \"low risk\" of dying from pneumonia. Having asthma is actually a severe risk factor, but since the patients having asthma would usually get much more medical care, they were relatively unlikely to die according to the training data. The correlation between asthma and low risk of dying from pneumonia was real, but misleading.[282]\nPeople who have been harmed by an algorithm's decision have a right to an explanation.[283] Doctors, for example, are expected to clearly and completely explain to their colleagues the reasoning behind any decision they make. Early drafts of the European Union's General Data Protection Regulation in 2016 included an explicit statement that this right exists.[n] Industry experts noted that this is an unsolved problem with no solution in sight. Regulators argued that nevertheless the harm is real: if the problem has no solution, the tools should not be used.[284]\nDARPA established the XAI (\"Explainable Artificial Intelligence\") program in 2014 to try to solve these problems.[285]\nSeveral approaches aim to address the transparency problem. SHAP enables to visualise the contribution of each feature to the output.[286] LIME can locally approximate a model's outputs with a simpler, interpretable model.[287] Multitask learning provides a large number of outputs in addition to the target classification. These other outputs can help developers deduce what the network has learned.[288] Deconvolution, DeepDream and other generative methods can allow developers to see what different layers of a deep network for computer vision have learned, and produce output that can suggest what the network is learning.[289] For generative pre-trained transformers, Anthropic developed a technique based on dictionary learning that associates patterns of neuron activations with human-understandable concepts.[290]\nBad actors and weaponized AI\nArtificial intelligence provides a number of tools that are useful to bad actors, such as authoritarian governments, terrorists, criminals or rogue states.\nA lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision.[o] Widely available AI tools can be used by bad actors to develop inexpensive autonomous weapons and, if produced at scale, they are potentially weapons of mass destruction.[292] Even when used in conventional warfare, they currently cannot reliably choose targets and could potentially kill an innocent person.[292] In 2014, 30 nations (including China) supported a ban on autonomous weapons under the United Nations' Convention on Certain Conventional Weapons, however the United States and others disagreed.[293] By 2015, over fifty countries were reported to be researching battlefield robots.[294]\nAI tools make it easier for authoritarian governments to efficiently control their citizens in several ways. Face and voice recognition allow widespread surveillance. Machine learning, operating this data, can classify potential enemies of the state and prevent them from hiding. Recommendation systems can precisely target propaganda and misinformation for maximum effect. Deepfakes and generative AI aid in producing misinformation. Advanced AI can make authoritarian centralized decision-making more competitive than liberal and decentralized systems such as markets. It lowers the cost and difficulty of digital warfare and advanced spyware.[295] All these technologies have been available since 2020 or earlier—AI facial recognition systems are already being used for mass surveillance in China.[296][297]\nThere are many other ways in which AI is expected to help bad actors, some of which can not be foreseen. For example, machine-learning AI is able to design tens of thousands of toxic molecules in a matter of hours.[298]\nTechnological unemployment\nEconomists have frequently highlighted the risks of redundancies from AI, and speculated about unemployment if there is no adequate social policy for full employment.[299]\nIn the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that \"we're in uncharted territory\" with AI.[300] A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit if productivity gains are redistributed.[301] Risk estimates vary; for example, in the 2010s, Michael Osborne and Carl Benedikt Frey estimated 47% of U.S. jobs are at \"high risk\" of potential automation, while an OECD report classified only 9% of U.S. jobs as \"high risk\".[p][303] The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology, rather than social policy, creates unemployment, as opposed to redundancies.[299] In April 2023, it was reported that 70% of the jobs for Chinese video game illustrators had been eliminated by generative artificial intelligence.[304][305]\nUnlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist stated in 2015 that \"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\" is \"worth taking seriously\".[306] Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.[307] In July 2025, Ford CEO Jim Farley predicted that \"artificial intelligence is going to replace literally half of all white-collar workers in the U.S.\"[308]\nFrom the early days of the development of artificial intelligence, there have been arguments, for example, those put forward by Joseph Weizenbaum, about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculation and qualitative, value-based judgement.[309]\nExistential risk\nIt has been argued AI will become so powerful that humanity may irreversibly lose control of it. This could, as physicist Stephen Hawking stated, \"spell the end of the human race\".[310] This scenario has been common in science fiction, when a computer or robot suddenly develops a human-like \"self-awareness\" (or \"sentience\" or \"consciousness\") and becomes a malevolent character.[q] These sci-fi scenarios are misleading in several ways.\nFirst, AI does not require human-like sentience to be an existential risk. Modern AI programs are given specific goals and use learning and intelligence to achieve them. Philosopher Nick Bostrom argued that if one gives almost any goal to a sufficiently powerful AI, it may choose to destroy humanity to achieve it (he used the example of an automated paperclip factory that destroys the world to get more iron for paperclips).[312] Stuart Russell gives the example of household robot that tries to find a way to kill its owner to prevent it from being unplugged, reasoning that \"you can't fetch the coffee if you're dead.\"[313] In order to be safe for humanity, a superintelligence would have to be genuinely aligned with humanity's morality and values so that it is \"fundamentally on our side\".[314]\nSecond, Yuval Noah Harari argues that AI does not require a robot body or physical control to pose an existential risk. The essential parts of civilization are not physical. Things like ideologies, law, government, money and the economy are built on language; they exist because there are stories that billions of people believe. The current prevalence of misinformation suggests that an AI could use language to convince people to believe anything, even to take actions that are destructive.[315] Geoffrey Hinton said in 2025 that modern AI is particularly \"good at persuasion\" and getting better all the time. He asks \"Suppose you wanted to invade the capital of the US. Do you have to go there and do it yourself? No. You just have to be good at persuasion.\"[316]\nThe opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI.[317] Personalities such as Stephen Hawking, Bill Gates, and Elon Musk,[318] as well as AI pioneers such as Yoshua Bengio, Stuart Russell, Demis Hassabis, and Sam Altman, have expressed concerns about existential risk from AI.\nIn May 2023, Geoffrey Hinton announced his resignation from Google in order to be able to \"freely speak out about the risks of AI\" without \"considering how this impacts Google\".[319] He notably mentioned risks of an AI takeover,[320] and stressed that in order to avoid the worst outcomes, establishing safety guidelines will require cooperation among those competing in use of AI.[321]\nIn 2023, many leading AI experts endorsed the joint statement that \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\".[322]\nSome other researchers were more optimistic. AI pioneer Jürgen Schmidhuber did not sign the joint statement, emphasising that in 95% of all cases, AI research is about making \"human lives longer and healthier and easier.\"[323] While the tools that are now being used to improve lives can also be used by bad actors, \"they can also be used against the bad actors.\"[324][325] Andrew Ng also argued that \"it's a mistake to fall for the doomsday hype on AI—and that regulators who do will only benefit vested interests.\"[326] Yann LeCun \"scoffs at his peers' dystopian scenarios of supercharged misinformation and even, eventually, human extinction.\"[327] In the early 2010s, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine.[328] However, after 2016, the study of current and future risks and possible solutions became a serious area of research.[329]\nEthical machines and alignment\nFriendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk.[330]\nMachines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.[331] The field of machine ethics is also called computational morality,[331] and was founded at an AAAI symposium in 2005.[332]\nOther approaches include Wendell Wallach's \"artificial moral agents\"[333] and Stuart J. Russell's three principles for developing provably beneficial machines.[334]\nOpen source\nActive organizations in the AI open-source community include Hugging Face,[335] Google,[336] EleutherAI and Meta.[337] Various AI models, such as Llama 2, Mistral or Stable Diffusion, have been made open-weight,[338][339] meaning that their architecture and trained parameters (the \"weights\") are publicly available. Open-weight models can be freely fine-tuned, which allows companies to specialize them with their own data and for their own use-case.[340] Open-weight models are useful for research and innovation but can also be misused. Since they can be fine-tuned, any built-in security measure, such as objecting to harmful requests, can be trained away until it becomes ineffective. Some researchers warn that future AI models may develop dangerous capabilities (such as the potential to drastically facilitate bioterrorism) and that once released on the Internet, they cannot be deleted everywhere if needed. They recommend pre-release audits and cost-benefit analyses.[341]\nFrameworks\nArtificial intelligence projects can be guided by ethical considerations during the design, development, and implementation of an AI system. An AI framework such as the Care and Act Framework, developed by the Alan Turing Institute and based on the SUM values, outlines four main ethical dimensions, defined as follows:[342][343]\n- Respect the dignity of individual people\n- Connect with other people sincerely, openly, and inclusively\n- Care for the wellbeing of everyone\n- Protect social values, justice, and the public interest\nOther developments in ethical frameworks include those decided upon during the Asilomar Conference, the Montreal Declaration for Responsible AI, and the IEEE's Ethics of Autonomous Systems initiative, among others;[344] however, these principles are not without criticism, especially regarding the people chosen to contribute to these frameworks.[345]\nPromotion of the wellbeing of the people and communities that these technologies affect requires consideration of the social and ethical implications at all stages of AI system design, development and implementation, and collaboration between job roles such as data scientists, product managers, data engineers, domain experts, and delivery managers.[346]\nThe UK AI Safety Institute released in 2024 a testing toolset called 'Inspect' for AI safety evaluations available under an MIT open-source licence which is freely available on GitHub and can be improved with third-party packages. It can be used to evaluate AI models in a range of areas including core knowledge, ability to reason, and autonomous capabilities.[347]\nRegulation\nThe regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating AI; it is therefore related to the broader regulation of algorithms.[348] The regulatory and policy landscape for AI is an emerging issue in jurisdictions globally.[349] According to AI Index at Stanford, the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone.[350][351] Between 2016 and 2020, more than 30 countries adopted dedicated strategies for AI.[352] Most EU member states had released national AI strategies, as had Canada, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, U.S., and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia.[352] The Global Partnership on Artificial Intelligence was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology.[352] Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher published a joint statement in November 2021 calling for a government commission to regulate AI.[353] In 2023, OpenAI leaders published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years.[354] In 2023, the United Nations also launched an advisory body to provide recommendations on AI governance; the body comprises technology company executives, government officials and academics.[355] On 1 August 2024, the EU Artificial Intelligence Act entered into force, establishing the first comprehensive EU-wide AI regulation.[356] In 2024, the Council of Europe created the first international legally binding treaty on AI, called the \"Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law\". It was adopted by the European Union, the United States, the United Kingdom, and other signatories.[357]\nIn a 2022 Ipsos survey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that \"products and services using AI have more benefits than drawbacks\".[350] A 2023 Reuters/Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity.[358] In a 2023 Fox News poll, 35% of Americans thought it \"very important\", and an additional 41% thought it \"somewhat important\", for the federal government to regulate AI, versus 13% responding \"not very important\" and 8% responding \"not at all important\".[359][360]\nIn November 2023, the first global AI Safety Summit was held in Bletchley Park in the UK to discuss the near and far term risks of AI and the possibility of mandatory and voluntary regulatory frameworks.[361] 28 countries including the United States, China, and the European Union issued a declaration at the start of the summit, calling for international co-operation to manage the challenges and risks of artificial intelligence.[362][363] In May 2024 at the AI Seoul Summit, 16 global AI tech companies agreed to safety commitments on the development of AI.[364][365]\nHistory\nThe study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity.\nThe initial idea of logic (both in pre-Socratic logic[367][368] and in Aristotelian logic) was based on substituting \"correct speech\" with an implicit (or explicit) apparatus of codified rules. Therefore, from a philosophical perspective, the fundamental idea of logic can be considered an instance of agent-independent intelligence (at least in some aspects at runtime, and based on concept of formality).[369][370]\nRumi, in the 13th century CE, states: \"The Masnavi will become a teacher after me and will guide seekers\".[371][372] This statement clearly expresses a philosophical idea similar to the concept of \"intelligent twins independent of the original system\".\nThe study of logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate any conceivable form of mathematical reasoning.[373][374] This, along with concurrent discoveries in cybernetics, information theory and neurobiology, led researchers to consider the possibility of building an \"electronic brain\".[r] They developed several areas of research that would become part of AI,[376] such as McCulloch and Pitts design for \"artificial neurons\" in 1943,[117] and Turing's influential 1950 paper 'Computing Machinery and Intelligence', which introduced the Turing test and showed that \"machine intelligence\" was plausible.[377][374]\nThe field of AI research was founded at a workshop at Dartmouth College in 1956.[s][6] The attendees became the leaders of AI research in the 1960s.[t] They and their students produced programs that the press described as \"astonishing\":[u] computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English.[v][7] Artificial intelligence laboratories were set up at a number of British and U.S. universities in the latter 1950s and early 1960s.[374]\nResearchers in the 1960s and the 1970s were convinced that their methods would eventually succeed in creating a machine with general intelligence and considered this the goal of their field.[381] In 1965 Herbert Simon predicted, \"machines will be capable, within twenty years, of doing any work a man can do\".[382] In 1967 Marvin Minsky agreed, writing that \"within a generation ... the problem of creating 'artificial intelligence' will substantially be solved\".[383] They had, however, underestimated the difficulty of the problem.[w] In 1974, both the U.S. and British governments cut off exploratory research in response to the criticism of Sir James Lighthill[385] and ongoing pressure from the U.S. Congress to fund more productive projects.[386] Minsky and Papert's book Perceptrons was understood as proving that artificial neural networks would never be useful for solving real-world tasks, thus discrediting the approach altogether.[387] The \"AI winter\", a period when obtaining funding for AI projects was difficult, followed.[9]\nIn the early 1980s, AI research was revived by the commercial success of expert systems,[388] a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S. and British governments to restore funding for academic research.[8] However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.[10]\nUp to this point, most of AI's funding had gone to projects that used high-level symbols to represent mental objects like plans, goals, beliefs, and known facts. In the 1980s, some researchers began to doubt that this approach would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition,[389] and began to look into \"sub-symbolic\" approaches.[390] Rodney Brooks rejected \"representation\" in general and focussed directly on engineering machines that move and survive.[x] Judea Pearl, Lotfi Zadeh, and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic.[87][395] But the most important development was the revival of \"connectionism\", including neural network research, by Geoffrey Hinton and others.[396] In 1990, Yann LeCun successfully showed that convolutional neural networks can recognize handwritten digits, the first of many successful applications of neural networks.[397]\nAI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This \"narrow\" and \"formal\" focus allowed researchers to produce verifiable results and collaborate with other fields (such as statistics, economics and mathematics).[398] By 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \"artificial intelligence\" (a tendency known as the AI effect).[399] However, several academic researchers became concerned that AI was no longer pursuing its original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield of artificial general intelligence (or \"AGI\"), which had several well-funded institutions by the 2010s.[68]\nDeep learning began to dominate industry benchmarks in 2012 and was adopted throughout the field.[11] For many specific tasks, other methods were abandoned.[y] Deep learning's success was based on both hardware improvements (faster computers,[401] graphics processing units, cloud computing[402]) and access to large amounts of data[403] (including curated datasets,[402] such as ImageNet). Deep learning's success led to an enormous increase in interest and funding in AI.[z] The amount of machine learning research (measured by total publications) increased by 50% in the years 2015–2019.[352]\nIn 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The alignment problem became a serious field of academic study.[329]\nIn the late 2010s and early 2020s, AGI companies began to deliver programs that created enormous interest. In 2015, AlphaGo, developed by DeepMind, beat the world champion Go player. The program taught only the game's rules and developed a strategy by itself. GPT-3 is a large language model that was released in 2020 by OpenAI and is capable of generating high-quality human-like text.[404] ChatGPT, launched on 30 November 2022, became the fastest-growing consumer software application in history, gaining over 100 million users in two months.[405] It marked what is widely regarded as AI's breakout year, bringing it into the public consciousness.[406] These programs, and others, inspired an aggressive AI boom, where large companies began investing billions of dollars in AI research. According to AI Impacts, about US$50 billion annually was invested in \"AI\" around 2022 in the U.S. alone and about 20% of the new U.S. Computer Science PhD graduates have specialized in \"AI\".[407] About 800,000 \"AI\"-related U.S. job openings existed in 2022.[408] According to PitchBook research, 22% of newly funded startups in 2024 claimed to be AI companies.[409]\nPhilosophy\nPhilosophical debates have historically sought to determine the nature of intelligence and how to make intelligent machines.[410] Another major focus has been whether machines can be conscious, and the associated ethical implications.[411] Many other topics in philosophy are relevant to AI, such as epistemology and free will.[412] Rapid advancements have intensified public discussions on the philosophy and ethics of AI.[411]\nDefining artificial intelligence\nAlan Turing wrote in 1950 \"I propose to consider the question 'can machines think'?\"[413] He advised changing the question from whether a machine \"thinks\", to \"whether or not it is possible for machinery to show intelligent behaviour\".[413] He devised the Turing test, which measures the ability of a machine to simulate human conversation.[377] Since we can only observe the behavior of the machine, it does not matter if it is \"actually\" thinking or literally has a \"mind\". Turing notes that we can not determine these things about other people but \"it is usual to have a polite convention that everyone thinks.\"[414]\nRussell and Norvig agree with Turing that intelligence must be defined in terms of external behavior, not internal structure.[1] However, they are critical that the test requires the machine to imitate humans. \"Aeronautical engineering texts\", they wrote, \"do not define the goal of their field as making 'machines that fly so exactly like pigeons that they can fool other pigeons.'\"[416] AI founder John McCarthy agreed, writing that \"Artificial intelligence is not, by definition, simulation of human intelligence\".[417]\nMcCarthy defines intelligence as \"the computational part of the ability to achieve goals in the world\".[418] Another AI founder, Marvin Minsky, similarly describes it as \"the ability to solve hard problems\".[419] The leading AI textbook defines it as the study of agents that perceive their environment and take actions that maximize their chances of achieving defined goals.[1] These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the \"intelligence\" of the machine—and no other philosophical discussion is required, or may not even be possible.\nAnother definition has been adopted by Google,[420] a major practitioner in the field of AI. This definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence.\nAs a result of the many circulating definitions scholars have started to critically analyze and order the AI discourse itself[421] including discussing the many AI narratives and myths to be found within societal, political and academic discourses.[422] Similarly, in practice, some authors have suggested that the term 'AI' is often used too broadly and vaguely. This raises the question of where the line should be drawn between AI and classical algorithms,[423] with many companies during the early 2020s AI boom using the term as a marketing buzzword, often even if they did \"not actually use AI in a material way\".[424]\nThere has been debate over whether large language models exhibit genuine intelligence or merely simulate it by imitating human text.[425]\nEvaluating approaches to AI\nNo established unifying theory or paradigm has guided AI research for most of its history.[aa] The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \"artificial intelligence\" to mean \"machine learning with neural networks\"). This approach is mostly sub-symbolic, soft and narrow. Critics argue that these questions may have to be revisited by future generations of AI researchers.\nSymbolic AI and its limits\nSymbolic AI (or \"GOFAI\")[427] simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at \"intelligent\" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the physical symbol systems hypothesis: \"A physical symbol system has the necessary and sufficient means of general intelligent action.\"[428]\nHowever, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object or commonsense reasoning. Moravec's paradox is the discovery that high-level \"intelligent\" tasks were easy for AI, but low level \"instinctive\" tasks were extremely difficult.[429] Philosopher Hubert Dreyfus had argued since the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a \"feel\" for the situation, rather than explicit symbolic knowledge.[430] Although his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree with him.[ab][16]\nThe issue is not resolved: sub-symbolic reasoning can make many of the same inscrutable mistakes that human intuition does, such as algorithmic bias. Critics such as Noam Chomsky argue continuing research into symbolic AI will still be necessary to attain general intelligence,[432][433] in part because sub-symbolic AI is a move away from explainable AI: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field of neuro-symbolic artificial intelligence attempts to bridge the two approaches.\nNeat vs. scruffy\n\"Neats\" hope that intelligent behavior is described using simple, elegant principles (such as logic, optimization, or neural networks). \"Scruffies\" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 1970s and 1980s,[434] but eventually was seen as irrelevant. Modern AI has elements of both.\nSoft vs. hard computing\nFinding a provably correct or optimal solution is intractable for many important problems.[15] Soft computing is a set of techniques, including genetic algorithms, fuzzy logic and neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 1980s and most successful AI programs in the 21st century are examples of soft computing with neural networks.\nNarrow vs. general AI\nAI researchers are divided as to whether to pursue the goals of artificial general intelligence and superintelligence directly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field's long-term goals.[435][436] General intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The sub-field of artificial general intelligence studies this area exclusively.\nThere is no settled consensus in philosophy of mind on whether a machine can have a mind, consciousness and mental states in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence. Russell and Norvig add that \"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\"[437] However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction.\nConsciousness\nDavid Chalmers identified two problems in understanding the mind, which he named the \"hard\" and \"easy\" problems of consciousness.[438] The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett's consciousness illusionism says this is an illusion). While human information processing is easy to explain, human subjective experience is difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person to know what red looks like.[439]\nComputationalism and functionalism\nComputationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind–body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.[440]\nPhilosopher John Searle characterized this position as \"strong AI\": \"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\"[ac] Searle challenges this claim with his Chinese room argument, which attempts to show that even a computer capable of perfectly simulating human behavior would not have a mind.[444]\nAI welfare and rights\nIt is difficult or impossible to reliably evaluate whether an advanced AI is sentient (has the ability to feel), and if so, to what degree.[445] But if there is a significant chance that a given machine can feel and suffer, then it may be entitled to certain rights or welfare protection measures, similarly to animals.[446][447] Sapience (a set of capacities related to high intelligence, such as discernment or self-awareness) may provide another moral basis for AI rights.[446] Robot rights are also sometimes proposed as a practical way to integrate autonomous agents into society.[448]\nIn 2017, the European Union considered granting \"electronic personhood\" to some of the most capable AI systems. Similarly to the legal status of companies, it would have conferred rights but also responsibilities.[449] Critics argued in 2018 that granting rights to AI systems would downplay the importance of human rights, and that legislation should focus on user needs rather than speculative futuristic scenarios. They also noted that robots lacked the autonomy to take part in society on their own.[450][451]\nProgress in AI increased interest in the topic. Proponents of AI welfare and rights often argue that AI sentience, if it emerges, would be particularly easy to deny. They warn that this may be a moral blind spot analogous to slavery or factory farming, which could lead to large-scale suffering if sentient AI is created and carelessly exploited.[447][446]\nFuture\nSuperintelligence and the singularity\nA superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.[436] If research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to what I. J. Good called an \"intelligence explosion\" and Vernor Vinge called a \"singularity\".[452]\nHowever, technologies cannot improve exponentially indefinitely, and typically follow an S-shaped curve, slowing when they reach the physical limits of what the technology can do.[453]\nTranshumanism\nRobot designer Hans Moravec, cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines may merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, has roots in the writings of Aldous Huxley and Robert Ettinger.[454]\nEdward Fredkin argues that \"artificial intelligence is the next step in evolution\", an idea first proposed by Samuel Butler's \"Darwin among the Machines\" as far back as 1863, and expanded upon by George Dyson in his 1998 book Darwin Among the Machines: The Evolution of Global Intelligence.[455]\nIn fiction\nThought-capable artificial beings have appeared as storytelling devices since antiquity,[456] and have been a persistent theme in science fiction.[457]\nA common trope in these works began with Mary Shelley's Frankenstein, where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke's and Stanley Kubrick's 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.[458]\nIsaac Asimov introduced the Three Laws of Robotics in many stories, most notably with the \"Multivac\" super-intelligent computer. Asimov's laws are often brought up during lay discussions of machine ethics;[459] while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.[460]\nSeveral works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel Čapek's R.U.R., the films A.I. Artificial Intelligence and Ex Machina, as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.[461]\nSee also\n- Artificial consciousness – Field in cognitive science\n- Artificial intelligence and elections – Use and impact of AI on political elections\n- Artificial intelligence content detection – Software to detect AI-generated content\n- Artificial intelligence in Wikimedia projects – Use of artificial intelligence to develop Wikipedia and other Wikimedia projects\n- Association for the Advancement of Artificial Intelligence (AAAI)\n- Behavior selection algorithm – Algorithm that selects actions for intelligent agents\n- Business process automation – Automation of business processes\n- Case-based reasoning – Process of solving new problems based on the solutions of similar past problems\n- Computational intelligence – Ability of a computer to learn a specific task from data or experimental observation\n- DARWIN EU – A European Union initiative coordinated by the European Medicines Agency (EMA) to generate and utilize real-world evidence (RWE) to support the evaluation and supervision of medicines across the EU\n- Digital immortality – Hypothetical concept of storing a personality in digital form\n- Emergent algorithm – Algorithm exhibiting emergent behavior\n- Female gendering of AI technologies – Gender biases in digital technology\n- Glossary of artificial intelligence – List of definitions of terms and concepts commonly used in the study of artificial intelligence\n- Intelligence amplification – Use of information technology to augment human intelligence\n- Intelligent agent – Software agent which acts autonomously\n- Intelligent automation – Software process that combines robotic process automation and artificial intelligence\n- List of artificial intelligence books\n- List of artificial intelligence journals\n- List of artificial intelligence projects\n- Mind uploading – Hypothetical process of digitally emulating a brain\n- Organoid intelligence – Use of brain cells and brain organoids for intelligent computing\n- Robotic process automation – Form of business process automation technology\n- The Last Day – 1967 Welsh science fiction novel\n- Wetware computer – Computer composed of organic material\nExplanatory notes\n- This list of intelligent traits is based on the topics covered by the major AI textbooks, including: Russell & Norvig (2021), Luger & Stubblefield (2004), Poole, Mackworth & Goebel (1998) and Nilsson (1998)\n- This list of tools is based on the topics covered by the major AI textbooks, including: Russell & Norvig (2021), Luger & Stubblefield (2004), Poole, Mackworth & Goebel (1998) and Nilsson (1998)\n- It is among the reasons that expert systems proved to be inefficient for capturing knowledge.[30][31]\n- \"Rational agent\" is general term used in economics, philosophy and theoretical artificial intelligence. It can refer to anything that directs its behavior to accomplish goals, such as a person, an animal, a corporation, a nation, or in the case of AI, a computer program.\n- Alan Turing discussed the centrality of learning as early as 1950, in his classic paper \"Computing Machinery and Intelligence\".[42] In 1956, at the original Dartmouth AI summer conference, Ray Solomonoff wrote a report on unsupervised probabilistic machine learning: \"An Inductive Inference Machine\".[43]\n- See AI winter § Machine translation and the ALPAC report of 1966.\n- Compared with symbolic logic, formal Bayesian inference is computationally expensive. For inference to be tractable, most observations must be conditionally independent of one another. AdSense uses a Bayesian network with over 300 million edges to learn which ads to serve.[94]\n- Expectation–maximization, one of the most popular algorithms in machine learning, allows clustering in the presence of unknown latent variables.[96]\n- Some form of deep neural networks (without a specific learning algorithm) were described by: Warren S. McCulloch and Walter Pitts (1943)[117] Alan Turing (1948);[118] Karl Steinbuch and Roger David Joseph (1961).[119] Deep or recurrent networks that learned (or used gradient descent) were developed by: Frank Rosenblatt(1957);[118] Oliver Selfridge (1959);[119] Alexey Ivakhnenko and Valentin Lapa (1965);[120] Kaoru Nakano (1971);[121] Shun-Ichi Amari (1972);[121] John Joseph Hopfield (1982).[121] Precursors to backpropagation were developed by: Henry J. Kelley (1960);[118] Arthur E. Bryson (1962);[118] Stuart Dreyfus (1962);[118] Arthur E. Bryson and Yu-Chi Ho (1969);[118] Backpropagation was independently developed by: Seppo Linnainmaa (1970);[122] Paul Werbos (1974).[118]\n- Geoffrey Hinton said, of his work on neural networks in the 1990s, \"our labeled datasets were thousands of times too small. [And] our computers were millions of times too slow.\"[123]\n- In statistics, a bias is a systematic error or deviation from the correct value. But in the context of fairness, it refers to a tendency in favor or against a certain group or individual characteristic, usually in a way that is considered unfair or harmful. A statistically unbiased AI system that produces disparate outcomes for different demographic groups may thus be viewed as biased in the ethical sense.[262]\n- Including Jon Kleinberg (Cornell University), Sendhil Mullainathan (University of Chicago), Cynthia Chouldechova (Carnegie Mellon) and Sam Corbett-Davis (Stanford)[272]\n- Moritz Hardt (a director at the Max Planck Institute for Intelligent Systems) argues that machine learning \"is fundamentally the wrong tool for a lot of domains, where you're trying to design interventions and mechanisms that change the world.\"[277]\n- When the law was passed in 2018, it still contained a form of this provision.\n- This is the United Nations' definition, and includes things like land mines as well.[291]\n- See table 4; 9% is both the OECD average and the U.S. average.[302]\n- Sometimes called a \"robopocalypse\"[311]\n- \"Electronic brain\" was the term used by the press around this time.[373][375]\n- Daniel Crevier wrote, \"the conference is generally recognized as the official birthdate of the new science.\"[378] Russell and Norvig called the conference \"the inception of artificial intelligence.\"[117]\n- Russell and Norvig wrote \"for the next 20 years the field would be dominated by these people and their students.\"[379]\n- Russell and Norvig wrote, \"it was astonishing whenever a computer did anything kind of smartish\".[380]\n- The programs described are Arthur Samuel's checkers program for the IBM 701, Daniel Bobrow's STUDENT, Newell and Simon's Logic Theorist and Terry Winograd's SHRDLU.\n- Russell and Norvig write: \"in almost all cases, these early systems failed on more difficult problems\"[384]\n- Embodied approaches to AI[391] were championed by Hans Moravec[392] and Rodney Brooks[393] and went by many names: Nouvelle AI.[393] Developmental robotics.[394]\n- Matteo Wong wrote in The Atlantic: \"Whereas for decades, computer-science fields such as natural-language processing, computer vision, and robotics used extremely different methods, now they all use a programming method called \"deep learning\". As a result, their code and approaches have become more similar, and their models are easier to integrate into one another.\"[400]\n- Jack Clark wrote in Bloomberg: \"After a half-decade of quiet breakthroughs in artificial intelligence, 2015 has been a landmark year. Computers are smarter and learning faster than ever\", and noted that the number of software projects that use machine learning at Google increased from a \"sporadic usage\" in 2012 to more than 2,700 projects in 2015.[402]\n- Nils Nilsson wrote in 1983: \"Simply put, there is wide disagreement in the field about what AI is all about.\"[426]\n- Daniel Crevier wrote that \"time has proven the accuracy and perceptiveness of some of Dreyfus's comments. Had he formulated them less aggressively, constructive actions they suggested might have been taken much earlier.\"[431]\n- Searle presented this definition of \"Strong AI\" in 1999.[441] Searle's original formulation was \"The appropriately programmed computer really is a mind, in the sense that computers given the right programs can be literally said to understand and have other cognitive states.\"[442] Strong AI is defined similarly by Russell and Norvig: \"Stong AI – the assertion that machines that do so are actually thinking (as opposed to simulating thinking).\"[443]\nReferences\n- Russell & Norvig (2021), pp. 1–4.\n- AI set to exceed human brain power Archived 19 February 2008 at the Wayback Machine CNN.com (26 July 2006)\n- Kaplan, Andreas; Haenlein, Michael (2019). \"Siri, Siri, in my hand: Who's the fairest in the land? On the interpretations, illustrations, and implications of artificial intelligence\". Business Horizons. 62: 15–25. doi:10.1016/j.bushor.2018.08.004. ISSN 0007-6813. S2CID 158433736.Snow White]\n- Russell & Norvig (2021, §1.2).\n- \"Tech companies want to build artificial general intelligence. But who decides when AGI is attained?\". AP News. 4 April 2024. Retrieved 20 May 2025.\n- Dartmouth workshop: Russell & Norvig (2021, p. 18), McCorduck (2004, pp. 111–136), NRC (1999, pp. 200–201)\nThe proposal: McCarthy et al. (1955) - Successful programs of the 1960s: McCorduck (2004, pp. 243–252), Crevier (1993, pp. 52–107), Moravec (1988, p. 9), Russell & Norvig (2021, pp. 19–21)\n- Funding initiatives in the early 1980s: Fifth Generation Project (Japan), Alvey (UK), Microelectronics and Computer Technology Corporation (US), Strategic Computing Initiative (US): McCorduck (2004, pp. 426–441), Crevier (1993, pp. 161–162, 197–203, 211, 240), Russell & Norvig (2021, p. 23), NRC (1999, pp. 210–211), Newquist (1994, pp. 235–248)\n- First AI Winter, Lighthill report, Mansfield Amendment: Crevier (1993, pp. 115–117), Russell & Norvig (2021, pp. 21–22), NRC (1999, pp. 212–213), Howe (1994), Newquist (1994, pp. 189–201)\n- Second AI Winter: Russell & Norvig (2021, p. 24), McCorduck (2004, pp. 430–435), Crevier (1993, pp. 209–210), NRC (1999, pp. 214–216), Newquist (1994, pp. 301–318)\n- Deep learning revolution, AlexNet: Goldman (2022), Russell & Norvig (2021, p. 26), McKinsey (2018)\n- Toews (2023).\n- Problem-solving, puzzle solving, game playing, and deduction: Russell & Norvig (2021, chpt. 3–5), Russell & Norvig (2021, chpt. 6) (constraint satisfaction), Poole, Mackworth & Goebel (1998, chpt. 2, 3, 7, 9), Luger & Stubblefield (2004, chpt. 3, 4, 6, 8), Nilsson (1998, chpt. 7–12)\n- Uncertain reasoning: Russell & Norvig (2021, chpt. 12–18), Poole, Mackworth & Goebel (1998, pp. 345–395), Luger & Stubblefield (2004, pp. 333–381), Nilsson (1998, chpt. 7–12)\n- Intractability and efficiency and the combinatorial explosion: Russell & Norvig (2021, p. 21)\n- Psychological evidence of the prevalence of sub-symbolic reasoning and knowledge: Kahneman (2011), Dreyfus & Dreyfus (1986), Wason & Shapiro (1966), Kahneman, Slovic & Tversky (1982)\n- Knowledge representation and knowledge engineering: Russell & Norvig (2021, chpt. 10), Poole, Mackworth & Goebel (1998, pp. 23–46, 69–81, 169–233, 235–277, 281–298, 319–345), Luger & Stubblefield (2004, pp. 227–243), Nilsson (1998, chpt. 17.1–17.4, 18)\n- Smoliar & Zhang (1994).\n- Neumann & Möller (2008).\n- Kuperman, Reichley & Bailey (2006).\n- McGarry (2005).\n- Bertini, Del Bimbo & Torniai (2006).\n- Russell & Norvig (2021), pp. 272.\n- Representing categories and relations: Semantic networks, description logics, inheritance (including frames, and scripts): Russell & Norvig (2021, §10.2 & 10.5), Poole, Mackworth & Goebel (1998, pp. 174–177), Luger & Stubblefield (2004, pp. 248–258), Nilsson (1998, chpt. 18.3)\n- Representing events and time:Situation calculus, event calculus, fluent calculus (including solving the frame problem): Russell & Norvig (2021, §10.3), Poole, Mackworth & Goebel (1998, pp. 281–298), Nilsson (1998, chpt. 18.2)\n- Causal calculus: Poole, Mackworth & Goebel (1998, pp. 335–337)\n- Representing knowledge about knowledge: Belief calculus, modal logics: Russell & Norvig (2021, §10.4), Poole, Mackworth & Goebel (1998, pp. 275–277)\n- Default reasoning, Frame problem, default logic, non-monotonic logics, circumscription, closed world assumption, abduction: Russell & Norvig (2021, §10.6), Poole, Mackworth & Goebel (1998, pp. 248–256, 323–335), Luger & Stubblefield (2004, pp. 335–363), Nilsson (1998, ~18.3.3) (Poole et al. places abduction under \"default reasoning\". Luger et al. places this under \"uncertain reasoning\").\n- Breadth of commonsense knowledge: Lenat & Guha (1989, Introduction), Crevier (1993, pp. 113–114), Moravec (1988, p. 13), Russell & Norvig (2021, pp. 241, 385, 982) (qualification problem)\n- Newquist (1994), p. 296.\n- Crevier (1993), pp. 204–208.\n- Russell & Norvig (2021), p. 528.\n- Automated planning: Russell & Norvig (2021, chpt. 11).\n- Automated decision making, Decision theory: Russell & Norvig (2021, chpt. 16–18).\n- Classical planning: Russell & Norvig (2021, Section 11.2).\n- Sensorless or \"conformant\" planning, contingent planning, replanning (a.k.a. online planning): Russell & Norvig (2021, Section 11.5).\n- Uncertain preferences: Russell & Norvig (2021, Section 16.7) Inverse reinforcement learning: Russell & Norvig (2021, Section 22.6)\n- Information value theory: Russell & Norvig (2021, Section 16.6).\n- Markov decision process: Russell & Norvig (2021, chpt. 17).\n- Game theory and multi-agent decision theory: Russell & Norvig (2021, chpt. 18).\n- Learning: Russell & Norvig (2021, chpt. 19–22), Poole, Mackworth & Goebel (1998, pp. 397–438), Luger & Stubblefield (2004, pp. 385–542), Nilsson (1998, chpt. 3.3, 10.3, 17.5, 20)\n- Turing (1950).\n- Solomonoff (1956).\n- Unsupervised learning: Russell & Norvig (2021, pp. 653) (definition), Russell & Norvig (2021, pp. 738–740) (cluster analysis), Russell & Norvig (2021, pp. 846–860) (word embedding)\n- Supervised learning: Russell & Norvig (2021, §19.2) (Definition), Russell & Norvig (2021, Chpt. 19–20) (Techniques)\n- Reinforcement learning: Russell & Norvig (2021, chpt. 22), Luger & Stubblefield (2004, pp. 442–449)\n- Transfer learning: Russell & Norvig (2021, pp. 281), The Economist (2016)\n- \"Artificial Intelligence (AI): What Is AI and How Does It Work? | Built In\". builtin.com. Retrieved 30 October 2023.\n- Computational learning theory: Russell & Norvig (2021, pp. 672–674), Jordan & Mitchell (2015)\n- Natural language processing (NLP): Russell & Norvig (2021, chpt. 23–24), Poole, Mackworth & Goebel (1998, pp. 91–104), Luger & Stubblefield (2004, pp. 591–632)\n- Subproblems of NLP: Russell & Norvig (2021, pp. 849–850)\n- Russell & Norvig (2021), pp. 856–858.\n- Dickson (2022).\n- Modern statistical and deep learning approaches to NLP: Russell & Norvig (2021, chpt. 24), Cambria & White (2014)\n- Vincent (2019).\n- Russell & Norvig (2021), pp. 875–878.\n- Bushwick (2023).\n- Computer vision: Russell & Norvig (2021, chpt. 25), Nilsson (1998, chpt. 6)\n- Russell & Norvig (2021), pp. 849–850.\n- Russell & Norvig (2021), pp. 895–899.\n- Russell & Norvig (2021), pp. 899–901.\n- Challa et al. (2011).\n- Russell & Norvig (2021), pp. 931–938.\n- MIT AIL (2014).\n- Affective computing: Thro (1993), Edelson (1991), Tao & Tan (2005), Scassellati (2002)\n- Waddell (2018).\n- Poria et al. (2017).\n-\nArtificial general intelligence: Russell & Norvig (2021, pp. 32–33, 1020–1021)\nProposal for the modern version: Pennachin & Goertzel (2007)\nWarnings of overspecialization in AI from leading researchers: Nilsson (1995), McCarthy (2007), Beal & Winston (2009) - Search algorithms: Russell & Norvig (2021, chpts. 3–5), Poole, Mackworth & Goebel (1998, pp. 113–163), Luger & Stubblefield (2004, pp. 79–164, 193–219), Nilsson (1998, chpts. 7–12)\n- State space search: Russell & Norvig (2021, chpt. 3)\n- Russell & Norvig (2021), sect. 11.2.\n- Uninformed searches (breadth first search, depth-first search and general state space search): Russell & Norvig (2021, sect. 3.4), Poole, Mackworth & Goebel (1998, pp. 113–132), Luger & Stubblefield (2004, pp. 79–121), Nilsson (1998, chpt. 8)\n- Heuristic or informed searches (e.g., greedy best first and A*): Russell & Norvig (2021, sect. 3.5), Poole, Mackworth & Goebel (1998, pp. 132–147), Poole & Mackworth (2017, sect. 3.6), Luger & Stubblefield (2004, pp. 133–150)\n- Adversarial search: Russell & Norvig (2021, chpt. 5)\n- Local or \"optimization\" search: Russell & Norvig (2021, chpt. 4)\n- Singh Chauhan, Nagesh (18 December 2020). \"Optimization Algorithms in Neural Networks\". KDnuggets. Retrieved 13 January 2024.\n- Evolutionary computation: Russell & Norvig (2021, sect. 4.1.2)\n- Merkle & Middendorf (2013).\n- Logic: Russell & Norvig (2021, chpts. 6–9), Luger & Stubblefield (2004, pp. 35–77), Nilsson (1998, chpt. 13–16)\n- Propositional logic: Russell & Norvig (2021, chpt. 6), Luger & Stubblefield (2004, pp. 45–50), Nilsson (1998, chpt. 13)\n- First-order logic and features such as equality: Russell & Norvig (2021, chpt. 7), Poole, Mackworth & Goebel (1998, pp. 268–275), Luger & Stubblefield (2004, pp. 50–62), Nilsson (1998, chpt. 15)\n- Logical inference: Russell & Norvig (2021, chpt. 10)\n- logical deduction as search: Russell & Norvig (2021, sects. 9.3, 9.4), Poole, Mackworth & Goebel (1998, pp. ~46–52), Luger & Stubblefield (2004, pp. 62–73), Nilsson (1998, chpt. 4.2, 7.2)\n- Resolution and unification: Russell & Norvig (2021, sections 7.5.2, 9.2, 9.5)\n- Warren, D.H.; Pereira, L.M.; Pereira, F. (1977). \"Prolog-the language and its implementation compared with Lisp\". ACM SIGPLAN Notices. 12 (8): 109–115. doi:10.1145/872734.806939.\n- Fuzzy logic: Russell & Norvig (2021, pp. 214, 255, 459), Scientific American (1999)\n- Stochastic methods for uncertain reasoning: Russell & Norvig (2021, chpt. 12–18, 20), Poole, Mackworth & Goebel (1998, pp. 345–395), Luger & Stubblefield (2004, pp. 165–191, 333–381), Nilsson (1998, chpt. 19)\n- decision theory and decision analysis: Russell & Norvig (2021, chpt. 16–18), Poole, Mackworth & Goebel (1998, pp. 381–394)\n- Information value theory: Russell & Norvig (2021, sect. 16.6)\n- Markov decision processes and dynamic decision networks: Russell & Norvig (2021, chpt. 17)\n- Stochastic temporal models: Russell & Norvig (2021, chpt. 14) Hidden Markov model: Russell & Norvig (2021, sect. 14.3) Kalman filters: Russell & Norvig (2021, sect. 14.4) Dynamic Bayesian networks: Russell & Norvig (2021, sect. 14.5)\n- Game theory and mechanism design: Russell & Norvig (2021, chpt. 18)\n- Bayesian networks: Russell & Norvig (2021, sects. 12.5–12.6, 13.4–13.5, 14.3–14.5, 16.5, 20.2–20.3), Poole, Mackworth & Goebel (1998, pp. 361–381), Luger & Stubblefield (2004, pp. ~182–190, ≈363–379), Nilsson (1998, chpt. 19.3–19.4)\n- Domingos (2015), chpt. 6.\n- Bayesian inference algorithm: Russell & Norvig (2021, sect. 13.3–13.5), Poole, Mackworth & Goebel (1998, pp. 361–381), Luger & Stubblefield (2004, pp. ~363–379), Nilsson (1998, chpt. 19.4 & 7)\n- Domingos (2015), p. 210.\n- Bayesian learning and the expectation–maximization algorithm: Russell & Norvig (2021, chpt. 20), Poole, Mackworth & Goebel (1998, pp. 424–433), Nilsson (1998, chpt. 20), Domingos (2015, p. 210)\n- Bayesian decision theory and Bayesian decision networks: Russell & Norvig (2021, sect. 16.5)\n- Statistical learning methods and classifiers: Russell & Norvig (2021, chpt. 20),\n- Ciaramella, Alberto; Ciaramella, Marco (2024). Introduction to Artificial Intelligence: from data analysis to generative AI. Intellisemantic Editions. ISBN 978-8-8947-8760-3.\n- Decision trees: Russell & Norvig (2021, sect. 19.3), Domingos (2015, p. 88)\n- Non-parameteric learning models such as K-nearest neighbor and support vector machines: Russell & Norvig (2021, sect. 19.7), Domingos (2015, p. 187) (k-nearest neighbor)\n- Domingos (2015, p. 88) (kernel methods)\n- Domingos (2015), p. 152.\n- Naive Bayes classifier: Russell & Norvig (2021, sect. 12.6), Domingos (2015, p. 152)\n- Neural networks: Russell & Norvig (2021, chpt. 21), Domingos (2015, Chapter 4)\n- Gradient calculation in computational graphs, backpropagation, automatic differentiation: Russell & Norvig (2021, sect. 21.2), Luger & Stubblefield (2004, pp. 467–474), Nilsson (1998, chpt. 3.3)\n- Universal approximation theorem: Russell & Norvig (2021, p. 752) The theorem: Cybenko (1988), Hornik, Stinchcombe & White (1989)\n- Feedforward neural networks: Russell & Norvig (2021, sect. 21.1)\n- Perceptrons: Russell & Norvig (2021, pp. 21, 22, 683, 22)\n- Deep learning: Russell & Norvig (2021, chpt. 21), Goodfellow, Bengio & Courville (2016), Hinton et al. (2016), Schmidhuber (2015)\n- Recurrent neural networks: Russell & Norvig (2021, sect. 21.6)\n- Convolutional neural networks: Russell & Norvig (2021, sect. 21.3)\n- Sindhu V, Nivedha S, Prakash M (February 2020). \"An Empirical Science Research on Bioinformatics in Machine Learning\". Journal of Mechanics of Continua and Mathematical Sciences (7). doi:10.26782/jmcms.spl.7/2020.02.00006.\n- Deng & Yu (2014), pp. 199–200.\n- Ciresan, Meier & Schmidhuber (2012).\n- Russell & Norvig (2021), p. 750.\n- Russell & Norvig (2021), p. 17.\n- Russell & Norvig (2021), p. 785.\n- Schmidhuber (2022), sect. 5.\n- Schmidhuber (2022), sect. 6.\n- Schmidhuber (2022), sect. 7.\n- Schmidhuber (2022), sect. 8.\n- Quoted in Christian (2020, p. 22)\n- Metz, Cade; Weise, Karen (5 May 2025). \"A.I. Hallucinations Are Getting Worse, Even as New Systems Become More Powerful\". The New York Times. ISSN 0362-4331. Retrieved 6 May 2025.\n- Smith (2023).\n- \"Explained: Generative AI\". 9 November 2023.\n- \"AI Writing and Content Creation Tools\". MIT Sloan Teaching & Learning Technologies. Archived from the original on 25 December 2023. Retrieved 25 December 2023.\n- Marmouyet (2023).\n- Kobielus (2019).\n- Thomason, James (21 May 2024). \"Mojo Rising: The resurgence of AI-first programming languages\". VentureBeat. Archived from the original on 27 June 2024. Retrieved 26 May 2024.\n- Wodecki, Ben (5 May 2023). \"7 AI Programming Languages You Need to Know\". AI Business. Archived from the original on 25 July 2024. Retrieved 5 October 2024.\n- Plumb, Taryn (18 September 2024). \"Why Jensen Huang and Marc Benioff see 'gigantic' opportunity for agentic AI\". VentureBeat. Archived from the original on 5 October 2024. Retrieved 4 October 2024.\n- Mims, Christopher (19 September 2020). \"Huang's Law Is the New Moore's Law, and Explains Why Nvidia Wants Arm\". Wall Street Journal. ISSN 0099-9660. Archived from the original on 2 October 2023. Retrieved 19 January 2025.\n- Davenport, T; Kalakota, R (June 2019). \"The potential for artificial intelligence in healthcare\". Future Healthc J. 6 (2): 94–98. doi:10.7861/futurehosp.6-2-94. PMC 6616181. PMID 31363513.\n- Lyakhova, U.A.; Lyakhov, P.A. (2024). \"Systematic review of approaches to detection and classification of skin cancer using artificial intelligence: Development and prospects\". Computers in Biology and Medicine. 178 108742. doi:10.1016/j.compbiomed.2024.108742. PMID 38875908. Archived from the original on 3 December 2024. Retrieved 10 October 2024.\n- Alqudaihi, Kawther S.; Aslam, Nida; Khan, Irfan Ullah; Almuhaideb, Abdullah M.; Alsunaidi, Shikah J.; Ibrahim, Nehad M. Abdel Rahman; Alhaidari, Fahd A.; Shaikh, Fatema S.; Alsenbel, Yasmine M.; Alalharith, Dima M.; Alharthi, Hajar M.; Alghamdi, Wejdan M.; Alshahrani, Mohammed S. (2021). \"Cough Sound Detection and Diagnosis Using Artificial Intelligence Techniques: Challenges and Opportunities\". IEEE Access. 9: 102327–102344. Bibcode:2021IEEEA...9j2327A. doi:10.1109/ACCESS.2021.3097559. ISSN 2169-3536. PMC 8545201. PMID 34786317.\n- Bax, Monique; Thorpe, Jordan; Romanov, Valentin (December 2023). \"The future of personalized cardiovascular medicine demands 3D and 4D printing, stem cells, and artificial intelligence\". Frontiers in Sensors. 4 1294721. doi:10.3389/fsens.2023.1294721. ISSN 2673-5067.\n- Dankwa-Mullan, Irene (2024). \"Health Equity and Ethical Considerations in Using Artificial Intelligence in Public Health and Medicine\". Preventing Chronic Disease. 21 240245: E64. doi:10.5888/pcd21.240245. ISSN 1545-1151. PMC 11364282. PMID 39173183.\n- Jumper, J; Evans, R; Pritzel, A (2021). \"Highly accurate protein structure prediction with AlphaFold\". Nature. 596 (7873): 583–589. Bibcode:2021Natur.596..583J. doi:10.1038/s41586-021-03819-2. PMC 8371605. PMID 34265844.\n- \"AI discovers new class of antibiotics to kill drug-resistant bacteria\". 20 December 2023. Archived from the original on 16 September 2024. Retrieved 5 October 2024.\n- \"AI speeds up drug design for Parkinson's ten-fold\". Cambridge University. 17 April 2024. Archived from the original on 5 October 2024. Retrieved 5 October 2024.\n- Horne, Robert I.; Andrzejewska, Ewa A.; Alam, Parvez; Brotzakis, Z. Faidon; Srivastava, Ankit; Aubert, Alice; Nowinska, Magdalena; Gregory, Rebecca C.; Staats, Roxine; Possenti, Andrea; Chia, Sean; Sormanni, Pietro; Ghetti, Bernardino; Caughey, Byron; Knowles, Tuomas P. J.; Vendruscolo, Michele (17 April 2024). \"Discovery of potent inhibitors of α-synuclein aggregation using structure-based iterative learning\". Nature Chemical Biology. 20 (5). Nature: 634–645. doi:10.1038/s41589-024-01580-x. PMC 11062903. PMID 38632492.\n- Grant, Eugene F.; Lardner, Rex (25 July 1952). \"The Talk of the Town – It\". The New Yorker. ISSN 0028-792X. Archived from the original on 16 February 2020. Retrieved 28 January 2024.\n- Anderson, Mark Robert (11 May 2017). \"Twenty years on from Deep Blue vs Kasparov: how a chess match started the big data revolution\". The Conversation. Archived from the original on 17 September 2024. Retrieved 28 January 2024.\n- Markoff, John (16 February 2011). \"Computer Wins on 'Jeopardy!': Trivial, It's Not\". The New York Times. ISSN 0362-4331. Archived from the original on 22 October 2014. Retrieved 28 January 2024.\n- Byford, Sam (27 May 2017). \"AlphaGo retires from competitive Go after defeating world number one 3–0\". The Verge. Archived from the original on 7 June 2017. Retrieved 28 January 2024.\n- Brown, Noam; Sandholm, Tuomas (30 August 2019). \"Superhuman AI for multiplayer poker\". Science. 365 (6456): 885–890. Bibcode:2019Sci...365..885B. doi:10.1126/science.aay2400. ISSN 0036-8075. PMID 31296650.\n- \"MuZero: Mastering Go, chess, shogi and Atari without rules\". Google DeepMind. 23 December 2020. Retrieved 28 January 2024.\n- Sample, Ian (30 October 2019). \"AI becomes grandmaster in 'fiendishly complex' StarCraft II\". The Guardian. ISSN 0261-3077. Archived from the original on 29 December 2020. Retrieved 28 January 2024.\n- Wurman, P. R.; Barrett, S.; Kawamoto, K. (2022). \"Outracing champion Gran Turismo drivers with deep reinforcement learning\" (PDF). Nature. 602 (7896): 223–228. Bibcode:2022Natur.602..223W. doi:10.1038/s41586-021-04357-7. PMID 35140384.\n- Wilkins, Alex (13 March 2024). \"Google AI learns to play open-world video games by watching them\". New Scientist. Archived from the original on 26 July 2024. Retrieved 21 July 2024.\n- Wu, Zhengxuan; Arora, Aryaman; Wang, Zheng; Geiger, Atticus; Jurafsky, Dan; Manning, Christopher D.; Potts, Christopher (2024). \"ReFT: Representation Finetuning for Language Models\". NeurIPS. arXiv:2404.03592.\n- \"Improving mathematical reasoning with process supervision\". OpenAI. 31 May 2023. Retrieved 26 January 2025.\n- Srivastava, Saurabh (29 February 2024). \"Functional Benchmarks for Robust Evaluation of Reasoning Performance, and the Reasoning Gap\". arXiv:2402.19450 [cs.AI].\n- Lightman, Hunter; Kosaraju, Vineet; Burda, Yura; Edwards, Harri; Baker, Bowen; Lee, Teddy; Leike, Jan; Schulman, John; Sutskever, Ilya; Cobbe, Karl (2023). \"Let's Verify Step by Step\". arXiv:2305.20050v1 [cs.LG].\n- Franzen, Carl (8 August 2024). \"Alibaba claims no. 1 spot in AI math models with Qwen2-Math\". VentureBeat. Retrieved 16 February 2025.\n- Franzen, Carl (9 January 2025). \"Microsoft's new rStar-Math technique upgrades small models to outperform OpenAI's o1-preview at math problems\". VentureBeat. Retrieved 26 January 2025.\n- Gina Genkina: New AI Model Advances the \"Kissing Problem\" and More. AlphaEvolve made several mathematical discoveries and practical optimizations IEEE Spectrum 14 May 2025. Retrieved 7 June 2025\n- Roberts, Siobhan (25 July 2024). \"AI achieves silver-medal standard solving International Mathematical Olympiad problems\". The New York Times. Archived from the original on 26 September 2024. Retrieved 7 August 2024.\n- Azerbayev, Zhangir; Schoelkopf, Hailey; Paster, Keiran; Santos, Marco Dos; McAleer', Stephen; Jiang, Albert Q.; Deng, Jia; Biderman, Stella; Welleck, Sean (16 October 2023). \"Llemma: An Open Language Model For Mathematics\". EleutherAI Blog. Retrieved 26 January 2025.\n- \"Julius AI\". julius.ai.\n- Metz, Cade (21 July 2025). \"Google A.I. System Wins Gold Medal in International Math Olympiad\". The New York Times. ISSN 0362-4331. Retrieved 24 July 2025.\n- McFarland, Alex (12 July 2024). \"8 Best AI for Math Tools (January 2025)\". Unite.AI. Retrieved 26 January 2025.\n- Matthew Finio & Amanda Downie: IBM Think 2024 Primer, \"What is Artificial Intelligence (AI) in Finance?\" 8 December 2023\n- M. Nicolas, J. Firzli: Pensions Age / European Pensions magazine, \"Artificial Intelligence: Ask the Industry\", May–June 2024. https://videovoice.org/ai-in-finance-innovation-entrepreneurship-vs-over-regulation-with-the-eus-artificial-intelligence-act-wont-work-as-intended/ Archived 11 September 2024 at the Wayback Machine.\n- Congressional Research Service (2019). Artificial Intelligence and National Security (PDF). Washington, DC: Congressional Research Service. Archived (PDF) from the original on 8 May 2020. Retrieved 25 February 2024.PD-notice\n- Slyusar, Vadym (2019). Artificial intelligence as the basis of future control networks (Preprint). doi:10.13140/RG.2.2.30247.50087.\n- Iraqi, Amjad (3 April 2024). \". +972 Magazine. Archived from the original on 10 October 2024. Retrieved 6 April 2024.\n- Davies, Harry; McKernan, Bethan; Sabbagh, Dan (1 December 2023). \". The Guardian. Archived from the original on 6 December 2023. Retrieved 4 December 2023.\n- Marti, J Werner (10 August 2024). \"Drohnen haben den Krieg in der Ukraine revolutioniert, doch sie sind empfindlich auf Störsender – deshalb sollen sie jetzt autonom operieren\". Neue Zürcher Zeitung (in German). Archived from the original on 10 August 2024. Retrieved 10 August 2024.\n- Newsom, Gavin; Weber, Shirley N. (5 September 2023). \"Executive Order N-12-23\" (PDF). Executive Department, State of California. Archived (PDF) from the original on 21 February 2024. Retrieved 7 September 2023.\n- \"What is ChatGPT, DALL-E, and generative AI?\". McKinsey. Archived from the original on 23 April 2023. Retrieved 14 December 2024.\n- \"What is generative AI?\". IBM. 22 March 2024. Archived from the original on 13 December 2024. Retrieved 13 December 2024.\n- Pasick, Adam (27 March 2023). \"Artificial Intelligence Glossary: Neural Networks and Other Terms Explained\". The New York Times. ISSN 0362-4331. Archived from the original on 1 September 2023. Retrieved 22 April 2023.\n- Karpathy, Andrej; Abbeel, Pieter; Brockman, Greg; Chen, Peter; Cheung, Vicki; Duan, Yan; Goodfellow, Ian; Kingma, Durk; Ho, Jonathan; Rein Houthooft; Tim Salimans; John Schulman; Ilya Sutskever; Wojciech Zaremba (16 June 2016). \"Generative models\". OpenAI. Archived from the original on 17 November 2023. Retrieved 15 March 2023.\n- Griffith, Erin; Metz, Cade (27 January 2023). \"Anthropic Said to Be Closing In on $300 Million in New A.I. Funding\". The New York Times. Archived from the original on 9 December 2023. Retrieved 14 March 2023.\n- Lanxon, Nate; Bass, Dina; Davalos, Jackie (10 March 2023). \"A Cheat Sheet to AI Buzzwords and Their Meanings\". Bloomberg News. Archived from the original on 17 November 2023. Retrieved 14 March 2023.\n- Roose, Kevin (21 October 2022). \"A Coming-Out Party for Generative A.I., Silicon Valley's New Craze\". The New York Times. Archived from the original on 15 February 2023. Retrieved 14 March 2023.\n- Metz, Cade (15 February 2024). \"OpenAI Unveils A.I. That Instantly Generates Eye-Popping Videos\". The New York Times. ISSN 0362-4331. Archived from the original on 15 February 2024. Retrieved 16 February 2024.\n- Fink, Charlie. \"LTX Video Breaks The 60-Second Barrier, Redefining AI Video As A Longform Medium\". Forbes. Retrieved 24 July 2025.\n- \"The race of the AI labs heats up\". The Economist. 30 January 2023. Archived from the original on 17 November 2023. Retrieved 14 March 2023.\n- Petrella, Stephanie; Miller, Chris; Cooper, Benjamin (2021). \"Russia's Artificial Intelligence Strategy: The Role of State-Owned Firms\". Orbis. 65 (1): 75–100. doi:10.1016/j.orbis.2020.11.004.\n- \"The Transformative Impact of Generative AI on Software Development and Quality Engineering\". Unite.AI. 17 July 2024. Archived from the original on 10 April 2025. Retrieved 10 April 2025.\n- Raza, Marium M.; Venkatesh, Kaushik P.; Kvedar, Joseph C. (7 March 2024). \"Generative AI and large language models in health care: pathways to implementation\". npj Digital Medicine. 7 (1): 62. doi:10.1038/s41746-023-00988-4. ISSN 2398-6352. PMC 10920625. PMID 38454007.\n- Mogaji, Emmanuel (7 January 2025). \"How generative AI is transforming financial services – and what it means for customers\". The Conversation. Retrieved 10 April 2025.\n- Bean, Thomas H. Davenport and Randy (19 June 2023). \"The Impact of Generative AI on Hollywood and Entertainment\". MIT Sloan Management Review. Archived from the original on 6 August 2024. Retrieved 10 April 2025.\n- Brynjolfsson, Erik; Li, Danielle; Raymond, Lindsey R. (April 2023), Generative AI at Work (Working Paper), Working Paper Series, doi:10.3386/w31161, archived from the original on 28 March 2024, retrieved 21 January 2024\n- \"Don't fear an AI-induced jobs apocalypse just yet\". The Economist. 6 March 2023. Archived from the original on 17 November 2023. Retrieved 14 March 2023.\n- Coyle, Jake (27 September 2023). \"In Hollywood writers' battle against AI, humans win (for now)\". AP News. Associated Press. Archived from the original on 3 April 2024. Retrieved 26 January 2024.\n- Harreis, H.; Koullias, T.; Roberts, Roger. \"Generative AI: Unlocking the future of fashion\". Archived from the original on 17 November 2023. Retrieved 14 March 2023.\n- \"How Generative AI Can Augment Human Creativity\". Harvard Business Review. 16 June 2023. ISSN 0017-8012. Archived from the original on 20 June 2023. Retrieved 20 June 2023.\n- \"AI has an environmental problem. Here's what the world can do about that\". www.unep.org. 21 September 2024. Retrieved 20 August 2025.\n- Poole, David; Mackworth, Alan (2023). Artificial Intelligence, Foundations of Computational Agents (3rd ed.). Cambridge University Press. doi:10.1017/9781009258227. ISBN 978-1-0092-5819-7.\n- Russell, Stuart; Norvig, Peter (2020). Artificial Intelligence: A Modern Approach (4th ed.). Pearson. ISBN 978-0-1346-1099-3.\n- \"Why agents are the next frontier of generative AI\". McKinsey Digital. 24 July 2024. Archived from the original on 3 October 2024. Retrieved 10 August 2024.\n- \"Introducing Copilot Search in Bing\". blogs.bing.com. 4 April 2025.\n- Peters, Jay (14 March 2023). \"The Bing AI bot has been secretly running GPT-4\". The Verge. Retrieved 31 August 2025.\n- \"Security for Microsoft 365 Copilot\". learn.microsoft.com.\n- O'Flaherty, Kate (21 May 2025). \"Google AI Overviews — Everything You Need To Know\". Forbes.\n- \"Generative AI in Search: Let Google do the searching for you\". Google. 14 May 2024.\n- Figueiredo, Mayara Costa; Ankrah, Elizabeth; Powell, Jacquelyn E.; Epstein, Daniel A.; Chen, Yunan (12 January 2024). \"Powered by AI: Examining How AI Descriptions Influence Perceptions of Fertility Tracking Applications\". Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies. 7 (4): 1–24. doi:10.1145/3631414.\n- Power, Jennifer; Pym, Tinonee; James, Alexandra; Waling, Andrea (5 July 2024). \"Smart Sex Toys: A Narrative Review of Recent Research on Cultural, Health and Safety Considerations\". Current Sexual Health Reports. 16 (3): 199–215. doi:10.1007/s11930-024-00392-3. ISSN 1548-3592.\n- Marcantonio, Tiffany L.; Avery, Gracie; Thrash, Anna; Leone, Ruschelle M. (10 September 2024). \"Large Language Models in an App: Conducting a Qualitative Synthetic Data Analysis of How Snapchat's \"My AI\" Responds to Questions About Sexual Consent, Sexual Refusals, Sexual Assault, and Sexting\". The Journal of Sex Research: 1–15. doi:10.1080/00224499.2024.2396457. ISSN 0022-4499. PMC 11891083. PMID 39254628. Archived from the original on 9 December 2024. Retrieved 9 December 2024.\n- Hanson, Kenneth R.; Bolthouse, Hannah (2024). \". Socius: Sociological Research for a Dynamic World. 10 23780231241259627. doi:10.1177/23780231241259627. ISSN 2378-0231.\n- Mania, Karolina (1 January 2024). \"Legal Protection of Revenge and Deepfake Porn Victims in the European Union: Findings From a Comparative Legal Study\". Trauma, Violence, & Abuse. 25 (1): 117–129. doi:10.1177/15248380221143772. ISSN 1524-8380. PMID 36565267.\n- Singh, Suyesha; Nambiar, Vaishnavi (2024). \"Role of Artificial Intelligence in the Prevention of Online Child Sexual Abuse: A Systematic Review of Literature\". Journal of Applied Security Research. 19 (4): 586–627. doi:10.1080/19361610.2024.2331885. ISSN 1936-1610. Archived from the original on 9 December 2024. Retrieved 9 December 2024.\n- Razi, Afsaneh; Kim, Seunghyun; Alsoubai, Ashwaq; Stringhini, Gianluca; Solorio, Thamar; De Choudhury, Munmun; Wisniewski, Pamela J. (13 October 2021). \"A Human-Centered Systematic Literature Review of the Computational Approaches for Online Sexual Risk Detection\". Proceedings of the ACM on Human-Computer Interaction. 5 (CSCW2): 1–38. doi:10.1145/3479609. ISSN 2573-0142. Archived from the original on 9 December 2024. Retrieved 9 December 2024.\n- Ransbotham, Sam; Kiron, David; Gerbert, Philipp; Reeves, Martin (6 September 2017). \"Reshaping Business With Artificial Intelligence\". MIT Sloan Management Review. Archived from the original on 13 February 2024.\n- Sun, Yuran; Zhao, Xilei; Lovreglio, Ruggiero; Kuligowski, Erica (1 January 2024), Naser, M. Z. (ed.), \"8 – AI for large-scale evacuation modeling: promises and challenges\", Interpretable Machine Learning for the Analysis, Design, Assessment, and Informed Decision Making for Civil Infrastructure, Woodhead Publishing Series in Civil and Structural Engineering, Woodhead Publishing, pp. 185–204, ISBN 978-0-1282-4073-1, archived from the original on 19 May 2024, retrieved 28 June 2024\n- Gomaa, Islam; Adelzadeh, Masoud; Gwynne, Steven; Spencer, Bruce; Ko, Yoon; Bénichou, Noureddine; Ma, Chunyun; Elsagan, Nour; Duong, Dana; Zalok, Ehab; Kinateder, Max (1 November 2021). \"A Framework for Intelligent Fire Detection and Evacuation System\". Fire Technology. 57 (6): 3179–3185. doi:10.1007/s10694-021-01157-3. ISSN 1572-8099.\n- Zhao, Xilei; Lovreglio, Ruggiero; Nilsson, Daniel (1 May 2020). \"Modelling and interpreting pre-evacuation decision-making using machine learning\". Automation in Construction. 113 103140. doi:10.1016/j.autcon.2020.103140. hdl:10179/17315. ISSN 0926-5805. Archived from the original on 19 May 2024. Retrieved 5 October 2024.\n- \"India's latest election embraced AI technology. Here are some ways it was used constructively\". PBS News. 12 June 2024. Archived from the original on 17 September 2024. Retrieved 28 October 2024.\n- \"Экономист Дарон Асемоглу написал книгу об угрозах искусственного интеллекта — и о том, как правильное управление может обратить его на пользу человечеству Спецкор \"Медузы\" Маргарита Лютова узнала у ученого, как скоро мир сможет приблизиться к этой утопии\". Meduza (in Russian). Archived from the original on 20 June 2023. Retrieved 21 June 2023.\n- \"Learning, thinking, artistic collaboration and other such human endeavours in the age of AI\". The Hindu. 2 June 2023. Archived from the original on 21 June 2023. Retrieved 21 June 2023.\n- Müller, Vincent C. (30 April 2020). \"Ethics of Artificial Intelligence and Robotics\". Stanford Encyclopedia of Philosophy Archive. Archived from the original on 5 October 2024. Retrieved 5 October 2024.\n- Simonite (2016).\n- Russell & Norvig (2021), p. 987.\n- \"Assessing potential future artificial intelligence risks, benefits and policy imperatives\". OECD. 14 November 2024. Retrieved 1 August 2025.\n- Laskowski (2023).\n- GAO (2022).\n- Valinsky (2019).\n- Russell & Norvig (2021), p. 991.\n- Russell & Norvig (2021), pp. 991–992.\n- Christian (2020), p. 63.\n- Vincent (2022).\n- Kopel, Matthew. \"Copyright Services: Fair Use\". Cornell University Library. Archived from the original on 26 September 2024. Retrieved 26 April 2024.\n- Burgess, Matt. \"How to Stop Your Data From Being Used to Train AI\". Wired. ISSN 1059-1028. Archived from the original on 3 October 2024. Retrieved 26 April 2024.\n- \"Exclusive: Multiple AI companies bypassing web standard to scrape publisher sites, licensing firm says\". Reuters. Archived from the original on 10 November 2024. Retrieved 13 November 2025.\n- Shilov, Anton (21 June 2024). \"Several AI companies said to be ignoring robots dot txt exclusion, scraping content without permission: report\". Tom's Hardware. Retrieved 13 November 2025.\n- Reisner (2023).\n- Alter & Harris (2023).\n- \"Getting the Innovation Ecosystem Ready for AI. An IP policy toolkit\" (PDF). WIPO.\n- Hammond, George (27 December 2023). \"Big Tech is spending more than VC firms on AI startups\". Ars Technica. Archived from the original on 10 January 2024.\n- Wong, Matteo (24 October 2023). \"The Future of AI Is GOMA\". The Atlantic. Archived from the original on 5 January 2024.\n- \"Big tech and the pursuit of AI dominance\". The Economist. 26 March 2023. Archived from the original on 29 December 2023.\n- Fung, Brian (19 December 2023). \"Where the battle to dominate AI may be won\". CNN Business. Archived from the original on 13 January 2024.\n- Metz, Cade (5 July 2023). \"In the Age of A.I., Tech's Little Guys Need Big Friends\". The New York Times. Archived from the original on 8 July 2024. Retrieved 5 October 2024.\n- \"Electricity 2024 – Analysis\". IEA. 24 January 2024. Retrieved 13 July 2024.\n- Calvert, Brian (28 March 2024). \"AI already uses as much energy as a small country. It's only the beginning\". Vox. New York, New York. Archived from the original on 3 July 2024. Retrieved 5 October 2024.\n- Halper, Evan; O'Donovan, Caroline (21 June 2024). \"AI is exhausting the power grid. Tech firms are seeking a miracle solution\". Washington Post.\n- Davenport, Carly. \"AI Data Centers and the Coming YS Power Demand Surge\" (PDF). Goldman Sachs. Archived from the original (PDF) on 26 July 2024. Retrieved 5 October 2024.\n- Ryan, Carol (12 April 2024). \"Energy-Guzzling AI Is Also the Future of Energy Savings\". Wall Street Journal. Dow Jones.\n- Hiller, Jennifer (1 July 2024). \"Tech Industry Wants to Lock Up Nuclear Power for AI\". Wall Street Journal. Dow Jones. Archived from the original on 5 October 2024. Retrieved 5 October 2024.\n- Kendall, Tyler (28 September 2024). \"Nvidia's Huang Says Nuclear Power an Option to Feed Data Centers\". Bloomberg.\n- Halper, Evan (20 September 2024). \"Microsoft deal would reopen Three Mile Island nuclear plant to power AI\". Washington Post.\n- Hiller, Jennifer (20 September 2024). \"Three Mile Island's Nuclear Plant to Reopen, Help Power Microsoft's AI Centers\". Wall Street Journal. Dow Jones. Archived from the original on 5 October 2024. Retrieved 5 October 2024.\n- Niva Yadav (19 August 2024). \"Taiwan to stop large data centers in the North, cites insufficient power\". DatacenterDynamics. Archived from the original on 8 November 2024. Retrieved 7 November 2024.\n- Mochizuki, Takashi; Oda, Shoko (18 October 2024). \"エヌビディア出資の日本企業、原発近くでＡＩデータセンター新設検討\". Bloomberg (in Japanese). Archived from the original on 8 November 2024. Retrieved 7 November 2024.\n- Naureen S Malik and Will Wade (5 November 2024). \"Nuclear-Hungry AI Campuses Need New Plan to Find Power Fast\". Bloomberg.\n- \"Energy and AI Executive summary\". International Energy Agency. Retrieved 10 April 2025.\n- Nicas (2018).\n- Rainie, Lee; Keeter, Scott; Perrin, Andrew (22 July 2019). \"Trust and Distrust in America\". Pew Research Center. Archived from the original on 22 February 2024.\n- Kosoff, Maya (8 February 2018). \"YouTube Struggles to Contain Its Conspiracy Problem\". Vanity Fair. Retrieved 10 April 2025.\n- Berry, David M. (19 March 2025). \"Synthetic media and computational capitalism: towards a critical theory of artificial intelligence\". AI & Society. doi:10.1007/s00146-025-02265-2. ISSN 1435-5655.\n- \"Unreal: A quantum leap in AI video\". The Week. 17 June 2025. Retrieved 20 June 2025.\n- Snow, Jackie (16 June 2025). \"AI video is getting real. Beware what comes next\". Quartz. Retrieved 20 June 2025.\n- Chow, Andrew R.; Perrigo, Billy (3 June 2025). \"Google's New AI Tool Generates Convincing Deepfakes of Riots, Conflict, and Election Fraud\". Time. Retrieved 20 June 2025.\n- Williams (2023).\n- Olanipekun, Samson Olufemi (2025). \"Computational propaganda and misinformation: AI technologies as tools of media manipulation\". World Journal of Advanced Research and Reviews. 25 (1): 911–923. doi:10.30574/wjarr.2025.25.1.0131. ISSN 2581-9615.\n- Taylor & Hern (2023).\n- \"To fight AI, we need 'personhood credentials,' say AI firms\". Archived from the original on 24 April 2025. Retrieved 9 May 2025.\n- Samuel, Sigal (19 April 2022). \"Why it's so damn hard to make AI fair and unbiased\". Vox. Archived from the original on 5 October 2024. Retrieved 24 July 2024.\n- Rose (2023).\n- CNA (2019).\n- Mazeika, Mantas; Yin, Xuwang; Tamirisa, Rishub; Lim, Jaehyuk; Lee, Bruce W.; Ren, Richard; Phan, Long; Mu, Norman; Khoja, Adam (2025), Utility Engineering: Analyzing and Controlling Emergent Value Systems in AIs, Figure 16, arXiv:2502.08640, retrieved 24 October 2025\n- Goffrey (2008), p. 17.\n- Berdahl et al. (2023); Goffrey (2008, p. 17); Rose (2023); Russell & Norvig (2021, p. 995)\n- Christian (2020), p. 25.\n- Russell & Norvig (2021), p. 995.\n- Grant & Hill (2023).\n- Larson & Angwin (2016).\n- Christian (2020), p. 67–70.\n- Christian (2020, pp. 67–70); Russell & Norvig (2021, pp. 993–994)\n- Russell & Norvig (2021, p. 995); Lipartito (2011, p. 36); Goodman & Flaxman (2017, p. 6); Christian (2020, pp. 39–40, 65)\n- Quoted in Christian (2020, p. 65).\n- Russell & Norvig (2021, p. 994); Christian (2020, pp. 40, 80–81)\n- Quoted in Christian (2020, p. 80)\n- Dockrill (2022).\n- Sample (2017).\n- \"Black Box AI\". 16 June 2023. Archived from the original on 15 June 2024. Retrieved 5 October 2024.\n- Christian (2020), p. 110.\n- Christian (2020), pp. 88–91.\n- Christian (2020, p. 83); Russell & Norvig (2021, p. 997)\n- Christian (2020), p. 91.\n- Christian (2020), p. 83.\n- Verma (2021).\n- Rothman (2020).\n- Christian (2020), pp. 105–108.\n- Christian (2020), pp. 108–112.\n- Ropek, Lucas (21 May 2024). \"New Anthropic Research Sheds Light on AI's 'Black Box'. Gizmodo. Archived from the original on 5 October 2024. Retrieved 23 May 2024.\n- Russell & Norvig (2021), p. 989.\n- Russell & Norvig (2021), pp. 987–990.\n- Russell & Norvig (2021), p. 988.\n- Robitzski (2018); Sainato (2015)\n- Harari (2018).\n- Buckley, Chris; Mozur, Paul (22 May 2019). \"How China Uses High-Tech Surveillance to Subdue Minorities\". The New York Times. Archived from the original on 25 November 2019. Retrieved 2 July 2019.\n- \"Security lapse exposed a Chinese smart city surveillance system\". 3 May 2019. Archived from the original on 7 March 2021. Retrieved 14 September 2020.\n- Urbina et al. (2022).\n- McGaughey (2022).\n- Ford & Colvin (2015);McGaughey (2022)\n- IGM Chicago (2017).\n- Arntz, Gregory & Zierahn (2016), p. 33.\n- Lohr (2017); Frey & Osborne (2017); Arntz, Gregory & Zierahn (2016, p. 33)\n- Zhou, Viola (11 April 2023). \"AI is already taking video game illustrators' jobs in China\". Rest of World. Archived from the original on 21 February 2024. Retrieved 17 August 2023.\n- Carter, Justin (11 April 2023). \"China's game art industry reportedly decimated by growing AI use\". Game Developer. Archived from the original on 17 August 2023. Retrieved 17 August 2023.\n- Morgenstern (2015).\n- Mahdawi (2017); Thompson (2014)\n- Ma, Jason (5 July 2025). \"Ford CEO Jim Farley warns AI will wipe out half of white-collar jobs, but the 'essential economy' has a huge shortage of workers\". Fortune. Retrieved 21 October 2025.\n- Tarnoff, Ben (4 August 2023). \"Lessons from Eliza\". The Guardian Weekly. pp. 34–39.\n- Cellan-Jones (2014).\n- Russell & Norvig 2021, p. 1001.\n- Bostrom (2014).\n- Russell (2019).\n- Bostrom (2014); Müller & Bostrom (2014); Bostrom (2015).\n- Harari (2023).\n- Stewart (2025).\n- Müller & Bostrom (2014).\n- Leaders' concerns about the existential risks of AI around 2015: Rawlinson (2015), Holley (2015), Gibbs (2014), Sainato (2015)\n- \". CBS News. 25 March 2023. Archived from the original on 28 March 2023. Retrieved 28 March 2023.\n- Pittis, Don (4 May 2023). \"Canadian artificial intelligence leader Geoffrey Hinton piles on fears of computer takeover\". CBC. Archived from the original on 7 July 2024. Retrieved 5 October 2024.\n- \". Bloomberg BNN. 14 June 2024. Archived from the original on 14 June 2024. Retrieved 6 July 2024.\n- Valance (2023).\n- Taylor, Josh (7 May 2023). \"Rise of artificial intelligence is inevitable but should not be feared, 'father of AI' says\". The Guardian. Archived from the original on 23 October 2023. Retrieved 26 May 2023.\n- Colton, Emma (7 May 2023). \". Fox News. Archived from the original on 26 May 2023. Retrieved 26 May 2023.\n- Jones, Hessie (23 May 2023). \"Juergen Schmidhuber, Renowned 'Father Of Modern AI,' Says His Life's Work Won't Lead To Dystopia\". Forbes. Archived from the original on 26 May 2023. Retrieved 26 May 2023.\n- McMorrow, Ryan (19 December 2023). \"Andrew Ng: 'Do we think the world is better off with more or less intelligence?'. Financial Times. Archived from the original on 25 January 2024. Retrieved 30 December 2023.\n- Levy, Steven (22 December 2023). \"How Not to Be Stupid About AI, With Yann LeCun\". Wired. Archived from the original on 28 December 2023. Retrieved 30 December 2023.\n- Arguments that AI is not an imminent risk: Brooks (2014), Geist (2015), Madrigal (2015), Lee (2014)\n- Christian (2020), pp. 67, 73.\n- Yudkowsky (2008).\n- Anderson & Anderson (2011).\n- AAAI (2014).\n- Wallach (2010).\n- Russell (2019), p. 173.\n- Stewart, Ashley; Melton, Monica. \"Hugging Face CEO says he's focused on building a 'sustainable model' for the $4.5 billion open-source-AI startup\". Business Insider. Archived from the original on 25 September 2024. Retrieved 14 April 2024.\n- Wiggers, Kyle (9 April 2024). \"Google open sources tools to support AI model development\". TechCrunch. Archived from the original on 10 September 2024. Retrieved 14 April 2024.\n- Heaven, Will Douglas (12 May 2023). \"The open-source AI boom is built on Big Tech's handouts. How long will it last?\". MIT Technology Review. Retrieved 14 April 2024.\n- Brodsky, Sascha (19 December 2023). \"Mistral AI's New Language Model Aims for Open Source Supremacy\". AI Business. Archived from the original on 5 September 2024. Retrieved 5 October 2024.\n- Edwards, Benj (22 February 2024). \"Stability announces Stable Diffusion 3, a next-gen AI image generator\". Ars Technica. Archived from the original on 5 October 2024. Retrieved 14 April 2024.\n- Marshall, Matt (29 January 2024). \"How enterprises are using open source LLMs: 16 examples\". VentureBeat. Archived from the original on 26 September 2024. Retrieved 5 October 2024.\n- Piper, Kelsey (2 February 2024). \"Should we make our most powerful AI models open source to all?\". Vox. Archived from the original on 5 October 2024. Retrieved 14 April 2024.\n- Alan Turing Institute (2019). \"Understanding artificial intelligence ethics and safety\" (PDF). Archived (PDF) from the original on 11 September 2024. Retrieved 5 October 2024.\n- Alan Turing Institute (2023). \"AI Ethics and Governance in Practice\" (PDF). Archived (PDF) from the original on 11 September 2024. Retrieved 5 October 2024.\n- Floridi, Luciano; Cowls, Josh (23 June 2019). \"A Unified Framework of Five Principles for AI in Society\". Harvard Data Science Review. 1 (1). doi:10.1162/99608f92.8cd550d1. S2CID 198775713. Archived from the original on 7 August 2019. Retrieved 5 December 2023.\n- Buruk, Banu; Ekmekci, Perihan Elif; Arda, Berna (1 September 2020). \"A critical perspective on guidelines for responsible and trustworthy artificial intelligence\". Medicine, Health Care and Philosophy. 23 (3): 387–399. doi:10.1007/s11019-020-09948-1. ISSN 1572-8633. PMID 32236794. S2CID 214766800.\n- Kamila, Manoj Kumar; Jasrotia, Sahil Singh (1 January 2023). \"Ethical issues in the development of artificial intelligence: recognizing the risks\". International Journal of Ethics and Systems. 41 (ahead-of-print): 45–63. doi:10.1108/IJOES-05-2023-0107. ISSN 2514-9369. S2CID 259614124.\n- \"AI Safety Institute releases new AI safety evaluations platform\". UK Government. 10 May 2024. Archived from the original on 5 October 2024. Retrieved 14 May 2024.\n- Regulation of AI to mitigate risks: Berryhill et al. (2019), Barfield & Pagallo (2018), Iphofen & Kritikos (2019), Wirtz, Weyerer & Geyer (2018), Buiten (2019)\n- Law Library of Congress (U.S.). Global Legal Research Directorate (2019).\n- Vincent (2023).\n- Stanford University (2023).\n- UNESCO (2021).\n- Kissinger (2021).\n- Altman, Brockman & Sutskever (2023).\n- VOA News (25 October 2023). \"UN Announces Advisory Body on Artificial Intelligence\". Archived from the original on 18 September 2024. Retrieved 5 October 2024.\n- \"AI Act enters into force - European Commission\". commission.europa.eu. Retrieved 11 August 2025.\n- \"Council of Europe opens first ever global treaty on AI for signature\". Council of Europe. 5 September 2024. Archived from the original on 17 September 2024. Retrieved 17 September 2024.\n- Edwards (2023).\n- Kasperowicz (2023).\n- Fox News (2023).\n- Milmo, Dan (3 November 2023). \"Hope or Horror? The great AI debate dividing its pioneers\". The Guardian Weekly. pp. 10–12.\n- \"The Bletchley Declaration by Countries Attending the AI Safety Summit, 1–2 November 2023\". GOV.UK. 1 November 2023. Archived from the original on 1 November 2023. Retrieved 2 November 2023.\n- \"Countries agree to safe and responsible development of frontier AI in landmark Bletchley Declaration\". GOV.UK (Press release). Archived from the original on 1 November 2023. Retrieved 1 November 2023.\n- \"Second global AI summit secures safety commitments from companies\". Reuters. 21 May 2024. Retrieved 23 May 2024.\n- \"Frontier AI Safety Commitments, AI Seoul Summit 2024\". gov.uk. 21 May 2024. Archived from the original on 23 May 2024. Retrieved 23 May 2024.\n- Buntz, Brian (3 November 2024). \"Quality vs. quantity: US and China chart different paths in global AI patent race in 2024 / Geographical breakdown of AI patents in 2024\". R&D World. Archived from the original on 9 December 2024.\n- Gardiner, Patrick (July 1954). \"The Origin and Goal of History. By Karl Jaspers. (Routledge and Kegan Paul. 21s.)\". Philosophy. 29 (110): 277–277. doi:10.1017/s0031819100054917. ISSN 0031-8191.\n- Bobzien, Susanne (13 December 2006). \"Stanford Encyclopedia of Philosophy Archive\". Ancient Logic.\n- Smith, R. (2020). Aristotle's logic. In E. N. Zalta (Ed.), The Stanford Encyclopedia of Philosophy (Fall 2020 ed.). Stanford University. https://plato.stanford.edu/entries/aristotle-logic/\n- Corcoran, J. (1974). Aristotle's natural deduction system. In J. Corcoran (Ed.), Ancient logic and its modern interpretations (pp. 85-131). D. Reidel Publishing Company.\n- Sepahsālār, F. A. (1325/1946). Risālah-yi Sepahsālār dar manāqib-i Ḥaẓrat-i Khudāvandgār [The treatise of Sepahsalar on the virtues of the Master]. Tehran.\n- Nicholson, R. A. (1926-1934). The Mathnawí of Jalálu'ddín Rúmí: Edited from the oldest manuscripts available, with critical notes, translation and commentary (Vols. 1-8). Luzac & Co.\n- Russell & Norvig 2021, p. 9.\n- Copeland, J., ed. (2004). The Essential Turing: the ideas that gave birth to the computer age. Oxford, England: Clarendon Press. ISBN 0-1982-5079-7.\n- \"Google books ngram\". Archived from the original on 5 October 2024. Retrieved 5 October 2024.\n- AI's immediate precursors: McCorduck (2004, pp. 51–107), Crevier (1993, pp. 27–32), Russell & Norvig (2021, pp. 8–17), Moravec (1988, p. 3)\n- Turing's original publication of the Turing test in \"Computing machinery and intelligence\": Turing (1950) Historical influence and philosophical implications: Haugeland (1985, pp. 6–9), Crevier (1993, p. 24), McCorduck (2004, pp. 70–71), Russell & Norvig (2021, pp. 2, 984)\n- Crevier (1993), pp. 47–49.\n- Russell & Norvig (2003), p. 17.\n- Russell & Norvig (2003), p. 18.\n- Newquist (1994), pp. 86–86.\n- Simon (1965, p. 96) quoted in Crevier (1993, p. 109)\n- Minsky (1967, p. 2) quoted in Crevier (1993, p. 109)\n- Russell & Norvig (2021), p. 21.\n- Lighthill (1973).\n- NRC 1999, pp. 212–213.\n- Russell & Norvig (2021), p. 22.\n- Expert systems: Russell & Norvig (2021, pp. 23, 292), Luger & Stubblefield (2004, pp. 227–331), Nilsson (1998, chpt. 17.4), McCorduck (2004, pp. 327–335, 434–435), Crevier (1993, pp. 145–162, 197–203), Newquist (1994, pp. 155–183)\n- Russell & Norvig (2021), p. 24.\n- Nilsson (1998), p. 7.\n- McCorduck (2004), pp. 454–462.\n- Moravec (1988).\n- Brooks (1990).\n- Developmental robotics: Weng et al. (2001), Lungarella et al. (2003), Asada et al. (2009), Oudeyer (2010)\n- Russell & Norvig (2021), p. 25.\n- Crevier (1993, pp. 214–215), Russell & Norvig (2021, pp. 24, 26)\n- Russell & Norvig (2021), p. 26.\n- Formal and narrow methods adopted in the 1990s: Russell & Norvig (2021, pp. 24–26), McCorduck (2004, pp. 486–487)\n- AI widely used in the late 1990s: Kurzweil (2005, p. 265), NRC (1999, pp. 216–222), Newquist (1994, pp. 189–201)\n- Wong (2023).\n- Moore's Law and AI: Russell & Norvig (2021, pp. 14, 27)\n- Clark (2015b).\n- Big data: Russell & Norvig (2021, p. 26)\n- Sagar, Ram (3 June 2020). \"OpenAI Releases GPT-3, The Largest Model So Far\". Analytics India Magazine. Archived from the original on 4 August 2020. Retrieved 15 March 2023.\n- Milmo, Dan (2 February 2023). \"ChatGPT reaches 100 million users two months after launch\". The Guardian. ISSN 0261-3077. Archived from the original on 3 February 2023. Retrieved 31 December 2024.\n- Gorichanaz, Tim (29 November 2023). \"ChatGPT turns 1: AI chatbot's success says as much about humans as technology\". The Conversation. Archived from the original on 31 December 2024. Retrieved 31 December 2024.\n- DiFeliciantonio (2023).\n- Goswami (2023).\n- \"Nearly 1 in 4 new startups is an AI company\". PitchBook. 24 December 2024. Retrieved 3 January 2025.\n- Grayling, Anthony; Ball, Brian (1 August 2024). \"Philosophy is crucial in the age of AI\". The Conversation. Archived from the original on 5 October 2024. Retrieved 4 October 2024.\n- Jarow, Oshan (15 June 2024). \"Will AI ever become conscious? It depends on how you think about biology\". Vox. Archived from the original on 21 September 2024. Retrieved 4 October 2024.\n- McCarthy, John. \"The Philosophy of AI and the AI of Philosophy\". jmc.stanford.edu. Archived from the original on 23 October 2018. Retrieved 3 October 2024.\n- Turing (1950), p. 1.\n- Turing (1950), Under \"The Argument from Consciousness\".\n- Kirk-Giannini, Cameron Domenico; Goldstein, Simon (16 October 2023). \"AI is closer than ever to passing the Turing test for 'intelligence'. What happens when it does?\". The Conversation. Archived from the original on 25 September 2024. Retrieved 17 August 2024.\n- Russell & Norvig (2021), p. 3.\n- Maker (2006).\n- McCarthy (1999).\n- Minsky (1986).\n- \"What Is Artificial Intelligence (AI)?\". Google Cloud Platform. Archived from the original on 31 July 2023. Retrieved 16 October 2023.\n- Suchman, Lucy (2023). \"The uncontroversial 'thingness' of AI\". Big Data & Society. 10 (2) 20539517231206794. doi:10.1177/20539517231206794.\n- Rehak, Rainer (2025). \"AI Narrative Breakdown: A Critical Assessment of Power and Promise\". Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency (FAccT '25). New York, NY, USA: Association for Computing Machinery. pp. 1250–1260. doi:10.1145/3715275.3732083.\n- \"One of the Biggest Problems in Regulating AI Is Agreeing on a Definition\". Carnegie Endowment for International Peace. Retrieved 31 July 2024.\n- \"AI or BS? How to tell if a marketing tool really uses artificial intelligence\". The Drum. Retrieved 31 July 2024.\n- Musser, George (1 September 2023). \"How AI Knows Things No One Told It\". Scientific American. Retrieved 17 July 2025.\n- Nilsson (1983), p. 10.\n- Haugeland (1985), pp. 112–117.\n- Physical symbol system hypothesis: Newell & Simon (1976, p. 116) Historical significance: McCorduck (2004, p. 153), Russell & Norvig (2021, p. 19)\n- Moravec's paradox: Moravec (1988, pp. 15–16), Minsky (1986, p. 29), Pinker (2007, pp. 190–191)\n- Dreyfus' critique of AI: Dreyfus (1972), Dreyfus & Dreyfus (1986) Historical significance and philosophical implications: Crevier (1993, pp. 120–132), McCorduck (2004, pp. 211–239), Russell & Norvig (2021, pp. 981–982), Fearn (2007, chpt. 3)\n- Crevier (1993), p. 125.\n- Langley (2011).\n- Katz (2012).\n- Neats vs. scruffies, the historic debate: McCorduck (2004, pp. 421–424, 486–489), Crevier (1993, p. 168), Nilsson (1983, pp. 10–11), Russell & Norvig (2021, p. 24) A classic example of the \"scruffy\" approach to intelligence: Minsky (1986) A modern example of neat AI and its aspirations in the 21st century: Domingos (2015)\n- Pennachin & Goertzel (2007).\n- Roberts (2016).\n- Russell & Norvig (2021), p. 986.\n- Chalmers (1995).\n- Dennett (1991).\n- Horst (2005).\n- Searle (1999).\n- Searle (1980), p. 1.\n- Russell & Norvig (2021), p. 9817.\n- Searle's Chinese room argument: Searle (1980). Searle's original presentation of the thought experiment., Searle (1999). Discussion: Russell & Norvig (2021, pp. 985), McCorduck (2004, pp. 443–445), Crevier (1993, pp. 269–271)\n- Leith, Sam (7 July 2022). \"Nick Bostrom: How can we be certain a machine isn't conscious?\". The Spectator. Archived from the original on 26 September 2024. Retrieved 23 February 2024.\n- Thomson, Jonny (31 October 2022). \"Why don't robots have rights?\". Big Think. Archived from the original on 13 September 2024. Retrieved 23 February 2024.\n- Kateman, Brian (24 July 2023). \"AI Should Be Terrified of Humans\". Time. Archived from the original on 25 September 2024. Retrieved 23 February 2024.\n- Wong, Jeff (10 July 2023). \"What leaders need to know about robot rights\". Fast Company.\n- Hern, Alex (12 January 2017). \"Give robots 'personhood' status, EU committee argues\". The Guardian. ISSN 0261-3077. Archived from the original on 5 October 2024. Retrieved 23 February 2024.\n- Dovey, Dana (14 April 2018). \"Experts Don't Think Robots Should Have Rights\". Newsweek. Archived from the original on 5 October 2024. Retrieved 23 February 2024.\n- Cuddy, Alice (13 April 2018). \"Robot rights violate human rights, experts warn EU\". euronews. Archived from the original on 19 September 2024. Retrieved 23 February 2024.\n- The Intelligence explosion and technological singularity: Russell & Norvig (2021, pp. 1004–1005), Omohundro (2008), Kurzweil (2005) I. J. Good's \"intelligence explosion\": Good (1965) Vernor Vinge's \"singularity\": Vinge (1993)\n- Russell & Norvig (2021), p. 1005.\n- Transhumanism: Moravec (1988), Kurzweil (2005), Russell & Norvig (2021, p. 1005)\n- AI as evolution: Edward Fredkin is quoted in McCorduck (2004, p. 401), Butler (1863), Dyson (1998)\n- AI in myth: McCorduck (2004, pp. 4–5)\n- McCorduck (2004), pp. 340–400.\n- Buttazzo (2001).\n- Anderson (2008).\n- McCauley (2007).\n- Galvan (1997).\nAI textbooks\nThe two most widely used textbooks in 2023 (see the Open Syllabus):\n- Russell, Stuart J.; Norvig, Peter (2021). Artificial Intelligence: A Modern Approach (4th ed.). Hoboken: Pearson. ISBN 978-0-1346-1099-3. LCCN 20190474.\n- Rich, Elaine; Knight, Kevin; Nair, Shivashankar (2010). Artificial Intelligence (3rd ed.). New Delhi: Tata McGraw Hill India. ISBN 978-0-0700-8770-5.\nThe four most widely used AI textbooks in 2008:\n- Luger, George; Stubblefield, William (2004). Artificial Intelligence: Structures and Strategies for Complex Problem Solving (5th ed.). Benjamin/Cummings. ISBN 978-0-8053-4780-7. Archived from the original on 26 July 2020. Retrieved 17 December 2019.\n- Nilsson, Nils (1998). Artificial Intelligence: A New Synthesis. Morgan Kaufmann. ISBN 978-1-5586-0467-4. Archived from the original on 26 July 2020. Retrieved 18 November 2019.\n- Russell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN 0-13-790395-2\n- Poole, David; Mackworth, Alan; Goebel, Randy (1998). Computational Intelligence: A Logical Approach. New York: Oxford University Press. ISBN 978-0-1951-0270-3. Archived from the original on 26 July 2020. Retrieved 22 August 2020.Mackworth, Alan (2017). Artificial Intelligence: Foundations of Computational Agents (2nd ed.). Cambridge University Press. ISBN 978-1-1071-9539-4. Archived from the original on 7 December 2017. Retrieved 6 December 2017.\nOther textbooks:\n- Ertel, Wolfgang (2017). Introduction to Artificial Intelligence (2nd ed.). Springer. ISBN 978-3-3195-8486-7.\n- Ciaramella, Alberto; Ciaramella, Marco (2024). Introduction to Artificial Intelligence: from data analysis to generative AI (1st ed.). Intellisemantic Editions. ISBN 978-8-8947-8760-3.\nHistory of AI\n- Crevier, Daniel (1993). AI: The Tumultuous Search for Artificial Intelligence. New York, NY: BasicBooks. ISBN 0-465-02997-3.\n- McCorduck, Pamela (2004), Machines Who Think (2nd ed.), Natick, Massachusetts: A. K. Peters, ISBN 1-5688-1205-1\n- Newquist, H. P. (1994). The Brain Makers: Genius, Ego, And Greed In The Quest For Machines That Think. New York: Macmillan/SAMS. ISBN 978-0-6723-0412-5.\n- Harmon, Paul; Sawyer, Brian (1990). Creating Expert Systems for Business and Industry. Foreword by Dr. Edward Feigenbaum. New York: John Wiley & Sons. ISBN 0-471-61496-3.\nOther sources\n- AI & ML in Fusion\n- AI & ML in Fusion, video lecture Archived 2 July 2023 at the Wayback Machine\n- Alter, Alexandra; Harris, Elizabeth A. (20 September 2023), \"Franzen, Grisham and Other Prominent Authors Sue OpenAI\", The New York Times, archived from the original on 14 September 2024, retrieved 5 October 2024\n- Altman, Sam; Brockman, Greg; Sutskever, Ilya (22 May 2023). \"Governance of Superintelligence\". openai.com. Archived from the original on 27 May 2023. Retrieved 27 May 2023.\n- Anderson, Susan Leigh (2008). \"Asimov's \"three laws of robotics\" and machine metaethics\". AI & Society. 22 (4): 477–493. doi:10.1007/s00146-007-0094-5. S2CID 1809459.\n- Anderson, Michael; Anderson, Susan Leigh (2011). Machine Ethics. Cambridge University Press.\n- Arntz, Melanie; Gregory, Terry; Zierahn, Ulrich (2016), \"The risk of automation for jobs in OECD countries: A comparative analysis\", OECD Social, Employment, and Migration Working Papers 189\n- Asada, M.; Hosoda, K.; Kuniyoshi, Y.; Ishiguro, H.; Inui, T.; Yoshikawa, Y.; Ogino, M.; Yoshida, C. (2009). \"Cognitive developmental robotics: a survey\". IEEE Transactions on Autonomous Mental Development. 1 (1): 12–34. Bibcode:2009ITAMD...1...12A. doi:10.1109/tamd.2009.2021702. S2CID 10168773.\n- \"Ask the AI experts: What's driving today's progress in AI?\". McKinsey & Company. Archived from the original on 13 April 2018. Retrieved 13 April 2018.\n- Barfield, Woodrow; Pagallo, Ugo (2018). Research handbook on the law of artificial intelligence. Cheltenham, UK: Edward Elgar Publishing. ISBN 978-1-7864-3904-8. OCLC 1039480085.\n- Beal, J.; Winston, Patrick (2009), \"The New Frontier of Human-Level Artificial Intelligence\", IEEE Intelligent Systems, 24 (4): 21–24, Bibcode:2009IISys..24d..21B, doi:10.1109/MIS.2009.75, hdl:1721.1/52357, S2CID 32437713\n- Berdahl, Carl Thomas; Baker, Lawrence; Mann, Sean; Osoba, Osonde; Girosi, Federico (7 February 2023). \"Strategies to Improve the Impact of Artificial Intelligence on Health Equity: Scoping Review\". JMIR AI. 2 e42936. doi:10.2196/42936. ISSN 2817-1705. PMC 11041459. PMID 38875587. S2CID 256681439.\n- Berryhill, Jamie; Heang, Kévin Kok; Clogher, Rob; McBride, Keegan (2019). Hello, World: Artificial Intelligence and its Use in the Public Sector (PDF). Paris: OECD Observatory of Public Sector Innovation. Archived (PDF) from the original on 20 December 2019. Retrieved 9 August 2020.\n- Bertini, M; Del Bimbo, A; Torniai, C (2006). \"Automatic annotation and semantic retrieval of video sequences using multimedia ontologies\". MM '06 Proceedings of the 14th ACM international conference on Multimedia. 14th ACM international conference on Multimedia. Santa Barbara: ACM. pp. 679–682.\n- Bostrom, Nick (2014). Superintelligence: Paths, Dangers, Strategies. Oxford University Press.\n- Bostrom, Nick (2015). \"What happens when our computers get smarter than we are?\". TED (conference). Archived from the original on 25 July 2020. Retrieved 30 January 2020.\n- Brooks, Rodney (10 November 2014). \"artificial intelligence is a tool, not a threat\". Rethink Robotics. Archived from the original on 12 November 2014.\n- Brooks, Rodney (1990). \"Elephants Don't Play Chess\" (PDF). Robotics and Autonomous Systems. 6 (1–2): 3–15. CiteSeerX 10.1.1.588.7539. doi:10.1016/S0921-8890(05)80025-9. Archived (PDF) from the original on 9 August 2007.\n- Buiten, Miriam C (2019). \"Towards Intelligent Regulation of Artificial Intelligence\". European Journal of Risk Regulation. 10 (1): 41–59. doi:10.1017/err.2019.8. ISSN 1867-299X.\n- Bushwick, Sophie (16 March 2023), \"What the New GPT-4 AI Can Do\", Scientific American, archived from the original on 22 August 2023, retrieved 5 October 2024\n- Butler, Samuel (13 June 1863). \"Darwin among the Machines\". Letters to the Editor. The Press. Christchurch, New Zealand. Archived from the original on 19 September 2008. Retrieved 16 October 2014 – via Victoria University of Wellington.\n- Buttazzo, G. (July 2001). \"Artificial consciousness: Utopia or real possibility?\". Computer. 34 (7): 24–30. Bibcode:2001Compr..34g..24B. doi:10.1109/2.933500.\n- Cambria, Erik; White, Bebo (May 2014). \"Jumping NLP Curves: A Review of Natural Language Processing Research [Review Article]\". IEEE Computational Intelligence Magazine. 9 (2): 48–57. doi:10.1109/MCI.2014.2307227. S2CID 206451986.\n- Cellan-Jones, Rory (2 December 2014). \"Stephen Hawking warns artificial intelligence could end mankind\". BBC News. Archived from the original on 30 October 2015. Retrieved 30 October 2015.\n- Chalmers, David (1995). \"Facing up to the problem of consciousness\". Journal of Consciousness Studies. 2 (3): 200–219. CiteSeerX 10.1.1.103.8362. Archived from the original on 8 March 2005. Retrieved 11 October 2018.\n- Challa, Subhash; Moreland, Mark R.; Mušicki, Darko; Evans, Robin J. (2011). Fundamentals of Object Tracking. Cambridge University Press. doi:10.1017/CBO9780511975837. ISBN 978-0-5218-7628-5.\n- Christian, Brian (2020). The Alignment Problem: Machine learning and human values. W. W. Norton & Company. ISBN 978-0-3938-6833-3. OCLC 1233266753.\n- Ciresan, D.; Meier, U.; Schmidhuber, J. (2012). \"Multi-column deep neural networks for image classification\". 2012 IEEE Conference on Computer Vision and Pattern Recognition. pp. 3642–3649. arXiv:1202.2745. doi:10.1109/cvpr.2012.6248110. ISBN 978-1-4673-1228-8. S2CID 2161592.\n- Clark, Jack (2015b). \"Why 2015 Was a Breakthrough Year in Artificial Intelligence\". Bloomberg.com. Archived from the original on 23 November 2016. Retrieved 23 November 2016.\n- CNA (12 January 2019). \"Commentary: Bad news. Artificial intelligence is biased\". CNA. Archived from the original on 12 January 2019. Retrieved 19 June 2020.\n- Cybenko, G. (1988). Continuous valued neural networks with two hidden layers are sufficient (Report). Department of Computer Science, Tufts University.\n- Deng, L.; Yu, D. (2014). \"Deep Learning: Methods and Applications\" (PDF). Foundations and Trends in Signal Processing. 7 (3–4): 197–387. doi:10.1561/2000000039. Archived (PDF) from the original on 14 March 2016. Retrieved 18 October 2014.\n- Dennett, Daniel (1991). Consciousness Explained. The Penguin Press. ISBN 978-0-7139-9037-9.\n- DiFeliciantonio, Chase (3 April 2023). \"AI has already changed the world. This report shows how\". San Francisco Chronicle. Archived from the original on 19 June 2023. Retrieved 19 June 2023.\n- Dickson, Ben (2 May 2022). \"Machine learning: What is the transformer architecture?\". TechTalks. Archived from the original on 22 November 2023. Retrieved 22 November 2023.\n- Dockrill, Peter (27 June 2022), \"Robots With Flawed AI Make Sexist And Racist Decisions, Experiment Shows\", Science Alert, archived from the original on 27 June 2022\n- Domingos, Pedro (2015). The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World. Basic Books. ISBN 978-0-4650-6570-7.\n- Dreyfus, Hubert (1972). What Computers Can't Do. New York: MIT Press. ISBN 978-0-0601-1082-6.\n- Dreyfus, Hubert; Dreyfus, Stuart (1986). Mind over Machine: The Power of Human Intuition and Expertise in the Era of the Computer. Oxford: Blackwell. ISBN 978-0-0290-8060-3. Archived from the original on 26 July 2020. Retrieved 22 August 2020.\n- Dyson, George (1998). Darwin among the Machines. Allan Lane Science. ISBN 978-0-7382-0030-9. Archived from the original on 26 July 2020. Retrieved 22 August 2020.\n- Edelson, Edward (1991). The Nervous System. New York: Chelsea House. ISBN 978-0-7910-0464-7. Archived from the original on 26 July 2020. Retrieved 18 November 2019.\n- Edwards, Benj (17 May 2023). \"Poll: AI poses risk to humanity, according to majority of Americans\". Ars Technica. Archived from the original on 19 June 2023. Retrieved 19 June 2023.\n- Fearn, Nicholas (2007). The Latest Answers to the Oldest Questions: A Philosophical Adventure with the World's Greatest Thinkers. New York: Grove Press. ISBN 978-0-8021-1839-4.\n- Ford, Martin; Colvin, Geoff (6 September 2015). \"Will robots create more jobs than they destroy?\". The Guardian. Archived from the original on 16 June 2018. Retrieved 13 January 2018.\n- Fox News (2023). \"Fox News Poll\" (PDF). Fox News. Archived (PDF) from the original on 12 May 2023. Retrieved 19 June 2023.\n- Frey, Carl Benedikt; Osborne, Michael A (1 January 2017). \"The future of employment: How susceptible are jobs to computerisation?\". Technological Forecasting and Social Change. 114: 254–280. CiteSeerX 10.1.1.395.416. doi:10.1016/j.techfore.2016.08.019. ISSN 0040-1625.\n- \"From not working to neural networking\". The Economist. 2016. Archived from the original on 31 December 2016. Retrieved 26 April 2018.\n- Galvan, Jill (1 January 1997). \"Entering the Posthuman Collective in Philip K. Dick's \"Do Androids Dream of Electric Sheep?\"Science Fiction Studies. 24 (3): 413–429. doi:10.1525/sfs.24.3.0413. JSTOR 4240644.\n- Geist, Edward Moore (9 August 2015). \"Is artificial intelligence really an existential threat to humanity?\". Bulletin of the Atomic Scientists. Archived from the original on 30 October 2015. Retrieved 30 October 2015.\n- Gibbs, Samuel (27 October 2014). \"Elon Musk: artificial intelligence is our biggest existential threat\". The Guardian. Archived from the original on 30 October 2015. Retrieved 30 October 2015.\n- Goffrey, Andrew (2008). \"Algorithm\". In Fuller, Matthew (ed.). Software studies: a lexicon. Cambridge, Mass.: MIT Press. pp. 15–20. ISBN 978-1-4356-4787-9.\n- Goldman, Sharon (14 September 2022). \"10 years later, deep learning 'revolution' rages on, say AI pioneers Hinton, LeCun and Li\". VentureBeat. Archived from the original on 5 October 2024. Retrieved 8 December 2023.\n- Good, I. J. (1965), Speculations Concerning the First Ultraintelligent Machine, archived from the original on 10 July 2023, retrieved 5 October 2024\n- Goodfellow, Ian; Bengio, Yoshua; Courville, Aaron (2016), Deep Learning, MIT Press., archived from the original on 16 April 2016, retrieved 12 November 2017\n- Goodman, Bryce; Flaxman, Seth (2017). \"EU regulations on algorithmic decision-making and a 'right to explanation'AI Magazine. 38 (3): 50. arXiv:1606.08813. doi:10.1609/aimag.v38i3.2741. S2CID 7373959.\n- Government Accountability Office (13 September 2022). Consumer Data: Increasing Use Poses Risks to Privacy. gao.gov (Report). Archived from the original on 13 September 2024. Retrieved 5 October 2024.\n- Grant, Nico; Hill, Kashmir (22 May 2023). \"Google's Photo App Still Can't Find Gorillas. And Neither Can Apple's\". The New York Times. Archived from the original on 14 September 2024. Retrieved 5 October 2024.\n- Goswami, Rohan (5 April 2023). \"Here's where the A.I. jobs are\". CNBC. Archived from the original on 19 June 2023. Retrieved 19 June 2023.\n- Harari, Yuval Noah (October 2018). \"Why Technology Favors Tyranny\". The Atlantic. Archived from the original on 25 September 2021. Retrieved 23 September 2021.\n- Harari, Yuval Noah (2023). \"AI and the future of humanity\". YouTube. Archived from the original on 30 September 2024. Retrieved 5 October 2024.\n- Haugeland, John (1985). Artificial Intelligence: The Very Idea. Cambridge, Mass.: MIT Press. ISBN 978-0-2620-8153-5.\n- Hinton, G.; Deng, L.; Yu, D.; Dahl, G.; Mohamed, A.; Jaitly, N.; Senior, A.; Vanhoucke, V.; Nguyen, P.; Sainath, T.; Kingsbury, B. (2012). \"Deep Neural Networks for Acoustic Modeling in Speech Recognition – The shared views of four research groups\". IEEE Signal Processing Magazine. 29 (6): 82–97. Bibcode:2012ISPM...29...82H. doi:10.1109/msp.2012.2205597. S2CID 206485943.\n- Holley, Peter (28 January 2015). \"Bill Gates on dangers of artificial intelligence: 'I don't understand why some people are not concerned'. The Washington Post. ISSN 0190-8286. Archived from the original on 30 October 2015. Retrieved 30 October 2015.\n- Hornik, Kurt; Stinchcombe, Maxwell; White, Halbert (1989). Multilayer Feedforward Networks are Universal Approximators (PDF). Neural Networks. Vol. 2. Pergamon Press. pp. 359–366. Archived (PDF) from the original on 21 April 2023. Retrieved 5 October 2024.\n- Horst, Steven (2005). \"The Computational Theory of Mind\". The Stanford Encyclopedia of Philosophy. Archived from the original on 6 March 2016. Retrieved 7 March 2016.\n- Howe, J. (November 1994). \"Artificial Intelligence at Edinburgh University: a Perspective\". Archived from the original on 15 May 2007. Retrieved 30 August 2007.\n- IGM Chicago (30 June 2017). \"Robots and Artificial Intelligence\". igmchicago.org. Archived from the original on 1 May 2019. Retrieved 3 July 2019.\n- Iphofen, Ron; Kritikos, Mihalis (3 January 2019). \"Regulating artificial intelligence and robotics: ethics by design in a digital society\". Contemporary Social Science. 16 (2): 170–184. doi:10.1080/21582041.2018.1563803. ISSN 2158-2041. S2CID 59298502.\n- Jordan, M. I.; Mitchell, T. M. (16 July 2015). \"Machine learning: Trends, perspectives, and prospects\". Science. 349 (6245): 255–260. Bibcode:2015Sci...349..255J. doi:10.1126/science.aaa8415. PMID 26185243. S2CID 677218.\n- Kahneman, Daniel (2011). Thinking, Fast and Slow. Macmillan. ISBN 978-1-4299-6935-2. Archived from the original on 15 March 2023. Retrieved 8 April 2012.\n- Kahneman, Daniel; Slovic, D.; Tversky, Amos (1982). \"Judgment under uncertainty: Heuristics and biases\". Science. 185 (4157). New York: Cambridge University Press: 1124–1131. Bibcode:1974Sci...185.1124T. doi:10.1126/science.185.4157.1124. ISBN 978-0-5212-8414-1. PMID 17835457. S2CID 143452957.\n- Kasperowicz, Peter (1 May 2023). \"Regulate AI? GOP much more skeptical than Dems that government can do it right: poll\". Fox News. Archived from the original on 19 June 2023. Retrieved 19 June 2023.\n- Katz, Yarden (1 November 2012). \"Noam Chomsky on Where Artificial Intelligence Went Wrong\". The Atlantic. Archived from the original on 28 February 2019. Retrieved 26 October 2014.\n- \"Kismet\". MIT Artificial Intelligence Laboratory, Humanoid Robotics Group. Archived from the original on 17 October 2014. Retrieved 25 October 2014.\n- Kissinger, Henry (1 November 2021). \"The Challenge of Being Human in the Age of AI\". The Wall Street Journal. Archived from the original on 4 November 2021. Retrieved 4 November 2021.\n- Kobielus, James (27 November 2019). \"GPUs Continue to Dominate the AI Accelerator Market for Now\". InformationWeek. Archived from the original on 19 October 2021. Retrieved 11 June 2020.\n- Kuperman, G. J.; Reichley, R. M.; Bailey, T. C. (1 July 2006). \"Using Commercial Knowledge Bases for Clinical Decision Support: Opportunities, Hurdles, and Recommendations\". Journal of the American Medical Informatics Association. 13 (4): 369–371. doi:10.1197/jamia.M2055. PMC 1513681. PMID 16622160.\n- Kurzweil, Ray (2005). The Singularity is Near. Penguin Books. ISBN 978-0-6700-3384-3.\n- Langley, Pat (2011). \"The changing science of machine learning\". Machine Learning. 82 (3): 275–279. doi:10.1007/s10994-011-5242-y.\n- Larson, Jeff; Angwin, Julia (23 May 2016). \"How We Analyzed the COMPAS Recidivism Algorithm\". ProPublica. Archived from the original on 29 April 2019. Retrieved 19 June 2020.\n- Laskowski, Nicole (November 2023). \"What is Artificial Intelligence and How Does AI Work? TechTarget\". Enterprise AI. Archived from the original on 5 October 2024. Retrieved 30 October 2023.\n- Law Library of Congress (U.S.). Global Legal Research Directorate, issuing body. (2019). Regulation of artificial intelligence in selected jurisdictions. LCCN 2019668143. OCLC 1110727808.\n- Lee, Timothy B. (22 August 2014). \"Will artificial intelligence destroy humanity? Here are 5 reasons not to worry\". Vox. Archived from the original on 30 October 2015. Retrieved 30 October 2015.\n- Lenat, Douglas; Guha, R. V. (1989). Building Large Knowledge-Based Systems. Addison-Wesley. ISBN 978-0-2015-1752-1.\n- Lighthill, James (1973). \"Artificial Intelligence: A General Survey\". Artificial Intelligence: a paper symposium. Science Research Council.\n- Lipartito, Kenneth (6 January 2011), The Narrative and the Algorithm: Genres of Credit Reporting from the Nineteenth Century to Today (PDF) (Unpublished manuscript), doi:10.2139/ssrn.1736283, S2CID 166742927, archived (PDF) from the original on 9 October 2022\n- Lohr, Steve (2017). \"Robots Will Take Jobs, but Not as Fast as Some Fear, New Report Says\". The New York Times. Archived from the original on 14 January 2018. Retrieved 13 January 2018.\n- Lungarella, M.; Metta, G.; Pfeifer, R.; Sandini, G. (2003). \"Developmental robotics: a survey\". Connection Science. 15 (4): 151–190. Bibcode:2003ConSc..15..151L. CiteSeerX 10.1.1.83.7615. doi:10.1080/09540090310001655110. S2CID 1452734.\n- \"Machine Ethics\". aaai.org. Archived from the original on 29 November 2014.\n- Madrigal, Alexis C. (27 February 2015). \"The case against killer robots, from a guy actually working on artificial intelligence\". Fusion.net. Archived from the original on 4 February 2016. Retrieved 31 January 2016.\n- Mahdawi, Arwa (26 June 2017). \"What jobs will still be around in 20 years? Read this to prepare your future\". The Guardian. Archived from the original on 14 January 2018. Retrieved 13 January 2018.\n- Maker, Meg Houston (2006), AI@50: AI Past, Present, Future, Dartmouth College, archived from the original on 8 October 2008, retrieved 16 October 2008\n- Marmouyet, Françoise (15 December 2023). \"Google's Gemini: is the new AI model really better than ChatGPT?\". The Conversation. Archived from the original on 4 March 2024. Retrieved 25 December 2023.\n- Minsky, Marvin (1986), The Society of Mind, Simon and Schuster\n- McCarthy, John; Minsky, Marvin; Rochester, Nathan; Shannon, Claude (1955). \"A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence\". stanford.edu. Archived from the original on 26 August 2007. Retrieved 30 August 2007.\n- McCarthy, John (2007), \"From Here to Human-Level AI\", Artificial Intelligence, p. 171\n- McCarthy, John (1999), What is AI?, archived from the original on 4 December 2022, retrieved 4 December 2022\n- McCauley, Lee (2007). \"AI armageddon and the three laws of robotics\". Ethics and Information Technology. 9 (2): 153–164. CiteSeerX 10.1.1.85.8904. doi:10.1007/s10676-007-9138-2. S2CID 37272949.\n- McGarry, Ken (1 December 2005). \"A survey of interestingness measures for knowledge discovery\". The Knowledge Engineering Review. 20 (1): 39–61. doi:10.1017/S0269888905000408. S2CID 14987656.\n- McGaughey, E (2022), Will Robots Automate Your Job Away? Full Employment, Basic Income, and Economic Democracy, p. 51(3) Industrial Law Journal 511–559, doi:10.2139/ssrn.3044448, S2CID 219336439, SSRN 3044448, archived from the original on 31 January 2021, retrieved 27 May 2023\n- Merkle, Daniel; Middendorf, Martin (2013). \"Swarm Intelligence\". In Burke, Edmund K.; Kendall, Graham (eds.). Search Methodologies: Introductory Tutorials in Optimization and Decision Support Techniques. Springer Science & Business Media. ISBN 978-1-4614-6940-7.\n- Minsky, Marvin (1967), Computation: Finite and Infinite Machines, Englewood Cliffs, N.J.: Prentice-Hall\n- Moravec, Hans (1988). Mind Children. Harvard University Press. ISBN 978-0-6745-7616-2. Archived from the original on 26 July 2020. Retrieved 18 November 2019.\n- Morgenstern, Michael (9 May 2015). \"Automation and anxiety\". The Economist. Archived from the original on 12 January 2018. Retrieved 13 January 2018.\n- Müller, Vincent C.; Bostrom, Nick (2014). \"Future Progress in Artificial Intelligence: A Poll Among Experts\" (PDF). AI Matters. 1 (1): 9–11. doi:10.1145/2639475.2639478. S2CID 8510016. Archived (PDF) from the original on 15 January 2016.\n- Neumann, Bernd; Möller, Ralf (January 2008). \"On scene interpretation with description logics\". Image and Vision Computing. 26 (1): 82–101. doi:10.1016/j.imavis.2007.08.013. S2CID 10767011.\n- Nilsson, Nils (1995), \"Eyes on the Prize\", AI Magazine, vol. 16, pp. 9–17\n- Newell, Allen; Simon, H. A. (1976). \"Computer Science as Empirical Inquiry: Symbols and Search\". Communications of the ACM. 19 (3): 113–126. doi:10.1145/360018.360022.\n- Nicas, Jack (7 February 2018). \"How YouTube Drives People to the Internet's Darkest Corners\". The Wall Street Journal. ISSN 0099-9660. Archived from the original on 5 October 2024. Retrieved 16 June 2018.\n- Nilsson, Nils (1983). \"Artificial Intelligence Prepares for 2001\" (PDF). AI Magazine. 1 (1). Archived (PDF) from the original on 17 August 2020. Retrieved 22 August 2020.Association for the Advancement of Artificial Intelligence.\n- NRC (United States National Research Council) (1999). \"Developments in Artificial Intelligence\". Funding a Revolution: Government Support for Computing Research. National Academy Press.\n- Omohundro, Steve (2008). The Nature of Self-Improving Artificial Intelligence. presented and distributed at the 2007 Singularity Summit, San Francisco, CA.\n- Oudeyer, P-Y. (2010). \"On the impact of robotics in behavioral and cognitive sciences: from insect navigation to human cognitive development\" (PDF). IEEE Transactions on Autonomous Mental Development. 2 (1): 2–16. Bibcode:2010ITAMD...2....2O. doi:10.1109/tamd.2009.2039057. S2CID 6362217. Archived (PDF) from the original on 3 October 2018. Retrieved 4 June 2013.\n- Pennachin, C.; Goertzel, B. (2007). \"Contemporary Approaches to Artificial General Intelligence\". Artificial General Intelligence. Cognitive Technologies. Berlin, Heidelberg: Springer. pp. 1–30. doi:10.1007/978-3-540-68677-4_1. ISBN 978-3-5402-3733-4.\n- Pinker, Steven (2007) [1994], The Language Instinct, Perennial Modern Classics, Harper, ISBN 978-0-0613-3646-1\n- Poria, Soujanya; Cambria, Erik; Bajpai, Rajiv; Hussain, Amir (September 2017). \"A review of affective computing: From unimodal analysis to multimodal fusion\". Information Fusion. 37: 98–125. doi:10.1016/j.inffus.2017.02.003. hdl:1893/25490. S2CID 205433041. Archived from the original on 23 March 2023. Retrieved 27 April 2021.\n- Rawlinson, Kevin (29 January 2015). \"Microsoft's Bill Gates insists AI is a threat\". BBC News. Archived from the original on 29 January 2015. Retrieved 30 January 2015.\n- Reisner, Alex (19 August 2023), \"Revealed: The Authors Whose Pirated Books are Powering Generative AI\", The Atlantic, archived from the original on 3 October 2024, retrieved 5 October 2024\n- Roberts, Jacob (2016). \"Thinking Machines: The Search for Artificial Intelligence\". Distillations. Vol. 2, no. 2. pp. 14–23. Archived from the original on 19 August 2018. Retrieved 20 March 2018.\n- Robitzski, Dan (5 September 2018). \"Five experts share what scares them the most about AI\". Archived from the original on 8 December 2019. Retrieved 8 December 2019.\n- Rose, Steve (11 July 2023). \"AI Utopia or dystopia?\". The Guardian Weekly. pp. 42–43.\n- Russell, Stuart (2019). Human Compatible: Artificial Intelligence and the Problem of Control. United States: Viking. ISBN 978-0-5255-5861-3. OCLC 1083694322.\n- Sainato, Michael (19 August 2015). \"Stephen Hawking, Elon Musk, and Bill Gates Warn About Artificial Intelligence\". Observer. Archived from the original on 30 October 2015. Retrieved 30 October 2015.\n- Sample, Ian (5 November 2017). \"Computer says no: why making AIs fair, accountable and transparent is crucial\". The Guardian. Archived from the original on 10 October 2022. Retrieved 30 January 2018.\n- Rothman, Denis (7 October 2020). \"Exploring LIME Explanations and the Mathematics Behind It\". Codemotion. Archived from the original on 25 November 2023. Retrieved 25 November 2023.\n- Scassellati, Brian (2002). \"Theory of mind for a humanoid robot\". Autonomous Robots. 12 (1): 13–24. doi:10.1023/A:1013298507114. S2CID 1979315.\n- Schmidhuber, J. (2015). \"Deep Learning in Neural Networks: An Overview\". Neural Networks. 61: 85–117. arXiv:1404.7828. doi:10.1016/j.neunet.2014.09.003. PMID 25462637. S2CID 11715509.\n- Schmidhuber, Jürgen (2022). \"Annotated History of Modern AI and Deep Learning\". Archived from the original on 7 August 2023. Retrieved 5 October 2024.\n- Searle, John (1980). \"Minds, Brains and Programs\" (PDF). Behavioral and Brain Sciences. 3 (3): 417–457. doi:10.1017/S0140525X00005756. S2CID 55303721. Archived (PDF) from the original on 17 March 2019. Retrieved 22 August 2020.\n- Searle, John (1999). Mind, language and society. New York: Basic Books. ISBN 978-0-4650-4521-1. OCLC 231867665. Archived from the original on 26 July 2020. Retrieved 22 August 2020.\n- Simon, H. A. (1965), The Shape of Automation for Men and Management, New York: Harper & Row\n- Simonite, Tom (31 March 2016). \"How Google Plans to Solve Artificial Intelligence\". MIT Technology Review. Archived from the original on 16 September 2024. Retrieved 5 October 2024.\n- Smith, Craig S. (15 March 2023). \"ChatGPT-4 Creator Ilya Sutskever on AI Hallucinations and AI Democracy\". Forbes. Archived from the original on 18 September 2024. Retrieved 25 December 2023.\n- Smoliar, Stephen W.; Zhang, HongJiang (1994). \"Content based video indexing and retrieval\". IEEE MultiMedia. 1 (2): 62–72. doi:10.1109/93.311653. S2CID 32710913.\n- Solomonoff, Ray (1956). An Inductive Inference Machine (PDF). Dartmouth Summer Research Conference on Artificial Intelligence. Archived (PDF) from the original on 26 April 2011. Retrieved 22 March 2011 – via std.com, pdf scanned copy of the original.\nSolomonoff, Ray (1957). \"An Inductive Inference Machine\". IRE Convention Record. Vol. Section on Information Theory, part 2. pp. 56–62. - Stanford University (2023). \"Artificial Intelligence Index Report 2023/Chapter 6: Policy and Governance\" (PDF). AI Index. Archived (PDF) from the original on 19 June 2023. Retrieved 19 June 2023.\n- Stewart, Jon (9 October 2025). \"AI: What Could Go Wrong? With Geoffrey Hinton\". The Weekly Show with Jon Stewart (Podcast).\n- Tao, Jianhua; Tan, Tieniu (2005). Affective Computing and Intelligent Interaction. Affective Computing: A Review. Lecture Notes in Computer Science. Vol. 3784. Springer. pp. 981–995. doi:10.1007/11573548. ISBN 978-3-5402-9621-8.\n- Taylor, Josh; Hern, Alex (2 May 2023). \". The Guardian. Archived from the original on 5 October 2024. Retrieved 5 October 2024.\n- Thompson, Derek (23 January 2014). \"What Jobs Will the Robots Take?\". The Atlantic. Archived from the original on 24 April 2018. Retrieved 24 April 2018.\n- Thro, Ellen (1993). Robotics: The Marriage of Computers and Machines. New York: Facts on File. ISBN 978-0-8160-2628-9. Archived from the original on 26 July 2020. Retrieved 22 August 2020.\n- Toews, Rob (3 September 2023). \"Transformers Revolutionized AI. What Will Replace Them?\". Forbes. Archived from the original on 8 December 2023. Retrieved 8 December 2023.\n- Turing, Alan (October 1950). \"Computing Machinery and Intelligence\". Mind. 59 (236): 433–460. doi:10.1093/mind/LIX.236.433. ISSN 1460-2113. JSTOR 2251299. S2CID 14636783.\n- UNESCO Science Report: the Race Against Time for Smarter Development. Paris: UNESCO. 2021. ISBN 978-9-2310-0450-6. Archived from the original on 18 June 2022. Retrieved 18 September 2021.\n- Urbina, Fabio; Lentzos, Filippa; Invernizzi, Cédric; Ekins, Sean (7 March 2022). \"Dual use of artificial-intelligence-powered drug discovery\". Nature Machine Intelligence. 4 (3): 189–191. doi:10.1038/s42256-022-00465-9. PMC 9544280. PMID 36211133. S2CID 247302391.\n- Valance, Christ (30 May 2023). \"Artificial intelligence could lead to extinction, experts warn\". BBC News. Archived from the original on 17 June 2023. Retrieved 18 June 2023.\n- Valinsky, Jordan (11 April 2019), \"Amazon reportedly employs thousands of people to listen to your Alexa conversations\", CNN.com, archived from the original on 26 January 2024, retrieved 5 October 2024\n- Verma, Yugesh (25 December 2021). \"A Complete Guide to SHAP – SHAPley Additive exPlanations for Practitioners\". Analytics India Magazine. Archived from the original on 25 November 2023. Retrieved 25 November 2023.\n- Vincent, James (7 November 2019). \"OpenAI has published the text-generating AI it said was too dangerous to share\". The Verge. Archived from the original on 11 June 2020. Retrieved 11 June 2020.\n- Vincent, James (15 November 2022). \"The scary truth about AI copyright is nobody knows what will happen next\". The Verge. Archived from the original on 19 June 2023. Retrieved 19 June 2023.\n- Vincent, James (3 April 2023). \"AI is entering an era of corporate control\". The Verge. Archived from the original on 19 June 2023. Retrieved 19 June 2023.\n- Vinge, Vernor (1993). \"The Coming Technological Singularity: How to Survive in the Post-Human Era\". Vision 21: Interdisciplinary Science and Engineering in the Era of Cyberspace: 11. Bibcode:1993vise.nasa...11V. Archived from the original on 1 January 2007. Retrieved 14 November 2011.\n- Waddell, Kaveh (2018). \"Chatbots Have Entered the Uncanny Valley\". The Atlantic. Archived from the original on 24 April 2018. Retrieved 24 April 2018.\n- Wallach, Wendell (2010). Moral Machines. Oxford University Press.\n- Wason, P. C.; Shapiro, D. (1966). \"Reasoning\". In Foss, B. M. (ed.). New horizons in psychology. Harmondsworth: Penguin. Archived from the original on 26 July 2020. Retrieved 18 November 2019.\n- Weng, J.; McClelland; Pentland, A.; Sporns, O.; Stockman, I.; Sur, M.; Thelen, E. (2001). \"Autonomous mental development by robots and animals\" (PDF). Science. 291 (5504): 599–600. doi:10.1126/science.291.5504.599. PMID 11229402. S2CID 54131797. Archived (PDF) from the original on 4 September 2013. Retrieved 4 June 2013 – via msu.edu.\n- \"What is 'fuzzy logic'? Are there computers that are inherently fuzzy and do not apply the usual binary logic?\". Scientific American. 21 October 1999. Archived from the original on 6 May 2018. Retrieved 5 May 2018.\n- Williams, Rhiannon (28 June 2023), \"Humans may be more likely to believe disinformation generated by AI\", MIT Technology Review, archived from the original on 16 September 2024, retrieved 5 October 2024\n- Wirtz, Bernd W.; Weyerer, Jan C.; Geyer, Carolin (24 July 2018). \"Artificial Intelligence and the Public Sector – Applications and Challenges\". International Journal of Public Administration. 42 (7): 596–615. doi:10.1080/01900692.2018.1498103. ISSN 0190-0692. S2CID 158829602. Archived from the original on 18 August 2020. Retrieved 22 August 2020.\n- Wong, Matteo (19 May 2023), \"ChatGPT Is Already Obsolete\", The Atlantic, archived from the original on 18 September 2024, retrieved 5 October 2024\n- Yudkowsky, E (2008), \"Artificial Intelligence as a Positive and Negative Factor in Global Risk\" (PDF), Global Catastrophic Risks, Oxford University Press, 2008, Bibcode:2008gcr..book..303Y, archived (PDF) from the original on 19 October 2013, retrieved 24 September 2021\nFurther reading\n- Autor, David H., \"Why Are There Still So Many Jobs? The History and Future of Workplace Automation\" (2015) 29(3) Journal of Economic Perspectives 3.\n- Boyle, James, The Line: AI and the Future of Personhood, MIT Press, 2024.\n- Cukier, Kenneth, \"Ready for Robots? How to Think about the Future of AI\", Foreign Affairs, vol. 98, no. 4 (July/August 2019), pp. 192–198. George Dyson, historian of computing, writes (in what might be called \"Dyson's Law\") that \"Any system simple enough to be understandable will not be complicated enough to behave intelligently, while any system complicated enough to behave intelligently will be too complicated to understand.\" (p. 197.) Computer scientist Alex Pentland writes: \"Current AI machine-learning algorithms are, at their core, dead simple stupid. They work, but they work by brute force.\" (p. 198.)\n- Evans, Woody (2015). \"Posthuman Rights: Dimensions of Transhuman Worlds\". Teknokultura. 12 (2). doi:10.5209/rev_TK.2015.v12.n2.49072. S2CID 147612763.\n- Frank, Michael (22 September 2023). \"US Leadership in Artificial Intelligence Can Shape the 21st Century Global Order\". The Diplomat. Archived from the original on 16 September 2024. Retrieved 8 December 2023.\nInstead, the United States has developed a new area of dominance that the rest of the world views with a mixture of awe, envy, and resentment: artificial intelligence... From AI models and research to cloud computing and venture capital, U.S. companies, universities, and research labs – and their affiliates in allied countries – appear to have an enormous lead in both developing cutting-edge AI and commercializing it. The value of U.S. venture capital investments in AI start-ups exceeds that of the rest of the world combined.\n- Gertner, Jon. (2023) \"Wikipedia's Moment of Truth: Can the online encyclopedia help teach A.I. chatbots to get their facts right — without destroying itself in the process?\" New York Times Magazine (18 July 2023) online Archived 20 July 2023 at the Wayback Machine\n- Gleick, James, \"The Fate of Free Will\" (review of Kevin J. Mitchell, Free Agents: How Evolution Gave Us Free Will, Princeton University Press, 2023, 333 pp.), The New York Review of Books, vol. LXXI, no. 1 (18 January 2024), pp. 27–28, 30. \"Agency is what distinguishes us from machines. For biological creatures, reason and purpose come from acting in the world and experiencing the consequences. Artificial intelligences – disembodied, strangers to blood, sweat, and tears – have no occasion for that.\" (p. 30.)\n- Gleick, James, \"The Parrot in the Machine\" (review of Emily M. Bender and Alex Hanna, The AI Con: How to Fight Big Tech's Hype and Create the Future We Want, Harper, 274 pp.; and James Boyle, The Line: AI and the Future of Personhood, MIT Press, 326 pp.), The New York Review of Books, vol. LXXII, no. 12 (24 July 2025), pp. 43–46. \"[C]hatbox 'writing' has a bland, regurgitated quality. Textures are flattened, sharp edges are sanded. No chatbox could ever have said that April is the cruelest month or that fog comes on little cat feet (though they might now, because one of their chief skills is plagiarism). And when synthetically extruded text turns out wrong, it can be comically wrong. When a movie fan asked Google whether a certain actor was in Heat, he received this 'AI Overview': 'No, Angelina Jolie is not in heat.'\" (p. 44.)\n- Halpern, Sue, \"The Coming Tech Autocracy\" (review of Verity Harding, AI Needs You: How We Can Change AI's Future and Save Our Own, Princeton University Press, 274 pp.; Gary Marcus, Taming Silicon Valley: How We Can Ensure That AI Works for Us, MIT Press, 235 pp.; Daniela Rus and Gregory Mone, The Mind's Mirror: Risk and Reward in the Age of AI, Norton, 280 pp.; Madhumita Murgia, Code Dependent: Living in the Shadow of AI, Henry Holt, 311 pp.), The New York Review of Books, vol. LXXI, no. 17 (7 November 2024), pp. 44–46. \"'We can't realistically expect that those who hope to get rich from AI are going to have the interests of the rest of us close at heart,' ... writes [Gary Marcus]. 'We can't count on governments driven by campaign finance contributions [from tech companies] to push back.'... Marcus details the demands that citizens should make of their governments and the tech companies. They include transparency on how AI systems work; compensation for individuals if their data [are] used to train LLMs (large language model)s and the right to consent to this use; and the ability to hold tech companies liable for the harms they cause by eliminating Section 230, imposing cash penalties, and passing stricter product liability laws... Marcus also suggests... that a new, AI-specific federal agency, akin to the FDA, the FCC, or the FTC, might provide the most robust oversight.... [T]he Fordham law professor Chinmayi Sharma... suggests... establish[ing] a professional licensing regime for engineers that would function in a similar way to medical licenses, malpractice suits, and the Hippocratic oath in medicine. 'What if, like doctors,' she asks..., 'AI engineers also vowed to do no harm?'\" (p. 46.)\n- Henderson, Mark (24 April 2007). \"Human rights for robots? We're getting carried away\". The Times Online. London. Archived from the original on 31 May 2014. Retrieved 31 May 2014.\n- Hughes-Castleberry, Kenna, \"A Murder Mystery Puzzle: The literary puzzle Cain's Jawbone, which has stumped humans for decades, reveals the limitations of natural-language-processing algorithms\", Scientific American, vol. 329, no. 4 (November 2023), pp. 81–82. \"This murder mystery competition has revealed that although NLP (natural-language processing) models are capable of incredible feats, their abilities are very much limited by the amount of context they receive. This [...] could cause [difficulties] for researchers who hope to use them to do things such as analyze ancient languages. In some cases, there are few historical records on long-gone civilizations to serve as training data for such a purpose.\" (p. 82.)\n- Immerwahr, Daniel, \"Your Lying Eyes: People now use A.I. to generate fake videos indistinguishable from real ones. How much does it matter?\", The New Yorker, 20 November 2023, pp. 54–59. \"If by 'deepfakes' we mean realistic videos produced using artificial intelligence that actually deceive people, then they barely exist. The fakes aren't deep, and the deeps aren't fake. [...] A.I.-generated videos are not, in general, operating in our media as counterfeited evidence. Their role better resembles that of cartoons, especially smutty ones.\" (p. 59.)\n- Johnston, John (2008) The Allure of Machinic Life: Cybernetics, Artificial Life, and the New AI, MIT Press.\n- Jumper, John; Evans, Richard; Pritzel, Alexander; et al. (26 August 2021). \"Highly accurate protein structure prediction with AlphaFold\". Nature. 596 (7873): 583–589. Bibcode:2021Natur.596..583J. doi:10.1038/s41586-021-03819-2. PMC 8371605. PMID 34265844. S2CID 235959867.\n- LeCun, Yann; Bengio, Yoshua; Hinton, Geoffrey (28 May 2015). \"Deep learning\". Nature. 521 (7553): 436–444. Bibcode:2015Natur.521..436L. doi:10.1038/nature14539. PMID 26017442. S2CID 3074096. Archived from the original on 5 June 2023. Retrieved 19 June 2023.\n- Leffer, Lauren, \"The Risks of Trusting AI: We must avoid humanizing machine-learning models used in scientific research\", Scientific American, vol. 330, no. 6 (June 2024), pp. 80–81.\n- Lepore, Jill, \"The Chit-Chatbot: Is talking with a machine a conversation?\", The New Yorker, 7 October 2024, pp. 12–16.\n- Maschafilm (2010). \"Content: Plug & Pray Film – Artificial Intelligence – Robots\". plugandpray-film.de. Archived from the original on 12 February 2016.\n- Marcus, Gary, \"Am I Human?: Researchers need new ways to distinguish artificial intelligence from the natural kind\", Scientific American, vol. 316, no. 3 (March 2017), pp. 58–63. Marcus points out a so far insuperable stumbling block to artificial intelligence: an incapacity for reliable disambiguation. \"[V]irtually every sentence [that people generate] is ambiguous, often in multiple ways. Our brain is so good at comprehending language that we do not usually notice.\" (p. 63.) A prominent example is known as the \"pronoun disambiguation problem\" (\"PDP\"): a machine has no way of determining to whom or what a pronoun in a sentence—such as \"he\", \"she\" or \"it\"—refers. (p. 61.)\n- Marcus, Gary, \"Artificial Confidence: Even the newest, buzziest systems of artificial general intelligence are stymmied by the same old problems\", Scientific American, vol. 327, no. 4 (October 2022), pp. 42–45.\n- Mitchell, Melanie (2019). Artificial intelligence: a guide for thinking humans. New York: Farrar, Straus and Giroux. ISBN 978-0-3742-5783-5.\n- Mnih, Volodymyr; Kavukcuoglu, Koray; Silver, David; et al. (26 February 2015). \"Human-level control through deep reinforcement learning\". Nature. 518 (7540): 529–533. Bibcode:2015Natur.518..529M. doi:10.1038/nature14236. PMID 25719670. S2CID 205242740. Archived from the original on 19 June 2023. Retrieved 19 June 2023.DQN, which produced human-level performance on some Atari games.\n- Press, Eyal, \"In Front of Their Faces: Does facial-recognition technology lead police to ignore contradictory evidence?\", The New Yorker, 20 November 2023, pp. 20–26.\n- \"Robots could demand legal rights\". BBC News. 21 December 2006. Archived from the original on 15 October 2019. Retrieved 3 February 2011.\n- Roivainen, Eka, \"AI's IQ: ChatGPT aced a [standard intelligence] test but showed that intelligence cannot be measured by IQ alone\", Scientific American, vol. 329, no. 1 (July/August 2023), p. 7. \"Despite its high IQ, ChatGPT fails at tasks that require real humanlike reasoning or an understanding of the physical and social world.... ChatGPT seemed unable to reason logically and tried to rely on its vast database of... facts derived from online texts.\"\n- Scharre, Paul, \"Killer Apps: The Real Dangers of an AI Arms Race\", Foreign Affairs, vol. 98, no. 3 (May/June 2019), pp. 135–144. \"Today's AI technologies are powerful but unreliable. Rules-based systems cannot deal with circumstances their programmers did not anticipate. Learning systems are limited by the data on which they were trained. AI failures have already led to tragedy. Advanced autopilot features in cars, although they perform well in some circumstances, have driven cars without warning into trucks, concrete barriers, and parked cars. In the wrong situation, AI systems go from supersmart to superdumb in an instant. When an enemy is trying to manipulate and hack an AI system, the risks are even greater.\" (p. 140.)\n- Schulz, Hannes; Behnke, Sven (1 November 2012). \"Deep Learning\". KI – Künstliche Intelligenz. 26 (4): 357–363. doi:10.1007/s13218-012-0198-z. ISSN 1610-1987. S2CID 220523562.\n- Serenko, Alexander; Michael Dohan (2011). \"Comparing the expert survey and citation impact journal ranking methods: Example from the field of Artificial Intelligence\" (PDF). Journal of Informetrics. 5 (4): 629–649. doi:10.1016/j.joi.2011.06.002. Archived (PDF) from the original on 4 October 2013. Retrieved 12 September 2013.\n- Silver, David; Huang, Aja; Maddison, Chris J.; et al. (28 January 2016). \"Mastering the game of Go with deep neural networks and tree search\". Nature. 529 (7587): 484–489. Bibcode:2016Natur.529..484S. doi:10.1038/nature16961. PMID 26819042. S2CID 515925. Archived from the original on 18 June 2023. Retrieved 19 June 2023.\n- Tarnoff, Ben, \"The Labor Theory of AI\" (review of Matteo Pasquinelli, The Eye of the Master: A Social History of Artificial Intelligence, Verso, 2024, 264 pp.), The New York Review of Books, vol. LXXII, no. 5 (27 March 2025), pp. 30–32. The reviewer, Ben Tarnoff, writes: \"The strangeness at the heart of the generative AI boom is that nobody really knows how the technology works. We know how the large language models within ChatGPT and its counterparts are trained, even if we don't always know which data they're being trained on: they are asked to predict the next string of characters in a sequence. But exactly how they arrive at any given prediction is a mystery. The computations that occur inside the model are simply too intricate for any human to comprehend.\" (p. 32.)\n- Vaswani, Ashish, Noam Shazeer, Niki Parmar et al. \"Attention is all you need.\" Advances in neural information processing systems 30 (2017). Seminal paper on transformers.\n- Vincent, James, \"Horny Robot Baby Voice: James Vincent on AI chatbots\", London Review of Books, vol. 46, no. 19 (10 October 2024), pp. 29–32. \"[AI chatbot] programs are made possible by new technologies but rely on the timelelss human tendency to anthropomorphise.\" (p. 29.)\n- White Paper: On Artificial Intelligence – A European approach to excellence and trust (PDF). Brussels: European Commission. 2020. Archived (PDF) from the original on 20 February 2020. Retrieved 20 February 2020.\nExternal links\n- Hauser, Larry. \"Artificial Intelligence\". In Fieser, James; Dowden, Bradley (eds.). Internet Encyclopedia of Philosophy. ISSN 2161-0002. OCLC 37741658.",
    "automotive industry": "The automotive industry comprises a wide range of companies and organizations involved in the design, development, manufacturing, marketing, selling, repairing, and modification of motor vehicles.[1][2] It is one of the world's largest industries by revenue (from 16% such as in France up to 40% in countries such as Slovakia).[3][failed verification]\nThe word automotive comes from the Greek autos (self), and Latin motivus (of motion), referring to any form of self-powered vehicle. This term, as proposed by Elmer Sperry[4][need quotation to verify] (1860–1930), first came into use to describe automobiles in 1898.[5]\nThe automotive industry began in the 1860s with hundreds of manufacturers pioneering the horseless carriage. Early car manufacturing involved manual assembly by a human worker. The process evolved from engineers working on a stationary car to a conveyor belt system where the car passed through multiple stations of more specialized engineers. In the 1960s, robotic equipment was introduced, and most cars are now mainly assembled by automated machinery.[6]\nFor many decades, the United States led the world in total automobile production, with the U.S. Big Three General Motors, Ford Motor Company, and Chrysler being the world's three largest auto manufacturers for a time, and G.M. and Ford remaining the two largest until the mid-2000s. In 1929, before the Great Depression, the world had 32,028,500 automobiles in use, of which the U.S. automobile enterprises produced more than 90%. At that time, the U.S. had one car per 4.87 persons.[7] After 1945, the U.S. produced around three-quarters of the world's auto production. In 1980, the U.S. was overtaken by Japan and then became a world leader again in 1994. Japan narrowly passed the U.S. in production during 2006 and 2007, and in 2008 also China, which in 2009 took the top spot (from Japan) with 13.8 million units, although the U.S. surpassed Japan in 2011, to become the second-largest automobile industry. In 2024, China produced more than 31 million vehicles in a year, after breaking 30 million in 2023, reaching 29 million for the first time in 2017 and 28 million the year before. In 2024, China produced the most passenger cars in the world, with Japan, India, Germany, and South Korea trailing. This was achieved by Chinese car companies signing joint ventures with foreign manufacturers.[8] From 1970 (140 models) to 1998 (260 models) to 2012 (684 models), the number of automobile models in the U.S. has grown exponentially.[9]\nSafety is a state that implies being protected from any risk, danger, damage, or cause of injury. In the automotive industry, safety means that users, operators, or manufacturers do not face any risk or danger coming from the motor vehicle or its spare parts. Safety for the automobiles themselves implies that there is no risk of damage.\nSafety in the automotive industry is particularly important and therefore highly regulated. Automobiles and other motor vehicles have to comply with a certain number of regulations, whether local or international, in order to be accepted on the market. The standard ISO 26262, is considered one of the best practice frameworks for achieving automotive functional safety.[10]\nIn case of safety issues, danger, product defect,[11][12] or faulty procedure during the manufacturing of the motor vehicle, the maker can request to return either a batch or the entire production run. This procedure is called product recall. Product recalls happen in every industry and can be production-related or stem from raw materials.\nProduct and operation tests and inspections at different stages of the value chain are made to avoid these product recalls by ensuring end-user security and safety and compliance with the automotive industry requirements. However, the automotive industry is still particularly concerned about product recalls, which cause considerable financial consequences.\nIn 2007, there were about 806 million cars and light trucks on the road, consuming over 980 billion litres (980,000,000 m3) of gasoline and diesel fuel yearly.[13] The automobile is a primary mode of transportation for many developed economies. The Detroit branch of Boston Consulting Group predicted that, by 2014, one-third of world demand would be in the four BRIC markets (Brazil, Russia, India, and China). Meanwhile, in developed countries, the automotive industry has slowed.[14] It is also expected that this trend will continue, especially as the younger generations of people (in highly urbanized countries) no longer want to own a car, and prefer other modes of transport.[15] Other potentially powerful automotive markets are Iran and Indonesia.[16] Emerging automobile markets already buy more cars than established markets.\nAccording to a J.D. Power study, emerging markets accounted for 51 percent of the global light-vehicle sales in 2010. The study, performed in 2010 expected this trend to accelerate.[17][18] However, more recent reports (2012) confirmed the opposite; namely that the automotive industry was slowing down even in BRIC countries.[14] In the United States, vehicle sales peaked in 2000, at 17.8 million units.[19]\nIn July 2021, the European Commission released its \"Fit for 55\" legislation package,[20] which contains important guidelines for the future of the automotive industry; all new cars on the European market must be zero-emission vehicles from 2035.[21]\nThe governments of 24 developed countries and a group of major car manufacturers including GM, Ford, Volvo, BYD Auto, Jaguar Land Rover and Mercedes-Benz committed to \"work towards all sales of new cars and vans being zero emission globally by 2040, and by no later than 2035 in leading markets\".[22][23] Major car manufacturing nations like the United States, Germany, China, Japan and South Korea, as well as Volkswagen, Toyota, Peugeot, Honda, Nissan and Hyundai, did not pledge.[24]\nThe global automotive industry is a major consumer of water. Some estimates surpass 180,000 L (39,000 imp gal) of water per car manufactured, depending on whether tyre production is included. Production processes that use a significant volume of water include surface treatment, painting, coating, washing, cooling, air-conditioning, and boilers, not counting component manufacturing. Paintshop operations consume especially large amounts of water because equipment running on water-based products must also be cleaned with water.[27]\nIn 2022, Tesla's Gigafactory Berlin-Brandenburg ran into legal challenges due to droughts and falling groundwater levels in the region. Brandenburg's Economy Minister Joerg Steinbach said that while water supply was sufficient during the first stage, more would be needed once Tesla expands the site. The factory would nearly double the water consumption in the Gruenheide area, with 1.4 million cubic meters being contracted from local authorities per year — enough for a city of around 40,000 people. Steinbach said that the authorities would like to drill for more water there and outsource any additional supply if necessary.[28]\n| Year | Production | Change | Ref. |\n|---|---|---|---|\n| 1997 | 54,434,000 | — | [31] |\n| 1998 | 52,987,000 | 2.7% | [31] |\n| 1999 | 56,258,892 | 6.2% | [32] |\n| 2000 | 58,374,162 | 3.8% | [33] |\n| 2001 | 56,304,925 | 3.5% | [34] |\n| 2002 | 58,994,318 | 4.8% | [35] |\n| 2003 | 60,663,225 | 2.8% | [36] |\n| 2004 | 64,496,220 | 6.3% | [37] |\n| 2005 | 66,482,439 | 3.1% | [38] |\n| 2006 | 69,222,975 | 4.1% | [39] |\n| 2007 | 73,266,061 | 5.8% | [40] |\n| 2008 | 70,520,493 | 3.7% | [41] |\n| 2009 | 61,791,868 | 12.4% | [42] |\n| 2010 | 77,857,705 | 26.0% | [43] |\n| 2011 | 79,989,155 | 3.1% | [44] |\n| 2012 | 84,141,209 | 5.3% | [45] |\n| 2013 | 87,300,115 | 3.7% | [46] |\n| 2014 | 89,747,430 | 2.6% | [47] |\n| 2015 | 90,086,346 | 0.4% | [48] |\n| 2016 | 94,976,569 | 4.5% | [49] |\n| 2017 | 97,302,534 | 2.36% | [50] |\n| 2018 | 95,634,593 | 1.71% | [51] |\n| 2019 | 91,786,861 | 5.2% | [52] |\n| 2020 | 77,621,582 | 16% | [53] |\n| 2021 | 80,145,988 | 3.25% | [54] |\n| 2022 | 85,016,728 | 6.08% | [55] |\nThe OICA counts over 50 countries that assemble, manufacture, or disseminate automobiles. Of those, only 15 countries (boldfaced in the list below) currently possess the capability to design original production automobiles from the ground up, and 17 countries (listed below) have at least one million produced vehicles a year (as of 2023).[57]\n- Algeria\n- Argentina\n- Australia (main page)\n- Austria\n- Azerbaijan\n- Bangladesh (main page)\n- Belarus (main page)\n- Belgium\n- Brazil (main page)\n- Bulgaria (main page)\n- Canada (main page)\n- China (main page)\n- Colombia\n- Czech Republic (main page)\n- Ecuador\n- Egypt (main page)\n- Finland\n- France (main page)\n- Ghana (main page)\n- Germany (main page)\n- Hungary (main page)\n- India (main page)\n- Indonesia (main page)\n- Iran (main page)\n- Italy (main page)\n- Japan (main page)\n- Jordan\n- Kazakhstan\n- Kenya (main page)\n- Republic of Korea (South Korea) (main page)\n- Malaysia (main page)\n- Mexico (main page)\n- Morocco (main page)\n- Netherlands\n- Pakistan (main page)\n- Philippines (main page)\n- Poland (main page)\n- Portugal\n- Romania (main page)\n- Russia (main page)\n- Serbia (main page)\n- Slovakia (main page)\n- Slovenia\n- South Africa (main page)\n- Spain (main page)\n- Sweden (main page)\n- Syria\n- Thailand (main page)\n- Tunisia\n- Turkey (main page)\n- Ukraine (main page)\n- United Kingdom (main page)\n- United States (main page)\n- Uzbekistan (main page)\n- Venezuela\n- Vietnam (main page)\n| Country | Produced vehicles 2023[58] |\n|---|---|\n| China (plus Taiwan) |\n30,160,966 (30,446,928) |\n| USA | 10,611,555 |\n| Japan | 8,997,440 |\n| India | 5,851,507 |\n| Republic of Korea | 4,243,597 |\n| Germany | 4,109,371 |\n| Mexico | 4,002,047 |\n| Spain | 2,451,221 |\n| Brazil | 2,324,838 |\n| Thailand | 1,841,663 |\n| Canada | 1,553,026 |\n| France | 1,505,076 |\n| Turkey | 1,468,393 |\n| Czechia | 1,404,501 |\n| Indonesia | 1,395,717 |\n| Slovakia | 1,080,000 |\n| U.K. | 1,025,474 |\nThese were the ten largest manufacturers by production volume as of 2017,[59] of which the eight largest were in the top 8 positions since Fiat's 2013 acquisition of the Chrysler Corporation (although the PSA Group had been in the top 8 1999 to 2012, and 2007 to 2012 one of the eight largest along with the seven largest as of 2017) and the five largest in the top 5 positions since 2007, according to OICA, which, however, stopped publishing statistics of motor vehicle production by manufacturer after 2017. All ten remained as the ten largest automakers by sales until the merger between Fiat-Chrysler and the PSA Group in early 2021; only Renault was degraded to 11th place, in 2022, when being surpassed by both BMW (which became the 10th largest in 2021) and Chang'an.[60]\n| Rank[a] | Group | Country | Produced vehicles (2017)[59] |\nSold vehicles (2018) |\nSold vehicles (2019)[61] |\n|---|---|---|---|---|---|\n| 1 | Toyota | Japan | 10,466,051 | 10,521,134 | 10,741,556 |\n| 2 | Volkswagen Group | Germany | 10,382,334 | 10,831,232 | 10,975,352 |\n| 3 | General Motors (except SAIC-GM-Wuling)[b] |\nUnited States | 9,027,658 (6,856,880) |\n8,787,233 | 7,724,163 |\n| 4 | Hyundai | South Korea | 7,218,391 | 7,437,209 | 7,189,893 |\n| 5 | Ford | United States | 6,386,818 | 5,734,217 | 5,385,972 |\n| 6 | Nissan | Japan | 5,769,277 | 5,653,743 | 5,176,211 |\n| 7 | Honda | Japan | 5,235,842 | 5,265,892 | 5,323,319 |\n| 8 | Fiat-Chrysler (now part of Stellantis) |\nItaly / United States |\n4,600,847 | 4,841,366 | 4,612,673 |\n| 9 | Renault | France | 4,153,589 | 3,883,987 | 3,749,815 |\n| 10 | PSA Group (now part of Stellantis) |\nFrance | 3,649,742 | 4,126,349 | 3,479,152 |\nThese were the twenty largest manufacturers by production volume in 2012 and 2013, or the 21 largest in 2011 (before the Fiat-Chrysler merger), of which the fourteen largest as of 2011 were in the top 14 in 2010, 2008 and 2007 (but not 2009, when Changan and Mazda temporarily degraded Chrysler to 16th place). The eighteen largest as of 2013 have remained in the top 20 as of 2017, except Mitsubishi which fell out of top 20 in 2016, while Geely fell out of the top 20 in 2014 and 2015 but re-entered it in 2016.\n| Rank[c] | Group | Country | Produced vehicles (2013)[62] |\nProduced vehicles (2012)[63] |\nProduced vehicles (2011)[64] |\n|---|---|---|---|---|---|\n| 1 | Toyota | Japan | 10,324,995 | 10,104,424 | 8,050,181 |\n| 2 | General Motors | United States | 9,628,912 | 9,285,425 | 9,031,670 |\n| 3 | Volkswagen Group | Germany | 9,379,229 | 9,254,742 | 8,525,573 |\n| 4 | Hyundai | South Korea | 7,233,080 | 7,126,413 | 6,616,858 |\n| 5 | Ford | United States | 6,077,126 | 5,595,483 | 5,516,931 |\n| 6 | Nissan | Japan | 4,950,924 | 4,889,379 | 4,631,673 |\n| 7 | Fiat / FCA | Italy | 4,681,704 | 4 498 722[d] | 2,336,954 |\n| 8 | Honda | Japan | 4,298,390 | 4,110,857 | 2,909,016 |\n| 9 | PSA Peugeot Citroën | France | 2,833,781 | 2,911,764 | 3,582,410 |\n| 10 | Suzuki | Japan | 2,842,133 | 2,893,602 | 2,725,899 |\n| 11 | Renault | France | 2,704,675 | 2,676,226 | 2,825,089 |\n| 12 | Daimler | Germany | 1,781,507 | 2,195,152 | 2,137,067 |\n| Chrysler | United States | part of FCA | part of FCA | 1,999,017 | |\n| 13 | BMW | Germany | 2,006,366 | 2,065,477 | 1,738,160 |\n| 14 | SAIC | China | 1,992,250 | 1,783,548 | 1,478,502 |\n| 15 | Tata | India | 1,062,654 | 1,241,239 | 1,197,192 |\n| 16 | Mazda | Japan | 1,264,173 | 1,189,283 | 1,165,591 |\n| 17 | Dongfeng | China | 1,238,948 | 1,137,950 | 1,108,949 |\n| 18 | Mitsubishi | Japan | 1,229,441 | 1,109,731 | 1,140,282 |\n| 19 | Changan | China | 1,109,889 | 1,063,721 | 1,167,208 |\n| 20 | Geely | China | 969,896 | 922,906 | 897,107 |\nThis section needs to be updated. The reason given is: several of these have changed.(September 2024) |\nIt is common for automobile manufacturers to hold stakes in other automobile manufacturers. These ownerships can be explored under the detail for the individual companies.\nNotable current relationships include:[citation needed]\n- Toyota subsidiary Daihatsu holds a 25% stake in Perodua.[65]\n- Mercedes-Benz Group holds a 30.01% stake in Daimler Truck and BAIC Group holds a 6.49% stake.\n- Daimler Truck holds an 89.29% stake in Fuso.\n- Mercedes-Benz Group held a combined 6.2% stake in the Renault-Nissan-Mitsubishi Alliance, and the Renault-Nissan-Mitsubishi Alliance also held a combined 6.2% stake in Mercedes-Benz Group until 2021.[66]\n- Mercedes-Benz Group holds a 12% stake in BAIC Group, while BAIC Group holds 5% stake in Mercedes-Benz Group.[67]\n- Dongfeng Motor holds a 12.23% stake and a 19.94% exercisable voting rights in PSA Group.\n- FAW Group holds a 49% stake of Haima Automobile.\n- Stellantis holds a 67% stake in FCA Srbija.\n- FCA holds a 37.8% stake in Tofaş with another 37.8% stake hold by Koç Holding.\n- Fiat Automobili Srbija holds a 54% stake in Zastava Trucks.\n- Fiat Industrial holds a 46% stake in Zastava Trucks.\n- Fujian Motors Group holds a 15% stake in King Long. FMG, Beijing Automotive Group, China Motor, and Mercedes-Benz Group has a joint venture called Fujian Benz. FMG, China Motor, and Mitsubishi Motors has a joint venture called Soueast, FMG holds a 50% stake, and both China Motor and Mitsubishi Motors holds an equal 25% stake.\n- Geely Automobile holds a 23% stake in London EV Company.\n- Geely Automobile holds a 49.9% stake in Proton Holdings and a 51% stake in Lotus Cars.[68]\n- Geely Holding Group holds a 9.69% stake in Mercedes-Benz Group.[69]\n- Geely Holding Group holds an 8.3% stake and a 15.9% exercisable voting rights in Volvo.\n- General Motors holds a 20% stake in Industries Mécaniques Maghrébines.\n- Isuzu holds a 10% stake in Industries Mécaniques Maghrébines.\n- Marcopolo holds a 19% stake in New Flyer Industries.\n- Mitsubishi Corporation holds a 20% stake in Mitsubishi Motors.\n- Nissan held a 34% stake in Mitsubishi Motors beginning October 2016,[70] thus having the right to nominate the chairman of Mitsubishi Motors' board and a third of its directors. Mitsubishi bought some of its shares back from Nissan in November 2024, decreasing Nissan's stake to 24%.[71]\n- Nissan holds a 43% stake in Nissan Shatai.\n- Porsche SE holding company holds a 53.3% voting stake in the Volkswagen Group. The Porsche AG automotive business is fully owned by the Volkswagen Group.\n- Renault and Nissan have an alliance (Renault-Nissan-Mitsubishi Alliance, with Mitsubishi joining in 2016 through Nissan's acquisition of a 34% stake in the company) involving two global companies linked by cross-shareholding, with Renault holding a 43.4% stake in Nissan shares, and Nissan holding a 15% stake of (non-voting) Renault shares. In January 2023, Renault said it intended to transfer almost 30% of its controlling stake in Nissan to a French trust, reducing its shares with voting rights to a minority 15% and, in doing so, matching Nissan shares in Renault to gain equal voting rights.[72][73] The share transfer was completed in November 2023.[74]\n- Renault formerly held a 25% stake in AvtoVAZ; on December 2018, Renault and Russian state-owned holding company Rostec acquired all shares of AvtoVAZ (with Renault owning a 67.61% stake), but in 2022 Renault sold all of its shares to state-owned Central Research and Development Automobile and Engine Institute (NAMI), re-nationalising AvtoVAZ.\n- Renault holds an 52.8% stake in Renault Korea.\n- SAIPA holds a 51% stake in Pars Khodro.\n- Tata Motors holds a 100% stake in Jaguar Land Rover.\n- Toyota holds a 100% stake in Daihatsu (since August 2016) and a 50.1% stake in Hino (since 2001 – and from 1998 to 2016 also a 51.2% stake in Daihatsu).\n- Toyota holds a 100% stake in Hino.\n- Toyota holds a 4.6% stake in Isuzu.\n- Toyota holds a 5.05% stake in Mazda, while Mazda holds a 0.25% stake in Toyota.[75]\n- Toyota holds a 16.7% stake in transportation, automotive, and defense conglomerate Subaru Corporation (formerly Fuji Heavy Industries), parent company of Subaru.\n- Toyota holds a 4.94% stake in Suzuki, while Suzuki holds a 0.2% stake in Toyota.[76]\n- Volkswagen Group holds a 99.55% stake in the Audi Group.\n- Volkswagen Group holds a 37.73% stake in Scania (68.6% voting rights), a 53.7% stake in MAN SE (55.9% voting rights). Volkswagen is integrating Scania, MAN, and its own truck division into one division.\n- Paccar holds a 19% stake in Tatra.\n- ZAP holds a 51% stake in Zhejiang Jonway.\n- Beijing Automotive Group has a joint venture with Mercedes-Benz Group called Beijing Benz, both companies hold a 50–50% stake. both companies also have a joint venture called Beijing Foton Daimler Automobile.\n- Beijing Automotive Group also has a joint venture with Hyundai called Beijing Hyundai, both companies hold a 50–50% stake.\n- BMW and Brilliance have a joint venture called BMW Brilliance. BMW owns a 50% stake, Brilliance owns a 40.5% stake, and the Shenyang municipal government owns a 9.5% stake.\n- Changan Automobile has a joint venture with PSA Group (Changan PSA), and both hold a 50–50% stake.\n- Changan Automobile has a joint venture with Suzuki (Changan Suzuki), and both hold a 50–50% stake.\n- Changan Automobile has a 50–50% joint venture with Mazda (Changan Mazda).\n- Changan Automobile and Ford have a 50–50% joint venture called Changan Ford.\n- Changan Automobile and JMCG have a joint venture called Jiangling Motor Holding.\n- Chery has a joint venture with Jaguar Land Rover called Chery Jaguar Land Rover, both companies hold a 50–50% stake.[77]\n- Chery and Israel Corporation have a joint venture called Qoros, and both companies hold a 50–50% stake.\n- Dongfeng Motor Corporation and Nissan have a 50–50% joint venture called Dongfeng Motor Company.\n- Mercedes-Benz Group and BYD Auto have a joint venture called Denza, both companies hold a 50–50% stake.\n- Mercedes-Benz Group and Geely Holding Group have a joint venture called smart Automobile, both companies hold a 50–50% stake.[78]\n- Dongfeng Motor and Stellantis (until 2021 PSA Group) have a 50–50% joint venture called Dongfeng Peugeot-Citroën.\n- Dongfeng Motor has a 50–50% joint venture with Honda called Dongfeng Honda.\n- Dongfeng Motor formerly had a joint venture with Volvo called Dongfeng Nissan-Diesel.\n- Dongfeng Motor has a 50–50% joint venture with Renault named Dongfeng Renault in Wuhan, which was founded in the end of 2013\n- FAW Group and General Motors has a 50-50 joint venture called FAW-GM.\n- FAW Group has a 50-50 joint venture with Volkswagen Group called FAW-Volkswagen.\n- FAW Group has a 50-50 joint venture with Toyota called Sichuan FAW Toyota Motor and both companies also have another joint venture called Ranz.\n- General Motors and SAIC Motor, both have two joint ventures in SAIC-GM and SAIC-GM-Wuling, the latter alongside Wuling Motors.\n- Navistar International and JAC has a joint venture called Anhui Jianghuai Navistar.\n- Ford and International Motors have a 50-50 joint venture called Blue Diamond Truck.\n- Ford and Sollers JSC have a 50-50 joint venture called Ford Sollers.\n- Ford and Koç Holding have a 50-50 joint venture called Ford Otosan.\n- Ford and Lio Ho Group have a joint venture called Ford Lio Ho, Ford owns 70% and Lio Ho Group owns 30%.\n- General Motors and UzAvtosanoat have a joint venture called GM Uzbekistan, UzAvtosanoat owns 75% and General Motors owns 25%.\n- General Motors, AvtoVAZ, and EBRD have a joint venture called GM-AvtoVAZ, Both GM and AvtoVAZ owns 41.61% and EBRD owns 16.76%.\n- Hyundai Motor Company and Kibar Holding has a joint venture called Hyundai Assan Otomotiv, Hyundai owns 70% and Kibar Holding owns 30%.\n- Isuzu and Anadolu Group have a 50–50% joint venture called Anadolu Isuzu.\n- Isuzu and General Motors has a 50–50% joint venture called Isuzu Truck South Africa.\n- Isuzu, Sollers JSC, and Imperial Sojitz have a joint venture called Sollers-Isuzu, Sollers JSC owns 66%, Isuzu owns 29%, and Imperial Sojitz owns 5%.\n- Mahindra & Mahindra and International Motors have a joint venture called Mahindra Trucks and Buses Limited. Mahindra & Mahindra owns 51% and International Motors owns 49%.\n- MAN SE and UzAvtosanoat have a joint venture called MAN Auto-Uzbekistan, UzAvtosanoat owns 51% and MAN SE owns 49%.\n- PSA and Toyota formerly owned a 50–50% joint venture called Toyota Peugeot Citroën Automobile Czech, however on 1 January 2021 Toyota bought all of PSA's shares and renamed the now wholly owned plant to Toyota Motor Manufacturing Czech Republic.\n- PSA and CK Birla Group (AVTEC) have a 50–50% joint venture called PSA AVTEC Powertrain Pvt. Ltd.\n- Sollers JSC is involved in joint ventures with Ford (Ford Sollers ) and Mazda to produce cars.\n- Tata Motors also formed a joint venture in India with Fiat and gained access to Fiat's diesel engine technology.\n- Tata Motors and Marcopolo have a joint venture called Tata Marcopolo, where Tata owns 51% and Marcopolo owns 49%.\n- Volvo and Eicher Motors have a 50–50% joint venture called VE Commercial Vehicles.\n- 2008–2010 automotive industry crisis\n- Alliance of Automobile Manufacturers\n- Automotive industry by country\n- Automotive industry in the United States\n- Big Three (automobile manufacturers)\n- Effects of the 2008–10 automotive industry crisis on the United States\n- List of countries by motor vehicle production\n- Automotive acronyms and abbreviations\n- Motocycle\n- As of 2017\n- OICA lists SAIC-GM-Wuling combined with G.M. until 2014 but separately from 2015. Including SAIC-GM-Wuling, G.M. would still be larger than Hyundai until 2020.\n- As of 2012\n- Fiat acquired Chrysler in 2012. However, Fiat and Chrysler was still listed separately by OICA in 2012, and combined first from 2013. Separately, the production by Fiat was 2,127,295 and by Chrysler 2,371,427.\n- Automotive industry at the Encyclopædia Britannica\n- Nieuwenhuis, Paul; Wells, Peter (2015). The Global Automotive Industry (1st ed.). Chicester: John Wiley & Sons. ISBN 9781118802397.\n- \"The 2021 EU Industrial R&D Investment Scoreboard\" (PDF). European Commission. Retrieved 27 February 2022.\n- Scientific and Technical Societies of the United States (Eighth ed.). Washington, DC: National Academy of Sciences. 1968. p. 164. Retrieved 25 March 2014.\n- \"Automotive Industry\". carbidebur.com. Retrieved 26 November 2023.\n- Jarvis, Alice-Azania (24 September 2010). \"The Timeline: Car manufacturing\". The Independent. Retrieved 19 April 2024.\n- \"U.S. Makes Ninety Percent of World's Automobiles\". Popular Science. Vol. 115, no. 5. November 1929. p. 84. Retrieved 6 August 2013.\n- \"China car production by type 2024\". Statista. Retrieved 15 May 2025.\n- Aichner, Thomas; Coletti, Paolo (2013). \"Customers' online shopping preferences in mass customization\". Journal of Direct, Data and Digital Marketing Practice. 15 (1): 20–35. doi:10.1057/dddmp.2013.34. S2CID 167801827.\n- \"ISO 26262-10:2012 Road vehicles -- Functional safety -- Part 10: Guideline on ISO 26262\". International Organization for Standardization. Retrieved 25 March 2014.\n- Machado, Miguel Araújo; Rosado, Luís Filipe Soldado Granadeiro; Mendes, Nuno Alberto Marques; Miranda, Rosa Maria Mendes; dos Santos, Telmo Jorge Gomes (January 2022). \"New directions for inline inspection of automobile laser welds using non-destructive testing\". The International Journal of Advanced Manufacturing Technology. 118 (3–4): 1183–1195. doi:10.1007/s00170-021-08007-0. hdl:10362/126077. ISSN 0268-3768.\n- Machado, Miguel A.; Rosado, Luís S.; Mendes, Nuno M.; Miranda, Rosa M.; Santos, Telmo G. (4 November 2021). \"Multisensor Inspection of Laser-Brazed Joints in the Automotive Industry\". Sensors. 21 (21): 7335. Bibcode:2021Senso..21.7335M. doi:10.3390/s21217335. ISSN 1424-8220. PMC 8587767. PMID 34770642.\n- \"Automobile Industry Introduction\". Plunkett Research. 2008. Archived from the original on 18 January 2008. Retrieved 25 March 2014.\n- Khor, Martin. \"Developing economies slowing down\". twnside.org.sg. Archived from the original on 13 October 2012. Retrieved 21 July 2015.\n- \"2014 Global Automotive Consumer Study: Exploring consumer preferences and mobility choices in Europe\" (PDF). Deloittelcom. Archived from the original (PDF) on 4 July 2015. Retrieved 3 July 2015.\n- Eisenstein, Paul A. (21 January 2010). \"Building BRIC's: 4 Markets Could Soon Dominate the Auto World\". thedetroitbureau.com.\n- Bertel Schmitt (15 February 2011). \"Auto Industry Sets New World Record In 2010. Will Do It Again In 2011\". The Truth About Cars. Retrieved 6 April 2019.\n- \"Global Automotive Outlook for 2011 Appears Positive as Mature Auto Markets Recover, Emerging Markets Continue to Expand\". J.D. Power and Associates. 15 February 2011. Archived from the original on 17 February 2011. Retrieved 7 August 2011.\n- \"U.S. vehicle sales peaked in 2000\". The Cherry Creek News. 27 May 2015. Archived from the original on 28 May 2015. Retrieved 18 June 2015.\n- \"European Green Deal: Commission proposes transformation of EU economy and society to meet climate ambitions\". European Commission. 14 July 2021.\n- \"Fit for 55: European Union to end sale of petrol and diesel models by 2035\". Autovista24. 14 July 2021.\n- \"COP26: Deal to end car emissions by 2040 idles as motor giants refuse to sign\". Financial Times. 8 November 2021. Archived from the original on 10 December 2022.\n- \"COP26: Every carmaker that pledged to stop selling fossil-fuel vehicles by 2040\". CarExpert. 11 November 2021.\n- \"COP26: Germany fails to sign up to 2040 combustion engine phaseout\". Deutsche Welle. 10 November 2021.\n- \"Highlights of the Automotive Trends Report\". EPA.gov. U.S. Environmental Protection Agency (EPA). 12 December 2022. Archived from the original on 2 September 2023.\n- Cazzola, Pierpaolo; Paoli, Leonardo; Teter, Jacob (November 2023). \"Trends in the Global Vehicle Fleet 2023 / Managing the SUV Shift and the EV Transition\" (PDF). Global Fuel Economy Initiative (GFEI). p. 3. doi:10.7922/G2HM56SV. Archived (PDF) from the original on 26 November 2023.\n- Isaiah, David (6 October 2014). \"Water, water, everywhere in vehicle manufacturing\". Automotive World.\n- Raymunt, Monica; Wilkes, William (22 February 2022). \"Elon Musk Laughed at the Idea of Tesla Using Too Much Water. Now It's a Real Problem\". bloomberg.com.\n- \"Table 1-23: World Motor Vehicle Production, Selected Countries (Thousands of vehicles)\". Bureau of Transportation Statistics. 23 May 2017. Retrieved 6 April 2019.\n- \"Arno A. Evers FAIR-PR\". Hydrogenambassadors.com. Retrieved 3 July 2015.\n- \"1998 - 1997 world motor vehicle production by type and economic area\" (PDF). oica.net. Retrieved 21 July 2015.\n- \"1999 Production Statistics\". oica.net.\n- \"2000 Production Statistics\". oica.net.\n- \"2001 Production Statistics\". oica.net.\n- \"2002 Production Statistics\". oica.net.\n- \"2003 Production Statistics\". oica.net.\n- \"2004 Production Statistics\". oica.net.\n- \"2005 Production Statistics\". oica.net.\n- \"2006 Production Statistics\". oica.net.\n- \"2007 Production Statistics\". oica.net.\n- \"2008 Production Statistics\". oica.net.\n- \"2009 Production Statistics\". oica.net.\n- \"2010 Production Statistics\". oica.net.\n- \"2011 Production Statistics\". oica.net.\n- \"2012 Production Statistics\". oica.net.\n- \"2013 Production Statistics\". oica.net.\n- \"2014 Production Statistics\". oica.net.\n- \"2015 Production Statistics\". oica.net.\n- \"2016 Production Statistics\". oica.net.\n- \"2017 Production Statistics\". oica.net.\n- \"2018 Production Statistics\". oica.net.\n- \"2019 Production Statistics\". oica.net.\n- \"2020 Production Statistics\". oica.net.\n- \"2021 Production Statistics\". oica.net.\n- \"2022 Production Statistics\". oica.net.\n- \"Harvard Atlas of Economic Complexity\". US: Harvard University. 2014. Retrieved 15 October 2023.\n- Lynch, Jared; Hawthorne, Mark (17 October 2015). \"Australia's car industry one year from closing its doors\". The Sydney Morning Herald. Archived from the original on 27 May 2017. Retrieved 27 May 2017.\n- \"World Motor Vehicle Production by Country/Region and Type\" (PDF). OICA. Retrieved 13 August 2024.\n- \"World Motor Vehicle Production: World Ranking of Manufacturers, Year 2017\" (PDF). OICA. Retrieved 5 May 2019.\n- \"Top 15 Automakers in the World | Car Sales Rank Worldwide\".\n- \"2020 Worldwide Car Sales by Manufacturer\". F&I Tools USA. 2022. Retrieved 4 January 2024.\n- \"World Ranking of Manufacturers Year 2013\" (PDF). OICA. Retrieved 13 August 2024.\n- \"World Ranking of Manufacturers Year 2012\" (PDF). OICA. Retrieved 13 August 2024.\n- \"World Ranking of Manufacturers Year 2011\" (PDF). OICA. Retrieved 13 August 2024.\n- \"Perusahaan Ootmobil Kedua\" [Second Automobile Company] (in Malay). Malaysia: Perodua. 17 January 2017. Archived from the original on 17 January 2017.\n- \"Mercedes-Benz Offloads Its Entire Renault Stake\". Auto Evolution. 12 November 2021. Retrieved 23 December 2024.\n- Sun, Edward; Taylor, Yilei (23 July 2019). \"China's BAIC buys 5% Mercedes-Benz Group stake to cement alliance\". Reuters. US. Retrieved 5 December 2020.\n- \"China's Geely to Acquire Stake in Malaysian Carmaker Proton\". Bloomberg.com. 23 May 2017. Retrieved 28 June 2017.\n- \"Mercedes and Geely joint ownership of Smart\". Auto Express. Retrieved 5 December 2020.\n- \"Nissan to take 34% stake in Mitsubishi Motors\". BBC News. 12 May 2016. Retrieved 1 July 2016.\n- Fitzgerald, Jack (8 November 2024). \"Mitsubishi Buys Large Percentage of Shares Back from Nissan\". US. Retrieved 4 May 2025.\n- \"Nissan, Renault move toward alliance rejig, to make statement -sources\". Euronews. 30 January 2023. Retrieved 4 May 2025.\n- \"Statement\" (Press release). Alliance. 30 January 2023. Archived from the original on 30 January 2023. Retrieved 4 May 2025.\n- Toyota buys stake in Mazda, joint US factory, EV development planned | CarAdvice\n- \"Toyota pulls Suzuki firmly into its orbit through stake deal\". Reuters. 28 August 2019. Retrieved 11 February 2020.\n- \"Corporate Introduction\". Chery Jaguar Land Rover. Retrieved 5 December 2020.\n- \"Mercedes-Benz and Geely Holding have formally established its global joint venture \"smart Automobile Co., Ltd.\" for the smart brand\". media.daimler.com (Press release). Archived from the original on 30 December 2020. Retrieved 5 December 2020.\n- Ajitha, P. V., and Ankita Nagra. \"An Overview of Artificial Intelligence in Automobile Industry–A Case Study on Tesla Cars.\" Solid State Technology 64.2 (2021): 503–512. online\n- Banerjee, Preeta M., and Micaela Preskill. \"The role of government in shifting firm innovation focus in the automobile industry\" in Entrepreneurship, Innovation and Sustainability (Routledge, 2017) pp. 108–129.\n- Bohnsack, René, et al. \"Driving the electric bandwagon: The dynamics of incumbents' sustainable innovation.\" Business Strategy and the Environment 29.2 (2020): 727–743 online.\n- Bungsche, Holger. \"Regional economic integration and the automobile industry: automobile policies, division of labour, production network formation and market development in the EU and ASEAN.\" International Journal of Automotive Technology and Management 18.4 (2018): 345–370.\n- Chen, Yuan, C-Y. Cynthia Lin Lawell, and Yunshi Wang. \"The Chinese automobile industry and government policy.\" Research in Transportation Economics 84 (2020): 100849. online\n- Clark, Kim B., et al. \"Product development in the world auto industry.\" Brookings Papers on economic activity 1987.3 (1987): 729–781. online\n- Guzik, Robert, Bolesław Domański, and Krzysztof Gwosdz. \"Automotive industry dynamics in Central Europe.\" in New Frontiers of the Automobile Industry (Palgrave Macmillan, Cham, 2020) pp. 377–397.\n- Imran, Muhammad, and Jawad Abbas. \"The role of strategic orientation in export performance of China automobile industry.\" in Handbook of Research on Managerial Practices and Disruptive Innovation in Asia (2020): 249–263.\n- Jetin, Bruno. \"Who will control the electric vehicle market?\" International Journal of Automotive Technology and Management 20.2 (2020): 156–177. online\n- Kawahara, Akira. The origin of competitive strength: fifty years of the auto industry in Japan and the US (Springer Science & Business Media, 2012).\n- Kuboniwa, Masaaki. \"Present and future problems of developments of the Russian auto-industry.\" RRC Working Paper Series 15 (2009): 1–12. online\n- Lee, Euna, and Jai S. Mah. \"Industrial policy and the development of the electric vehicles industry: The case of Korea.\" Journal of technology management & innovation 15.4 (2020): 71–80. online\n- Link, Stefan J. Forging Global Fordism: Nazi Germany, Soviet Russia, and the Contest over the Industrial Order (2020) excerpt; influential overview\n- Liu, Shiyong. \"Competition and Valuation: A Case Study of Tesla Motors.\" IOP Conference Series: Earth and Environmental Science . Vol. 692. No. 2. (IOP Publishing, 2021) online\n- Miglani, Smita. \"The growth of the Indian automobile industry: Analysis of the roles of government policy and other enabling factors.\" in Innovation, economic development, and intellectual property in India and China (Springer, Singapore, 2019) pp. 439–463.\n- Pavlinek, Petr (2025). Europe's Auto Industry: Global Production Networks and Spatial Change. Cambridge University Press. ISBN 9781009453196.\n- Qin, Yujie, Yuqing Xiao, and Jiawei Yuan. \"The Comprehensive Competitiveness of Tesla Based on Financial Analysis: A Case Study.\" in 2021 International Conference on Financial Management and Economic Transition (FMET 2021). (Atlantis Press, 2021). online\n- Rawlinson, Michael, and Peter Wells. The new European automobile industry (Springer, 2016).\n- Rubenstein, James M. The changing US auto industry: a geographical analysis (Routledge, 2002).\n- Seo, Dae-Sung. \"EV Energy Convergence Plan for Reshaping the European Automobile Industry According to the Green Deal Policy.\" Journal of Convergence for Information Technology 11.6 (2021): 40–48. online\n- Shigeta, Naoya, and Seyed Ehsan Hosseini. \"Sustainable Development of the Automobile Industry in the United States, Europe, and Japan with Special Focus on the Vehicles' Power Sources.\" Energies 14.1 (2021): 78+ online\n- Ueno, Hiroya, and Hiromichi Muto. \"The automobile industry of Japan.\" on Industry and Business in Japan (Routledge, 2017) pp. 139–190.\n- Verma, Shrey, Gaurav Dwivedi, and Puneet Verma. \"Life cycle assessment of electric vehicles in comparison to combustion engine vehicles: A review.\" Materials Today: Proceedings (2021) online.\n- Vošta, M. I. L. A. N., and A. L. E. Š. Kocourek. \"Competitiveness of the European automobile industry in the global context.\" Politics in Central Europe 13.1 (2017): 69–89. online\n- Zhu, Xiaoxi, et al. \"Promoting new energy vehicles consumption: The effect of implementing carbon regulation on automobile industry in China.\" Computers & Industrial Engineering 135 (2019): 211–226. online\n- The dictionary definition of automotive industry at Wiktionary\n- Media related to Automotive industry at Wikimedia Commons",
    "battery industry": "| Component type | Active |\n|---|---|\n| Inventor | Alessandro Volta |\n| Invention year | 1800 |\n| Pin names | Cathode and anode |\n| Electronic symbol | |\nAn electric battery is a source of electric power consisting of one or more electrochemical cells with external connections[1] for powering electrical devices. When a battery is supplying power, its positive terminal is the cathode and its negative terminal is the anode.[2] The terminal marked negative is the source of electrons. When a battery is connected to an external electric load, those negatively charged electrons flow through the circuit and reach the positive terminal, thus causing a redox reaction by attracting positively charged ions, or cations. Thus, higher energy reactants are converted to lower energy products, and the free-energy difference is delivered to the external circuit as electrical energy. Historically the term \"battery\" specifically referred to a device composed of multiple cells; however, the usage has evolved to include devices composed of a single cell.[3]\nPrimary (single-use or \"disposable\") batteries are used once and discarded, as the electrode materials are irreversibly changed during discharge; a common example is the alkaline battery used for flashlights and a multitude of portable electronic devices. Secondary (rechargeable) batteries can be discharged and recharged multiple times using an applied electric current; the original composition of the electrodes can be restored by reverse current. Examples include the lead–acid batteries used in vehicles and lithium-ion batteries used for portable electronics such as laptops and mobile phones.\nBatteries come in many shapes and sizes, from miniature cells used to power hearing aids and wristwatches to, at the largest extreme, huge battery banks the size of rooms that provide standby or emergency power for telephone exchanges and computer data centers. Batteries have much lower specific energy (energy per unit mass) than common fuels such as gasoline. In automobiles, this is somewhat offset by the higher efficiency of electric motors in converting electrical energy to mechanical work, compared to combustion engines.\nHistory\nInvention\nBenjamin Franklin first used the term \"battery\" in 1749 when he was doing experiments with electricity using a set of linked Leyden jar capacitors.[4] Franklin grouped a number of the jars into what he described as a \"battery\", using the military term for weapons functioning together.[5] By multiplying the number of holding vessels, a stronger charge could be stored, and more power would be available on discharge.\nItalian physicist Alessandro Volta built and described the first electrochemical battery, the voltaic pile, in 1800.[6] This was a stack of copper and zinc plates, separated by brine-soaked paper disks, that could produce a steady current for a considerable length of time. Volta did not understand that the voltage was due to chemical reactions. He thought that his cells were an inexhaustible source of energy,[7] and that the associated corrosion effects at the electrodes were a mere nuisance, rather than an unavoidable consequence of their operation, as Michael Faraday showed in 1834.[8]\nAlthough early batteries were of great value for experimental purposes,[9] in practice their voltages fluctuated and they could not provide a large current for a sustained period. The Daniell cell, invented in 1836 by British chemist John Frederic Daniell, was the first practical source of electricity, becoming an industry standard and seeing widespread adoption as a power source for electrical telegraph networks.[10] It consisted of a copper pot filled with a copper sulfate solution, in which was immersed an unglazed earthenware container filled with sulfuric acid and a zinc electrode.[11]\nThese wet cells used liquid electrolytes, which were prone to leakage and spillage if not handled correctly. Many used glass jars to hold their components, which made them fragile and potentially dangerous. These characteristics made wet cells unsuitable for portable appliances. Near the end of the nineteenth century, the invention of dry cell batteries, which replaced the liquid electrolyte with a paste, made portable electrical devices practical.[12]\nBatteries in vacuum tube devices historically used a wet cell for the \"A\" battery (to provide power to the filament) and a dry cell for the \"B\" battery (to provide the plate voltage).[citation needed]\nOngoing developments\nBetween 2010 and 2018, battery demand grew by 30% annually, reaching a total of 180 GWh in 2018. Conservatively, the growth rate is expected to be maintained at an estimated 25%, culminating in demand reaching 2600 GWh in 2030. In addition, cost reductions are expected to further increase the demand to as much as 3562 GWh.[13]\nImportant reasons for this high rate of growth of the electric battery industry include the electrification of transport, and large-scale deployment in electricity grids, supported by decarbonization initiatives.[13]\nDistributed electric batteries, such as those used in battery electric vehicles (vehicle-to-grid) and in home energy storage with smart metering and that are connected to smart grids for demand response are active participants in smart power supply grids.[14] Secondary use of partially depleted batteries can add to the overall utility of electric batteries by reducing energy storage costs and emission impact due to longer service life. In this use, vehicle electric batteries that have their battery capacity reduced to less than 80% (usually after 5–8 years of service) are repurposed for use in backup supplies or renewable energy storage systems.[15]\nGrid scale energy storage envisages the large-scale use of batteries to collect and store energy from the grid or a power plant and then discharge that energy at a later time to provide electricity or other grid services when needed. Grid scale energy storage (either turnkey or distributed) are important components of smart power supply grids.[16]\nComputational Paradigm Shift: The advent of computational modeling has revolutionized battery materials design, enabling high-throughput screening and atomistic simulations that accelerate the discovery of novel electrolytes and electrodes, moving beyond traditional trial-and-error approaches.[17]\nChemistry and principles\nBatteries convert chemical energy directly to electrical energy. In many cases, the electrical energy released is the difference in the cohesive[18] or bond energies of the metals, oxides, or molecules undergoing the electrochemical reaction. For instance, energy can be stored in Zn or Li, which are high-energy metals because they are not stabilized by d-electron bonding, unlike transition metals. Batteries are designed so that the energetically favorable redox reaction can occur only when electrons move through the external part of the circuit.\nA battery consists of some number of voltaic cells. Each cell consists of two half-cells connected in series by a conductive electrolyte containing metal cations. One half-cell includes electrolyte and the negative electrode, the electrode to which anions (negatively charged ions) migrate; the other half-cell includes electrolyte and the positive electrode, to which cations (positively charged ions) migrate. Cations are reduced (electrons are added) at the cathode, while metal atoms are oxidized (electrons are removed) at the anode.[19] Some cells use different electrolytes for each half-cell; then a separator is used to prevent mixing of the electrolytes while allowing ions to flow between half-cells to complete the electrical circuit.\nEach half-cell has an electromotive force (emf, measured in volts) relative to a standard. The net emf of the cell is the difference between the emfs of its half-cells.[20] Thus, if the electrodes have emfs and , then the net emf is ; in other words, the net emf is the difference between the reduction potentials of the half-reactions.[21]\nThe electrical driving force or across the terminals of a cell is known as the terminal voltage (difference) and is measured in volts.[22] The terminal voltage of a cell that is neither charging nor discharging is called the open-circuit voltage and equals the emf of the cell. Because of internal resistance,[23] the terminal voltage of a cell that is discharging is smaller in magnitude than the open-circuit voltage and the terminal voltage of a cell that is charging exceeds the open-circuit voltage.[24] An ideal cell has negligible internal resistance, so it would maintain a constant terminal voltage of until exhausted, then dropping to zero. If such a cell maintained 1.5 volts and produced a charge of one coulomb then on complete discharge it would have performed 1.5 joules of work.[22] In actual cells, the internal resistance increases under discharge[23] and the open-circuit voltage also decreases under discharge. If the voltage and resistance are plotted against time, the resulting graphs typically are a curve; the shape of the curve varies according to the chemistry and internal arrangement employed.\nThe voltage developed across a cell's terminals depends on the energy release of the chemical reactions of its electrodes and electrolyte. Alkaline and zinc–carbon cells have different chemistries, but approximately the same emf of 1.5 volts; likewise NiCd and NiMH cells have different chemistries, but approximately the same emf of 1.2 volts.[25] The high electrochemical potential changes in the reactions of lithium compounds give lithium cells emfs of 3 volts or more.[26]\nAlmost any liquid or moist object that has enough ions to be electrically conductive can serve as the electrolyte for a cell. As a novelty or science demonstration, it is possible to insert two electrodes made of different metals into a lemon,[27] potato,[28] etc. and generate small amounts of electricity.\nA voltaic pile can be made from two coins (such as a nickel and a penny) and a piece of paper towel dipped in salt water. Such a pile generates a very low voltage but, when many are stacked in series, they can replace normal batteries for a short time.[29]\nTypes\nPrimary and secondary batteries\nBatteries are classified into primary and secondary forms:\n- Primary batteries are designed to be used until exhausted of energy then discarded. Their chemical reactions are generally not reversible, so they cannot be recharged. When the supply of reactants in the battery is exhausted, the battery stops producing current and is useless.[30]\n- Secondary batteries can be recharged; that is, they can have their chemical reactions reversed by applying electric current to the cell. This regenerates the original chemical reactants, so they can be used, recharged, and used again multiple times.[31]\nSome types of primary batteries used, for example, for telegraph circuits, were restored to operation by replacing the electrodes.[32] Secondary batteries are not indefinitely rechargeable due to dissipation of the active materials, loss of electrolyte and internal corrosion.\nPrimary batteries, or primary cells, can produce current immediately on assembly. These are most commonly used in portable devices that have low current drain, are used only intermittently, or are used well away from an alternative power source, such as in alarm and communication circuits where other electric power is only intermittently available. Disposable primary cells cannot be reliably recharged, since the chemical reactions are not easily reversible and active materials may not return to their original forms. Battery manufacturers recommend against attempting to recharge primary cells.[33] In general, these have higher energy densities than rechargeable batteries,[34] but disposable batteries do not fare well under high-drain applications with loads under 75 ohms (75 Ω). Common types of disposable batteries include zinc–carbon batteries and alkaline batteries.\nSecondary batteries, also known as secondary cells, or rechargeable batteries, must be charged before first use; they are usually assembled with active materials in the discharged state. Rechargeable batteries are (re)charged by applying electric current, which reverses the chemical reactions that occur during discharge/use. Devices to supply the appropriate current are called chargers. The oldest form of rechargeable battery is the lead–acid battery, which are widely used in automotive and boating applications. This technology contains liquid electrolyte in an unsealed container, requiring that the battery be kept upright and the area be well ventilated to ensure safe dispersal of the hydrogen gas it produces during overcharging. The lead–acid battery is relatively heavy for the amount of electrical energy it can supply. Its low manufacturing cost and its high surge current levels make it common where its capacity (over approximately 10 Ah) is more important than weight and handling issues. A common application is the modern car battery, which can, in general, deliver a peak current of 450 amperes.\nComposition\nMany types of electrochemical cells have been produced, with varying chemical processes and designs, including galvanic cells, electrolytic cells, fuel cells, flow cells and voltaic piles.[35]\nwet cell battery has a liquid electrolyte. Other names are flooded cell, since the liquid covers all internal parts or vented cell, since gases produced during operation can escape to the air. Wet cells were a precursor to dry cells and are commonly used as a learning tool for electrochemistry. They can be built with common laboratory supplies, such as beakers, for demonstrations of how electrochemical cells work. A particular type of wet cell known as a concentration cell is important in understanding corrosion. Wet cells may be primary cells (non-rechargeable) or secondary cells (rechargeable). Originally, all practical primary batteries such as the Daniell cell were built as open-top glass jar wet cells. Other primary wet cells are the Leclanche cell, Grove cell, Bunsen cell, Chromic acid cell, Clark cell, and Weston cell. The Leclanche cell chemistry was adapted to the first dry cells. Wet cells are still used in automobile batteries and in industry for standby power for switchgear, telecommunication or large uninterruptible power supplies, but in many places batteries with gel cells have been used instead. These applications commonly use lead–acid or nickel–cadmium cells. Molten salt batteries are primary or secondary batteries that use a molten salt as electrolyte. They operate at high temperatures and must be well insulated to retain heat.\nA dry cell uses a paste electrolyte, with only enough moisture to allow current to flow. Unlike a wet cell, a dry cell can operate in any orientation without spilling, as it contains no free liquid, making it suitable for portable equipment. By comparison, the first wet cells were typically fragile glass containers with lead rods hanging from the open top and needed careful handling to avoid spillage. Lead–acid batteries did not achieve the safety and portability of the dry cell until the development of the gel battery. A common dry cell is the zinc–carbon battery, sometimes called the dry Leclanché cell, with a nominal voltage of 1.5 volts, the same as the alkaline battery (since both use the same zinc–manganese dioxide combination). A standard dry cell comprises a zinc anode, usually in the form of a cylindrical pot, with a carbon cathode in the form of a central rod. The electrolyte is ammonium chloride in the form of a paste next to the zinc anode. The remaining space between the electrolyte and carbon cathode is taken up by a second paste consisting of ammonium chloride and manganese dioxide, the latter acting as a depolariser. In some designs, the ammonium chloride is replaced by zinc chloride.\nA reserve battery can be stored unassembled (unactivated and supplying no power) for a long period (perhaps years). When the battery is needed, then it is assembled (e.g., by adding electrolyte); once assembled, the battery is charged and ready to work. For example, a battery for an electronic artillery fuze might be activated by the impact of firing a gun. The acceleration breaks a capsule of electrolyte that activates the battery and powers the fuze's circuits. Reserve batteries are usually designed for a short service life (seconds or minutes) after long storage (years). A water-activated battery for oceanographic instruments or military applications becomes activated on immersion in water.\nOn 28 February 2017, the University of Texas at Austin issued a press release about a new type of solid-state battery, developed by a team led by lithium-ion battery inventor John Goodenough, \"that could lead to safer, faster-charging, longer-lasting rechargeable batteries for handheld mobile devices, electric cars and stationary energy storage\".[36] The solid-state battery is also said to have \"three times the energy density\", increasing its useful life in electric vehicles, for example. It should also be more ecologically sound since the technology uses less expensive, earth-friendly materials such as sodium extracted from seawater. They also have much longer life.[37]\nSony has developed a biological battery that generates electricity from sugar in a way that is similar to the processes observed in living organisms. The battery generates electricity through the use of enzymes that break down carbohydrates.[38]\nThe sealed valve regulated lead–acid battery (VRLA battery) is popular in the automotive industry as a replacement for the lead–acid wet cell. The VRLA battery uses an immobilized sulfuric acid electrolyte, reducing the chance of leakage and extending shelf life.[39] VRLA batteries immobilize the electrolyte. The two types are:\n- Gel batteries (or \"gel cell\") use a semi-solid electrolyte.\n- Absorbed Glass Mat (AGM) batteries absorb the electrolyte in a special fiberglass matting.\nOther portable rechargeable batteries include several sealed \"dry cell\" types, that are useful in applications such as mobile phones and laptop computers. Cells of this type (in order of increasing power density and cost) include nickel–cadmium (NiCd), nickel–zinc (NiZn), nickel–metal hydride (NiMH), and lithium-ion (Li-ion) cells. Li-ion has by far the highest share of the dry cell rechargeable market. NiMH has replaced NiCd in most applications due to its higher capacity, but NiCd remains in use in power tools, two-way radios, and medical equipment.\nIn the 2000s, developments include batteries with embedded electronics such as USBCELL, which allows charging an AA battery through a USB connector, nanoball batteries that allow for a discharge rate about 100x greater than current batteries, and smart battery packs with state-of-charge monitors and battery protection circuits that prevent damage on over-discharge. Low self-discharge (LSD) allows secondary cells to be charged prior to shipping.\nLithium–sulfur batteries were used on the longest and highest solar-powered flight.[40]\nConsumer and industrial grades\nBatteries of all types are manufactured in consumer and industrial grades. Costlier industrial-grade batteries may use chemistries that provide higher power-to-size ratio, have lower self-discharge and hence longer life when not in use, more resistance to leakage and, for example, ability to handle the high temperature and humidity associated with medical autoclave sterilization.[41]\nCombination and management\nStandard-format batteries are inserted into battery holder in the device that uses them. When a device does not uses standard-format batteries, they are typically combined into a custom battery pack which holds multiple batteries in addition to features such as a battery management system and battery isolator which ensure that the batteries within are charged and discharged evenly.\nSizes\nPrimary batteries readily available to consumers range from tiny button cells used for electric watches, to the No. 6 cell used for signal circuits or other long duration applications. Secondary cells are made in very large sizes; very large batteries can power a submarine or stabilize an electrical grid and help level out peak loads.\nAs of 2017[update], the world's largest battery was built in South Australia by Tesla. It can store 129 MWh.[42] A battery in Hebei Province, China, which can store 36 MWh of electricity was built in 2013 at a cost of $500 million.[43] Another large battery, composed of Ni–Cd cells, was in Fairbanks, Alaska. It covered 2,000 square metres (22,000 sq ft)—bigger than a football pitch—and weighed 1,300 tonnes. It was manufactured by ABB to provide backup power in the event of a blackout. The battery can provide 40 MW of power for up to seven minutes.[44] Sodium–sulfur batteries have been used to store wind power.[45] A 4.4 MWh battery system that can deliver 11 MW for 25 minutes stabilizes the output of the Auwahi wind farm in Hawaii.[46]\nComparison\nMany important cell properties, such as voltage, energy density, flammability, available cell constructions, operating temperature range and shelf life, are dictated by battery chemistry.[47]\n| Chemistry | Anode (−) | Cathode (+) | Max. voltage, theoretical (V) | Nominal voltage, practical (V) | Specific energy (kJ/kg) | Elaboration | Shelf life at 25 °C, 80% capacity (months) |\n|---|---|---|---|---|---|---|---|\n| Zinc–carbon | Zn | C | 1.6 | 1.2 | 130 | Inexpensive. | 18 |\n| Zinc–chloride | Zn | C | 1.5 | Also known as \"heavy-duty\", inexpensive. | |||\n| Alkaline (zinc–manganese dioxide) | Zn | MnO2 | 1.5 | 1.15 | 400–590 | Moderate energy density. Good for high- and low-drain uses. | 30 |\n| Nickel oxyhydroxide (zinc–manganese dioxide/nickel oxyhydroxide) | 1.7 | Moderate energy density. Good for high drain uses. | |||||\n| Lithium (lithium–copper oxide) Li–CuO | Li | CuO | 1.7 | No longer manufactured. Replaced by silver oxide (IEC-type \"SR\") batteries. | |||\n| Lithium (lithium–iron disulfide) LiFeS2 | Li | FeS2 | 1.8 | 1.5 | 1070 | Expensive. Used in 'plus' or 'extra' batteries. | 337[48] |\n| Lithium (lithium–manganese dioxide) LiMnO2 | Li | MnO2 | 3.0 | 830–1010 | Expensive. Used only in high-drain devices or for long shelf-life due to very low rate of self-discharge. 'Lithium' alone usually refers to this type of chemistry. | ||\n| Lithium (lithium–carbon fluoride) Li–(CF)n | Li | (CF)n | 3.6 | 3.0 | 120 | ||\n| Lithium (lithium–chromium oxide) Li–CrO2 | Li | CrO2 | 3.8 | 3.0 | 108 | ||\n| Lithium (lithium-silicon) | Li22Si5 | ||||||\n| Mercury oxide | Zn | HgO | 1.34 | 1.2 | High-drain and constant voltage. Banned in most countries because of health concerns. | 36 | |\n| Zinc–air | Zn | O2 | 1.6 | 1.1 | 1590[49] | Used mostly in hearing aids. | |\n| Zamboni pile | Zn | Ag or Au | 0.8 | Very long life. Very low (nanoamp, nA) current | >2,000 | ||\n| Silver oxide (silver–zinc) | Zn | Ag2O | 1.85 | 1.5 | 470 | Very expensive. Used only commercially in 'button' cells. | 30 |\n| Magnesium | Mg | MnO2 | 2.0 | 1.5 | 40 |\n| Chemistry | Cell voltage | Specific energy (kJ/kg) | Energy density (kJ/liter) | Comments |\n|---|---|---|---|---|\n| NiCd | 1.2 | 140 | Inexpensive. High-/low-drain, moderate energy density. Can withstand very high discharge rates with virtually no loss of capacity. Moderate rate of self-discharge. Environmental hazard due to Cadmium, use now virtually prohibited in Europe. | |\n| Lead–acid | 2.1 | 140 | Moderately expensive. Moderate energy density. Moderate rate of self-discharge. Higher discharge rates result in considerable loss of capacity. Environmental hazard due to Lead. Common use: automobile batteries | |\n| NiMH | 1.2 | 360 | Inexpensive. Performs better than alkaline batteries in higher drain devices. Traditional chemistry has high energy density, but also a high rate of self-discharge. Newer chemistry has low self-discharge rate, but also a ~25% lower energy density. Used in some cars. | |\n| NiZn | 1.6 | 360 | Moderately inexpensive. High drain device suitable. Low self-discharge rate. Voltage closer to alkaline primary cells than other secondary cells. No toxic components. Newly introduced to the market (2009). Has not yet established a track record. Limited size availability. | |\n| AgZn | 1.86 1.5 | 460 | Smaller volume than equivalent Li-ion. Extremely expensive due to silver. Very high energy density. Very high drain capable. For many years considered obsolete due to high silver prices. Cell suffers from oxidation if unused. Reactions are not fully understood. Terminal voltage very stable but suddenly drops to 1.5 volts at 70–80% charge (believed to be due to presence of both argentous and argentic oxide in positive plate; one is consumed first). Has been used in lieu of primary battery (moon buggy). Is being developed once again as a replacement for Li-ion. | |\n| LiFePO4 | 3.3 3.0 | 360 | 790 | Lithium–Iron–Phosphate chemistry. |\n| Lithium ion | 3.6 | 460 | Very expensive. Very high energy density. Not usually available in \"common\" battery sizes. Lithium polymer battery is common in laptop computers, digital cameras, camcorders, and cellphones. Very low rate of self-discharge. Terminal voltage varies from 4.2 to 3.0 volts during discharge. Volatile: Chance of explosion if short-circuited, allowed to overheat, or not manufactured with rigorous quality standards. |\nA battery's characteristics may vary over load cycle, over charge cycle, and over lifetime due to many factors including internal chemistry, current drain, and temperature. At low temperatures, a battery cannot deliver as much power. As such, in cold climates, some car owners install battery warmers, which are small electric heating pads that keep the car battery warm.\nA battery's capacity is the amount of electric charge it can deliver at a voltage that does not drop below the specified terminal voltage. The more electrode material contained in the cell the greater its capacity. A small cell has less capacity than a larger cell with the same chemistry, although they develop the same open-circuit voltage.[50] Capacity is usually stated in ampere-hours (A·h) (mAh for small batteries). The rated capacity of a battery is usually expressed as the product of 20 hours multiplied by the current that a new battery can consistently supply for 20 hours at 20 °C (68 °F), while remaining above a specified terminal voltage per cell. For example, a battery rated at 100 A·h can deliver 5 A over a 20-hour period at room temperature. The fraction of the stored charge that a battery can deliver depends on multiple factors, including battery chemistry, the rate at which the charge is delivered (current), the required terminal voltage, the storage period, ambient temperature and other factors.[51][50]\nThe higher the discharge rate, the lower the capacity.[52] The relationship between current, discharge time and capacity for a lead acid battery is approximated (over a typical range of current values) by Peukert's law:\nwhere\n- is the capacity when discharged at a rate of 1 amp.\n- is the current drawn from battery (A).\n- is the amount of time (in hours) that a battery can sustain.\n- is a constant around 1.3.\nCharged batteries (rechargeable or disposable) lose charge by internal self-discharge over time although not discharged, due to the presence of generally irreversible side reactions that consume charge carriers without producing current. The rate of self-discharge depends upon battery chemistry and construction, typically from months to years for significant loss. When batteries are recharged, additional side reactions reduce capacity for subsequent discharges. After enough recharges, in essence all capacity is lost and the battery stops producing power. Internal energy losses and limitations on the rate that ions pass through the electrolyte cause battery efficiency to vary. Above a minimum threshold, discharging at a low rate delivers more of the battery's capacity than at a higher rate. Installing batteries with varying A·h ratings changes operating time, but not device operation unless load limits are exceeded. High-drain loads such as digital cameras can reduce total capacity of rechargeable or disposable batteries. For example, a battery rated at 2 A·h for a 10- or 20-hour discharge would not sustain a current of 1 A for a full two hours as its stated capacity suggests.\nC-rate is a measure of the rate at which a battery is being charged or discharged. It is defined as the current through the battery divided by the theoretical current draw under which the battery would deliver its nominal rated capacity in one hour.[53] It has the units h−1. Because of internal resistance loss and the chemical processes inside the cells, a battery rarely delivers nameplate rated capacity in only one hour. Typically, maximum capacity is found at a low C-rate, and charging or discharging at a higher C-rate reduces the usable life and capacity of a battery. Manufacturers often publish datasheets with graphs showing capacity versus C-rate curves. C-rate is also used as a rating on batteries to indicate the maximum current that a battery can safely deliver in a circuit. Standards for rechargeable batteries generally rate the capacity and charge cycles over a 4-hour (0.25C), 8 hour (0.125C) or longer discharge time. Types intended for special purposes, such as in a computer uninterruptible power supply, may be rated by manufacturers for discharge periods much less than one hour (1C) but may suffer from limited cycle life.\nIn 2009 experimental lithium iron phosphate (LiFePO\n4) battery technology provided the fastest charging and energy delivery, discharging all its energy into a load in 10 to 20 seconds.[54] In 2024 a prototype battery for electric cars that could charge from 10% to 80% in five minutes was demonstrated,[55] and a Chinese company claimed that car batteries it had introduced charged 10% to 80% in 10.5 minutes—the fastest batteries available—compared to Tesla's 15 minutes to half-charge.[56]\nLifespan and endurance\nBattery life (or lifetime) has two meanings for rechargeable batteries but only one for non-chargeable batteries. It can be used to describe the length of time a device can run on a fully charged battery—this is also unambiguously termed \"endurance\".[57] For a rechargeable battery it may also be used for the number of charge/discharge cycles possible before the cells fail to operate satisfactorily—this is also termed \"lifespan\".[58] The term shelf life is used to describe how long a battery will retain its performance between manufacture and use. Available capacity of all batteries drops with decreasing temperature. In contrast to most of today's batteries, the Zamboni pile, invented in 1812, offers a very long service life without refurbishment or recharge, although it can supply very little current (nanoamps). The Oxford Electric Bell has been ringing almost continuously since 1840 on its original pair of batteries, thought to be Zamboni piles.[citation needed]\nDisposable batteries typically lose 8–20% of their original charge per year when stored at room temperature (20–30 °C).[59] This is known as the \"self-discharge\" rate, and is due to non-current-producing \"side\" chemical reactions that occur within the cell even when no load is applied. The rate of side reactions is reduced for batteries stored at lower temperatures, although some can be damaged by freezing and storing in a fridge will not meaningfully prolong shelf life and risks damaging condensation.[60] Old rechargeable batteries self-discharge more rapidly than disposable alkaline batteries, especially nickel-based batteries; a freshly charged nickel cadmium (NiCd) battery loses 10% of its charge in the first 24 hours, and thereafter discharges at a rate of about 10% a month. However, newer low self-discharge nickel–metal hydride (NiMH) batteries and modern lithium designs display a lower self-discharge rate (but still higher than for primary batteries).\nThe active material on the battery plates changes chemical composition on each charge and discharge cycle; active material may be lost due to physical changes of volume, further limiting the number of times the battery can be recharged. Most nickel-based batteries are partially discharged when purchased, and must be charged before first use.[61] Newer NiMH batteries are ready to be used when purchased, and have only 15% discharge in a year.[62]\nSome deterioration occurs on each charge–discharge cycle. Degradation usually occurs because electrolyte migrates away from the electrodes or because active material detaches from the electrodes. Low-capacity NiMH batteries (1,700–2,000 mA·h) can be charged some 1,000 times, whereas high-capacity NiMH batteries (above 2,500 mA·h) last about 500 cycles.[63] NiCd batteries tend to be rated for 1,000 cycles before their internal resistance permanently increases beyond usable values. Fast charging increases component changes, shortening battery lifespan.[63] If a charger cannot detect when the battery is fully charged then overcharging is likely, damaging it.[64]\nNiCd cells, if used in a particular repetitive manner, may show a decrease in capacity called \"memory effect\".[65] The effect can be avoided with simple practices. NiMH cells, although similar in chemistry, suffer less from memory effect.[66]\nAutomotive lead–acid rechargeable batteries must endure stress due to vibration, shock, and temperature range. Because of these stresses and sulfation of their lead plates, few automotive batteries last beyond six years of regular use.[67] Automotive starting (SLI: Starting, Lighting, Ignition) batteries have many thin plates to maximize current. In general, the thicker the plates the longer the life. They are typically discharged only slightly before recharge. \"Deep-cycle\" lead–acid batteries such as those used in electric golf carts have much thicker plates to extend longevity.[68] The main benefit of the lead–acid battery is its low cost; its main drawbacks are large size and weight for a given capacity and voltage. Lead–acid batteries should never be discharged to below 20% of their capacity,[69] because internal resistance will cause heat and damage when they are recharged. Deep-cycle lead–acid systems often use a low-charge warning light or a low-charge power cut-off switch to prevent the type of damage that will shorten the battery's life.[70]\nBattery life can be extended by storing the batteries at a low temperature, as in a refrigerator or freezer, which slows the side reactions. Such storage can extend the life of alkaline batteries by about 5%; rechargeable batteries can hold their charge much longer, depending upon type.[71] To reach their maximum voltage, batteries must be returned to room temperature; discharging an alkaline battery at 250 mA at 0 °C is only half as efficient as at 20 °C.[34] Alkaline battery manufacturers such as Duracell do not recommend refrigerating batteries.[33]\nHazards\nA battery explosion is generally caused by misuse or malfunction, such as attempting to recharge a primary (non-rechargeable) battery, or a short circuit.\nWhen a battery is recharged at an excessive rate, an explosive gas mixture of hydrogen and oxygen may be produced faster than it can escape from within the battery (e.g. through a built-in vent), leading to pressure build-up and eventual bursting of the battery case. In extreme cases, battery chemicals may spray violently from the casing and cause injury. An expert summary of the problem indicates that this type uses \"liquid electrolytes to transport lithium ions between the anode and the cathode. If a battery cell is charged too quickly, it can cause a short circuit, leading to explosions and fires\".[72][73] Car batteries are most likely to explode when a short circuit generates very large currents. Such batteries produce hydrogen, which is very explosive, when they are overcharged (because of electrolysis of the water in the electrolyte). During normal use, the amount of overcharging is usually very small and generates little hydrogen, which dissipates quickly. However, when \"jump starting\" a car, the high current can cause the rapid release of large volumes of hydrogen, which can be ignited explosively by a nearby spark, e.g. when disconnecting a jumper cable.\nOvercharging (attempting to charge a battery beyond its electrical capacity) can also lead to a battery explosion, in addition to leakage or irreversible damage. It may also cause damage to the charger or device in which the overcharged battery is later used.\nDisposing of a battery via incineration may cause an explosion as steam builds up within the sealed case.\nMany battery chemicals are corrosive, poisonous or both. If leakage occurs, either spontaneously or through accident, the chemicals released may be dangerous. For example, disposable batteries often use a zinc \"can\" both as a reactant and as the container to hold the other reagents. If this kind of battery is over-discharged, the reagents can emerge through the cardboard and plastic that form the remainder of the container. The active chemical leakage can then damage or disable the equipment that the batteries power. For this reason, many electronic device manufacturers recommend removing the batteries from devices that will not be used for extended periods of time.\nMany types of batteries employ toxic materials such as lead, mercury, and cadmium as an electrode or electrolyte. When each battery reaches end of life it must be disposed of to prevent environmental damage.[74] Batteries are one form of electronic waste (e-waste). E-waste recycling services recover toxic substances, which can then be used for new batteries.[75] Of the nearly three billion batteries purchased annually in the United States, about 179,000 tons end up in landfills across the country.[76]\nBatteries may be harmful or fatal if swallowed.[77] Small button cells can be swallowed, in particular by young children. While in the digestive tract, the battery's electrical discharge may lead to tissue damage;[78] such damage is occasionally serious and can lead to death. Ingested disk batteries do not usually cause problems unless they become lodged in the gastrointestinal tract. The most common place for disk batteries to become lodged is the esophagus, resulting in clinical sequelae. Batteries that successfully traverse the esophagus are unlikely to lodge elsewhere. The likelihood that a disk battery will lodge in the esophagus is a function of the patient's age and battery size. Older children do not have problems with batteries smaller than 21–23 mm. Liquefaction necrosis may occur because sodium hydroxide is generated by the current produced by the battery (usually at the anode). Perforation has occurred as rapidly as 6 hours after ingestion.[79]\nSome battery manufactures have added a bad taste to batteries to discourage swallowing.[80]\nLegislation and regulation\nLegislation around electric batteries includes such topics as safe disposal and recycling.\nIn the United States, the Mercury-Containing and Rechargeable Battery Management Act of 1996 banned the sale of mercury-containing batteries, enacted uniform labeling requirements for rechargeable batteries and required that rechargeable batteries be easily removable.[81] California and New York City prohibit the disposal of rechargeable batteries in solid waste.[82][83] The rechargeable battery industry operates nationwide recycling programs in the United States and Canada, with dropoff points at local retailers.[84]\nThe Battery Directive of the European Union has similar requirements, in addition to requiring increased recycling of batteries and promoting research on improved battery recycling methods.[85] In accordance with this directive all batteries to be sold within the EU must be marked with the \"collection symbol\" (a crossed-out wheeled bin). This must cover at least 3% of the surface of prismatic batteries and 1.5% of the surface of cylindrical batteries. All packaging must be marked likewise.[86]\nIn response to reported accidents and failures, occasionally ignition or explosion, recalls of devices using lithium-ion batteries have become more common in recent years.[87][88]\nOn 9 December 2022, the European Parliament reached an agreement to force, from 2026, manufacturers to design all electrical appliances sold in the EU (and not used predominantly in wet conditions) so that consumers can easily remove and replace batteries themselves.[89][90]\nSee also\nReferences\n- Crompton, T. R. (20 March 2000). Battery Reference Book (third ed.). Newnes. p. Glossary 3. ISBN 978-0-08-049995-6. Retrieved 18 March 2016.\n- Pauling, Linus (1988). \"15: Oxidation-Reduction Reactions; Electrolysis\". General Chemistry. New York: Dover Publications, Inc. p. 539. ISBN 978-0-486-65622-9.\n- Pistoia, Gianfranco (25 January 2005). Batteries for Portable Devices. Elsevier. p. 1. ISBN 978-0-08-045556-3. Retrieved 18 March 2016.\n- \"The history and development of batteries\". 30 April 2015.\n- \". www.benfranklin300.org.\n- Bellis, Mary. Biography of Alessandro Volta, Inventor of the Battery. About.com. Retrieved 7 August 2008\n- Stinner, Arthur. Alessandro Volta and Luigi Galvani Archived 10 September 2008 at the Wayback Machine (PDF). Retrieved 11 August 2008.\n- Fascinating facts about the invention of the Electric Battery by Alessandro Volta in 1800. The Great Idea Finder. Retrieved 11 August 2008\n- for instance, in the discovery of electromagnetism in 1820\n- Battery History, Technology, Applications and Development Archived 12 May 2011 at the Wayback Machine. MPower Solutions Ltd. Retrieved 19 March 2007.\n- Borvon, Gérard (10 September 2012). \"History of the electrical units\". Association S-EAU-S.\n- \"Columbia Dry Cell Battery\". National Historic Chemical Landmarks. American Chemical Society. Archived from the original on 23 February 2013. Retrieved 25 March 2013.\n- Brudermüller, Martin; Sobotka, Benedikt; Dominic, Waughray (September 2019). Insight Report — A Vision for a Sustainable Battery Value Chain in 2030 : Unlocking the Full Potential to Power Sustainable Development and Climate Change Mitigation (PDF) (Report). World Economic Forum & Global Battery Alliance. pp. 11, 29. Retrieved 2 June 2021.\n- Siano, Pierluigi (2014). \"Demand response and smart grids-A survey\". Renewable and Sustainable Energy Reviews. 30. Elsevier: 461–478. Bibcode:2014RSERv..30..461S. doi:10.1016/j.rser.2013.10.022. ISSN 1364-0321.\n- Pan, AQ; Li, XZ; Shang, J; Feng, JH; Tao, YB; Ye, JL; Yang, X; Li, C; Liao, QQ (2019). The applications of echelon use batteries from electric vehicles to distributed energy storage systems. 2019 International Conference on New Energy and Future Energy System (IOP Conf. Series: Earth and Environmental Science). Vol. 354. IOP Publishing Ltd. doi:10.1088/1755-1315/354/1/012012. 012012.\n- Leisch, Jennifer E.; Chernyakhovskiy, Ilya (September 2019). Grid-Scale Battery Storage : Frequently Asked Questions (PDF) (Report). National Renewable Energy Laboratory (NREL) & greeningthegrid.org. Retrieved 21 May 2021.\n- Hanaor, Dorian A. H., ed. (2024). Computational Design of Battery Materials. Topics in Applied Physics. Vol. 150. Springer. doi:10.1007/978-3-031-47303-6. ISBN 978-3-031-47302-9.\n- Ashcroft, N.W.; Mermin (1976). Solid State Physics. N.D. Belmont, CA: Brooks/Cole.\n- Dingrando 665.\n- Saslow 338.\n- Dingrando 666.\n- Knight 943.\n- Knight 976.\n- Terminal Voltage. Tiscali Reference. Originally from Hutchinson Encyclopaedia. Retrieved 7 April 2007\n- Dingrando 674.\n- Dingrando 677.\n- \"The Lemon Battery\". ushistory.org. Archived from the original on 9 May 2007. Retrieved 10 April 2007.\n- ZOOM activities: phenom Potato Battery. Accessed 10 April 2007.\n- Howstuffworks \"Battery Experiments: Voltaic Pile\". Accessed 10 April 2007.\n- Dingrando 675.\n- Fink, Ch. 11, Sec. \"Batteries and Fuel Cells.\"\n- Franklin Leonard Pope, Modern Practice of the Electric Telegraph 15th Edition, D. Van Nostrand Company, New York, 1899, pp. 7–11. Available on the Internet Archive\n- Duracell: Battery Care Archived 3 September 2011 at the Wayback Machine. Retrieved 10 August 2008.\n- Alkaline Manganese Dioxide Handbook and Application Manual Archived 16 December 2010 at the Wayback Machine (PDF). Energizer. Retrieved 25 August 2008.\n- \"Spotlight on Photovoltaics & Fuel Cells: A Web-based Study & Comparison\" (PDF). pp. 1–2. Retrieved 14 March 2007.\n- \"Lithium-Ion Battery Inventor Introduces New Technology for Fast-Charging, Noncombustible Batteries\". University of Texas at Austin. University of Texas. 28 February 2017. Retrieved 15 March 2017.\n- Hislop, Martin (1 March 2017). \"Solid-state EV battery breakthrough from Li-ion battery inventor John Goodenough\". North American Energy News. The American Energy News. Retrieved 15 March 2017.\nBut even John Goodenough's work doesn't change my forecast that EVs will take at least 50 years to reach 70 to 80 percent of the global vehicle market.\n- Sony Develops A Bio Battery Powered By Sugar Archived 11 October 2007 at the Wayback Machine. Accessed 24 August 2007.\n- Dynasty VRLA Batteries and Their Application Archived 6 February 2009 at the Wayback Machine. C&D Technologies, Inc. Retrieved 26 August 2008.\n- Amos, J. (24 August 2008) \"Solar plane makes record flight\" BBC News\n- Adams, Louis (November 2015). \"Powering Tomorrow's Medicine: Critical Decisions for Batteries in Medical Applications\". Medical Design Briefs.\n- \"Elon Musk wins $50m bet with giant battery for South Australia\". Sky News. 24 November 2017. Retrieved 20 September 2018.\n- Dillow, Clay (21 December 2012). \"China Builds the World's Largest Battery, a Building-Sized, 36-Megawatt-Hour Behemoth | Popular Science\". Popsci.com. Retrieved 31 July 2013.\n- Conway, E. (2 September 2008) \"World's biggest battery switched on in Alaska\" Telegraph.co.uk\n- Biello, D. (22 December 2008) \"Storing the Breeze: New Battery Might Make Wind Power More Reliable\" Scientific American\n- \"Auwahi Wind | Energy Solutions | Sempra U.S. Gas & Power, LLC\". Semprausgp.com. Archived from the original on 2 May 2014. Retrieved 31 July 2013.\n- \"How a battery works\". Curious. 25 February 2016. Archived from the original on 26 March 2022.\n- \"Lithium Iron Disulfide Handbook and Application Manual\" (PDF). energizer.com. Archived from the original (PDF) on 17 March 2006. Retrieved 20 September 2018.\n- Excludes the mass of the air oxidizer.\n- Battery Knowledge – AA Portable Power Corp. Retrieved 16 April 2007. Archived 23 May 2007 at the Wayback Machine\n- Schlesinger, Henry R. (2010). The battery: how portable power sparked a technological revolution (1st ed.). [Washington, D.C.] : New York: Smithsonian Books ; Harper. ISBN 978-0-06-144293-3. OCLC 419855785.\n- \"Battery Capacity\". techlib.com.\n- A Guide to Understanding Battery Specifications, MIT Electric Vehicle Team, December 2008\n- Kang, B.; Ceder, G. (2009). \"Battery materials for ultrafast charging and discharging\". Nature. 458 (7235): 190–193. Bibcode:2009Natur.458..190K. doi:10.1038/nature07853. PMID 19279634. S2CID 20592628.1:00–6:50 (audio) Archived 22 February 2012 at the Wayback Machine\n- \"Cambridge spin-out's sportscar prototype takes ultra-fast charging out of the lab and onto the road\". University of Cambridge. 1 July 2024.\n- da Silva, João (14 August 2024). \"Zeekr: China EV firm claims world's fastest-charging battery\". BBC News.\n- \"Battery cycling and endurance testing\". University of Sheffield Centre for Research into Electrical Energy Storage and Applications. 5 October 2020.\n- \"Battery Lifespan\". NREL - Transportation & Mobility Research. 30 March 2023.\n- Self discharge of batteries. Corrosion Doctors. Retrieved 9 September 2007\n- Tugend, Alina (10 November 2007). \"In Battery Buying, Enough Decisions to Exhaust That Bunny\". The New York Times. Retrieved 6 July 2024.\n- Energizer Rechargeable Batteries and Chargers: Frequently Asked Questions Archived 9 February 2009 at the Wayback Machine. Energizer. Retrieved 3 February 2009.\n- \"eneloop, environmentally friendly and energy saving batteries | Panasonic eneloop\". www.panasonic-eneloop.eu. Archived from the original on 2 February 2010.\n- Rechargeable battery Tips. NIMH Technology Information. Retrieved 10 August 2007\n- Battery Myths vs Battery Facts. Retrieved 10 August 2007\n- Filip M. Gieszczykiewicz. \"Sci.Electronics FAQ: More Battery Info\". repairfaq.org.\n- RechargheableBatteryInfo.com, ed. (28 October 2005), What does 'memory effect' mean?, archived from the original on 15 July 2007, retrieved 10 August 2007\n- Rich, Vincent (1994). The International Lead Trade. Cambridge: Woodhead. 129.\n- Deep Cycle Battery FAQ Archived 22 July 2010 at the Wayback Machine. Northern Arizona Wind & Sun. Retrieved 3 February 2009.\n- Car and Deep Cycle Battery FAQ Archived 6 November 2020 at the Wayback Machine. Rainbow Power Company. Retrieved 3 February 2009.\n- Deep cycle battery guide Archived 17 February 2009 at the Wayback Machine. Energy Matters. Retrieved 3 February 2009.\n- Ask Yahoo: Does putting batteries in the freezer make them last longer? Archived 27 April 2006 at the Wayback Machine. Retrieved 7 March 2007.\n- Hislop, Martin (1 March 2017). \"Solid-state EV battery breakthrough from Li-ion battery inventor John Goodenough\". North American Energy News. The American Energy News. Retrieved 15 March 2017.\n- \"battery hazards\". YouTube. Retrieved 20 September 2018.\n- Batteries. EPA. Retrieved 11 September 2007\n- Battery Recycling » Earth 911 Archived 12 October 2008 at the Wayback Machine. Retrieved 9 September 2007.\n- \"San Francisco Supervisor Takes Aim at Toxic Battery Waste\". Environmental News Network (11 July 2001).\n- \"Product Safety DataSheet. Energizer (p. 2). Retrieved 9 September 2007\" (PDF). Archived from the original (PDF) on 27 September 2007. Retrieved 9 September 2007.\n- \"Swallowed a Button Battery? | Battery in the Nose or Ear?\". Poison.org. 3 March 2010. Archived from the original on 16 August 2013. Retrieved 26 July 2013.\n- Dire, Daniel J. (9 June 2016), Vearrier, David (ed.), \"Disk Battery Ingestion: Background, Pathophysiology, Epidemiology\", Medscape\n- Bitter tasting battey discourages ingestion., 25 October 2021\n- \"Mercury-Containing and Rechargeable Battery Management Act\" (PDF). EPA. Retrieved 15 February 2021.\n- \"Battery Recycling in New York... it's the law!\". call2recycle.org. 31 October 2013. Retrieved 2 June 2021.\n- Bill No. 1125 - Rechargeable Battery Recycling Act of 2006, State of California (PDF), 2006, retrieved 2 June 2021\n- \"Rechargeable Battery Recycling Corporation\". www.rbrc.org. Archived from the original on 12 August 2008. Retrieved 15 January 2022.\n- Disposal of spent batteries and accumulators. European Union. Retrieved 27 July 2009.\n- \"Guidelines on Portable Batteries Marking Requirements in the European Union 2008\" (PDF). EPBA-EU. Archived from the original (PDF) on 7 October 2011.\n- Schweber, Bill (4 August 2015). \"Lithium Batteries: The Pros and Cons\". GlobalSpec. Retrieved 15 March 2017.\n- Fowler, Suzanne (21 September 2016). \"Samsung's Recall – The Problem with Lithium Ion Batteries\". The New York Times. New York. Retrieved 15 March 2016.\n- \"Batteries: deal on new EU rules for design, production and waste treatment\". News European Parliament (Press release). European Parliament. 9 December 2022. Archived from the original on 11 December 2022. Retrieved 11 December 2022.\n- \"Neue EU-Regeln: Jeder soll Handy-Akkus selbst tauschen können\" [New EU rules: Everyone should be able to replace smartphone batteries themselves]. Wirtschaft. Der Spiegel (in German). 9 December 2022. Archived from the original on 11 December 2022. Retrieved 11 December 2022.\nBibliography\n- Dingrando, Laurel; et al. (2007). Chemistry: Matter and Change. New York: Glencoe/McGraw-Hill. ISBN 978-0-07-877237-5.\n- Fink, Donald G.; H. Wayne Beaty (1978). Standard Handbook for Electrical Engineers, Eleventh Edition. New York: McGraw-Hill. ISBN 978-0-07-020974-9.\n- Knight, Randall D. (2004). Physics for Scientists and Engineers: A Strategic Approach. San Francisco: Pearson Education. ISBN 978-0-8053-8960-9.\n- Linden, David; Thomas B. Reddy (2001). Handbook of Batteries. New York: McGraw-Hill. ISBN 978-0-07-135978-8.\n- Saslow, Wayne M. (2002). Electricity, Magnetism, and Light. Toronto: Thomson Learning. ISBN 978-0-12-619455-5.\n- Turner, James Morton. Charged: A History of Batteries and Lessons for a Clean Energy Future (University of Washington Press, 2022). online review\nExternal links\n- Media related to Electric batteries at Wikimedia Commons\n- Non-rechargeable batteries (archived 22 October 2013)\n- HowStuffWorks: How batteries work\n- Other Battery Cell Types\n- DoITPoMS Teaching and Learning Package- \"Batteries\"",
    "beverage industry": "The drink industry (or drinks industry, also known as the beverage industry) produces drinks, in particular alcoholic beverages, ready to drink beverages, and soft drink products.[1]\nDrink production can vary greatly depending on the product being made. ManufacturingDrinks.com explains that \"bottling facilities differ in the types of bottling lines they operate and the types of products they can run\". Drinks may be packaged in glass bottles, plastic bottles, or metal cans. Innovations in the drink industry, catalysed by requests for non-alcoholic drinks, include hot-fill or cold-fill, drink plants, processing, and packing.[2]\nLargest beverage companies worldwide in 2021:[3]\n- Alcoholic beverage\n- Alcoholic beverage industry in Europe\n- Brewing industry\n- List of drinks\n- Soft drink\n- Bottled water\n- Food industry\n- Container-deposit legislation\n- Beverage Digest\n- Drinks Industry Group of Ireland, Welcome to DIGI Online, accessed 28 November 2022\n- \"Beverage Production\". Manufacturingdrinks.com. 7 June 2010. Retrieved 21 May 2013.\n- \"Entreprises de boissons : ventes nettes Monde\". Statista (in French). Retrieved 12 November 2023.\n- Principles of Food, Beverage, and Labor Cost Controls. Paul R. Dittmer, J. Desmond Keefe. John Wiley & Sons. 3 December 2008\n- Lea, Andrew Geoffrey Howard; Piggott, John Raymond (2003). Fermented Beverage Production. Springer. ISBN 9780306472756.\n| |||||||||||\n| |||||||||||\n| |||||||||||\n| |||||||||||\n| Africa | |\n|---|---|\n| Asia | |\n| Europe |\n|\n| North America | |\n| South America | |\n| Oceania | |\n| Ale |\n| ||||\n|---|---|---|---|---|---|\n| Lager | |||||\n| Other styles |\n| ||||\n| See also | |||||\n| Absinthe | ||\n|---|---|---|\n| Beer | ||\n| Brandy | ||\n| Cachaça | ||\n| Champagne | ||\n| Gin | ||\n| Ouzo | ||\n| Rum | ||\n| Sake | ||\n| Tequila | ||\n| Vodka |\n| |\n| Whisky | ||\n| See also |\n| The Unforgettables |\n|\n|---|---|\n| Contemporary Classics |\n|\n| New Era Drinks |\n|\n| See also |\n| Fortified wine | |\n|---|---|\n| Wine cocktails | |\n| Sparkling wine | |\n| Champagne | |\n| Red wine | |\n| White wine | |\n| Miscellaneous |\n| Brands | |\n|---|---|\n| Types | |\n| Health | |\n| Companies | |\n| Misc. | |\n| Africa | |\n|---|---|\n| Asia | |\n| Europe |\n|\n| North America | |\n| Oceania | |\n| South America |",
    "biotechnology industry": "Biotechnology is a multidisciplinary field that involves the integration of natural sciences and engineering sciences in order to achieve the application of organisms and parts thereof for products and services.[1] Specialists in the field are known as biotechnologists.\nThe term biotechnology was first used by Károly Ereky in 1919[2] to refer to the production of products from raw materials with the aid of living organisms. The core principle of biotechnology involves harnessing biological systems and organisms, such as bacteria, yeast, and plants, to perform specific tasks or produce valuable substances.\nBiotechnology had a significant impact on many areas of society, from medicine to agriculture to environmental science. One of the key techniques used in biotechnology is genetic engineering, which allows scientists to modify the genetic makeup of organisms to achieve desired outcomes. This can involve inserting genes from one organism into another, and consequently, create new traits or modifying existing ones.[3]\nOther important techniques used in biotechnology include tissue culture, which allows researchers to grow cells and tissues in the lab for research and medical purposes, and fermentation, which is used to produce a wide range of products such as beer, wine, and cheese.\nThe applications of biotechnology are diverse and have led to the development of products like life-saving drugs, biofuels, genetically modified crops, and innovative materials.[4] It has also been used to address environmental challenges, such as developing biodegradable plastics and using microorganisms to clean up contaminated sites.\nBiotechnology is a rapidly evolving field with significant potential to address pressing global challenges and improve the quality of life for people around the world; however, despite its numerous benefits, it also poses ethical and societal challenges, such as questions around genetic modification and intellectual property rights. As a result, there is ongoing debate and regulation surrounding the use and application of biotechnology in various industries and fields.[5]\n| Part of a series on |\n| Biology |\n|---|\nBiotechnology encompasses a wide range of procedures for modifying living organisms for human purposes, going back to domestication of animals, cultivation of plants, and \"improvements\" to these through breeding programs that employ artificial selection and hybridization. Modern usage also includes genetic engineering, as well as cell and tissue culture technologies. The American Chemical Society defines biotechnology as the application of biological organisms, systems, or processes by various industries to learning about the science of life and the improvement of the value of materials and organisms, such as pharmaceuticals, crops, and livestock.[6] As per the European Federation of Biotechnology, biotechnology is the integration of natural science and organisms, cells, parts thereof, and molecular analogues for products and services.[7] Biotechnology is based on the basic biological sciences (e.g., molecular biology, biochemistry, cell biology, embryology, genetics, microbiology) and conversely provides methods to support and perform basic research in biology.[citation needed]\nBiotechnology is the research and development in the laboratory using bioinformatics for exploration, extraction, exploitation, and production from any living organisms and any source of biomass by means of biochemical engineering where high value-added products could be planned (reproduced by biosynthesis, for example), forecasted, formulated, developed, manufactured, and marketed for the purpose of sustainable operations (for the return from bottomless initial investment on R & D) and gaining durable patents rights (for exclusives rights for sales, and prior to this to receive national and international approval from the results on animal experiment and human experiment, especially on the pharmaceutical branch of biotechnology to prevent any undetected side-effects or safety concerns by using the products).[8][9][10] The utilization of biological processes, organisms or systems to produce products that are anticipated to improve human lives is termed biotechnology.[11]\nBy contrast, bioengineering is generally thought of as a related field that more heavily emphasizes higher systems approaches (not necessarily the altering or using of biological materials directly) for interfacing with and utilizing living things. Bioengineering is the application of the principles of engineering and natural sciences to tissues, cells, and molecules. This can be considered as the use of knowledge from working with and manipulating biology to achieve a result that can improve functions in plants and animals.[12] Relatedly, biomedical engineering is an overlapping field that often draws upon and applies biotechnology (by various definitions), especially in certain sub-fields of biomedical or chemical engineering such as tissue engineering, biopharmaceutical engineering, and genetic engineering.[citation needed]\nMany forms of human-derived agriculture fit the broad definition of \"utilizing a biotechnological system to make products\". The cultivation of plants may be viewed as the earliest biotechnological enterprise.[citation needed]\nAgriculture has been theorized to have become the dominant way of producing food since the Neolithic Revolution. Through early biotechnology, the earliest farmers selected and bred the best-suited crops (e.g., those with the highest yields) to produce enough food to support a growing population. As crops and fields became increasingly large and difficult to maintain, it was discovered that specific organisms and their by-products could effectively fertilize, restore nitrogen, and control pests. Throughout the history of agriculture, farmers have inadvertently altered the genetics of their crops through introducing them to new environments and breeding them with other plants — one of the first forms of biotechnology.[clarification needed]\nThese processes also were included in early fermentation of beer.[13] These processes were introduced in early Mesopotamia, Egypt, China and India, and still use the same basic biological methods. In brewing, malted grains (containing enzymes) convert starch from grains into sugar and then adding specific yeasts to produce beer. In this process, carbohydrates in the grains broke down into alcohols, such as ethanol. Later, other cultures produced the process of lactic acid fermentation, which produced other preserved foods, such as soy sauce. Fermentation was also used in this time period to produce leavened bread. Although the process of fermentation was not fully understood until Louis Pasteur's work in 1857, it is still the first use of biotechnology to convert a food source into another form.[citation needed]\nBefore the time of Charles Darwin's work and life, animal and plant scientists had already used selective breeding. Darwin added to that body of work with his scientific observations about the ability of science to change species. These accounts contributed to Darwin's theory of natural selection.[14]\nFor thousands of years, humans have used selective breeding to improve the production of crops and livestock to use them for food. In selective breeding, organisms with desirable characteristics are mated to produce offspring with the same characteristics. For example, this technique was used with corn to produce the largest and sweetest crops.[15]\nIn the early twentieth century scientists gained a greater understanding of microbiology and explored ways of manufacturing specific products. In 1917, Chaim Weizmann first used a pure microbiological culture in an industrial process, that of manufacturing corn starch using Clostridium acetobutylicum, to produce acetone, which the United Kingdom desperately needed to manufacture explosives during World War I.[16]\nBiotechnology has also led to the development of antibiotics. In 1928, Alexander Fleming discovered the mold Penicillium. His work led to the purification of the antibiotic formed by the mold by Howard Florey, Ernst Boris Chain and Norman Heatley – to form what we today know as penicillin. In 1940, penicillin became available for medicinal use to treat bacterial infections in humans.[15]\nThe field of modern biotechnology is generally thought of as having been born in 1971 when Paul Berg's (Stanford) experiments in gene splicing had early success. Herbert W. Boyer (Univ. Calif. at San Francisco) and Stanley N. Cohen (Stanford) significantly advanced the new technology in 1972 by transferring genetic material into a bacterium, such that the imported material would be reproduced. The commercial viability of a biotechnology industry was significantly expanded on June 16, 1980, when the United States Supreme Court ruled that a genetically modified microorganism could be patented in the case of Diamond v. Chakrabarty.[17] Indian-born Ananda Chakrabarty, working for General Electric, had modified a bacterium (of the genus Pseudomonas) capable of breaking down crude oil, which he proposed to use in treating oil spills. (Chakrabarty's work did not involve gene manipulation but rather the transfer of entire organelles between strains of the Pseudomonas bacterium).[citation needed]\nThe MOSFET invented at Bell Labs between 1955 and 1960,[18][19][20][21][22][23] Two years later, Leland C. Clark and Champ Lyons invented the first biosensor in 1962.[24][25] Biosensor MOSFETs were later developed, and they have since been widely used to measure physical, chemical, biological and environmental parameters.[26] The first BioFET was the ion-sensitive field-effect transistor (ISFET), invented by Piet Bergveld in 1970.[27][28] It is a special type of MOSFET,[26] where the metal gate is replaced by an ion-sensitive membrane, electrolyte solution and reference electrode.[29] The ISFET is widely used in biomedical applications, such as the detection of DNA hybridization, biomarker detection from blood, antibody detection, glucose measurement, pH sensing, and genetic technology.[29]\nBy the mid-1980s, other BioFETs had been developed, including the gas sensor FET (GASFET), pressure sensor FET (PRESSFET), chemical field-effect transistor (ChemFET), reference ISFET (REFET), enzyme-modified FET (ENFET) and immunologically modified FET (IMFET).[26] By the early 2000s, BioFETs such as the DNA field-effect transistor (DNAFET), gene-modified FET (GenFET) and cell-potential BioFET (CPFET) had been developed.[29]\nA factor influencing the biotechnology sector's success is improved intellectual property rights legislation—and enforcement—worldwide, as well as strengthened demand for medical and pharmaceutical products.[30]\nRising demand for biofuels is expected to be good news for the biotechnology sector, with the Department of Energy estimating ethanol usage could reduce U.S. petroleum-derived fuel consumption by up to 30% by 2030. The biotechnology sector has allowed the U.S. farming industry to rapidly increase its supply of corn and soybeans—the main inputs into biofuels—by developing genetically modified seeds that resist pests and drought. By increasing farm productivity, biotechnology boosts biofuel production.[31]\nBiotechnology has applications in four major industrial areas, including health care (medical), crop production and agriculture, non-food (industrial) uses of crops and other products (e.g., biodegradable plastics, vegetable oil, biofuels), and environmental uses.[32]\nFor example, one application of biotechnology is the directed use of microorganisms for the manufacture of organic products (examples include beer and milk products). Another example is using naturally present bacteria by the mining industry in bioleaching.[33] Biotechnology is also used to recycle, treat waste, clean up sites contaminated by industrial activities (bioremediation), and also to produce biological weapons.\nA series of derived terms have been coined to identify several branches of biotechnology, for example:\n- Bioinformatics (or \"gold biotechnology\") is an interdisciplinary field that addresses biological problems using computational techniques, and makes the rapid organization as well as analysis of biological data possible. The field may also be referred to as computational biology, and can be defined as, \"conceptualizing biology in terms of molecules and then applying informatics techniques to understand and organize the information associated with these molecules, on a large scale\".[34] Bioinformatics plays a key role in various areas, such as functional genomics, structural genomics, and proteomics, and forms a key component in the biotechnology and pharmaceutical sector.[35]\n- Blue biotechnology is based on the exploitation of sea resources to create products and industrial applications.[36] This branch of biotechnology is the most used for the industries of refining and combustion principally on the production of bio-oils with photosynthetic micro-algae.[36][37]\n- Green biotechnology is biotechnology applied to agricultural processes. An example would be the selection and domestication of plants via micropropagation. Another example is the designing of transgenic plants to grow under specific environments in the presence (or absence) of chemicals. One hope is that green biotechnology might produce more environmentally friendly solutions than traditional industrial agriculture. An example of this is the engineering of a plant to express a pesticide, thereby ending the need of external application of pesticides. An example of this would be Bt corn. Whether or not green biotechnology products such as this are ultimately more environmentally friendly is a topic of considerable debate.[36] It is commonly considered as the next phase of green revolution, which can be seen as a platform to eradicate world hunger by using technologies which enable the production of more fertile and resistant, towards biotic and abiotic stress, plants and ensures application of environmentally friendly fertilizers and the use of biopesticides, it is mainly focused on the development of agriculture.[36] On the other hand, some of the uses of green biotechnology involve microorganisms to clean and reduce waste.[38][36]\n- Red biotechnology is the use of biotechnology in the medical and pharmaceutical industries, and health preservation.[36] This branch involves the production of vaccines and antibiotics, regenerative therapies, creation of artificial organs and new diagnostics of diseases.[36] As well as the development of hormones, stem cells, antibodies, siRNA and diagnostic tests.[36]\n- White biotechnology, also known as industrial biotechnology, is biotechnology applied to industrial processes. An example is the designing of an organism to produce a useful chemical. Another example is the using of enzymes as industrial catalysts to either produce valuable chemicals or destroy hazardous/polluting chemicals. White biotechnology tends to consume less in resources than traditional processes used to produce industrial goods.[39][40]\n- Yellow biotechnology refers to the use of biotechnology in food production (food industry), for example in making wine (winemaking), cheese (cheesemaking), and beer (brewing) by fermentation.[36] It has also been used to refer to biotechnology applied to insects. This includes biotechnology-based approaches for the control of harmful insects, the characterisation and utilisation of active ingredients or genes of insects for research, or application in agriculture and medicine and various other approaches.[41]\n- Gray biotechnology is dedicated to environmental applications, and focused on the maintenance of biodiversity and the remotion of pollutants.[36]\n- Brown biotechnology is related to the management of arid lands and deserts. One application is the creation of enhanced seeds that resist extreme environmental conditions of arid regions, which is related to the innovation, creation of agriculture techniques and management of resources.[36]\n- Violet biotechnology is related to law, ethical and philosophical issues around biotechnology.[36]\n- Microbial biotechnology has been proposed for the rapidly emerging area of biotechnology applications in space and microgravity (space bioeconomy)[42]\n- Dark biotechnology is the color associated with bioterrorism or biological weapons and biowarfare which uses microorganisms, and toxins to cause diseases and death in humans, livestock and crops.[43][36]\nIn medicine, modern biotechnology has many applications in areas such as pharmaceutical drug discoveries and production, pharmacogenomics, and genetic testing (or genetic screening). In 2021, nearly 40% of the total company value of pharmaceutical biotech companies worldwide were active in Oncology with Neurology and Rare Diseases being the other two big applications.[44]\nPharmacogenomics (a combination of pharmacology and genomics) is the technology that analyses how genetic makeup affects an individual's response to drugs.[45] Researchers in the field investigate the influence of genetic variation on drug responses in patients by correlating gene expression or single-nucleotide polymorphisms with a drug's efficacy or toxicity.[46] The purpose of pharmacogenomics is to develop rational means to optimize drug therapy, with respect to the patients' genotype, to ensure maximum efficacy with minimal adverse effects.[47] Such approaches promise the advent of \"personalized medicine\"; in which drugs and drug combinations are optimized for each individual's unique genetic makeup.[48][49]\nBiotechnology has contributed to the discovery and manufacturing of traditional small molecule pharmaceutical drugs as well as drugs that are the product of biotechnology – biopharmaceutics. Modern biotechnology can be used to manufacture existing medicines relatively easily and cheaply. The first genetically engineered products were medicines designed to treat human diseases. To cite one example, in 1978 Genentech developed synthetic humanized insulin by joining its gene with a plasmid vector inserted into the bacterium Escherichia coli. Insulin, widely used for the treatment of diabetes, was previously extracted from the pancreas of abattoir animals (cattle or pigs). The genetically engineered bacteria are able to produce large quantities of synthetic human insulin at relatively low cost.[50][51] Biotechnology has also enabled emerging therapeutics like gene therapy. The application of biotechnology to basic science (for example through the Human Genome Project) has also dramatically improved our understanding of biology and as our scientific knowledge of normal and disease biology has increased, our ability to develop new medicines to treat previously untreatable diseases has increased as well.[51]\nGenetic testing allows the genetic diagnosis of vulnerabilities to inherited diseases, and can also be used to determine a child's parentage (genetic mother and father) or in general a person's ancestry. In addition to studying chromosomes to the level of individual genes, genetic testing in a broader sense includes biochemical tests for the possible presence of genetic diseases, or mutant forms of genes associated with increased risk of developing genetic disorders. Genetic testing identifies changes in chromosomes, genes, or proteins.[52] Most of the time, testing is used to find changes that are associated with inherited disorders. The results of a genetic test can confirm or rule out a suspected genetic condition or help determine a person's chance of developing or passing on a genetic disorder. As of 2011 several hundred genetic tests were in use.[53][54] Since genetic testing may open up ethical or psychological problems, genetic testing is often accompanied by genetic counseling.\nGenetically modified crops (\"GM crops\", or \"biotech crops\") are plants used in agriculture, the DNA of which has been modified with genetic engineering techniques. In most cases, the main aim is to introduce a new trait that does not occur naturally in the species. Biotechnology firms can contribute to future food security by improving the nutrition and viability of urban agriculture. Furthermore, the protection of intellectual property rights encourages private sector investment in agrobiotechnology.[55]\nExamples in food crops include resistance to certain pests,[56] diseases,[57] stressful environmental conditions,[58] resistance to chemical treatments (e.g. resistance to a herbicide[59]), reduction of spoilage,[60] or improving the nutrient profile of the crop.[61] Examples in non-food crops include production of pharmaceutical agents,[62] biofuels,[63] and other industrially useful goods,[64] as well as for bioremediation.[65][66]\nFarmers have widely adopted GM technology. Between 1996 and 2011, the total surface area of land cultivated with GM crops had increased by a factor of 94, from 17,000 to 1,600,000 square kilometers (4,200,000 to 395,400,000 acres).[67] 10% of the world's crop lands were planted with GM crops in 2010.[67] As of 2011, 11 different transgenic crops were grown commercially on 395 million acres (160 million hectares) in 29 countries such as the US, Brazil, Argentina, India, Canada, China, Paraguay, Pakistan, South Africa, Uruguay, Bolivia, Australia, Philippines, Myanmar, Burkina Faso, Mexico, and Spain.[67]\nGenetically modified foods are foods produced from organisms that have had specific changes introduced into their DNA with the methods of genetic engineering. These techniques have allowed for the introduction of new crop traits as well as a far greater control over a food's genetic structure than previously afforded by methods such as selective breeding and mutation breeding.[68] Commercial sale of genetically modified foods began in 1994, when Calgene first marketed its Flavr Savr delayed ripening tomato.[69] To date most genetic modification of foods have primarily focused on cash crops in high demand by farmers such as soybean, corn, canola, and cotton seed oil. These have been engineered for resistance to pathogens and herbicides and better nutrient profiles. GM livestock have also been experimentally developed; in November 2013 none were available on the market,[70] but in 2015 the FDA approved the first GM salmon for commercial production and consumption.[71]\nThere is a scientific consensus[72][73][74][75] that currently available food derived from GM crops poses no greater risk to human health than conventional food,[76][77][78][79][80] but that each GM food needs to be tested on a case-by-case basis before introduction.[81][82][83] Nonetheless, members of the public are much less likely than scientists to perceive GM foods as safe.[84][85][86][87] The legal and regulatory status of GM foods varies by country, with some nations banning or restricting them, and others permitting them with widely differing degrees of regulation.[88][89][90][91]\nGM crops also provide a number of ecological benefits, if not used in excess.[92] Insect-resistant crops have proven to lower pesticide usage, therefore reducing the environmental impact of pesticides as a whole.[93] However, opponents have objected to GM crops per se on several grounds, including environmental concerns, whether food produced from GM crops is safe, whether GM crops are needed to address the world's food needs, and economic concerns raised by the fact these organisms are subject to intellectual property law.\nBiotechnology has several applications in the realm of food security. Crops like Golden rice are engineered to have higher nutritional content, and there is potential for food products with longer shelf lives.[94] Though not a form of agricultural biotechnology, vaccines can help prevent diseases found in animal agriculture. Additionally, agricultural biotechnology can expedite breeding processes in order to yield faster results and provide greater quantities of food.[95] Transgenic biofortification in cereals has been considered as a promising method to combat malnutrition in India and other countries.[96]\nIndustrial biotechnology (known mainly in Europe as white biotechnology) is the application of biotechnology for industrial purposes, including industrial fermentation. It includes the practice of using cells such as microorganisms, or components of cells like enzymes, to generate industrially useful products in sectors such as chemicals, food and feed, detergents, paper and pulp, textiles and biofuels.[97] In the current decades, significant progress has been done in creating genetically modified organisms (GMOs) that enhance the diversity of applications and economical viability of industrial biotechnology. By using renewable raw materials to produce a variety of chemicals and fuels, industrial biotechnology is actively advancing towards lowering greenhouse gas emissions and moving away from a petrochemical-based economy.[98]\nSynthetic biology is considered one of the essential cornerstones in industrial biotechnology due to its financial and sustainable contribution to the manufacturing sector. Jointly biotechnology and synthetic biology play a crucial role in generating cost-effective products with nature-friendly features by using bio-based production instead of fossil-based.[99] Synthetic biology can be used to engineer model microorganisms, such as Escherichia coli, by genome editing tools to enhance their ability to produce bio-based products, such as bioproduction of medicines and biofuels.[100] For instance, E. coli and Saccharomyces cerevisiae in a consortium could be used as industrial microbes to produce precursors of the chemotherapeutic agent paclitaxel by applying the metabolic engineering in a co-culture approach to exploit the benefits from the two microbes.[101]\nAnother example of synthetic biology applications in industrial biotechnology is the re-engineering of the metabolic pathways of E. coli by CRISPR and CRISPRi systems toward the production of a chemical known as 1,4-butanediol, which is used in fiber manufacturing. In order to produce 1,4-butanediol, the authors alter the metabolic regulation of the Escherichia coli by CRISPR to induce point mutation in the gltA gene, knockout of the sad gene, and knock-in six genes (cat1, sucD, 4hbd, cat2, bld, and bdh). Whereas CRISPRi system used to knockdown the three competing genes (gabD, ybgC, and tesB) that affect the biosynthesis pathway of 1,4-butanediol. Consequently, the yield of 1,4-butanediol significantly increased from 0.9 to 1.8 g/L.[102]\nEnvironmental biotechnology includes various disciplines that play an essential role in reducing environmental waste and providing environmentally safe processes, such as biofiltration and biodegradation.[103][104] The environment can be affected by biotechnologies, both positively and adversely. Vallero and others have argued that the difference between beneficial biotechnology (e.g., bioremediation is to clean up an oil spill or hazard chemical leak) versus the adverse effects stemming from biotechnological enterprises (e.g., flow of genetic material from transgenic organisms into wild strains) can be seen as applications and implications, respectively.[105] Cleaning up environmental wastes is an example of an application of environmental biotechnology; whereas loss of biodiversity or loss of containment of a harmful microbe are examples of environmental implications of biotechnology.[citation needed]\nMany cities have installed CityTrees, which use biotechnology to filter pollutants from urban atmospheres.[106]\nThe regulation of genetic engineering concerns approaches taken by governments to assess and manage the risks associated with the use of genetic engineering technology, and the development and release of genetically modified organisms (GMO), including genetically modified crops and genetically modified fish. There are differences in the regulation of GMOs between countries, with some of the most marked differences occurring between the US and Europe.[107][108] Regulation varies in a given country depending on the intended use of the products of the genetic engineering. For example, a crop not intended for food use is generally not reviewed by authorities responsible for food safety.[109] The European Union differentiates between approval for cultivation within the EU and approval for import and processing. While only a few GMOs have been approved for cultivation in the EU a number of GMOs have been approved for import and processing.[110] The cultivation of GMOs has triggered a debate about the coexistence of GM and non-GM crops. Depending on the coexistence regulations, incentives for the cultivation of GM crops differ.[111]\nThe EUginius (European GMO Initiative for a Unified Database System) database is intended to help companies, interested private users and competent authorities to find precise information on the presence, detection and identification of GMOs used in the European Union. The information is provided in English.[112]\nIn 1988, after prompting from the United States Congress, the National Institute of General Medical Sciences (National Institutes of Health) (NIGMS) instituted a funding mechanism for biotechnology training. Universities nationwide compete for these funds to establish Biotechnology Training Programs (BTPs). Each successful application is generally funded for five years then must be competitively renewed. Graduate students in turn compete for acceptance into a BTP; if accepted, then stipend, tuition and health insurance support are provided for two or three years during the course of their PhD thesis work. Nineteen institutions offer NIGMS supported BTPs.[113] Biotechnology training is also offered at the undergraduate level and in community colleges.[citation needed]\n- \"Biotechnology\". IUPAC Goldbook. 2014. doi:10.1351/goldbook.B00666. Archived from the original on January 20, 2022. Retrieved February 14, 2022.\n- Ereky, Karl. (June 8, 1919). Biotechnologie der Fleisch-, Fett-, und Milcherzeugung im landwirtschaftlichen Grossbetriebe: für naturwissenschaftlich gebildete Landwirte verfasst. P. Parey. Archived from the original on March 5, 2016. Retrieved March 16, 2022 – via Hathi Trust.\n- \"Genetic Engineering\". National Human Genome Research Institute, US National Institutes of Health. December 15, 2023. Retrieved December 18, 2023.\n- Gupta, Varsha; Sengupta, Manjistha; Prakash, Jaya; Tripathy, Baishnab Charan (October 23, 2016). \"An Introduction to Biotechnology\". Basic and Applied Aspects of Biotechnology. pp. 1–21. doi:10.1007/978-981-10-0875-7_1. ISBN 978-981-10-0873-3. PMC 7119977.\n- O'Mathúna, Dónal P. (April 1, 2007). \"Bioethics and biotechnology\". Cytotechnology. 53 (1–3): 113–119. doi:10.1007/s10616-007-9053-8. ISSN 0920-9069. PMC 2267612. PMID 19003197.\n- \"Biotechnology\". portal.acs.org. American Chemical Society. Archived from the original on November 7, 2012. Retrieved March 20, 2013.\n- \"BIOTECHNOLOGY-PRINCIPLES & PROCESSES\" (PDF). Archived from the original (PDF) on August 7, 2015. Retrieved December 29, 2014.\n- What is biotechnology?. Europabio. Retrieved on March 20, 2013.\n- Key Biotechnology Indicators (December 2011) Archived November 8, 2012, at the Wayback Machine. oecd.org\n- \"Biotechnology policies\" – Organization for Economic Co-operation and Development. Archived August 31, 2012, at the Wayback Machine. Retrieved on March 20, 2013.\n- Goli, Divakar; Bhatia, Saurabh (May 2018). History, scope and development of biotechnology. IOPscience. doi:10.1088/978-0-7503-1299-8ch1. ISBN 978-0-7503-1299-8.\n- What Is Bioengineering? Archived January 23, 2013, at the Wayback Machine. Bionewsonline.com. Retrieved on March 20, 2013.\n- See Arnold JP (2005). Origin and History of Beer and Brewing: From Prehistoric Times to the Beginning of Brewing Science and Technology. Cleveland, Ohio: BeerBooks. p. 34. ISBN 978-0-9662084-1-2. OCLC 71834130.\n- Cole-Turner R (2003). \"Biotechnology\". Encyclopedia of Science and Religion. Archived from the original on October 25, 2009. Retrieved December 7, 2014.\n- Thieman WJ, Palladino MA (2008). Introduction to Biotechnology. Pearson/Benjamin Cummings. ISBN 978-0-321-49145-9.\n- Springham D, Springham G, Moses V, Cape RE (1999). Biotechnology: The Science and the Business. CRC Press. p. 1. ISBN 978-90-5702-407-8.\n- \"Diamond v. Chakrabarty, 447 U.S. 303 (1980). No. 79-139 Archived June 28, 2011, at the Wayback Machine.\" United States Supreme Court. June 16, 1980. Retrieved on May 4, 2007.\n- US2802760A, Lincoln, Derick & Frosch, Carl J., \"Oxidation of semiconductive surfaces for controlled diffusion\", issued August 13, 1957\n- Huff, Howard; Riordan, Michael (September 1, 2007). \"Frosch and Derick: Fifty Years Later (Foreword)\". The Electrochemical Society Interface. 16 (3): 29. doi:10.1149/2.F02073IF. ISSN 1064-8208.\n- Frosch, C. J.; Derick, L (1957). \"Surface Protection and Selective Masking during Diffusion in Silicon\". Journal of the Electrochemical Society. 104 (9): 547. doi:10.1149/1.2428650.\n- KAHNG, D. (1961). \"Silicon-Silicon Dioxide Surface Device\". Technical Memorandum of Bell Laboratories: 583–596. doi:10.1142/9789814503464_0076. ISBN 978-981-02-0209-5.\n{{cite journal}}\n: ISBN / Date incompatibility (help) - Lojek, Bo (2007). History of Semiconductor Engineering. Berlin, Heidelberg: Springer-Verlag Berlin Heidelberg. p. 321. ISBN 978-3-540-34258-8.\n- Lojek, Bo (2007). History of Semiconductor Engineering. Springer Science & Business Media. p. 120. ISBN 978-3-540-34258-8.\n- Park, Jeho; Nguyen, Hoang Hiep; Woubit, Abdela; Kim, Moonil (2014). \"Applications of Field-Effect Transistor (FET)–Type Biosensors\". Applied Science and Convergence Technology. 23 (2): 61–71. doi:10.5757/ASCT.2014.23.2.61. ISSN 2288-6559. S2CID 55557610.\n- Clark, Leland C.; Lyons, Champ (1962). \"Electrode Systems for Continuous Monitoring in Cardiovascular Surgery\". Annals of the New York Academy of Sciences. 102 (1): 29–45. Bibcode:1962NYASA.102...29C. doi:10.1111/j.1749-6632.1962.tb13623.x. ISSN 1749-6632. PMID 14021529. S2CID 33342483.\n- Bergveld, Piet (October 1985). \"The impact of MOSFET-based sensors\" (PDF). Sensors and Actuators. 8 (2): 109–127. Bibcode:1985SeAc....8..109B. doi:10.1016/0250-6874(85)87009-8. ISSN 0250-6874. Archived (PDF) from the original on October 9, 2022.\n- Chris Toumazou; Pantelis Georgiou (December 2011). \"40 years of ISFET technology:From neuronal sensing to DNA sequencing\". Electronics Letters. Retrieved May 13, 2016.\n- Bergveld, P. (January 1970). \"Development of an Ion-Sensitive Solid-State Device for Neurophysiological Measurements\". IEEE Transactions on Biomedical Engineering. BME-17 (1): 70–71. doi:10.1109/TBME.1970.4502688. PMID 5441220.\n- Schöning, Michael J.; Poghossian, Arshak (September 10, 2002). \"Recent advances in biologically sensitive field-effect transistors (BioFETs)\" (PDF). Analyst. 127 (9): 1137–1151. Bibcode:2002Ana...127.1137S. doi:10.1039/B204444G. ISSN 1364-5528. PMID 12375833. Archived (PDF) from the original on October 9, 2022.\n- VoIP Providers And Corn Farmers Can Expect To Have Bumper Years In 2008 And Beyond, According To The Latest Research Released By Business Information Analysts At IBISWorld. Los Angeles (March 19, 2008)\n- \"The Recession List - Top 10 Industries to Fly and Flop in 2008\". Bio-Medicine.org. March 19, 2008. Archived from the original on June 2, 2008. Retrieved May 19, 2008.\n- Amarakoon, Icolyn; Hamilton, Cindy; Mitchell, Sylvia; Tennant, Paula; Roye, Marcia (October 20, 2023). \"Biotechnology: principles and applications\". Pharmacognosy: 627–645. doi:10.1016/b978-0-443-18657-8.00017-7. ISBN 978-0-443-18657-8. Retrieved November 1, 2024.\n- Terry, Nick (2007). \"Microbial Biotechnology in Industry\". Applied Microbiology and Biotechnology. 77 (1): 1–10. doi:10.1007/s00253-007-1173-0.\n- Gerstein, M. \"Bioinformatics Introduction Archived 2007-06-16 at the Wayback Machine.\" Yale University. Retrieved on May 8, 2007.\n- Siam, R. (2009). Biotechnology Research and Development in Academia: providing the foundation for Egypt's Biotechnology spectrum of colors. Sixteenth Annual American University in Cairo Research Conference, American University in Cairo, Cairo, Egypt. BMC Proceedings, 31–35.\n- Kafarski, P. (2012). Rainbow Code of Biotechnology Archived February 14, 2019, at the Wayback Machine. CHEMIK. Wroclaw University\n- Biotech: true colours. (2009). TCE: The Chemical Engineer, (816), 26–31.\n- Aldridge, S. (2009). The four colours of biotechnology: the biotechnology sector is occasionally described as a rainbow, with each sub sector having its own colour. But what do the different colours of biotechnology have to offer the pharmaceutical industry. Pharmaceutical Technology Europe, (1). 12.\n- Frazzetto G (September 2003). \"White biotechnology\". EMBO Reports. 4 (9): 835–7. doi:10.1038/sj.embor.embor928. PMC 1326365. PMID 12949582.\n- Frazzetto, G. (2003). White biotechnology Archived November 11, 2018, at the Wayback Machine. March 21, 2017, de EMBOpress Sitio\n- Advances in Biochemical Engineering/Biotechnology Archived July 19, 2018, at the Wayback Machine, Volume 135 2013, Yellow Biotechnology I\n- Santomartino R, Averesch NJ, Bhuiyan M, Cockell CS, Colangelo J, Gumulya Y, Lehner B, Lopez-Ayala I, McMahon S, Mohanty A, Santa Maria SR, Urbaniak C, Volger R, Yang J, Zea L (March 2023). \"Toward sustainable space exploration: a roadmap for harnessing the power of microorganisms\". Nature Communications. 14 (1) 1391. Bibcode:2023NatCo..14.1391S. doi:10.1038/s41467-023-37070-2. PMC 10030976. PMID 36944638.\n- Edgar, J.D. (2004). The Colours of Biotechnology: Science, Development and Humankind. Electronic Journal of Biotechnology, (3), 01\n- \"Top Global Pharmaceutical Company Report\" (PDF). The Pharma 1000. November 2021. Archived (PDF) from the original on March 15, 2022. Retrieved December 29, 2022.\n- Ermak G. (2013) Modern Science & Future Medicine (second edition)\n- Wang L (2010). \"Pharmacogenomics: a systems approach\". Wiley Interdisciplinary Reviews: Systems Biology and Medicine. 2 (1): 3–22. doi:10.1002/wsbm.42. PMC 3894835. PMID 20836007.\n- Becquemont L (June 2009). \"Pharmacogenomics of adverse drug reactions: practical applications and perspectives\". Pharmacogenomics. 10 (6): 961–9. doi:10.2217/pgs.09.37. PMID 19530963.\n- \"Guidance for Industry Pharmacogenomic Data Submissions\" (PDF). U.S. Food and Drug Administration. March 2005. Archived from the original (PDF) on October 9, 2022. Retrieved August 27, 2008.\n- Squassina A, Manchia M, Manolopoulos VG, Artac M, Lappa-Manakou C, Karkabouna S, Mitropoulos K, Del Zompo M, Patrinos GP (August 2010). \"Realities and expectations of pharmacogenomics and personalized medicine: impact of translating genetic knowledge into clinical practice\". Pharmacogenomics. 11 (8): 1149–67. doi:10.2217/pgs.10.97. PMID 20712531.\n- Bains W (1987). Genetic Engineering For Almost Everybody: What Does It Do? What Will It Do?. Penguin. p. 99. ISBN 978-0-14-013501-5.\n- U.S. Department of State International Information Programs, \"Frequently Asked Questions About Biotechnology\", USIS Online; available from USinfo.state.gov Archived September 12, 2007, at the Wayback Machine, accessed September 13, 2007. Cf. Feldbaum C (February 2002). \"Biotechnology. Some history should be repeated\". Science. 295 (5557): 975. doi:10.1126/science.1069614. PMID 11834802. S2CID 32595222.\n- \"What is genetic testing? – Genetics Home Reference\". Ghr.nlm.nih.gov. May 30, 2011. Archived from the original on May 29, 2006. Retrieved June 7, 2011.\n- \"Genetic Testing: MedlinePlus\". Nlm.nih.gov. Archived from the original on June 8, 2011. Retrieved June 7, 2011.\n- \"Definitions of Genetic Testing\". Definitions of Genetic Testing (Jorge Sequeiros and Bárbara Guimarães). EuroGentest Network of Excellence Project. September 11, 2008. Archived from the original on February 4, 2009. Retrieved August 10, 2008.\n- Serageldin, Ismail (July 16, 1999). \"Biotechnology and Food Security in the 21st Century\". Science. 285 (5426): 387–389. doi:10.1126/science.285.5426.387. ISSN 0036-8075. PMID 10411497.\n- Genetically Altered Potato Ok'd For Crops Archived July 31, 2022, at the Wayback Machine Lawrence Journal-World – May 6, 1995\n- National Academy of Sciences (2001). Transgenic Plants and World Agriculture. Washington: National Academy Press.\n- Paarlburg R (January 2011). \"Drought Tolerant GMO Maize in Africa, Anticipating Regulatory Hurdles\" (PDF). International Life Sciences Institute. Archived from the original (PDF) on December 22, 2014. Retrieved April 25, 2011.\n- Carpenter J. & Gianessi L. (1999). Herbicide tolerant soybeans: Why growers are adopting Roundup Ready varieties Archived November 19, 2012, at the Wayback Machine. AgBioForum, 2(2), 65–72.\n- Haroldsen VM, Paulino G, Chi-ham C, Bennett AB (2012). \"Research and adoption of biotechnology strategies could improve California fruit and nut crops\". California Agriculture. 66 (2): 62–69. doi:10.3733/ca.v066n02p62.\n- About Golden Rice Archived November 2, 2012, at the Wayback Machine. Irri.org. Retrieved on March 20, 2013.\n- Gali Weinreb and Koby Yeshayahou for Globes May 2, 2012. FDA approves Protalix Gaucher treatment Archived May 29, 2013, at the Wayback Machine\n- Carrington, Damien (January 19, 2012) GM microbe breakthrough paves way for large-scale seaweed farming for biofuels Archived May 11, 2017, at the Wayback Machine The Guardian. Retrieved March 12, 2012\n- van Beilen JB, Poirier Y (May 2008). \"Production of renewable polymers from crop plants\". The Plant Journal. 54 (4): 684–701. doi:10.1111/j.1365-313X.2008.03431.x. PMID 18476872. S2CID 25954199.\n- Strange, Amy (September 20, 2011) Scientists engineer plants to eat toxic pollution Archived September 13, 2011, at the Wayback Machine The Irish Times. Retrieved September 20, 2011\n- Diaz E, ed. (2008). Microbial Biodegradation: Genomics and Molecular Biology. Caister Academic Press. ISBN 978-1-904455-17-2.\n- James C (2011). \"ISAAA Brief 43, Global Status of Commercialized Biotech/GM Crops: 2011\". ISAAA Briefs. Ithaca, New York: International Service for the Acquisition of Agri-biotech Applications (ISAAA). Archived from the original on February 10, 2012. Retrieved June 2, 2012.\n- GM Science Review First Report Archived October 16, 2013, at the Wayback Machine, Prepared by the UK GM Science Review panel (July 2003). Chairman Professor Sir David King, Chief Scientific Advisor to the UK Government, P 9\n- James C (1996). \"Global Review of the Field Testing and Commercialization of Transgenic Plants: 1986 to 1995\" (PDF). The International Service for the Acquisition of Agri-biotech Applications. Archived (PDF) from the original on October 9, 2022. Retrieved July 17, 2010.\n- \"Consumer Q&A\". Fda.gov. March 6, 2009. Archived from the original on January 10, 2013. Retrieved December 29, 2012.\n- \"AquAdvantage Salmon\". FDA. Archived from the original on December 31, 2012. Retrieved July 20, 2018.\n- Nicolia, Alessandro; Manzo, Alberto; Veronesi, Fabio; Rosellini, Daniele (2013). \"An overview of the last 10 years of genetically engineered crop safety research\" (PDF). Critical Reviews in Biotechnology. 34 (1): 77–88. doi:10.3109/07388551.2013.823595. PMID 24041244. S2CID 9836802. Archived (PDF) from the original on October 9, 2022.\nWe have reviewed the scientific literature on GE crop safety for the last 10 years that catches the scientific consensus matured since GE plants became widely cultivated worldwide, and we can conclude that the scientific research conducted so far has not detected any significant hazard directly connected with the use of GM crops.\nThe literature about Biodiversity and the GE food/feed consumption has sometimes resulted in animated debate regarding the suitability of the experimental designs, the choice of the statistical methods or the public accessibility of data. Such debate, even if positive and part of the natural process of review by the scientific community, has frequently been distorted by the media and often used politically and inappropriately in anti-GE crops campaigns. - \"State of Food and Agriculture 2003–2004. Agricultural Biotechnology: Meeting the Needs of the Poor. Health and environmental impacts of transgenic crops\". Food and Agriculture Organization of the United Nations. Archived from the original on January 9, 2019. Retrieved August 30, 2019.\nCurrently available transgenic crops and foods derived from them have been judged safe to eat and the methods used to test their safety have been deemed appropriate. These conclusions represent the consensus of the scientific evidence surveyed by the ICSU (2003) and they are consistent with the views of the World Health Organization (WHO, 2002). These foods have been assessed for increased risks to human health by several national regulatory authorities (inter alia, Argentina, Brazil, Canada, China, the United Kingdom and the United States) using their national food safety procedures (ICSU). To date no verifiable untoward toxic or nutritionally deleterious effects resulting from the consumption of foods derived from genetically modified crops have been discovered anywhere in the world (GM Science Review Panel). Many millions of people have consumed foods derived from GM plants – mainly maize, soybean and oilseed rape – without any observed adverse effects (ICSU).\n- Ronald, Pamela (May 1, 2011). \"Plant Genetics, Sustainable Agriculture and Global Food Security\". Genetics. 188 (1): 11–20. doi:10.1534/genetics.111.128553. PMC 3120150. PMID 21546547.\nThere is broad scientific consensus that genetically engineered crops currently on the market are safe to eat. After 14 years of cultivation and a cumulative total of 2 billion acres planted, no adverse health or environmental effects have resulted from commercialization of genetically engineered crops (Board on Agriculture and Natural Resources, Committee on Environmental Impacts Associated with Commercialization of Transgenic Plants, National Research Council and Division on Earth and Life Studies 2002). Both the U.S. National Research Council and the Joint Research Centre (the European Union's scientific and technical research laboratory and an integral part of the European Commission) have concluded that there is a comprehensive body of knowledge that adequately addresses the food safety issue of genetically engineered crops (Committee on Identifying and Assessing Unintended Effects of Genetically Engineered Foods on Human Health and National Research Council 2004; European Commission Joint Research Centre 2008). These and other recent reports conclude that the processes of genetic engineering and conventional breeding are no different in terms of unintended consequences to human health and the environment (European Commission Directorate-General for Research and Innovation 2010).\nBut see also:\nDomingo, José L.; Bordonaba, Jordi Giné (2011). \"A literature review on the safety assessment of genetically modified plants\" (PDF). Environment International. 37 (4): 734–742. Bibcode:2011EnInt..37..734D. doi:10.1016/j.envint.2011.01.003. PMID 21296423. Archived (PDF) from the original on October 9, 2022.\nIn spite of this, the number of studies specifically focused on safety assessment of GM plants is still limited. However, it is important to remark that for the first time, a certain equilibrium in the number of research groups suggesting, on the basis of their studies, that a number of varieties of GM products (mainly maize and soybeans) are as safe and nutritious as the respective conventional non-GM plant, and those raising still serious concerns, was observed. Moreover, it is worth mentioning that most of the studies demonstrating that GM foods are as nutritional and safe as those obtained by conventional breeding, have been performed by biotechnology companies or associates, which are also responsible of commercializing these GM plants. Anyhow, this represents a notable advance in comparison with the lack of studies published in recent years in scientific journals by those companies.\nKrimsky, Sheldon (2015). \"An Illusory Consensus behind GMO Health Assessment\". Science, Technology, & Human Values. 40 (6): 883–914. doi:10.1177/0162243915598381. S2CID 40855100.\nI began this article with the testimonials from respected scientists that there is literally no scientific controversy over the health effects of GMOs. My investigation into the scientific literature tells another story.\nAnd contrast:\nPanchin, Alexander Y.; Tuzhikov, Alexander I. (January 14, 2016). \"Published GMO studies find no evidence of harm when corrected for multiple comparisons\". Critical Reviews in Biotechnology. 37 (2): 213–217. doi:10.3109/07388551.2015.1130684. ISSN 0738-8551. PMID 26767435. S2CID 11786594.\nHere, we show that a number of articles some of which have strongly and negatively influenced the public opinion on GM crops and even provoked political actions, such as GMO embargo, share common flaws in the statistical evaluation of the data. Having accounted for these flaws, we conclude that the data presented in these articles does not provide any substantial evidence of GMO harm.\nThe presented articles suggesting possible harm of GMOs received high public attention. However, despite their claims, they actually weaken the evidence for the harm and lack of substantial equivalency of studied GMOs. We emphasize that with over 1783 published articles on GMOs over the last 10 years it is expected that some of them should have reported undesired differences between GMOs and conventional crops even if no such differences exist in reality.and\nYang, Y.T.; Chen, B. (2016). \"Governing GMOs in the USA: science, law and public health\". Journal of the Science of Food and Agriculture. 96 (4): 1851–1855. Bibcode:2016JSFA...96.1851Y. doi:10.1002/jsfa.7523. PMID 26536836.It is therefore not surprising that efforts to require labeling and to ban GMOs have been a growing political issue in the USA (citing Domingo and Bordonaba, 2011). Overall, a broad scientific consensus holds that currently marketed GM food poses no greater risk than conventional food... Major national and international science and medical associations have stated that no adverse human health effects related to GMO food have been reported or substantiated in peer-reviewed literature to date.\nDespite various concerns, today, the American Association for the Advancement of Science, the World Health Organization, and many independent international science organizations agree that GMOs are just as safe as other foods. Compared with conventional breeding techniques, genetic engineering is far more precise and, in most cases, less likely to create an unexpected outcome.- \"Statement by the AAAS Board of Directors On Labeling of Genetically Modified Foods\" (PDF). American Association for the Advancement of Science. October 20, 2012. Archived (PDF) from the original on October 9, 2022. Retrieved August 30, 2019.\nThe EU, for example, has invested more than €300 million in research on the biosafety of GMOs. Its recent report states: \"The main conclusion to be drawn from the efforts of more than 130 research projects, covering a period of more than 25 years of research and involving more than 500 independent research groups, is that biotechnology, and in particular GMOs, are not per se more risky than e.g. conventional plant breeding technologies.\" The World Health Organization, the American Medical Association, the U.S. National Academy of Sciences, the British Royal Society, and every other respected organization that has examined the evidence has come to the same conclusion: consuming foods containing ingredients derived from GM crops is no riskier than consuming the same foods containing ingredients from crop plants modified by conventional plant improvement techniques.\nPinholster, Ginger (October 25, 2012). \"AAAS Board of Directors: Legally Mandating GM Food Labels Could \"Mislead and Falsely Alarm Consumers\" (PDF). American Association for the Advancement of Science. Archived (PDF) from the original on October 9, 2022. Retrieved August 30, 2019. - European Commission. Directorate-General for Research (2010). A decade of EU-funded GMO research (2001–2010) (PDF). Directorate-General for Research and Innovation. Biotechnologies, Agriculture, Food. European Commission, European Union. doi:10.2777/97784. ISBN 978-92-79-16344-9. Archived (PDF) from the original on October 9, 2022. Retrieved August 30, 2019.\n- \"AMA Report on Genetically Modified Crops and Foods\". American Medical Association. January 2001. Archived from the original on April 2, 2016. Retrieved August 30, 2019 – via International Service for the Acquisition of Agri-biotech Applications.\"Report 2 of the Council on Science and Public Health (A-12): Labeling of Bioengineered Foods\" (PDF). American Medical Association. 2012. Archived from the original (PDF) on September 7, 2012. Retrieved August 30, 2019.\n- \"Restrictions on Genetically Modified Organisms: United States. Public and Scholarly Opinion\". Library of Congress. June 30, 2015. Archived from the original on December 30, 2019. Retrieved August 30, 2019.\nSeveral scientific organizations in the US have issued studies or statements regarding the safety of GMOs indicating that there is no evidence that GMOs present unique safety risks compared to conventionally bred products. These include the National Research Council, the American Association for the Advancement of Science, and the American Medical Association. Groups in the US opposed to GMOs include some environmental organizations, organic farming organizations, and consumer organizations. A substantial number of legal academics have criticized the US's approach to regulating GMOs.\n- National Academies Of Sciences, Engineering; Division on Earth Life Studies; Board on Agriculture Natural Resources; Committee on Genetically Engineered Crops: Past Experience Future Prospects (2016). Genetically Engineered Crops: Experiences and Prospects. The National Academies of Sciences, Engineering, and Medicine (US). p. 149. doi:10.17226/23395. ISBN 978-0-309-43738-7. PMID 28230933. Archived from the original on November 16, 2021. Retrieved August 30, 2019.\nOverall finding on purported adverse effects on human health of foods derived from GE crops: On the basis of detailed examination of comparisons of currently commercialized GE with non-GE foods in compositional analysis, acute and chronic animal toxicity tests, long-term data on health of livestock fed GE foods, and human epidemiological data, the committee found no differences that implicate a higher risk to human health from GE foods than from their non-GE counterparts.\n- \"Frequently asked questions on genetically modified foods\". World Health Organization. Archived from the original on November 4, 2020. Retrieved August 30, 2019.\nDifferent GM organisms include different genes inserted in different ways. This means that individual GM foods and their safety should be assessed on a case-by-case basis and that it is not possible to make general statements on the safety of all GM foods.\nGM foods currently available on the international market have passed safety assessments and are not likely to present risks for human health. In addition, no effects on human health have been shown as a result of the consumption of such foods by the general population in the countries where they have been approved. Continuous application of safety assessments based on the Codex Alimentarius principles and, where appropriate, adequate post market monitoring, should form the basis for ensuring the safety of GM foods. - Haslberger, Alexander G. (2003). \"Codex guidelines for GM foods include the analysis of unintended effects\". Nature Biotechnology. 21 (7): 739–741. doi:10.1038/nbt0703-739. PMID 12833088. S2CID 2533628.\nThese principles dictate a case-by-case premarket assessment that includes an evaluation of both direct and unintended effects.\n- Some medical organizations, including the British Medical Association, advocate further caution based upon the precautionary principle:\n\"Genetically modified foods and health: a second interim statement\" (PDF). British Medical Association. March 2004. Archived (PDF) from the original on October 9, 2022. Retrieved August 30, 2019.In our view, the potential for GM foods to cause harmful health effects is very small and many of the concerns expressed apply with equal vigour to conventionally derived foods. However, safety concerns cannot, as yet, be dismissed completely on the basis of information currently available.\nWhen seeking to optimise the balance between benefits and risks, it is prudent to err on the side of caution and, above all, learn from accumulating knowledge and experience. Any new technology such as genetic modification must be examined for possible benefits and risks to human health and the environment. As with all novel foods, safety assessments in relation to GM foods must be made on a case-by-case basis.\nMembers of the GM jury project were briefed on various aspects of genetic modification by a diverse group of acknowledged experts in the relevant subjects. The GM jury reached the conclusion that the sale of GM foods currently available should be halted and the moratorium on commercial growth of GM crops should be continued. These conclusions were based on the precautionary principle and lack of evidence of any benefit. The Jury expressed concern over the impact of GM crops on farming, the environment, food safety and other potential health effects.\nThe Royal Society review (2002) concluded that the risks to human health associated with the use of specific viral DNA sequences in GM plants are negligible, and while calling for caution in the introduction of potential allergens into food crops, stressed the absence of evidence that commercially available GM foods cause clinical allergic manifestations. The BMA shares the view that there is no robust evidence to prove that GM foods are unsafe but we endorse the call for further research and surveillance to provide convincing evidence of safety and benefit. - Funk, Cary; Rainie, Lee (January 29, 2015). \"Public and Scientists' Views on Science and Society\". Pew Research Center. Archived from the original on January 9, 2019. Retrieved August 30, 2019.\nThe largest differences between the public and the AAAS scientists are found in beliefs about the safety of eating genetically modified (GM) foods. Nearly nine-in-ten (88%) scientists say it is generally safe to eat GM foods compared with 37% of the general public, a difference of 51 percentage points.\n- Marris, Claire (2001). \"Public views on GMOs: deconstructing the myths\". EMBO Reports. 2 (7): 545–548. doi:10.1093/embo-reports/kve142. PMC 1083956. PMID 11463731.\n- Final Report of the PABE research project (December 2001). \"Public Perceptions of Agricultural Biotechnologies in Europe\". Commission of European Communities. Archived from the original on May 25, 2017. Retrieved August 30, 2019.\n- Scott, Sydney E.; Inbar, Yoel; Rozin, Paul (2016). \"Evidence for Absolute Moral Opposition to Genetically Modified Food in the United States\" (PDF). Perspectives on Psychological Science. 11 (3): 315–324. doi:10.1177/1745691615621275. PMID 27217243. S2CID 261060. Archived (PDF) from the original on October 9, 2022.\n- \"Restrictions on Genetically Modified Organisms\". Library of Congress. June 9, 2015. Archived from the original on April 3, 2019. Retrieved August 30, 2019.\n- Bashshur, Ramona (February 2013). \"FDA and Regulation of GMOs\". American Bar Association. Archived from the original on June 21, 2018. Retrieved August 30, 2019.\n- Sifferlin, Alexandra (October 3, 2015). \"Over Half of E.U. Countries Are Opting Out of GMOs\". Time. Retrieved August 30, 2019.\n- Lynch, Diahanna; Vogel, David (April 5, 2001). \"The Regulation of GMOs in Europe and the United States: A Case-Study of Contemporary European Regulatory Politics\". Council on Foreign Relations. Archived from the original on September 29, 2016. Retrieved August 30, 2019.\n- Pollack A (April 13, 2010). \"Study Says Overuse Threatens Gains From Modified Crops\". The New York Times. Archived from the original on November 21, 2017. Retrieved February 24, 2017.\n- Brookes, Graham; Barfoot, Peter (May 8, 2017). \"Farm income and production impacts of using GM crop technology 1996–2015\". GM Crops & Food. 8 (3): 156–193. Bibcode:2017GMCFB...8..156B. doi:10.1080/21645698.2017.1317919. ISSN 2164-5698. PMC 5617554. PMID 28481684.\n- Tyczewska, Agata; Twardowski, Tomasz; Woźniak-Gientka, Ewa (January 2023). \"Agricultural biotechnology for sustainable food security\". Trends in Biotechnology. 41 (3): 331–341. doi:10.1016/j.tibtech.2022.12.013. ISSN 0167-7799. PMC 9881846. PMID 36710131. S2CID 256304868.\n- Sairam, R. V.; Prakash, C. S. (July 2005). \"OBPC Symposium: maize 2004 & beyond—Can agricultural biotechnology contribute to global food security?\". In Vitro Cellular & Developmental Biology - Plant. 41 (4): 424–430. Bibcode:2005IVCDB..41..424S. doi:10.1079/ivp2005663. ISSN 1054-5476. S2CID 25855065.\n- Kumar, Pankaj; Kumar, Arun; Dhiman, Karuna; Srivastava, Dinesh Kumar (2021), \"Recent Progress in Cereals Biofortification to Alleviate Malnutrition in India: An Overview\", Agricultural Biotechnology: Latest Research and Trends, Singapore: Springer Nature Singapore, pp. 253–280, doi:10.1007/978-981-16-2339-4_11, ISBN 978-981-16-2338-7, S2CID 245834290\n- Industrial Biotechnology and Biomass Utilisation Archived April 5, 2013, at the Wayback Machine\n- \"Industrial biotechnology, A powerful, innovative technology to mitigate climate change\". Archived from the original on January 2, 2014. Retrieved January 1, 2014.\n- Clarke, Lionel; Kitney, Richard (February 28, 2020). \"Developing synthetic biology for industrial biotechnology applications\". Biochemical Society Transactions. 48 (1): 113–122. doi:10.1042/BST20190349. ISSN 0300-5127. PMC 7054743. PMID 32077472.\n- McCarty, Nicholas S.; Ledesma-Amaro, Rodrigo (February 2019). \"Synthetic Biology Tools to Engineer Microbial Communities for Biotechnology\". Trends in Biotechnology. 37 (2): 181–197. doi:10.1016/j.tibtech.2018.11.002. ISSN 0167-7799. PMC 6340809. PMID 30497870.\n- Zhou, Kang; Qiao, Kangjian; Edgar, Steven; Stephanopoulos, Gregory (April 2015). \"Distributing a metabolic pathway among a microbial consortium enhances production of natural products\". Nature Biotechnology. 33 (4): 377–383. doi:10.1038/nbt.3095. ISSN 1087-0156. PMC 4867547. PMID 25558867.\n- Wu, Meng-Ying; Sung, Li-Yu; Li, Hung; Huang, Chun-Hung; Hu, Yu-Chen (December 15, 2017). \"Combining CRISPR and CRISPRi Systems for Metabolic Engineering of E. coli and 1,4-BDO Biosynthesis\". ACS Synthetic Biology. 6 (12): 2350–2361. doi:10.1021/acssynbio.7b00251. ISSN 2161-5063. PMID 28854333.\n- Pakshirajan, Kannan; Rene, Eldon R.; Ramesh, Aiyagari (2014). \"Biotechnology in environmental monitoring and pollution abatement\". BioMed Research International. 2014 235472. doi:10.1155/2014/235472. ISSN 2314-6141. PMC 4017724. PMID 24864232.\n- Danso, Dominik; Chow, Jennifer; Streit, Wolfgang R. (October 1, 2019). \"Plastics: Environmental and Biotechnological Perspectives on Microbial Degradation\". Applied and Environmental Microbiology. 85 (19) e01095-19. Bibcode:2019ApEnM..85E1095D. doi:10.1128/AEM.01095-19. ISSN 1098-5336. PMC 6752018. PMID 31324632.\n- Daniel A. Vallero, Environmental Biotechnology: A Biosystems Approach, Academic Press, Amsterdam, NV; ISBN 978-0-12-375089-1; 2010.\n- \"Debate on robot trees looks to clear the air: What are other countries doing?\". The Echo. November 9, 2023. Retrieved January 17, 2024.\n- \"Europeans' distaste for gene-edited food\". Chemical & Engineering News. January 21, 2025. Retrieved May 1, 2025.\n- Spök, Armin; Sprink, Thorben; Allan, Andrew C.; Yamaguchi, Tomiko; Dayé, Christian (August 31, 2022). \"Towards social acceptability of genome-edited plants in industrialised countries? Emerging evidence from Europe, United States, Canada, Australia, New Zealand, and Japan\". Frontiers in Genome Editing. 4 899331. doi:10.3389/fgeed.2022.899331. ISSN 2673-3439. PMC 9473316. PMID 36120531.\n- \"The History and Future of GM Potatoes\". Potato Pro. March 10, 2010. Archived from the original on October 12, 2013. Retrieved January 1, 2014.\n- Wesseler J, Kalaitzandonakes N (2011). \"Present and Future EU GMO policy\". In Oskam A, Meesters G, Silvis H (eds.). EU Policy for Agriculture, Food and Rural Areas (2nd ed.). Wageningen: Wageningen Academic Publishers. pp. 23–332.\n- Beckmann VC, Soregaroli J, Wesseler J (2011). \"Coexistence of genetically modified (GM) and non-modified (non GM) crops: Are the two main property rights regimes equivalent with respect to the coexistence value?\". In Carter C, Moschini G, Sheldon I (eds.). Genetically modified food and global welfare. Frontiers of Economics and Globalization Series. Vol. 10. Bingley, UK: Emerald Group Publishing. pp. 201–224.\n- \"The European GMO database\". www.euginius.eu. Retrieved June 19, 2025.\n- \"Biotechnology Predoctoral Training Program\". National Institute of General Medical Sciences. December 18, 2013. Archived from the original on October 28, 2014. Retrieved October 28, 2014.",
    "business intelligence": "| Business administration |\n|---|\nBusiness intelligence (BI) consists of strategies, methodologies, and technologies used by enterprises for data analysis and management of business information to inform business strategies and business operations.[1][2] Common functions of BI technologies include reporting, online analytical processing, analytics, dashboard development, data mining, process mining, complex event processing, business performance management, benchmarking, text mining, predictive analytics, and prescriptive analytics.\nBI tools can handle large amounts of structured and sometimes unstructured data to help organizations identify, develop, and otherwise create new strategic business opportunities. They aim to allow for the easy interpretation of these big data. Identifying new opportunities and implementing an effective strategy based on insights is assumed to potentially provide businesses with a competitive market advantage and long-term stability, and help them take strategic decisions.[3]\nBusiness intelligence can be used by enterprises to support a wide range of business decisions ranging from operational to strategic. Basic operating decisions include product positioning or pricing. Strategic business decisions involve priorities, goals, and directions at the broadest level. In all cases, Business Intelligence (BI) is considered most effective when it combines data from the market in which a company operates (external data) with data from internal company sources, such as financial and operational information. When integrated, external and internal data provide a comprehensive view that creates ‘intelligence’ not possible from any single data source alone.[4]\nAmong their many uses, business intelligence tools empower organizations to gain insight into new markets, to assess demand and suitability of products and services for different market segments, and to gauge the impact of marketing efforts.[5]\nBI applications use data gathered from a data warehouse (DW) or from a data mart, and the concepts of BI and DW combine as \"BI/DW\"[6] or as \"BIDW\". A data warehouse contains a copy of analytical data that facilitates decision support.\nThe earliest known use of the term business intelligence is in Richard Millar Devens' Cyclopædia of Commercial and Business Anecdotes (1865). Devens used the term to describe how the banker Sir Henry Furnese gained profit by receiving and acting upon information about his environment, prior to his competitors:\nThroughout Holland, Flanders, France, and Germany, he maintained a complete and perfect train of business intelligence. The news of the many battles fought was thus received first by him, and the fall of Namur added to his profits, owing to his early receipt of the news.\n— Devens, p. 210\nThe ability to collect and react accordingly based on the information retrieved, Devens says, is central to business intelligence.[7]\nWhen Hans Peter Luhn, a researcher at IBM, used the term business intelligence in an article published in 1958, he employed the Webster's Dictionary definition of intelligence: \"the ability to apprehend the interrelationships of presented facts in such a way as to guide action towards a desired goal.\"[8]\nIn 1989, Howard Dresner (later a Gartner analyst) proposed business intelligence as an umbrella term to describe \"concepts and methods to improve business decision making by using fact-based support systems.\"[9] It was not until the late 1990s that this usage was widespread.[10]\nAccording to Solomon Negash and Paul Gray, business intelligence (BI) can be defined as systems that combine:\nwith analysis to evaluate complex corporate and competitive information for presentation to planners and decision makers, with the objective of improving the timeliness and the quality of the input to the decision process.\"[11]\nAccording to Forrester Research, business intelligence is \"a set of methodologies, processes, architectures, and technologies that transform raw data into meaningful and useful information used to enable more effective strategic, tactical, and operational insights and decision-making.\"[12] Under this definition, business intelligence encompasses information management (data integration, data quality, data warehousing, master-data management, text- and content-analytics, et al.). Therefore, Forrester refers to data preparation and data usage as two separate but closely linked segments of the business-intelligence architectural stack.\nSome elements of business intelligence are:[citation needed]\n- Multidimensional aggregation and allocation\n- Denormalization, tagging, and standardization\n- Realtime reporting with analytical alert\n- A method of interfacing with unstructured data sources\n- Group consolidation, budgeting, and rolling forecasts\n- Statistical inference and probabilistic simulation\n- Key performance indicators optimization\n- Version control and process management\n- Open item management\nForrester distinguishes this from the business-intelligence market, which is \"just the top layers of the BI architectural stack, such as reporting, analytics, and dashboards.\"[13]\nThough the term business intelligence is sometimes a synonym for competitive intelligence (because they both support decision making), BI uses technologies, processes, and applications to analyze mostly internal, structured data and business processes while competitive intelligence gathers, analyzes, and disseminates information with a topical focus on company competitors. If understood broadly, competitive intelligence can be considered as a subset of business intelligence.[14]\nBusiness intelligence and business analytics are sometimes used interchangeably, but there are alternate definitions.[15] Thomas Davenport, professor of information technology and management at Babson College argues that business intelligence should be divided into querying, reporting, Online analytical processing (OLAP), an \"alerts\" tool, and business analytics. In this definition, business analytics is the subset of BI focusing on statistics, prediction, and optimization, rather than the reporting functionality.[16]\nBusiness operations can generate a very large amount of data in the form of e-mails, memos, notes from call-centers, news, user groups, chats, reports, web-pages, presentations, image-files, video-files, and marketing material. According to Merrill Lynch, more than 85% of all business information exists in these forms; a company might only use such a document a single time.[17] Because of the way it is produced and stored, this information is either unstructured or semi-structured.\nThe management of semi-structured data is an unsolved problem in the information technology industry.[18] According to projections from Gartner (2003), white-collar workers spend 30–40% of their time searching, finding, and assessing unstructured data. BI uses both structured and unstructured data. The former is easy to search, and the latter contains a large quantity of the information needed for analysis and decision-making.[18][19] Because of the difficulty of properly searching, finding, and assessing unstructured or semi-structured data, organizations may not draw upon these vast reservoirs of information, which could influence a particular decision, task, or project. This can ultimately lead to poorly informed decision-making.[17]\nTherefore, when designing a business intelligence/DW-solution, the specific problems associated with semi-structured and unstructured data must be accommodated for as well as those for the structured data.\nThis section needs to be updated. The reason given is: It's dubious that searchability and semantic analysis are still limitations at the current stage of NLP and AI development.(December 2023) |\nThere are several challenges to developing BI with semi-structured data. According to Inmon & Nesavich,[20] some of those are:\n- Physically accessing unstructured textual data – unstructured data is stored in a huge variety of formats.\n- Terminology – Among researchers and analysts, there is a need to develop standardized terminology.\n- Volume of data – As stated earlier, up to 85% of all data exists as semi-structured data. Couple that with the need for word-to-word and semantic analysis.\n- Searchability of unstructured textual data – A simple search on some data, e.g. apple, results in links where there is a reference to that precise search term. (Inmon & Nesavich, 2008)[20] gives an example: \"a search is made on the term felony. In a simple search, the term felony is used, and everywhere there is a reference to felony, a hit to an unstructured document is made. But a simple search is crude. It does not find references to crime, arson, murder, embezzlement, vehicular homicide, and such, even though these crimes are types of felonies\".\nTo solve problems with searchability and assessment of data, it is necessary to know something about the content. This can be done by adding context through the use of metadata.[17][needs independent confirmation] Many systems already capture some metadata (e.g. filename, author, size, etc.), but more useful would be metadata about the actual content – e.g. summaries, topics, people, or companies mentioned. Two technologies designed for generating metadata about content are automatic categorization and information extraction.\nGenerative business intelligence is the application of generative AI techniques, such as large language models, in business intelligence. This combination facilitates data analysis and enables users to interact with data more intuitively, generating actionable insights through natural language queries. Microsoft Copilot was, for example, integrated into the business analytics tool Power BI.[21]\nBusiness intelligence can be applied to the following business purposes:\n- Performance metrics and benchmarking inform business leaders of progress towards business goals.[22] (Business process management).[citation needed]\n- Analytics quantify processes for a business to arrive at optimal decisions, and to perform business knowledge discovery. Analytics may variously involve data mining, process mining, statistical analysis, predictive analytics, predictive modeling, business process modeling, data lineage, complex event processing, and prescriptive analytics. For example within banking industry, academic research has explored potential for BI based analytics in credit evaluation, customer churn management for managerial adoption[23]\n- Reporting, dashboards and data visualization,[22] executive information system, and/or OLAP\n- BI can facilitate collaboration both inside and outside the business by enabling data sharing and electronic data interchange[22]\n- Knowledge management is concerned with the creation, distribution, use, and management of business intelligence, and of business knowledge in general.[22] Knowledge management leads to learning management and regulatory compliance.[citation needed]\nIn a 2013 report, Gartner categorized business intelligence vendors as either an independent \"pure-play\" vendor or a consolidated \"mega-vendor\".[24][non-primary source needed] In 2019, the BI market was shaken within Europe for the new legislation of GDPR (General Data Protection Regulation) which puts the responsibility of data collection and storage onto the data user with strict laws in place to make sure the data is compliant. Growth within Europe has steadily increased since May 2019 when GDPR was brought in. The legislation refocused companies to look at their own data from a compliance perspective but also revealed future opportunities using personalization and external BI providers to increase market share.[25]\n- Agile Business Intelligence\n- Analytic applications\n- Arcplan\n- Artificial intelligence marketing\n- Business activity monitoring\n- Business Intelligence 2.0\n- Business Intelligence Competency Center\n- Business intelligence software\n- Business process discovery\n- Business process management\n- Customer dynamics\n- Decision engineering\n- Embedded analytics\n- Enterprise planning systems\n- Integrated business planning\n- Management information system\n- Mobile business intelligence\n- Process mining\n- Real-time business intelligence\n- Sales intelligence\n- Test and learn\n- Dedić N. & Stanier noC. (2016). \"Measuring the Success of Changes to Existing Business Intelligence Solutions to Improve Business Intelligence Reporting\" (PDF). Measuring the Success of Changes to Existing Business Intelligence Solutions to Improve Business Intelligence Reporting. Lecture Notes in Business Information Processing. Vol. 268. Springer International Publishing. pp. 225–236. doi:10.1007/978-3-319-49944-4_17. ISBN 978-3-319-49943-7. S2CID 30910248.\n- \"What Is Business Intelligence (BI)? | IBM\". IBM.\n- (Rud, Olivia (2009). Business Intelligence Success Factors: Tools for Aligning Your Business in the Global Economy. Hoboken, N.J.: Wiley & Sons. ISBN 978-0-470-39240-9.\n- Coker, Frank (2014). Pulse: Understanding the Vital Signs of Your Business. Ambient Light Publishing. pp. 41–42. ISBN 978-0-9893086-0-1.\n- Chugh, R. & Grandhi, S. (2013,). \"Why Business Intelligence? Significance of Business Intelligence tools and integrating BI governance with corporate governance\". International Journal of E-Entrepreneurship and Innovation', vol. 4, no.2, pp. 1–14.\n-\nGolden, Bernard (2013). Amazon Web Services For Dummies. John Wiley & Sons. p. 234. ISBN 9781118652268. Retrieved 6 July 2014.\n[...] traditional business intelligence or data warehousing tools (the terms are used so interchangeably that they're often referred to as BI/DW) are extremely expensive [...]\n- Miller Devens, Richard (1865). Cyclopaedia of Commercial and Business Anecdotes; Comprising Interesting Reminiscences and Facts, Remarkable Traits and Humors of Merchants, Traders, Bankers Etc. in All Ages and Countries. D. Appleton and company. p. 210. Retrieved 15 February 2014.\nbusiness intelligence.\n- Luhn, H. P. (1958). \"A Business Intelligence System\" (PDF). IBM Journal of Research and Development. 2 (4): 314–319. doi:10.1147/rd.24.0314. Archived from the original (PDF) on 13 September 2008.\n- D. J. Power (10 March 2007). \"A Brief History of Decision Support Systems, version 4.0\". DSSResources.COM. Retrieved 10 July 2008.\n- Power, D. J. \"A Brief History of Decision Support Systems\". Retrieved 1 November 2010.\n- Springer-Verlag Berlin Heidelberg, Springer-Verlag Berlin Heidelberg (21 November 2008). Topic Overview: Business Intelligence. doi:10.1007/978-3-540-48716-6. ISBN 978-3-540-48715-9.\n- Evelson, Boris (21 November 2008). \"Topic Overview: Business Intelligence\".\n- Evelson, Boris (29 April 2010). \"Want to know what Forrester's lead data analysts are thinking about BI and the data domain?\". Archived from the original on 6 August 2016. Retrieved 4 November 2010.\n- Kobielus, James (30 April 2010). \"What's Not BI? Oh, Don't Get Me Started... Oops Too Late... Here Goes...\" Archived from the original on 7 May 2010. Retrieved 4 November 2010.\n- \"Business Analytics vs Business Intelligence?\". timoelliott.com. 9 March 2011. Retrieved 15 June 2014.\n- Henschen, Doug (4 January 2010). \"Analytics at Work: Q&A with Tom Davenport\" (Interview). Archived from the original on 3 April 2012. Retrieved 26 September 2011.\n- Rao, R. (2003). \"From unstructured data to actionable intelligence\" (PDF). IT Professional. 5 (6): 29–35. doi:10.1109/MITP.2003.1254966.\n- Blumberg, R. & S. Atre (2003). \"The Problem with Unstructured Data\" (PDF). DM Review: 42–46. Archived from the original (PDF) on 25 January 2011.\n- Negash, S (2004). \"Business Intelligence\". Communications of the Association for Information Systems. 13: 177–195. doi:10.17705/1CAIS.01315.\n- Inmon, B. & A. Nesavich, \"Unstructured Textual Data in the Organization\" from \"Managing Unstructured data in the organization\", Prentice Hall 2008, pp. 1–13\n- Novet, Jordan (23 May 2023). \"Microsoft is bringing an A.I. chatbot to data analysis\". CNBC. Retrieved 19 August 2024.\n- Feldman, D.; Himmelstein, J. (2013). Developing Business Intelligence Apps for SharePoint. O'Reilly Media, Inc. pp. 140–1. ISBN 9781449324681. Retrieved 8 May 2018.\n- Moro, Sérgio; Cortez, Paulo; Rita, Paulo (February 2015). \"Business intelligence in banking: A literature analysis from 2002 to 2013 using text mining and latent Dirichlet allocation\". Expert Systems with Applications. 42 (3): 1314–1324. doi:10.1016/j.eswa.2014.09.024. hdl:10071/8522. S2CID 15595226.\n- Andrew Brust (14 February 2013). \"Gartner releases 2013 BI Magic Quadrant\". ZDNet. Retrieved 21 August 2013.\n- SaaS BI growth will soar in 2010. InfoWorld (1 February 2010). Retrieved 17 January 2012.\n- Kimball, Ralph; et al. (1998). The Data warehouse Lifecycle Toolkit\" (2nd ed.). John Wiley & Sons Inc. ISBN 0-470-47957-4.\n- Rausch, Peter; Sheta, Alaa; Ayesh, Aladdin (2013). Business Intelligence and Performance Management: Theory, Systems, and Industrial Applications. Springer Verlag U.K. ISBN 978-1-4471-4865-4.\n- Munoz, J.M. (2017). Global Business Intelligence. Routledge : UK. ISBN 978-1-1382-03686.\n- Chaudhuri, Surajit; Dayal, Umeshwar; Narasayya, Vivek (August 2011). \"An Overview of Business Intelligence Technology\". Communications of the ACM. 54 (8): 88–98. doi:10.1145/1978542.1978562. S2CID 13843514.",
    "business-to-business": "Business-to-business (B2B or, in some countries, BtoB or B4B) refers to trade and commercial activity where a business sees other businesses as its customer base. This typically occurs when:\n- A business sources materials for its production process for output (e.g., a food manufacturer purchasing salt), i.e. providing raw material to the other company that will produce output.\n- A business needs the services of another for operational reasons (e.g., a food manufacturer employing an accountancy firm to audit their finances).\n- A business re-sells goods and services produced by others (e.g., a retailer buying the end product from the food manufacturer).\nBusiness-to-business activity is thought to allow business segmentation.[1]\nB2B is often contrasted with business-to-consumer (B2C) trade, the latter of which typically sells directly to the general public and consumers, rather than other businesses and organisations.\nSuccessful B2B operations depend upon sales personnel understanding the purchasing behaviour and outlook of the types of business they wish to work with.[2]\nB2B involves specific challenges at different stages. At their formation, organizations should be careful to rely on an appropriate combination of contractual and relational mechanisms.[3] Specific combinations of contracts and relational norms may influence the nature and dynamics of the negotiations between firms.[4]\nVertical B2B is generally oriented to manufacturing or business. It can be divided into two directions: upstream and downstream. Producers or commercial retailers can have a supply relationship with upstream suppliers, including manufacturers, and form a sales relationship.[5] As an example, Dell works with upstream suppliers of integrated circuit microchips and computer printed circuit boards (PCBs).\nA vertical B2B website can be similar to the enterprise's online store.[5] Through the website, the company can promote its products vigorously, more efficiently, and more comprehensively, enriching transactions by helping customers better understand their products. Alternatively, the website can be created for business purposes, where the seller advertises their products to promote and expand transactions.\nA good example of a vertical B2B model is manufacturers vs wholesalers.\nHorizontal B2B is the transaction pattern for the intermediate trading market.[clarification needed] It consolidates similar transactions from various industries into one platform, offering trading opportunities for both buyers and suppliers. Typically, it involves companies that do not own or sell the products but serve as a platform to connect sellers and buyers online.[6] The better platforms help buyers easily find information about the sellers and the relevant information about the products via the website.\nA good example of a horizontal B2B model is bankers vs corporate lawyers.\nA 2022 Amazon report highlighted a \"rapid transformation of B2B e-procurement in recent years\", with 91% of the B2B buyers surveyed in their study stating that they preferred online purchasing.[7]\nB2B2C means \"business-to-business-to-consumer\". According to the TechTarget website, the purpose of the terminology is to \"extend the business-to-business model to include e-commerce for consumers\". An aim of B2B2C is to \"create a mutually beneficial relationship between suppliers of goods and services and online retailers\".[8] According to Lomate and Ramachandran, it enables manufacturers (the first \"B\" in B2B2C) to connect with, understand and serve their end customers (\"C\") without undermining their sales and distribution networks, including online sellers (the second \"B\") or excluding them from continuing customer engagement.[9]\nThe defining difference between B2B and business-to-consumer trade (B2C) is that the first one refers to commerce transactions between manufacturer and retailer, and the second one it is the retailer supplying goods to the consumer.[10] In B2B commerce, it is often the case that the parties to the relationship have comparable negotiating power, and even when they do not, each party typically involves professional staff and legal counsel in the negotiation of terms, whereas within a B2C context, relationships are shaped to a far greater degree by the economic implications of information asymmetry. However, in B2B, large companies may have many commercial, resource and information advantages over smaller businesses. The United Kingdom government, for example, created the post of Small Business Commissioner under the Enterprise Act 2016 to \"enable small businesses to resolve disputes\" and \"consider complaints by small business suppliers about payment issues with larger businesses that they supply.\"[11]\nIn B2B there are business people on both sides, whereas in B2C there is normally one business person and one consumer. In the first case, the decision is pursued by need (because the other business needs it), and in the second case, they are expectations rather than needs. B2B concentrates on raw data for another company, but B2C focuses on producing something for consumers. A B2B transaction entails direct-sourcing contract management, which involves negotiating terms that establish prices and various other factors such as volume-based pricing, carrier and logistics preferences, etc. B2C transaction is clearer, it has spot sourcing contract management that offers a flat retail rate for each item sold. Time is also different as B2B has a slower process than B2C which is concluded in shorter periods (that could be minutes or days).\nBusiness-to-business generally requires an upfront investment whereas business-to-consumers do not need a business to spend money on infrastructure. The last difference mentioned here is that in B2B, lagging in the digital transformation, has to deal with back-office connectivity and invoicing a number of different partners and suppliers, while B2C results in more seamless transactions as options, such as cyber-cash, allows the business to accept a wider variety of payment options. B2B typically only allows payment via credit card or invoice, making the purchasing process longer and more expensive than with B2C. B2B, as there are normally bigger amounts involved over longer periods of time, usually have higher costs than B2C, which consists of quick, daily transactions. Businesses typically want to buy on net terms, meaning that B2B merchants have to wait weeks, if not months to get paid for their goods or services. As a result, smaller businesses with less capital often struggle to stay afloat. In B2B, brand reputations greatly depend on the personal relationship between businesses. On the other hand, in B2C, the business's reputation is often fueled by publicity through the media.\nIn many cases, the overall volume of B2B (business-to-business) transactions is much higher than the volume of B2C transactions.[12][13][14] The primary reason for this is that in a typical supply chain there will be many B2B transactions involving subcomponents or raw materials, and only one B2C transaction, specifically the sale of the finished product to the end customer. For example, an automobile manufacturer makes several B2B transactions such as buying tires, glass for windows, and rubber hoses for its vehicles. The final transaction, a finished vehicle sold to the consumer, is a single (B2C) transaction.\nBusiness-to-business companies represent a significant part of the United States economy. This is especially true in firms with 500 employees and above, of which there were 19,464 in 2015,[15] where it is estimated that as many as 72% are businesses that primarily serve other businesses.[16]\n- Account manager\n- B2B e-commerce\n- Business-to-consumer (B2C)\n- Business-to-government (B2G)\n- Customer to customer (C2C)\n- Hayter, Roger; Patchell, Jerry; Rees, Kevin (1999). \"Business Segmentation and Location Revisited: Innovation and the Terra Incognita of Large Firms\". Regional Studies. 33 (5). Taylor & Francis Online: 425–442. Bibcode:1999RegSt..33..425H. doi:10.1080/00343409950081275. Retrieved 8 April 2023.\n- Bunn, Michele D. (January 1993). \"Taxonomy of Buying Decision Approaches\". Journal of Marketing. 57 (1). American Marketing Association: 38–56. doi:10.2307/1252056. JSTOR 1252056.\n- Poppo, Laura; Zenger, Todd (2002). \"Do formal contracts and relational governance function as substitutes or complements?\". Strategic Management Journal. 23 (8): 707–725. doi:10.1002/smj.249. ISSN 0143-2095.\n- Arief, Faisal; Salehudin, Imam (2024). \"Unlocking B2B Purchase Engagement: Investigating Its Drivers and Consequences in App-Based Service Subscriptions for MSMEs\". Jurnal Manajemen Teori Dan Terapan (Journal of Theory and Applied Management). 17 (1): 1–22. doi:10.20473/jmtt.v17i1.51494.\n- E-COMMERCE, AN INDIAN PERSPECTIVE. P.T. Joseph, S.J. 2015. pp. 43–45. ISBN 978-81-203-5154-7.\n- E-commerce: Formulation of Strategy. Robert T. Plant. 2000. pp. 26-27. ISBN 0-13-019844-7.\n- Amazon Business, Amazon Business' 2022 State of Business Procurement Report Highlights Opportunities in E-Procurement, published 28 September 2022, accessed 24 March 2023\n- TechTarget, B2B2C (business-to-business-to-consumer), accessed 23 January 2021\n- Lomate, O. S. and Ramachandran, S., B2B2C: The Future of Customer Engagement, Infosys, 2019, accessed 23 January 2021\n- Kumar, Vinod; Raheja, Gagandeep. \"Business to business and business to consumer management\". CiteSeerX 10.1.1.299.8382.\n- Small Business Commissioner role, 26 July 2015, accessed 22 October 2017\n- Sandhusen, Richard (2008). Marketing. Hauppauge, N.Y: Barron's Educational Series. p. 520. ISBN 978-0-7641-3932-1.\n- Shelly, Gary (2011). Systems analysis and design. Boston, MA: Course Technology, Cengage Learning. p. 10. ISBN 978-0-538-47443-6.\n- Garbade, Michael (2011). Differences in Venture Capital Financing of U.S., UK, German and French Information Technology Start-ups A Comparative Empirical Research of the Investment Process on the Venture Capital Firm Level. München: GRIN Verlag GmbH. p. 31. ISBN 978-3-640-89316-4.\n- \"2015 SUSB Annual Data Tables by Establishment Industry\". www.census.gov.\n- \"Fortune 500 2015\". Fortune.com. Retrieved 2018-10-18.",
    "café": "A coffeehouse, coffee shop, or café (French: [kafe] ⓘ), is an establishment that serves various types of coffee drinks like espresso, latte, americano and cappuccino, and other beverages. An espresso bar is a type of coffeehouse that specializes in serving espresso and espresso-based drinks. Some coffeehouses may serve iced coffee among other cold beverages, such as iced tea, as well as other non-caffeinated beverages. A coffeehouse may also serve food, such as light snacks, sandwiches, muffins, cakes, breads, pastries or donuts. Many doughnut shops in Canada and the U.S. serve coffee as an accompaniment to doughnuts, so these can be also classified as coffee shops, although doughnut shop tends to be more casual and serve lower-end fare which also facilitates take-out and drive-through which is popular in those countries, compared to a coffee shop or cafe which provides more gourmet pastries and beverages.[1][2] In continental Europe, some cafés even serve alcoholic beverages, and it is popular in West Asia to offer a flavored tobacco smoked through a hookah, called shisha in most varieties of Arabic or nargile in Levantine Arabic, Greek, and Turkish.\nWhile café may refer to a coffeehouse, the term \"café\" can also refer to a diner, British café (also colloquially called a \"caff\"), \"greasy spoon\" (a small and inexpensive restaurant), transport café, teahouse or tea room, or other casual eating and drinking place.[3][4][5][6][7] A coffeehouse may share some of the same characteristics of a bar or restaurant, but it is different from a cafeteria (a canteen-type restaurant without table service). Coffeehouses range from owner-operated small businesses to large multinational corporations. Some coffeehouse chains operate on a franchise business model, with numerous branches across various countries around the world.\nFrom a cultural standpoint coffeehouses largely serve as centers of social interaction: a coffeehouse provides patrons with a place to congregate, talk, read, write, entertain one another, or pass the time, whether individually or in small groups. A coffeehouse can serve as an informal social club for its regular members.[8] As early as the 1950s Beatnik era and the 1960s folk music scene, coffeehouses have hosted singer-songwriter performances, typically in the evening.[9] The digital age saw the rise of the Internet café along similar principles.\nThe most common English spelling of café is the French word for both coffee and coffeehouse;[11][12] it was adopted by English-speaking countries in the late 19th century.[13] The Italian spelling, caffè, is also sometimes used in English.[14] In Southern England, especially around London in the 1950s, the French pronunciation was often facetiously altered to / / and spelt caff.[15]\nThe English word coffee and French word café (coffeehouse) both derive from the Italian caffè[11][16]—first attested as caveé in Venice in 1570[17]—and in turn derived from Arabic qahwa (قهوة). The Arabic term qahwa originally referred to a type of wine, but after the wine ban by Islam, the name was transferred to coffee because of the similar rousing effect it induced.[18] European knowledge of coffee (the plant, its seeds, and the drink made from the seeds) came through European contact with Turkey, likely via Venetian-Ottoman trade relations.\nThe English word café to describe a restaurant that usually serves coffee and snacks rather than the word coffee that describes the drink, is derived from the French café. The first café in France is believed to have opened in 1660.[11] The first café in Europe is believed to have been opened in Belgrade, Ottoman Serbia in 1522 as a Kafana (Serbian coffee house).[19]\nThe translingual word root /kafe/ appears in many European languages with various naturalized spellings, including Portuguese and French (café); German (Kaffeehaus or Café); Swedish (kafé or fik); Finnish (kahvila); Spanish (cafetería); Italian (caffè or caffetteria); Polish (kawa); Serbian (кафа / kafa); Ukrainian (кава (kava)); Turkish (kahvehane).\nThe first coffeehouses appeared in Damascus. These Ottoman coffeehouses have also appeared in Mecca, in the Arabian Peninsula in the 15th century, then spread to the Ottoman Empire's capital of Istanbul in the 16th century and in Baghdad. Coffeehouses became popular meeting places where people gathered to drink coffee, have conversations, play board games such as chess and backgammon, listen to stories and music, and discuss news and politics. They became known as \"schools of wisdom\" for the type of clientele they attracted, and their free and frank discourse.[20][21]\nCoffeehouses in Mecca became a concern of imams who viewed them as places for political gatherings and drinking, leading to bans between 1512 and 1524.[22] However, these bans could not be maintained, due to coffee becoming ingrained in daily ritual and culture among Arabs and neighboring peoples.[20] The Ottoman chronicler İbrahim Peçevi reports in his writings (1642–49) about the opening of the first coffeehouse (kiva han) in Istanbul:\nUntil the year 962 [1555], in the High, God-Guarded city of Constantinople, as well as in Ottoman lands generally, coffee and coffeehouses did not exist. About that year, a fellow called Hakam from Aleppo and a wag called Shams from Damascus came to the city; they each opened a large shop in the district called Tahtakale, and began to purvey coffee.[23]\nThe 17th-century French traveler and writer Jean Chardin gave a lively description of the Persian coffeehouse (qahveh khaneh in Persian) scene:\nPeople engage in conversation, for it is there that news is communicated and where those interested in politics criticize the government in all freedom and without being fearful, since the government does not heed what the people say. Innocent games ... resembling checkers, hopscotch, and chess, are played. In addition, mollas, dervishes, and poets take turns telling stories in verse or in prose. The narrations by the mollas and the dervishes are moral lessons, like our sermons, but it is not considered scandalous not to pay attention to them. No one is forced to give up his game or his conversation because of it. A molla will stand up in the middle, or at one end of the qahveh-khaneh, and begin to preach in a loud voice, or a dervish enters all of a sudden, and chastises the assembled on the vanity of the world and its material goods. It often happens that two or three people talk at the same time, one on one side, the other on the opposite, and sometimes one will be a preacher and the other a storyteller.[24]\nIn the 17th century, coffee appeared for the first time in Europe outside the Ottoman Empire, and coffeehouses were established, soon becoming increasingly popular. The first coffeehouse is said to have appeared in 1632 in Livorno, Italy founded by a Jewish merchant,[25][26] or later in 1640, in Venice.[27] In the 19th and 20th centuries in Europe, coffeehouses were very often meeting points for writers and artists.[28]\nThe traditional tale of the origins of the Viennese café begins with the mysterious sacks of green beans left behind when the Turks were defeated in the Battle of Vienna in 1683. All the sacks of coffee were granted to the victorious Polish king Jan III Sobieski, who in turn gave them to one of his officers, Jerzy Franciszek Kulczycki, a Ukrainian cossack and Polish diplomat of Ruthenian descent. Kulczycki, according to the tale, then began the first coffeehouse in Vienna with the hoard, also being the first to serve coffee with milk. There is a statue of Kulczycki on a street also named after him.\nHowever, it is now widely accepted that the first Viennese coffeehouse was actually opened by an Armenian merchant named Johannes Diodato (also known as Johannes Theodat). He opened a registered coffeehouse in Vienna in 1685.[29][30] Fifteen years later, four other Armenians owned coffeehouses.[30] The culture of drinking coffee was itself widespread in the country in the second half of the 18th century.\nOver time, a special coffee house culture developed in Habsburg Vienna. On the one hand, writers, artists, musicians, intellectuals, bon vivants and their financiers met in the coffee house, and on the other hand, new coffee varieties were always served. In the coffee house, people played cards or chess, worked, read, thought, composed, discussed, argued, observed and just chatted. A lot of information was also obtained in the coffee house, because local and foreign newspapers were freely available to all guests. This form of coffee house culture spread throughout the Habsburg Empire in the 19th century.[31][32]\nScientific theories, political plans but also artistic projects were worked out and discussed in Viennese coffee houses all over Central Europe. James Joyce even enjoyed his coffee in a Viennese coffee house on the Adriatic sea in Trieste, then and now the main port for coffee and coffee processing in Italy and Central Europe. From there, the Viennese Kapuziner coffee developed into today's world-famous cappuccino. This special multicultural atmosphere of the Habsburg coffee houses was largely destroyed by the later National Socialism and Communism and can only be found today in a few places that have long been in the slipstream of history, such as Vienna or Trieste.[33][34][35][36]\nThe first coffeehouse in England was set up on the High Street in Oxford in 1650[37]–1651[38][page needed] by \"Jacob the Jew\". A second competing coffee house was opened across the street in 1654, by \"Cirques Jobson, the Jew\" (Queen's Lane Coffee House).[39] In London, the earliest coffeehouse was established by Pasqua Rosée in 1652.[40] Anthony Wood observed of the coffee houses of Oxford in his Life and Times (1674) \"The decay of study, and consequently of learning, are coffee houses, to which most scholars retire and spend much of the day in hearing and speaking of news\".[41] The proprietor was Pasqua Rosée, the servant of a trader in goods from the Ottoman Empire named Daniel Edwards, who imported the coffee and assisted Rosée in setting up the establishment there.[42][43]\nFrom 1670 to 1685, the number of London coffeehouses began to increase, and they also began to gain political importance due to their popularity as places of debate.[44] English coffeehouses were significant meeting places, particularly in London. By 1675, there were more than 3,000 coffeehouses in England.[45] The coffeehouses were great social levelers, open to all men and indifferent to social status, and as a result associated with equality and republicanism. Entry gave access to books or print news. Coffeehouses boosted the popularity of print news culture and helped the growth of various financial markets including insurance, stocks, and auctions. Lloyd's of London had its origins in a coffeehouse run by Edward Lloyd, where underwriters of ship insurance met to do business. The rich intellectual atmosphere of early London coffeehouses was available to anyone who could pay the sometimes one penny entry fee, giving them the name of 'Penny Universities'.[46]\nThough Charles II later tried to suppress London coffeehouses as \"places where the disaffected met, and spread scandalous reports concerning the conduct of His Majesty and his Ministers\", the public still flocked to them. For several decades following the Restoration, the wits gathered around John Dryden at Will's Coffee House, in Russell Street, Covent Garden.[47] As coffeehouses were believed to be areas where anti-government gossip could easily spread, Queen Mary II and the London City magistrates tried to prosecute people who frequented coffeehouses as they were liable to \"spread false and seditious reports\". William III's privy council also suppressed Jacobite sympathizers in the 1680s and 1690s in coffeehouses as these were the places that they believed harbored plotters against the regimes.[48]\nBy 1739, there were 551 coffeehouses in London; each attracted a particular clientele divided by occupation or attitude, such as Tories and Whigs, wits and stockjobbers, merchants and lawyers, booksellers and authors, men of fashion or the \"cits\" of the old city centre. According to one French visitor, Abbé Prévost, coffeehouses, \"where you have the right to read all the papers for and against the government\", were the \"seats of English liberty\".[49]\nJonathan's Coffee-House in 1698 saw the listing of stock and commodity prices that evolved into the London Stock Exchange. Lloyd's Coffee House provided the venue for merchants and shippers to discuss insurance deals[repetition], leading to the establishment of Lloyd's of London insurance market, the Lloyd's Register classification society, and other related businesses. Auctions in salesrooms attached to coffeehouses provided the start for the great auction houses of Sotheby's and Christie's.\nIn Victorian England, the temperance movement set up coffeehouses (also known as coffee taverns) for the working classes, as a place of relaxation free of alcohol, an alternative to the public house.[50][51]\nFinland's first coffee house, Kaffehus, was founded in Turku in 1778.[52] The oldest still-in-use coffee house in Helsinki called Café Ekberg was founded in 1852.[53]\nPasqua Rosée, an Armenian by the name Harutiun Vartian, also established the first coffeehouse in Paris in 1672 and held a citywide coffee monopoly until Procopio Cutò, his apprentice, opened the Café Procope in 1686.[54] This coffeehouse still exists today and was a popular meeting place of the French Enlightenment; Voltaire, Rousseau, and Denis Diderot frequented it, and it is arguably the birthplace of the Encyclopédie, the first modern encyclopedia.\nThe first known cafes in Pest date back to 1714 when a house intended to serve as a Cafe (Balázs Kávéfőző) was purchased. Minutes of the Pest City Council from 1729 mention complaints by the Balázs café and Franz Reschfellner Cafe against the Italian-originated café of Francesco Bellieno for selling underpriced coffee.[55]\nDuring the 18th century, the oldest extant coffeehouses in Italy were established: Caffè Florian in Venice, Antico Caffè Greco in Rome, Caffè Pedrocchi in Padua, Caffè dell'Ussero in Pisa and Caffè Fiorio in Turin.\nIn the 18th century, Dublin coffeehouses functioned as early reading centers and the emergence of circulation and subscription libraries that provided greater access to printed material for the public. The interconnectivity of the coffeehouse and virtually every aspect of the print trade were evidenced by the incorporation of printing, publishing, selling, and viewing of newspapers, pamphlets and books on the premises, most notably in the case of Dick's Coffee House, owned by Richard Pue; thus contributing to a culture of reading and increased literacy.[56] These coffeehouses were a social magnet where different strata of society came together to discuss topics covered by the newspapers and pamphlets. Most coffeehouses of the 18th century would eventually be equipped with their own printing presses or incorporate a book shop.[57]\nToday, the term café is used for most coffeehouses – this can be spelled both with and without an acute accent, but is always pronounced as two syllables. The name café has also come to be used for a type of diners that offers cooked meals (again, without alcoholic beverages) which can be standalone or operating within shopping centres or department stores. In Irish usage, the presence or absence of the acute accent does not signify the type of establishment (coffeehouse versus diner), and is purely a decision by the owner: for instance, the two largest diner-style café chains in Ireland in the 1990s were named \"Kylemore Cafe\" and \"Bewley's Café\" – i.e., one written without, and one with, the acute accent.\nThe history of coffee in Portugal is usually told to have begun during the reign of king John V, when Portuguese agent Francisco de Melo Palheta supposedly managed to steal coffee beans from the Dutch East India Company and introduce it to Brazil. From Brazil, coffee was taken to Cape Verde and São Tomé and Príncipe, which were also Portuguese colonies at the time. Despite this story, coffee already existed in Angola, having been introduced by Portuguese missionaries. During the 18th century, the first public cafés appeared, inspired by French gatherings from the 17th century, becoming spaces for cultural and artistic entertainment.\nSeveral cafes emerged in Lisbon such as: Martinho da Arcada (being the oldest café still functioning, having opened in 1782), Café Tavares, Botequim Parras, among others. Of these several became famous for harbouring poets and artists, such as Manuel du Bocage with his visits to Café Nicola, which opened in 1796 by the Italian Nicola Breteiro; and Fernando Pessoa with his visits to A Brasileira, which opened in 1905 by Adriano Teles. The most famous of these coffee houses was the Café Marrare, opened by the napolitan Antonio Marrare, in 1820, frequently visited by Júlio Castilho, Raimundo de Bulhão Pato, Almeida Garrett, Alexandre Herculano and other members of the Portuguese government and the intelligentsia. It began its saying: «Lisboa era Chiado, o Chiado era o Marrare e o Marrare ditava a lei» (English: \"Lisbon was the Chiado, the Chiado was the Marrare and the Marrare dictated the law\").\nOther coffee houses soon opened across the country, such as Café Vianna, opened in Braga, in 1858, by Manoel José da Costa Vianna, which was also visited by important Portuguese writers such as Camilo Castelo Branco and Eça de Queirós. During the 1930's, a surge in coffee houses happened in Porto with the opening of several that still exist, such as Café Guarany, opened in 1933, and A Regaleira, opened in 1934.\nIn 1667, Kara Hamie, a former Ottoman Janissary from Constantinople, opened the first coffee shop in Bucharest (then the capital of the Principality of Wallachia), in the center of the city, where today sits the main building of the National Bank of Romania.[58]\nIn 1761 the Turm Kaffee, a shop for exported goods, was opened in St. Gallen.[59]\nThe exclusion of women from coffeehouses as guests was not universal, but does appear to have been common in Europe. In Germany, women frequented them, but in England and France they were banned.[60] Émilie du Châtelet purportedly cross-dressed to gain entrance to a coffeehouse in Paris.[61]\nIn a well-known engraving of a Parisian café c. 1700,[62] the gentlemen hang their hats on pegs and sit at long communal tables strewn with papers and writing implements. Coffee pots are ranged at an open fire, with a hanging cauldron of boiling water. The only woman present presides, separated in a canopied booth, from which she serves coffee in tall cups.\nAside from the discussion around women as guests of the coffeehouses, it is noted that women did work as waitresses at coffeehouses and also managed coffeehouses as proprietors. Well known women in the coffeehouse business were Moll King in England, and Maja-Lisa Borgman in Sweden.[63]\nIn most European countries, such as Spain, Austria, Denmark, Germany, Norway, Sweden, Portugal, and others, the term café means a restaurant primarily serving coffee, as well as pastries such as cakes, tarts, pies, or buns. Many cafés also serve light meals such as sandwiches. European cafés often have tables on the pavement (sidewalk) as well as indoors. Some cafés also serve alcoholic drinks (e.g., wine), particularly in Southern Europe. In the Netherlands and Belgium, a café is the equivalent of a bar, and also sells alcoholic drinks. In the Netherlands a koffiehuis serves coffee, while a coffee shop (using the English term) sells \"soft\" drugs (cannabis and hashish) and is generally not allowed to sell alcoholic drinks. In France, most cafés serve as lunch restaurants in the day, and bars in the evening. They generally do not have pastries except in the mornings, when a croissant or pain au chocolat can be purchased with breakfast coffee. In Italy, cafés are similar to those found in France and known as bar. They typically serve a variety of espresso coffee, cakes and alcoholic drinks. Bars in city centers usually have different prices for consumption at the bar and consumption at a table.[64][citation needed]\nCoffeehouses are part of the culture of Buenos Aires and the customs of its inhabitants. They are traditional meeting places for 'porteños' and have inspired innumerable artistic creations. Some notable coffeehouses include Confitería del Molino, Café Tortoni, El Gato Negro, and Café La Biela.\nThe first coffeehouse in America opened in Boston, in 1676.[65] However, Americans did not start choosing coffee over tea until the Boston Tea Party and the Revolutionary War. After the Revolutionary War, Americans momentarily went back to drinking tea until after the War of 1812 when they began importing high-quality coffee from Latin America and expensive inferior-quality tea from American shippers instead of Great Britain.[66][67] Whether they were drinking coffee or tea, coffeehouses served a similar purpose to that which they did in Great Britain, as places where business was done. In the 1780s, Merchant's Coffee House located on Wall Street in New York City was home to the organization of the Bank of New York and the New York Chamber of Commerce.[68]\nCoffeehouses in the United States arose from the espresso- and pastry-centered Italian coffeehouses of the Italian American immigrant communities in the major U.S. cities, notably New York City's Little Italy and Greenwich Village, Boston's North End, and San Francisco's North Beach. From the late 1950s onward, coffeehouses also served as a venue for entertainment, most commonly folk performers during the American folk music revival.[69] Both Greenwich Village and North Beach became major haunts of the Beats, who were highly identified with these coffeehouses. As the youth culture of the 1960s evolved, non-Italians consciously copied these coffeehouses. The political nature of much of 1960s folk music made the music a natural tie-in with coffeehouses with their association with political action. A number of well-known performers like Joan Baez and Bob Dylan began their careers performing in coffeehouses. Blues singer Lightnin' Hopkins bemoaned his woman's inattentiveness to her domestic situation due to her overindulgence in coffeehouse socializing in his 1969 song \"Coffeehouse Blues\".[citation needed]\nIn 1966, Alfred Peet began applying the dark roast style to high quality beans and opened up a small shop in Berkeley, California to educate customers on the virtues of good coffee.[66] Starting in 1967 with the opening of the historic Last Exit on Brooklyn coffeehouse, Seattle became known for its thriving countercultural coffeehouse scene; the Starbucks chain later standardized and mainstreamed this espresso bar model, now prevalent throughout the country.[70][71][72]\nFrom the 1960s through the mid-1980s, churches and individuals in the United States used the coffeehouse concept for outreach. They were often storefronts and had names like The Lost Coin (Greenwich Village), The Gathering Place (Riverside, CA), Catacomb Chapel (New York City), and Jesus For You (Buffalo, NY). Christian music (often guitar-based) was performed, coffee and food was provided, and Bible studies were convened as people of varying backgrounds gathered in a casual setting that was purposefully different from traditional churches. An out-of-print book, published by the ministry of David Wilkerson, titled, A Coffeehouse Manual, served as a guide for Christian coffeehouses, including a list of name suggestions for coffeehouses.[73]\nCafés may have an outdoor section (terrace, pavement or sidewalk café) with seats, tables and parasols. This is especially the case with European cafés. Cafés offer a more open public space compared to many of the traditional pubs they have replaced, which were more male dominated with a focus on drinking alcohol.\nOne of the original uses of the café, as a place for information exchange and communication, was reintroduced in the 1990s with the Internet café or Hotspot.[74] The spread of modern-style cafés to urban and rural areas went hand-in-hand with the rising use of mobile computers. Computers and Internet access in a contemporary-styled venue help to create a youthful, modern place, compared to the traditional pubs or old-fashioned diners that they replaced.\nCoffeehouses in Egypt are colloquially called 'ahwah /ʔhwa/, which is the dialectal pronunciation of قَهْوة qahwah (literally \"coffee\")[75][76] (see also Arabic phonology#Local variations). Also commonly served in 'ahwah are tea (shāy) and herbal teas, especially the highly popular hibiscus blend (Egyptian Arabic: karkadeh or ennab). The first 'ahwah opened around the 1850s and were originally patronized mostly by older people, with youths frequenting but not always ordering. There were associated by the 1920s with clubs (Cairo), bursa (Alexandria) and gharza (rural inns). In the early 20th century, some of them became crucial venues for political and social debates.[75]\nIn India, coffee culture has expanded in the past twenty years. Chains like Indian Coffee House, Café Coffee Day, Barista Lavazza have become very popular. Cafes are considered good venues to conduct office meetings and for friends to meet.[77]\nIn China, an abundance of recently started domestic coffeehouse chains may be seen accommodating business people for conspicuous consumption, with coffee prices sometimes even higher than in the West.\nIn Malaysia and Singapore, traditional breakfast and coffee shops are called kopi tiam. The word is a portmanteau of the Malay word for coffee (as borrowed and altered from English) and the Hokkien dialect word for shop (店; POJ: tiàm). Menus typically feature simple offerings: a variety of foods based on egg, toast, and coconut jam, plus coffee, tea, and Milo, a malted chocolate drink that is extremely popular in Southeast Asia and Australasia, particularly Singapore and Malaysia.\nIn Indonesia, traditional coffee houses are called kedai kopi, rumah kopi, or warung kopi which is often abbreviated as warkop. Kopi tubruk is a common drink in small warkop. As a coffee drink companion, traditional kue is also served in the coffee house. The first coffee house in Indonesia was founded in 1878 in Jakarta which named Warung Tinggi Tek Sun Ho.[78]\nIn the Philippines, coffee shop chains like Starbucks have become the prevalent hangouts for upper- and middle-class professionals in such districts as the Makati CBD. However, carinderias (small eateries) continue to serve coffee alongside breakfast and snack dishes. Events called \"Kapihan\" (fora) are often held inside bakeshops or restaurants that also serve coffee for breakfast or merienda. There are also a number of establishments often referred to as \"cafés\" that serve not just coffee and pastries, but full meals, often international cuisine highly altered to Filipino tastes.[79]\nIn Thailand, the term \"café\" is not only a coffeehouse in the international definition, as in other countries, but in the past was considered a night restaurant that serves alcoholic drinks during a comedy show on stage. The era in which this type of business flourished was the 1990s, before the 1997 financial crisis.[80]\nThe first real coffeehouse in Thailand opened in 1917 at the Si Kak Phraya Si in the area of Rattanakosin Island, by Madam Cole, an American woman who living in Thailand at that time, Later, Chao Phraya Ram Rakop (เจ้าพระยารามราฆพ), Thai aristocrat, opened a coffeehouse named \"Café de Norasingha\" (คาเฟ่นรสิงห์) located at Sanam Suea Pa (สนามเสือป่า), the ground next to the Royal Plaza.[81] At present, Café de Norasingha has been renovated and moved to within Phayathai Palace.[82] In the southern region, a traditional coffeehouse or kopi tiam is popular with locals, like many countries in the Malay Peninsula.[83]\nIn the 19th century, coffee houses such as the Collingwood Coffee Palace or the Federal Coffee Palace in the centre of Melbourne were established and were part of the temperance movement to reduce the consumption of alcohol in society.[84]\nIn modern Australia, coffee shops are ubiquitously known as cafés. Since the post-World War II influx of Italian and Greek immigrants introduced the first espresso coffee machines to Australia in the 1950s, there was initially a slow rise in café culture, particularly in Melbourne, until a boom in locally owned cafés Australia-wide began in the 1990s.[85] Alongside the rise in the number of cafés there has been a rise in demand for locally (or on-site) roasted specialty coffee, particularly in Sydney and Melbourne. A local favourite is the \"flat white\" which remains a popular coffee drink.[86]\nIn Cairo, the capital of Egypt, most cafés have shisha (waterpipe). Most Egyptians indulge in the habit of smoking shisha while hanging out at the café, watching a match, studying, or even sometimes finishing some work. In Addis Ababa, the capital of Ethiopia, independent coffeehouses that struggled before 1991 have become popular with young professionals who do not have time for traditional coffee roasting at home. One establishment that has become well-known is the Tomoca coffee shop, which opened in 1953.[87][88]\nThe patrons of the first coffeehouse in England, The Angel, which opened in Oxford in 1650,[89] and the mass of London coffee houses that flourished over the next three centuries, were far removed from those of modern Britain. Haunts for teenagers in particular, Italian-run espresso bars and their formica-topped tables were a feature of 1950s Soho that provided a backdrop as well as a title for Cliff Richard's 1960 film Expresso Bongo. The first was The Moka in Frith Street, opened by Gina Lollobrigida in 1953. With their \"exotic Gaggia coffee machine[s],... Coke, Pepsi, weak frothy coffee and... Suncrush orange fountain[s]\"[90] they spread to other urban centers during the 1960s, providing affordable, warm places for young people to congregate and an ambience far removed from the global coffee bar standard that would be established in the final decades of the century by chains such as Starbucks and Pret a Manger.[90][91]\nThe espresso bar is a type of coffeehouse that specializes in coffee drinks made from espresso. Originating in Italy, the espresso bar has spread throughout the world in various forms. Prime examples that are internationally known are Starbucks Coffee, based in Seattle, U.S., and Costa Coffee, based in Loudwater, U.K. (the first and second largest coffeehouse chains respectively), although the espresso bar exists in some form throughout much of the world.\nThe espresso bar is typically centered around a long counter with a high-yield espresso machine (usually bean to cup machines, automatic or semiautomatic pump-type machine, although occasionally a manually operated lever-and-piston system) and a display case containing pastries and occasionally savory items such as sandwiches. In the traditional Italian bar, customers either order at the bar and consume their drinks standing or, if they wish to sit down and be served, are usually charged a higher price. In some bars there is an additional charge for drinks served at an outside table. In other countries, especially the United States, seating areas for customers to relax and work are provided free of charge. Some espresso bars also sell coffee paraphernalia, candy, and even music. North American espresso bars were also at the forefront of widespread adoption of public Wi-Fi access points to provide Internet services to people doing work on laptop computers on the premises.\nThe offerings at the typical espresso bar are generally quite Italianate in inspiration; biscotti, cannoli and pizzelle are a common traditional accompaniment to a caffe latte or cappuccino. Some upscale espresso bars even offer alcoholic drinks such as grappa and sambuca. Nevertheless, typical pastries are not always strictly Italianate and common additions include scones, muffins, croissants, and even doughnuts. There is usually a large selection of teas as well, and the North American espresso bar culture is responsible for the popularization of the Indian spiced tea drink masala chai. Iced drinks are also popular in some countries, including both iced tea and iced coffee as well as blended drinks such as Starbucks' Frappucino.\nA worker in an espresso bar is referred to as a barista. The barista is a skilled position that requires familiarity with the drinks being made (often very elaborate, especially in North American-style espresso bars), a reasonable facility with some equipment as well as the usual customer service skills.\n- Café society\n- Caffè sospeso\n- Cat café\n- Cha chaan teng, Hong Kong-style café\n- Coffeehouse culture of Baghdad\n- Coffee service\n- Death Cafe\n- Dog café\n- English coffeehouses in the 17th and 18th centuries\n- Greasy spoon\n- History of coffee\n- Kafana\n- Kissaten\n- Kopi tiam\n- List of coffeehouse chains\n- Manga café\n- Teahouse\n- Turkish coffee\n- Castella, Krystina (2010). A World of Cake. Storey Publishing. pp. 44. ISBN 978-1603425766.\n- Liberman, Sherri (2011). American Food by the Decades. ABC-CLIO. pp. 133–134. ISBN 978-0313376993.\n- Haine, W. Scott (1998-09-11). The World of the Paris Café. JHU Press. pp. 1–5. ISBN 0801860709.\n- Haine, W. Scott (2006-06-12). Alcohol: A Social and Cultural History. Berg. p. 121. ISBN 9781845201654. Archived from the original on 2017-03-29. Retrieved 2019-09-20.\n- The Rough Guide to France. Rough Guides. 2003. p. 49. ISBN 9781843530381. Retrieved 2019-09-20.\n- \"Classic Cafes: London's vintage Formica caffs!\". classiccafes.co.uk. Archived from the original on 2013-08-20. Retrieved 2013-09-28.\n- Davies, Russell (2005). Egg, Bacon, Chips and Beans: 50 Great Cafes and the Stuff That Makes Them Great. HarperCollins Entertainment. ISBN 9780007213788. Archived from the original on 2016-06-10. Retrieved 2013-09-28.\n- \"Coffeehouse\". MerriamWebster. Archived from the original on 2011-11-04. Retrieved 2012-04-07.\n- Rubin, Joan Shelley; Boyer, Paul S.; Casper, Professor Scott E. (2013). \"Bob Dylan\". The Oxford Encyclopedia of American Cultural and Intellectual History. USA: Oxford University Press. p. 317.\n- \"Blue Mountain Café vs Blue Mountain Coffee\". Jamaican Blue Mountain Coffee. Archived from the original on 2013-01-13. Retrieved 2012-12-10.\n- \"Online Etymology Dictionary\". etymonline.com. Archived from the original on 2017-06-27. Retrieved 2017-09-01.\n- \"CAFÉ definition and meaning – Collins English Dictionary\". collinsdictionary.com.\n- Oxford English Dictionary, 2nd ed (1989), entry number 50031127 (café).\n- Oxford English Dictionary, 2nd ed (1989), entry number 00333259 (caffé, n)\n- Oxford English Dictionary, 2nd ed (1989), entry number 50031130 (caff)\n- \"Coffee definition and meaning – Collins English Dictionary\". collinsdictionary.com. Archived from the original on 2018-06-12. Retrieved 2018-03-15.\n- \"CAFE : Etymologie de CAFE\". cnrtl.fr. Archived from the original on 2017-10-18. Retrieved 2018-03-15.\n- \"etymologiebank.nl\". etymologiebank.nl. Archived from the original on 2018-03-19. Retrieved 2018-03-15.\n- \". serbia.com. Archived from the original on 2013-06-15.\n- \"Coffee | Origin, Types, Uses, History, & Facts\". Archived from the original on 2019-04-25. Retrieved 2019-09-20.\n- \"صحيفة التاخي – المســــرح في المقاهي والملاهي البغدادية\". 2018-08-10. Archived from the original on 2018-08-10. Retrieved 2023-07-15.\n- Çomak, Nebahat; Pembecioğlu, Nilüfer (2014). \"Changing the values of the past to future\". Archived from the original on 2022-11-08. Retrieved 2022-08-06.\n- Quoted in Bernard Lewis, Istanbul and the Civilization of the Ottoman Empire, University of Oklahoma Press (reprint, 1989), p. 132 Internet Archive Archived 2017-03-28 at the Wayback Machine. ISBN 978-0-8061-1060-8.\n- \"Coffee – The Wine of Islam\". Superluminal.com. Archived from the original on 2011-06-11. Retrieved 2011-05-29.\n- Encyclopedia of Jewish Food, Gil Marks, HMH, 17 November 2010\n- APM – Archeologia Postmedievale, 19, 2015 – Gran Bretagna e Italia tra Mediterraneo e Atlantico: Livorno – 'un porto inglese' / Italy and Britain between Mediterranean and Atlantic worlds: Leghorn – 'an English port' Hugo Blake All'Insegna del Giglio, 8 September 2017, p. 18\n- Horowitz, Elliot. \"Coffee, Coffeehouses, and the Nocturnal Rituals of Early Modern Jewry\". AJS Review Vol. 14, No. 1 (Spring, 1989), pp. 17–46, citing Antonio Pilot, La Bottega da Caffe(Venice, 1916)\n- Winick, Stephen (2014-04-17). \"Coffeehouses: Folk Music, Culture, and Counterculture | Folklife Today\". The Library of Congress. Retrieved 2024-04-19.\n- Weinberg, Bennett Alan; Bealer, Bonnie K. (2002). The World of Caffeine: The Science and Culture of the World's Most Popular Drug. Routledge. p. page 77. ISBN 0-415-92722-6.\n- Teply, Karl (1980). Czeike, Felix (ed.). Die Einführung des Kaffees in Wien. Georg Franz Koltschitzky. Johannes Diodato. Isaac de Luca. Sonderreihe der \"Wiener Geschichtsblätter\" (später Reihe: \"Forschungen und Beiträge zur Wiener Stadtgeschichte\") (in German). Vol. 6. Vienna, Austria & Munich, Germany: Verein für Geschichte der Stadt Wien / Kommissionsverlag Jugend und Volk. p. 104. ISBN 3-7141-9330-8. OCLC 14949012. S2CID 190364058. ISBN 3-7005-4536-3.https://utheses.univie.ac.at/detail/1675\n- Friedrich Torberg \"Kaffeehaus war überall\" (1982) pp 8.\n- Wolfram Siebeck \"Die Kaffeehäuser von Wien. Eine Melange aus Mythos und Schmäh\" (1996) pp 7.\n- Helmut Luther \"Warum Kaffeetrinken in Triest anspruchsvoll ist\" In: Die Welt, 16 February 2015.\n- \"Doron Rabinovici \"Kaffeehaus als Menschenrecht (German: Coffee house as a human right)\". 2017-01-23. Archived from the original on 2021-06-23. Retrieved 2021-01-06.\n- \"Coffeehouse culture – Austria's culinary heritage\". Archived from the original on 2021-01-16. Retrieved 2021-01-06.\n- Riha, Fritz \"Das alte Wiener Caféhaus\" (1987), pp 12.\n- Prinz, Deborah R. (2013). On the Chocolate Trail: A Delicious Adventure Connecting Jews, Religions, History, Travel, Rituals and Recipes to the Magic of Cacao. Jewish Lights Publishing. p. 5. ISBN 9781683366775.\n- Palmer, Alan; Palmer, Veronica (1992). The Chronology of British History. London: Century. ISBN 978-0-7126-5616-0.\n- \"Oxford Exclusion\". Archived from the original on 2021-04-11. Retrieved 2021-04-11.\n- Cowan, Brian (2006). \"Pasqua Rosee\". Oxford Dictionary of National Biography (online ed.). Oxford University Press. doi:10.1093/ref:odnb/92862. Archived from the original on 2013-01-14. Retrieved 2011-05-29.(Subscription, Wikipedia Library access or UK public library membership required.)\n- Macaulay, Rose (1936) The Minor Pleasures of Life. London: Victor Gollancz; p. 257\n- Weinberg, Bennett Alan; Bealer, Bonnie K. (2002). The World of Caffeine: The Science and Culture of the World's Most Popular Drug. Routledge. p. page 154. ISBN 0-415-92722-6.\n- Wild, Anthony (2005). Coffee A Dark History. W. W. Norton & Company. p. page 90. ISBN 0-393-06071-3.\n- \"Internet History Sourcebooks\". Fordham.edu. Archived from the original on 2013-10-11. Retrieved 2013-08-15.\n- Ferreira, Jennifer (2017). \"Café nation? Exploring the growth of the UK café industry\". Area. 49 (1): 67–76. Bibcode:2017Area...49...69F. doi:10.1111/area.12285.\n- Wild, Antony (2005). \"Chapter 5: Coffee and Societies\". Coffee: A Dark History. W.W. Norton Company & Ltd. p. 85.\n- White, Lucy Cecil (February 1891). \"WILL'S COFFEE-HOUSE\". The Chautauquan; A Weekly Newsmagazine (1880–1914), 12(5). p. 687.\n- Cowan, Brian (2008-10-01). The Social Life of Coffee: The Emergence of the British Coffeehouse. Yale University Press. p. 215. ISBN 978-0-300-13350-9.\n- Prévost, Abbé (1930) Adventures of a man of quality (translation of Séjour en Angleterre, v. 5 of Mémoires et aventures d'un homme de qualité qui s'est retiré du monde) G. Routledge & Sons, London, OCLC 396693\n- Beatty-Kingston, William (1892). Intemperance: Its Causes and Its Remedies. No publisher name given. JSTOR 60222729.\n- \"Coffee Tavern\". Lincolnshire Free Press. 1881-12-27. p. 7.\n- \"Suomen historian merkkipaaluja: Ensimmäisenä Turussa\" (in Finnish). City of Turku. 2021-06-08. Retrieved 2024-09-11.\n- \"Ekberg – Helsingin Historiallinen Herkkukeidas\" (in Finnish). Parasta Stadissa. 2024-02-22. Retrieved 2024-09-11.\n- \"Le Procope – Paris – Brasserie\". Zenchef. Archived from the original on 2018-03-09. Retrieved 2018-03-15.\n- \"Az első pesti kávéház háborúja\". Budapest romantikája. Archived from the original on 2022-04-01. Retrieved 2020-04-09.\n- Abbas, Hyder (February 2014). \"Library & Information History. 30 (1). Taylor & Francis, Ltd.: 41–61 [46]. doi:10.1179/1758348913Z.00000000051. ISSN 1758-3489. S2CID 161212491.\n- White, Matthew. \"Newspapers, gossip and coffeehouse culture\". British Library. Archived from the original on 2019-09-26. Retrieved 2019-02-24.\n- \"Cafenele din Vechiul București (secolele XIX–XX) ('Coffeeshops from Old Bucharest (19th–20th centuries)')\". Historia.ro. 2000-03-30. Archived from the original on 2013-01-16. Retrieved 2013-01-01.\n- Willi Leuthold: 222 Jahre Lebensmittel Gross- und Detailhandel \"hinterm Turm\" in St.Gallen, 1983\n- \"Coffee History\". Archived from the original on 2007-09-15. Retrieved 2007-10-27.\n- \"Gabrielle Emilie le Tonnelier de Breteuil du Chatelet – and Voltaire\". Archived from the original on 2007-10-18. Retrieved 2007-10-27.\n- \"A coffeehouse at the close of the seventeenth century\". Archived from the original on 2009-10-19.\n- Du Rietz, Anita, Kvinnors entreprenörskap: under 400 år, 1. uppl., Dialogos, Stockholm, 2013\n- Tomalin, Barry (2016). Italy – Culture Smart! : The Essential Guide to Customs & Culture. London: Kuperard. p. 101. ISBN 9781857338300.\n- \"America's First Coffeehouse\". Massachusetts Travel Journal. Archived from the original on 2010-09-27. Retrieved 2010-09-21.\n- Wolf, Burt (2002). What We Eat: The True Story of Why We Put Sugar in our Coffee and Ketchup on our Fries. Tehabi Books. pp. 112–115.\n- McDonald, Michelle Craig (2025). Coffee Nation: How One Commodity Transformed the Early United States (1st ed.). Philadelphia, PA: University of Pennsylvania Press. ISBN 9781512827552.\n- Rotondi, Jessica Pearce (2020-02-11). \"How Coffee Fueled Revolutions—And Changed History\". HISTORY. Archived from the original on 2021-04-10. Retrieved 2021-04-10.\n- Shelton, Robert \"Something happened in America\", in: Laing, Dave, et al. (1975) The Electric Muse. London: Eyre Methuen; pp. 7–44: p. 31\n- \"Starbucks Coffee Company: Past, Present and Future\". PurelyCoffeeBeans. Archived from the original on 2019-11-07. Retrieved 2019-11-07.\n- Walrath-Holdridge, Mary (2024-06-13). \"Starbucks Introduces Value Meals with New 'Pairings Menu'. USA Today. Retrieved 2024-08-07.\n- Sources: Chase Purdy, author, \"That joke about a Starbucks on every corner? It's actually true and hurting the company's sales\", Quartz, 2017.\n- Sources: Tim Schultz, Director, \"Jesus For You\". A Coffeehouse Manual, Bethany Fellowship, 1972.\n- \"Julius Briner Message Board\". Investorshub.advfn.com. Archived from the original on 2011-05-01. Retrieved 2010-09-21.\n- Alpion, Gëzim (2011-05-18). Encounters With Civilizations: From Alexander the Great to Mother Teresa. Transaction Publishers. p. 48. ISBN 978-1-4128-1831-5. Archived from the original on 2013-09-06. Retrieved 2012-04-01.\n[T]he drinking establishment began to be named after its newest beverage [i.e., coffee]. This is how qahwa (coffee shop) came into being in Egypt.\n- The [q] is debuccalized to [ʔ]. Stewart, Desmond (1965). Cairo. Phoenix House. Archived from the original on 2014-01-03. Retrieved 2012-04-01.\n[...] qahwah, coffee, is pronounced as ahwah; the word for citadel, qal'ah, is pronounced al'ah; in both cases, it should be added, the final 'h' is silent and is often omitted.\n- \"Middle-class India embraces coffee culture\". Asian Correspondent. 2013-02-18. Archived from the original on 2013-09-06. Retrieved 2013-08-15.\n- Asriyati, Asriyati. \"Inilah Kedai Kopi Pertama di Indonesia\". goodnewsfromindonesia.id (in Indonesian). Archived from the original on 2023-05-14. Retrieved 2023-05-14.\n- Yuvallos, Andrei (2024-01-17). \"What is Filipino café food, anyway?\". NOLISOLI. Retrieved 2024-05-17.\n- \"40 ปี \"ตำนานคาเฟ่\" เมืองหลวง จากศูนย์รวมบันเทิงถึงยุคเสื่อม นักร้องต้องขายตัวแลกพวงมาลัย\". Manager Daily (in Thai). 2015-06-30. Archived from the original on 2016-06-21. Retrieved 2018-04-03.\n- บุนนาค, โรม (2018-02-06). \"เมื่อ \"เครื่องดื่มปีศาจ\" มาสยาม! ร.๓ ทรงปลูกเป็นสวนหลวงในหัวแหวนกรุงรัตนโกสินทร์!!\". Manager Daily (in Thai). Archived from the original on 2018-04-02. Retrieved 2018-04-03.\n- \"เที่ยวร้านกาแฟนรสิงห์ ร้านกาแฟแห่งแรกของสยาม ณ พระราชวังพญาไท\". today.line.me (in Thai). 2017-10-30. Archived from the original on 2018-04-03. Retrieved 2018-04-03.\n- ประชาธิปัตย์ปราศรัย [DEMOCRAT LIVE] (in Thai). Bangkok: politikpress. 2005. pp. 4–5. ISBN 974-92738-6-9.\n- \"State Library Victoria Temperance and Melbourne's grand coffee palaces\". State Library Victoria. 2014-05-31. Retrieved 2024-10-12.\n- \"Coffee is consumed everywhere — even in space. How did it win over the world?\". ABC News. 2023-06-11. Retrieved 2024-10-12.\n- \"How the flat white conquered the UK coffee scene\". The Independent. 2018-04-16. Retrieved 2024-10-12.\n- Jeffrey, James (2014-10-15). \"Boom times for Ethiopia's coffee shops\". BBC News. Archived from the original on 2014-10-19. Retrieved 2014-10-21.\n- \"Ethiopian Coffee Ceremony\". Carey Nash Photography. 2014-09-28. Archived from the original on 2014-10-08. Retrieved 2014-10-21.\n- \"Drugs and Society\". Vol. 2, no. 9. June 1973.\n- Lyn Perry, \"Cabbages and Cuppas\", in Adventures in the Mediatheque: Personal Selections of Films Archived 15 May 2011 at the Wayback Machine, (London: BFI Southbank / University of the Third Age, 2008), pp 26–27.\n- \"The Coming of the Cafes\". Classic Cafes. Archived from the original on 2016-03-23.\n- Marie-France Boyer; photographs by Eric Morin (1994) The French Café. London: Thames & Hudson.\n- Brian Cowan (2005), The Social Life of Coffee: The Emergence of the British Coffeehouse, Yale University Press.\n- Markman Ellis (2004), The Coffee House: A Cultural History, Weidenfeld & Nicolson.\n- Ellis, Markman (2004). The Coffee-House: A Cultural History. London: Weidenfeld & Nicolson.\n- Homsi, Nada; Hendawi, Hamza; Mahmoud, Sinan; Oweis, Khaled Yacoub (2023-02-24). \"Coffee houses of the Middle East: inside the region's historic cauldrons of culture\". The National. Abu Dhabi. Archived from the original on 2023-04-30. Retrieved 2023-04-30.\n- Robert Hume. \"Percolating Society\", Irish Examiner, 27 April 2017. p. 13.\n- Nautiyal, J. J. (2016). \"Aesthetic and affective experiences in coffee shops: a Deweyan engagement with ordinary affects in ordinary spaces\". Education & Culture, 32(2), 99–118.\n- Ray Oldenburg, The Great Good Place: Cafes, Coffee Shops, Community Centers, General Stores, Bars, Hangouts, and How They Get You through the Day. New York: Parragon Books, 1989. ISBN 1-56924-681-5.\n- Tom Standage (2006). A History of the World in Six Glasses, Walker & Company, ISBN 0-8027-1447-1.\n- Antony Wild, Coffee: A Dark History, New York: W. W. Norton & Company, ISBN 9780393060713; London: Fourth Estate, 2004 ISBN 1841156493.\n- Withington, Phil. \"Public and Private Pleasures.\" History Today (June 2020) 70#6 pp. 16–18. Covers London 1630 to 1800.\n- Withington, Phil. \"Where was the coffee in early modern England?\" Journal of Modern History 92.1 (2020): 40–75.\n- Yaşar, Ahmet (2003). The Coffeehouses in Early Modern Istanbul: Public Space, Sociability and Surveillance (M.A.). Istanbul: Boğaziçi University. Archived from the original on 2022-04-05. Retrieved 2023-05-18.\n- Ahmet Yaşar, \"Osmanlı Şehir Mekânları: Kahvehane Literatürü / Ottoman Urban Spaces: An Evaluation of Literature on Coffeehouses\", TALİD Türkiye Araştırmaları Literatür Dergisi, 6, 2005, 237–256. Talid.org.\n- Media related to Cafés at Wikimedia Commons",
    "calculator": "A calculator is typically a portable electronic device used to perform calculations, ranging from basic arithmetic to complex mathematics.\nThe first solid-state electronic calculator was created in the early 1960s. Pocket-sized devices became available in the 1970s, especially after the Intel 4004, the first microprocessor, was developed by Intel for the Japanese calculator company Busicom. Modern electronic calculators vary from cheap, give-away, credit-card-sized models to sturdy desktop models with built-in printers. They became popular in the mid-1970s as the incorporation of integrated circuits reduced their size and cost. By the end of that decade, prices had dropped to the point where a basic calculator was affordable to most and they became common in schools.\nIn addition to general-purpose calculators, there are those designed for specific markets. For example, there are scientific calculators, which include trigonometric and statistical calculations. Some calculators even have the ability to do computer algebra. Graphing calculators can be used to graph functions defined on the real line, or higher-dimensional Euclidean space. As of 2016[update], basic calculators cost little, but scientific and graphing models tend to cost more.[1]\nComputer operating systems as far back as early Unix have included interactive calculator programs such as dc and hoc, and interactive BASIC could be used to do calculations on most 1970s and 1980s home computers. Calculator functions are included in most smartphones, tablets, and personal digital assistant (PDA) type devices. With the very wide availability of smartphones and the like, dedicated hardware calculators, while still widely used, are less common than they once were. In 1986, calculators still represented an estimated 41% of the world's general-purpose hardware capacity to compute information. By 2007, this had diminished to less than 0.05%.[2]\nDesign\nInput\nElectronic calculators contain a keyboard with buttons for digits and arithmetical operations; some even contain \"00\" and \"000\" buttons to make larger or smaller numbers easier to enter.[3] Most basic calculators assign only one digit or operation on each button; however, in more specific calculators, a button can perform multi-function working with key combinations.\nDisplay output\nCalculators usually have liquid-crystal displays (LCD) as output in place of historical light-emitting diode (LED) displays and vacuum fluorescent displays (VFD); details are provided in the section Technical improvements.\nLarge-sized figures are often used to improve readability; while using decimal separator (usually a point rather than a comma) instead of or in addition to vulgar fractions. Various symbols for function commands may also be shown on the display. Fractions such as 1⁄3 are displayed as decimal approximations, for example rounded to 0.33333333. Also, some fractions (such as 1⁄7, which is 0.14285714285714; to 14 significant figures) can be difficult to recognize in decimal form; as a result, many scientific calculators are able to work in vulgar fractions or mixed numbers.\nMemory\nCalculators also have the ability to save numbers into computer memory. Basic calculators usually store only one number at a time; more specific types are able to store many numbers represented in variables. Usually these variables are named ans or ans(0).[4] The variables can also be used for constructing formulas. Some models have the ability to extend memory capacity to store more numbers; the extended memory address is termed an array index.\nPower source\nPower sources of calculators are batteries, solar cells or mains electricity (for old models), turning on with a switch or button. Some models even have no turn-off button but they provide some way to put off (for example, leaving no operation for a moment, covering solar cell exposure, or closing their lid). Crank-powered calculators were also common in the early computer era.\nKey layout\nThe following keys are common to most pocket calculators. While the arrangement of the digits is standard, the positions of other keys vary from model to model; the illustration is an example.\n| MC or CM | Memory Clear | T\nypical layout of a basic pocket calculator |\n| MR, RM, or MRC | Memory Recall | |\n| M− | Memory Subtraction | |\n| M+ | Memory Addition | |\n| C or AC | All Clear | |\n| CE | Clear (last) Entry; sometimes called CE/C: a first press clears the last entry (CE), a second press clears all (C) | |\n| ± or CHS | Toggle positive/negative number aka CHange Sign | |\n| % | Percent | |\n| ÷ | Division | |\n| × | Multiplication | |\n| − | Subtraction | |\n| + | Addition | |\n| . | Decimal point | |\n| √ | Square root | |\n| = | Result |\nThe arrangement of digits on calculator and other numeric keypads with the 7-8-9 keys two rows above the 1-2-3 keys is derived from calculators and cash registers. It is notably different from the layout of telephone Touch-Tone keypads which have the 1-2-3 keys on top and 7-8-9 keys on the third row.\nInternal workings\nIn general, a basic electronic calculator consists of the following components:[5]\n- Power source (mains electricity, battery and/or solar cell)\n- Keypad (input device) – consists of keys used to input numbers and function commands (addition, multiplication, square root, etc.)\n- Display panel (output device) – displays input numbers, commands and results. Liquid-crystal displays (LCDs), vacuum fluorescent displays (VFDs), and light-emitting diode (LED) displays use seven segments to represent each digit in a basic calculator. Advanced calculators may use dot matrix displays.\n- A printing calculator, in addition to a display panel, has a printing unit that prints results in ink onto a roll of paper, using a printing mechanism.\n- Processor chip (microprocessor or central processing unit).\n| Unit | Function |\n|---|---|\n| Scanning (Polling) unit | When a calculator is powered on, it scans the keypad waiting to pick up an electrical signal when a key is pressed. |\n| Encoder unit | Converts the numbers and functions into binary code. |\n| X register and Y register | They are number stores where numbers are stored temporarily while doing calculations. All numbers go into the X register first; the number in the X register is shown on the display. |\n| Flag register | The function for the calculation is stored here until the calculator needs it. |\n| Permanent memory (ROM) | The instructions for in-built functions (arithmetic operations, square roots, percentages, trigonometry, etc.) are stored here in binary form. These instructions are programs, stored permanently, and cannot be erased. |\n| User memory (RAM) | The store where numbers can be stored by the user. User memory contents can be changed or erased by the user. |\n| Arithmetic logic unit (ALU) | The ALU executes all arithmetic and logic instructions, and provides the results in binary coded form. |\n| Binary decoder unit | Converts binary code into decimal numbers which can be displayed on the display unit. |\nClock rate of a processor chip refers to the frequency at which the central processing unit (CPU) is running. It is used as an indicator of the processor's speed, and is measured in clock cycles per second or hertz (Hz). For basic calculators, the speed can vary from a few hundred hertz to the kilohertz range.\nExample\nA basic explanation as to how calculations are performed in a simple four-function calculator:\nTo perform the calculation 25 + 9, one presses keys in the following sequence on most calculators: 2 5 + 9 =.\n- When 2 5 is entered, it is picked up by the scanning unit; the number 25 is encoded and sent to the X register;\n- Next, when the + key is pressed, the \"addition\" instruction is also encoded and sent to the flag or the status register;\n- The second number 9 is encoded and sent to the X register. This \"pushes\" (shifts) the first number out into the Y register;\n- When the = key is pressed, a \"message\" (signal) from the flag or status register tells the permanent or non-volatile memory that the operation to be done is \"addition\";\n- The numbers in the X and Y registers are then loaded into the ALU and the calculation is carried out following instructions from the permanent or non-volatile memory;\n- The answer, 34 is sent (shifted) back to the X register. From there, it is converted by the binary decoder unit into a decimal number (usually binary-coded decimal), and then shown on the display panel.\nOther functions are usually performed using repeated additions or subtractions.\nNumeric representation\nMost pocket calculators do all their calculations in binary-coded decimal (BCD) rather than binary. BCD is common in electronic systems where a numeric value is to be displayed, especially in systems consisting solely of digital logic, and not containing a microprocessor. By employing BCD, the manipulation of numerical data for display can be greatly simplified by treating each digit as a separate single sub-circuit. This matches much more closely the physical reality of display hardware—a designer might choose to use a series of separate identical seven-segment displays to build a metering circuit, for example. If the numeric quantity were stored and manipulated as pure binary, interfacing to such a display would require complex circuitry. Therefore, in cases where the calculations are relatively simple, working throughout with BCD can lead to a simpler overall system than converting to and from binary. (For example, CDs keep the track number in BCD, limiting them to 99 tracks.)\nThe same argument applies when hardware of this type uses an embedded microcontroller or other small processor. Often, smaller code results when representing numbers internally in BCD format, since a conversion from or to binary representation can be expensive on such limited processors. For these applications, some small processors feature BCD arithmetic modes, which assist when writing routines that manipulate BCD quantities.[6][7]\nWhere calculators have added functions (such as square root, or trigonometric functions), software algorithms are required to produce high precision results. Sometimes significant design effort is needed to fit all the desired functions in the limited memory space available in the calculator chip, with acceptable calculation time.[8]\nHistory\nPrecursors to the electronic calculator\nThe first known tools used to aid arithmetic calculations were: bones (used to tally items), pebbles, and counting boards, and the abacus, known to have been used by Sumerians and Egyptians before 2000 BC.[9] Except for the Antikythera mechanism (an \"out of the time\" astronomical device), development of computing tools arrived near the start of the 17th century: the geometric-military compass (by Galileo), logarithms and Napier bones (by Napier), and the slide rule (by Edmund Gunter).[1]\nThe Renaissance saw the invention of the mechanical calculator by Wilhelm Schickard in 1623,[10] and later by Blaise Pascal in 1642.[11] A device that was at times somewhat over-promoted as being able to perform all four arithmetic operations with minimal human intervention.[12] Pascal's calculator could add and subtract two numbers directly and thus, if the tedium could be borne, multiply and divide by repetition. Schickard's machine, constructed several decades earlier, used a clever set of mechanised multiplication tables to ease the process of multiplication and division with the adding machine as a means of completing this operation. There is a debate about whether Pascal or Shickard should be credited as the known inventor of a calculating machine due to the differences (like the different aims) of both inventions.[13] Schickard and Pascal were followed by Gottfried Leibniz who spent forty years designing a four-operation mechanical calculator, the stepped reckoner, inventing in the process his leibniz wheel, but who couldn't design a fully operational machine.[14] There were also five unsuccessful attempts to design a calculating clock in the 17th century.[15]\nThe 18th century saw the arrival of some notable improvements, first by Poleni with the first fully functional calculating clock and four-operation machine, but these machines were almost always one of a kind. Luigi Torchi invented the first direct multiplication machine in 1834: this was also the second key-driven machine in the world, following that of James White (1822).[16] It was not until the 19th century and the Industrial Revolution that real developments began to occur. Although machines capable of performing all four arithmetic functions existed prior to the 19th century, the refinement of manufacturing and fabrication processes during the eve of the industrial revolution made large scale production of more compact and modern units possible. The Arithmometer, invented in 1820 as a four-operation mechanical calculator, was released to production in 1851 as an adding machine and became the first commercially successful unit; forty years later, by 1890, about 2,500 arithmometers had been sold[17] plus a few hundreds more from two arithmometer clone makers (Burkhardt, Germany, 1878 and Layton, UK, 1883) and Felt and Tarrant, the only other competitor in true commercial production, had sold 100 comptometers.[18]\nIt wasn't until 1902 that the familiar push-button user interface was developed, with the introduction of the Dalton Adding Machine, developed by James L. Dalton in the United States.\nIn 1921, Edith Clarke invented the \"Clarke calculator\", a simple graph-based calculator for solving line equations involving hyperbolic functions. This allowed electrical engineers to simplify calculations for inductance and capacitance in power transmission lines.[19]\nThe Curta calculator was developed in 1948 and, although costly, became popular for its portability. This purely mechanical hand-held device could do addition, subtraction, multiplication and division. By the early 1970s electronic pocket calculators ended manufacture of mechanical calculators, although the Curta remains a popular collectable item.\nDevelopment of electronic calculators\nThe first mainframe computers, initially using vacuum tubes and later transistors in the logic circuits, appeared in the 1940s and 1950s. Electronic circuits developed for computers also had application to electronic calculators.\nThe Casio Computer Company, in Japan, released the Model 14-A calculator in 1957, which was the world's first all-electric (relatively) compact calculator. It did not use electronic logic but was based on relay technology, and was built into a desk. The IBM 608 plugboard programmable calculator was IBM's first all-transistor product, released in 1957; this was a console type system, with input and output on punched cards, and replaced the earlier, larger, vacuum-tube IBM 603.\nIn October 1961, the world's first all-electronic desktop calculator, the British Bell Punch/Sumlock Comptometer ANITA (A New Inspiration To Arithmetic/Accounting) was announced.[20][21] This machine used vacuum tubes, cold-cathode tubes and Dekatrons in its circuits, with 12 cold-cathode \"Nixie\" tubes for its display. Two models were displayed, the Mk VII for continental Europe and the Mk VIII for Britain and the rest of the world, both for delivery from early 1962. The Mk VII was a slightly earlier design with a more complicated mode of multiplication, and was soon dropped in favour of the simpler Mark VIII. The ANITA had a full keyboard, similar to mechanical comptometers of the time, a feature that was unique to it and the later Sharp CS-10A among electronic calculators. The ANITA weighed roughly 33 pounds (15 kg) due to its large tube system.[22] Bell Punch had been producing key-driven mechanical calculators of the comptometer type under the names \"Plus\" and \"Sumlock\", and had realised in the mid-1950s that the future of calculators lay in electronics. They employed the young graduate Norbert Kitz, who had worked on the early British Pilot ACE computer project, to lead the development. The ANITA sold well since it was the only electronic desktop calculator available, and was silent and quick.\nThe tube technology of the ANITA was superseded in June 1963 by the U.S. manufactured Friden EC-130, which had an all-transistor design, a stack of four 13-digit numbers displayed on a 5-inch (13 cm) cathode-ray tube (CRT), and introduced Reverse Polish Notation (RPN) to the calculator market for a price of $2200, which was about three times the cost of an electromechanical calculator of the time. Like Bell Punch, Friden was a manufacturer of mechanical calculators that had decided that the future lay in electronics. In 1964 more all-transistor electronic calculators were introduced: Sharp introduced the CS-10A, which weighed 25 kilograms (55 lb) and cost 500,000 yen ($4555.81), and Industria Macchine Elettroniche of Italy introduced the IME 84, to which several extra keyboard and display units could be connected so that several people could make use of it (but apparently not at the same time). The Victor 3900 was the first to use integrated circuits in place of individual transistors, but production problems delayed sales until 1966.\nThere followed a series of electronic calculator models from these and other manufacturers, including Canon, Mathatronics, Olivetti, SCM (Smith-Corona-Marchant), Sony, Toshiba, and Wang. The early calculators used hundreds of germanium transistors, which were cheaper than silicon transistors, on multiple circuit boards. Display types used were CRT, cold-cathode Nixie tubes, and filament lamps. Memory technology was usually based on the delay-line memory or the magnetic-core memory, though the Toshiba \"Toscal\" BC-1411 appears to have used an early form of dynamic RAM built from discrete components. Already there was a desire for smaller and less power-hungry machines.\nBulgaria's ELKA 6521,[23][24] introduced in 1965, was developed by the Central Institute for Calculation Technologies and built at the Elektronika factory in Sofia. The name derives from ELektronen KAlkulator, and it weighed around 8 kg (18 lb). It is the first calculator in the world which includes the square root function. Later that same year were released the ELKA 22 (with a luminescent display)[23][25][26] and the ELKA 25, with an built-in printer. Several other models were developed until the first pocket model, the ELKA 101, was released in 1974. The writing on it was in Roman script, and it was exported to western countries.[23][27][28][29]\nProgrammable calculators\nThe first desktop programmable calculators were produced in the mid-1960s. They included the Mathatronics Mathatron (1964) and the Olivetti Programma 101 (late 1965) which were solid-state, desktop, printing, floating point, algebraic entry, programmable, stored-program electronic calculators.[30][31] Both could be programmed by the end user and print out their results. The Programma 101 saw much wider distribution and had the added feature of offline storage of programs via magnetic cards.[31]\nAnother early programmable desktop calculator (and maybe the first Japanese one) was the Casio (AL-1000) produced in 1967. It featured a nixie tubes display and had transistor electronics and ferrite core memory.[32]\nThe Monroe Epic programmable calculator came on the market in 1967. A large, printing, desk-top unit, with an attached floor-standing logic tower, it could be programmed to perform many computer-like functions. However, the only branch instruction was an implied unconditional branch (GOTO) at the end of the operation stack, returning the program to its starting instruction. Thus, it was not possible to include any conditional branch (IF-THEN-ELSE) logic. During this era, the absence of the conditional branch was sometimes used to distinguish a programmable calculator from a computer.\nThe first Soviet programmable desktop calculator ISKRA 123, powered by the power grid, was released at the start of the 1970s.\n1970s to mid-1980s\nThe electronic calculators of the mid-1960s were large and heavy desktop machines due to their use of hundreds of transistors on several circuit boards with a large power consumption that required an AC power supply. There were great efforts to put the logic required for a calculator into fewer and fewer integrated circuits (chips) and calculator electronics was one of the leading edges of semiconductor development. U.S. semiconductor manufacturers led the world in large scale integration (LSI) semiconductor development, squeezing more and more functions into individual integrated circuits. This led to alliances between Japanese calculator manufacturers and U.S. semiconductor companies: Canon Inc. with Texas Instruments, Hayakawa Electric (later renamed Sharp Corporation) with North-American Rockwell Microelectronics (later renamed Rockwell International), Busicom with Mostek and Intel, and General Instrument with Sanyo.\nPocket calculators\nReleased in 1947, the first pocket calculator which could perform the four basic arithmetic functions with digital precision was the Curta, a mechanical device operated by a crank, bearing “an uncanny resemblance to a pepper grinder”.[33] The readout was digital with eleven digits of precision. For comparison, the contemporaneous ten inch slide rule used analog calculation to approximate answers to only four digits of precision.[34] The Curta remained the finest pocket calculator available for a quarter of a century.[33]\nBy 1970, a calculator could be made using just a few chips of low power consumption, allowing portable models powered from rechargeable batteries. Cal Tech, whose development was led by Jack Kilby at Texas Instruments in a research project to produce a portable calculator. It could add, multiply, subtract, and divide, and its output device was a paper tape.[35][36][37][38][39][40] As a result of the \"Cal-Tech\" project, Texas Instruments was granted master patents on portable calculators.[a]\nThe first commercially produced portable calculators appeared in Japan in 1970, and were soon marketed around the world. These included the Sanyo ICC-0081 \"Mini Calculator\", the Canon Pocketronic, and the Sharp QT-8B \"micro Compet\". The Canon Pocketronic was a development from the \"Cal-Tech\" project. It had no traditional display; numerical output was on thermal paper tape.\nSharp put in great efforts in size and power reduction and introduced in January 1971 the Sharp EL-8, also marketed as the Facit 1111, which was close to being a pocket calculator. It weighed 1.59 pounds (721 grams), had a vacuum fluorescent display, rechargeable NiCad batteries, and initially sold for US$395.\nHowever, integrated circuit development efforts culminated in early 1971 with the introduction of the first \"calculator on a chip\", the MK6010 by Mostek,[43] followed by Texas Instruments later in the year. Although these early hand-held calculators were very costly, these advances in electronics, together with developments in display technology (such as the vacuum fluorescent display, LED, and LCD), led within a few years to the cheap pocket calculator available to all.\nIn 1971, Pico Electronics[44] and General Instrument also introduced their first collaboration in ICs, a full single chip calculator IC for the Monroe Royal Digital III calculator. Pico was a spinout by five GI design engineers whose vision was to create single chip calculator ICs. Pico and GI went on to have significant success in the burgeoning handheld calculator market.\nThe first truly pocket-sized electronic calculator was the Busicom LE-120A \"HANDY\", which was marketed early in 1971.[45] Made in Japan, this was also the first calculator to use an LED display, the first hand-held calculator to use a single integrated circuit (then proclaimed as a \"calculator on a chip\"), the Mostek MK6010, and the first electronic calculator to run off replaceable batteries. Using four AA-size cells the LE-120A measures 4.9 by 2.8 by 0.9 inches (124 mm × 71 mm × 23 mm).\nThe first European-made pocket-sized calculator, DB 800[46][47] was made in May 1971 by Digitron in Buje, Croatia (former Yugoslavia) with four functions and an eight-digit display and special characters for a negative number and a warning that the calculation has too many digits to display.\nThe first American-made pocket-sized calculator, the Bowmar 901B (popularly termed The Bowmar Brain), measuring 5.2 by 3.0 by 1.5 inches (132 mm × 76 mm × 38 mm), came out in the autumn of 1971, with four functions and an eight-digit red LED display, for US$240, while in August 1972 the four-function Sinclair Executive became the first slimline pocket calculator measuring 5.4 by 2.2 by 0.35 inches (137.2 mm × 55.9 mm × 8.9 mm) and weighing 2.5 ounces (71 g). It retailed for around £79 (US$194 at the time). By the end of the decade, similar calculators were priced less than £5 ($6.85). Following protracted development over the course of two years including a botched partnership with Texas Instruments, Eldorado Electrodata released five pocket calculators in 1972. One called the Touch Magic was \"no bigger than a pack of cigarettes\" according to Administrative Management.[48]\nThe first Soviet Union made pocket-sized calculator, the Elektronika B3-04[49] was developed by the end of 1973 and sold at the start of 1974.\nOne of the first low-cost calculators was the Sinclair Cambridge, launched in August 1973. It retailed for £29.95 ($41.03), or £5 ($6.85) less in kit form, and later models included some scientific functions. The Sinclair calculators were successful because they were far cheaper than the competition; however, their design led to slow and less accurate computations of transcendental functions (maximum three decimal places of accuracy).[50]\nScientific pocket calculators\nMeanwhile, Hewlett-Packard (HP) had been developing a pocket calculator. Launched in early 1972, it was unlike the other basic four-function pocket calculators then available in that it was the first pocket calculator with scientific functions that could replace a slide rule. The $395 HP-35, along with nearly all later HP engineering calculators, uses reverse Polish notation (RPN), also called postfix notation. A calculation like \"8 plus 5\" is, using RPN, performed by pressing 8, Enter↑, 5, and +; instead of the algebraic infix notation: 8, +, 5, =. It had 35 buttons and was based on Mostek Mk6020 chip.\nThe first Soviet scientific pocket-sized calculator the \"B3-18\" was completed by the end of 1975.\nIn 1973, Texas Instruments (TI) introduced the SR-10, (SR signifying slide rule) an algebraic entry pocket calculator using scientific notation for $150. Shortly after the SR-11 featured an added key for entering pi (π). It was followed the next year by the SR-50 which added log and trig functions to compete with the HP-35, and in 1977 the mass-marketed TI-30 line which is still produced.\nIn 1978, a new company, Calculated Industries arose which focused on specialized markets. Their first calculator, the Loan Arranger[51] (1978) was a pocket calculator marketed to the Real Estate industry with preprogrammed functions to simplify the process of calculating payments and future values. In 1985, CI launched a calculator for the construction industry called the Construction Master[52] which came preprogrammed with common construction calculations (such as angles, stairs, roofing math, pitch, rise, run, and feet-inch fraction conversions). This would be the first in a line of construction related calculators.\n-\nThe Casio CM-602 Mini electronic calculator provided basic functions in the 1970s.\n-\nCanon Pocketronic calculator prints output using paper tape (1971).\nProgrammable pocket calculators\nThe first programmable pocket calculator was the HP-65, in 1974; it had a capacity of 100 instructions, and could store and retrieve programs with a built-in magnetic card reader. Two years later the HP-25C introduced continuous memory, i.e., programs and data were retained in CMOS memory during power-off. In 1979, HP released the first alphanumeric, programmable, expandable calculator, the HP-41C. It could be expanded with random-access memory (RAM, for memory) and read-only memory (ROM, for software) modules, and peripherals like bar code readers, microcassette and floppy disk drives, paper-roll thermal printers, and miscellaneous communication interfaces (RS-232, HP-IL, HP-IB).\nThe first Soviet pocket battery-powered programmable calculator, Elektronika B3-21, was developed by the end of 1976 and released at the start of 1977.[53] The successor of B3-21, the Elektronika B3-34 wasn't backward compatible with B3-21, even if it kept the reverse Polish notation (RPN). Thus B3-34 defined a new command set, which later was used in a series of later programmable Soviet calculators. Despite very limited abilities (98 bytes of instruction memory and about 19 stack and addressable registers), people managed to write all kinds of programs for them, including adventure games and libraries of calculus-related functions for engineers. Hundreds, perhaps thousands, of programs were written for these machines, from practical scientific and business software, which were used in real-life offices and labs, to fun games for children. The Elektronika MK-52 calculator (using the extended B3-34 command set, and featuring internal EEPROM memory for storing programs and external interface for EEPROM cards and other periphery) was used in Soviet spacecraft program (for Soyuz TM-7 flight) as a backup of the board computer.\nThis series of calculators was also noted for a large number of highly counter-intuitive mysterious undocumented features, somewhat similar to \"synthetic programming\" of the American HP-41, which were exploited by applying normal arithmetic operations to error messages, jumping to nonexistent addresses and other methods. A number of respected monthly publications, including the popular science magazine Nauka i Zhizn (Наука и жизнь, Science and Life), featured special columns, dedicated to optimization methods for calculator programmers and updates on undocumented features for hackers, which grew into a whole esoteric science with many branches, named \"yeggogology\" (\"еггогология\"). The error messages on those calculators appear as a Russian word \"YEGGOG\" (\"ЕГГОГ\") which, unsurprisingly, is translated to \"Error\".\nA similar hacker culture in the US revolved around the HP-41, which was also noted for a large number of undocumented features and was much more powerful than B3-34.\nTechnical improvements\nThrough the 1970s the hand-held electronic calculator underwent rapid development. The red LED and blue/green vacuum fluorescent displays consumed a lot of power and the calculators either had a short battery life (often measured in hours, so rechargeable nickel-cadmium batteries were common) or were large so that they could take larger, higher capacity batteries. In the early 1970s liquid-crystal displays (LCDs) were in their infancy and there was a great deal of concern that they only had a short operating lifetime. Busicom introduced the Busicom LE-120A \"HANDY\" calculator, the first pocket-sized calculator and the first with an LED display, and announced the Busicom LC with LCD. However, there were problems with this display and the calculator never went on sale. The first successful calculators with LCDs were manufactured by Rockwell International and sold from 1972 by other companies under such names as: Dataking LC-800, Harden DT/12, Ibico 086, Lloyds 40, Lloyds 100, Prismatic 500 (a.k.a. P500), Rapid Data Rapidman 1208LC. The LCDs were an early form using the Dynamic Scattering Mode DSM with the numbers appearing as bright against a dark background. To present a high-contrast display these models illuminated the LCD using a filament lamp and solid plastic light guide, which negated the low power consumption of the display. These models appear to have been sold only for a year or two.\nA more successful series of calculators using a reflective DSM-LCD was launched in 1972 by Sharp Inc with the Sharp EL-805, which was a slim pocket calculator. This, and another few similar models, used Sharp's Calculator On Substrate (COS) technology. An extension of one glass plate needed for the liquid crystal display was used as a substrate to mount the needed chips based on a new hybrid technology. The COS technology may have been too costly since it was only used in a few models before Sharp reverted to conventional circuit boards.\nIn the mid-1970s the first calculators appeared with field-effect, twisted nematic (TN) LCDs with dark numerals against a grey background, though the early ones often had a yellow filter over them to cut out damaging ultraviolet rays. The advantage of LCDs is that they are passive light modulators reflecting light, which require much less power than light-emitting displays such as LEDs or VFDs. This led the way to the first credit-card-sized calculators, such as the Casio Mini Card LC-78 of 1978, which could run for months of normal use on button cells.\nThere were also improvements to the electronics inside the calculators. All of the logic functions of a calculator had been squeezed into the first \"calculator on a chip\" integrated circuits (ICs) in 1971, but this was leading edge technology of the time and yields were low and costs were high. Many calculators continued to use two or more ICs, especially the scientific and the programmable ones, into the late 1970s.\nThe power consumption of the integrated circuits was also reduced, especially with the introduction of CMOS technology. Appearing in the Sharp \"EL-801\" in 1972, the transistors in the logic cells of CMOS ICs only used any appreciable power when they changed state. The LED and VFD displays often required added driver transistors or ICs, whereas the LCDs were more amenable to being driven directly by the calculator IC itself.\nWith this low power consumption came the possibility of using solar cells as the power source, realised around 1978 by calculators such as the Royal Solar 1, Sharp EL-8026, and Teal Photon.\n-\nThe interior of a Casio fx-20 scientific calculator from the mid-1970s, using a VFD. The processor integrated circuit (IC) is made by NEC (marked μPD978C). Discrete electronic components like capacitors and resistors and the IC are mounted on a printed circuit board (PCB). This calculator uses a battery pack as a power source.\n-\nThe processor chip (integrated circuit package) inside a 1980s Sharp pocket calculator, marked SC6762 1•H. An LCD is directly under the chip. This was a PCB-less design. No discrete components are used. The battery compartment at the top can hold two button cells.\n-\nInside a Casio scientific calculator from the mid-1990s, showing the processor chip (small square; top-middle; left), keypad contacts, right (with matching contacts on the left), the back of the LCD (top; marked 4L102E), battery compartment, and other components. The solar cell assembly is under the chip.\nMass-market phase\nAt the start of the 1970s, hand-held electronic calculators were very costly, at two or three weeks' wages, and so were a luxury item. The high price was due to their construction requiring many mechanical and electronic components which were costly to produce, and production runs that were too small to exploit economies of scale. Many firms saw that there were good profits to be made in the calculator business with the margin on such high prices. However, the cost of calculators fell as components and their production methods improved, and the effect of economies of scale was felt.\nBy 1976, the cost of the cheapest four-function pocket calculator had dropped to a few dollars, about 1/20 of the cost five years before. The results of this were that the pocket calculator was affordable, and that it was now difficult for the manufacturers to make a profit from calculators, leading to many firms dropping out of the business or closing. The firms that survived making calculators tended to be those with high outputs of higher quality calculators, or producing high-specification scientific and programmable calculators.[citation needed]\nMid-1980s to present\nThe first calculator capable of symbolic computing was the HP-28C, released in 1987. It could, for example, solve quadratic equations symbolically. The first graphing calculator was the Casio fx-7000G released in 1985.\nThe two leading manufacturers, HP and TI, released increasingly feature-laden calculators during the 1980s and 1990s. At the turn of the millennium, the line between a graphing calculator and a handheld computer was not always clear, as some very advanced calculators such as the TI-89, the Voyage 200 and HP-49G could differentiate and integrate functions, solve differential equations, run word processing and PIM software, and connect by wire or IR to other calculators/computers.\nThe HP 12c financial calculator is still produced. It was introduced in 1981 and is still being made with few changes. The HP 12c featured the reverse Polish notation mode of data entry. In 2003 several new models were released, including an improved version of the HP 12c, the \"HP 12c platinum edition\" which added more memory, more built-in functions, and the addition of the algebraic mode of data entry.\nCalculated Industries competed with the HP 12c in the mortgage and real estate markets by differentiating the key labeling; changing the \"I\", \"PV\", \"FV\" to easier labeling terms such as \"Int\", \"Term\", \"Pmt\", and not using the reverse Polish notation. However, CI's more successful calculators involved a line of construction calculators, which evolved and expanded in the 1990s to present. According to Mark Bollman,[54] a mathematics and calculator historian and associate professor of mathematics at Albion College, the \"Construction Master is the first in a long and profitable line of CI construction calculators\" which carried them through the 1980s, 1990s, and to the present.\nUse in education\nIn most countries, students use calculators for schoolwork. There was some[by whom?] initial resistance to the idea out of fear that basic or elementary arithmetic skills would suffer.[55][56] There remains disagreement about the importance of the ability to perform calculations in the head, with some curricula restricting calculator use until a certain level of proficiency has been obtained, while others concentrate more on teaching estimation methods and problem-solving. Research suggests that inadequate guidance in the use of calculating tools can restrict the kind of mathematical thinking that students engage in.[57] Others have argued[who?] that calculator use can even cause core mathematical skills to atrophy, or that such use can prevent understanding of advanced algebraic concepts.[58] In December 2011 the UK's Minister of State for Schools, Nick Gibb, voiced concern that children can become \"too dependent\" on the use of calculators.[59] As a result, the use of calculators is to be included as part of a review of the Curriculum.[59] In the United States, many math educators and boards of education have enthusiastically endorsed the National Council of Teachers of Mathematics (NCTM) standards and actively promoted the use of classroom calculators from kindergarten through high school.\nCalculators may in some circumstances be used within school and college examinations. In the United Kingdom there are limitations on the type of calculator which may be used in an examination to avoid malpractice. Some calculators which offer additional functionality have an \"exam mode\" setting which makes them compliant with examination regulations.[60]\nPersonal computers\nPersonal computers often come with a calculator utility program that emulates the appearance and functions of a calculator, using the graphical user interface to portray a calculator. Examples include the Windows Calculator, Apple's Calculator, and KDE's KCalc. Most personal data assistants (PDAs) and smartphones also have such a feature.\nCalculators compared to computers\nThe fundamental difference between a calculator and computer is that a computer can be programmed in a way that allows the program to take different branches according to intermediate results, while calculators are pre-designed with specific functions (such as addition, multiplication, and logarithms) built in. The distinction is not clear-cut: some devices classed as programmable calculators have programming functions, sometimes with support for programming languages (such as RPL or TI-BASIC).\nFor instance, instead of a hardware multiplier, a calculator might implement floating point mathematics with code in read-only memory (ROM), and compute trigonometric functions with the CORDIC algorithm because CORDIC does not require much multiplication. Bit serial logic designs are more common in calculators whereas bit parallel designs dominate general-purpose computers, because a bit serial design minimizes chip complexity, but takes many more clock cycles. This distinction blurs with high-end calculators, which use processor chips associated with computer and embedded systems design, more so the Z80, MC68000, and ARM architectures, and some custom designs specialized for the calculator market.\nSee also\n- Calculator spelling\n- Comparison of HP graphing calculators\n- Comparison of Texas Instruments graphing calculators\n- Formula calculator\n- HP calculators\n- History of computing hardware\n- Scientific calculator\n- Software calculator\n- Solar-powered calculator\n- Photomath\nNotes\n- The Japanese Patent Office granted a patent in June 1978 to Texas Instruments (TI) based on US patent 3819921, notwithstanding objections from 12 Japanese calculator manufacturers. This gave TI the right to claim royalties retroactively to the original publication of the Japanese patent application in August 1974. A TI spokesman said that it would actively seek what was due, either in cash or technology cross-licensing agreements. 19 other countries, including the United Kingdom, had already granted a similar patent to Texas Instruments.[41][42]\nReferences\n- Houston (2023).\n- Martin Hilbert; Priscila López (1 April 2011). \"The World's Technological Capacity to Store, Communicate, and Compute Information\" (PDF). Science. 332 (6025): 60–65. Bibcode:2011Sci...332...60H. doi:10.1126/science.1200970. PMID 21310967. S2CID 206531385. Archived from the original (PDF) on 2012-10-26.\n- China, Amanda Yiwu. \"Electronic Calculator | AMANDA INTL GROUP in Yiwu China\". Retrieved 2025-07-14.\n- Texas Instruments TI-30X IIB Quick Reference Guide, Page 1 - Last Answer\n- John Lewis, The Pocket Calculator Book. (London: Usborne, 1982)\n- University of Alicante. \"A Cordic-based Architecture for High Performance Decimal Calculations\" (PDF). IEEE. Archived (PDF) from the original on 2016-03-03. Retrieved 2015-08-15.\n- \"Decimal CORDIC Rotation based on Selection by Rounding: Algorithm and Architecture\" (PDF). British Computer Society. Archived (PDF) from the original on 2016-03-04. Retrieved 2015-08-14.\n- \"David S. Cochran, Algorithms and accuracy in the HP35, Hewlett Packard Journal, June 1972\" (PDF). Archived (PDF) from the original on 2013-10-04. Retrieved 2013-10-03.\n- Ifrah (2001), p. 11.\n- Jim Falk. \"Early Evolution of the Modern Calculator, Part 2. The Modern Era: 4.1 Schickard's Calculating Clock\". Things that Count. Archived from the original on 2014-04-16.\n- Chapman (1942), pp. 508, 509; \"Pascal's invention of the calculating machine. Pascal invented his machine just four hundred years ago, as a youth of nineteen. He was spurred to it by sharing the burden of arithmetical labor involved in his father's official work as supervisor of taxes at Rouen. He conceived the idea of doing the work mechanically, and developed a design appropriate for this purpose; showing herein the same combination of pure science and mechanical genius that characterized his whole life. But it was one thing to conceive and design the machine, and another to get it made and put into use. Here were needed those practical gifts that he displayed later in his inventions....\nIn a sense, Pascal's invention was premature, in that the mechanical arts in his time were not sufficiently advanced to enable his machine to be made at an economic price, with the accuracy and strength needed for reasonably long use. This difficulty was not overcome until well on into the nineteenth century, by which time also a renewed stimulus to invention was given by the need for many kinds of calculation more intricate than those considered by Pascal.\" - \"A New Calculator\". The Gentleman's magazine. Vol. 202. 1857. p. 100.\nPascal and Leibnitz, in the seventeenth century, and Diderot at a later period, endeavored to construct a machine which might serve as a substitute for human intelligence in the combination of figures.\n- Jim Falk. \"Schickard versus Pascal - an empty debate?\". Things that Count. Archived from the original on 2014-04-08.\n- Ginsburg, Jekuthiel (1933). \"Scripta Mathematica\". Science. 86 (2218). Kessinger Publishing, LLC: 149. doi:10.1126/science.86.2218.13-a. ISBN 978-0-7661-3835-3. PMID 17737911. S2CID 28216043.\nIn 1893, the German calculating machine inventor Arthur Burkhardt was asked to put Leibniz machine in operating condition if possible. His report was favorable except for the sequence in the carry.\n{{cite journal}}\n: ISBN / Date incompatibility (help) - see Mechanical calculator#Other calculating machines\n- Denis Roegel (October–December 2016). David Walden (ed.). \"Before Torchi and Schwilgué, There Was White\". IEEE Annals of the History of Computing. 38 (4): 92–93. Bibcode:2016IAHC...38d..92R. doi:10.1109/MAHC.2016.46. S2CID 28873771.\n- \"Modèles Payen\". Arithmometre.org. Archived from the original on 2013-05-21. Retrieved 2013-10-03.\n- Felt, Dorr E. (1916). Mechanical arithmetic, or The history of the counting machine. Chicago: Washington Institute. p. 4. Archived from the original on 2016-07-03.\n- Lott, Melissa C. \"The Engineer Who Foreshadowed the Smart Grid—in 1921\". Plugged In. Scientific American Blog Network. Archived from the original on 2017-08-14. Retrieved 2017-08-14.\n- \"Simple and Silent\". Office Magazine. December 1961. p. 1244.\n- \"Büromaschinen Mechaniker. November 1961. p. 207.\n- Ball, Guy; Flamm, Bruce (1996). \"The History of Pocket Electronic Calculators\". Vintage Calculators Web Museum. Archived from the original on 2014-07-03. Retrieved 2014-07-08.\n- \"Българските електронни калкулатори ЕЛКА\" [The Bulgarian ELKA electronic calculators]. The Clockwiser's Collections (in Bulgarian). 10 January 2012. Archived from the original on 2013-10-23. Retrieved 2013-10-01.\n- \"ELKA 6521 (photo)\". The Clockwiser's Collections. Archived from the original on 2013-10-23. Retrieved 2013-10-01.\n- \"ELKA 22 (photo)\". The Clockwiser's Collections. Archived from the original on 2013-10-23. Retrieved 2013-10-01.\n- \"ELKA 22, Bulgarian Calculator\". Archived from the original on 2015-05-26. Retrieved 2013-10-01.\n- \"Elka 101-135 series (photo)\". The Clockwiser's Collections. 10 January 2012. Archived from the original on 2013-10-23. Retrieved 2013-10-01.\n- \"Elka 100 series (photo)\". The Clockwiser's Collections. Archived from the original on 2013-10-23. Retrieved 2013-10-01.\n- \"ELKA 101\". Vintage Calculators Web Museum. Archived from the original on 2013-10-16. Retrieved 2013-10-01.\n- \"Olivetti Programma 101 Electronic Calculator\". The Old Calculator Web Museum.\n- \"Mathatronics Mathatron 8-48M Mod II Electronic Calculator\". The Old Calculator Web Museum.\n- \"Casio AL-1000 calculator\". Australia: Museum of Applied Arts & Sciences. Retrieved 2023-06-08.\n- Stoll, Cliff (2004). \"the Curious History of the First Pocket Calculator\". Scientific American. 290 (1): 92–99. Bibcode:2004SciAm.290a..92S. doi:10.1038/scientificamerican0104-92. ISSN 0036-8733. JSTOR 26172659. PMID 14682043.\n- Harris, Charles Overton; American Technical Society. (1944). Slide rule simplified. Chicago: American technical society.\n- \"Texas Instruments Celebrates the 35th Anniversary of Its Invention of the Calculator\". Education Technology. Texas Instruments. 15 August 2002. Archived from the original on 2008-06-27.\n- \"Electronic Calculator Invented 40 Years Ago\". All Things Considered. NPR. 30 September 2007. Archived from the original on 2008-12-05.\n- \"50 Jahre Taschenrechner – Die Erfindung, die niemand haben wollte\" [50th anniversary of calculators – the invention not wanted by anyone]. Frankfurter Allgemeine Zeitung (FAZ) (in German). 27 March 2017. Archived from the original on 2017-03-29. Retrieved 2017-03-30.\n- May, Mike (Spring 2000). \"How the Computer Got Into Your Pocket\" (PDF). American Heritage of Invention & Technology. Vol. 15, no. 4. pp. 42–54. Retrieved 2017-03-30.\n- Reid, T. R. (July 1982). \"The Texas Edison\". Texas Monthly.\n- Okon, Thomas (27 March 2017). \"The First Handheld Digital Calculator Celebrates 50 Years\". Electronic Design. Archived from the original on 2017-04-13.\n- \"New from Texas Instruments: The World's Most Powerful Pocket Calculator\". New Scientist: 455. 17 August 1978 – via Google Books.\n- \"Patent Victory\" (PDF). Practical Electronics. 14 (14): 1095. October 1978 – via World Radio History.\n- \"Single Chip Calculator Hits the Finish Line\", Electronics, February 1, 1971, p. 19.\n- James McGonigal (September 2010) [September 2006]. \"Microprocessor History – Foundations in Glenrothes, Scotland\". Spingal.plus.com. Archived from the original on 2011-07-20. Retrieved 2011-07-19.\n- \"The one-chip calculator is here, and it's only the beginning\". Electronic Design. 18 February 1971. p. 34.\n- \"The first portable calculators\". epocalc. Archived from the original on 2016-10-28. Retrieved 2016-12-30.\n- \"U Bujama je izrađen prvi europski džepni kalkulator. Te 1971. koštao je koliko i fićo\" [The first European pocket calculator was made in Buje. In 1971, it cost as much as a son] (in Croatian). 20 June 2011. Archived from the original on 2016-03-04. Retrieved 2016-12-30.\n- Bellotto, Sam Jr. (August 1972). \"Calculators: They Just Keep Multiplying\". Administrative Management. 33 (8). Geyer-McAllister Publications: 68–73 – via Internet Archive.\n- \"ELEKTRONIKA B3-04\". Коллекция советской цифровой электроники [Collection of Soviet digital electronics]. Soviet Digital Electronics Museum.\n- \"Reversing Sinclair's amazing 1974 calculator hack – half the ROM of the HP-35\". Ken Shirriff's blog.\"Google chap reverse engineers Sinclair Scientific Calculator\". The Register. Archived from the original on 2017-08-23.\n- \"The Loan Arranger II\". Mathcs.albion.edu. Archived from the original on 2011-07-19. Retrieved 2011-07-19.\n- \"Construction Master\". Mathcs.albion.edu. Archived from the original on 2011-07-19. Retrieved 2011-07-19.\n- \"Elektronika B3-21\". www.rskey.org. Archived from the original on 2015-07-03. Retrieved 2023-06-07.\n- Mark Bollman. \"Mark->'s Calculator Collection\". Mathcs.albion.edu. Archived from the original on 2011-07-19. Retrieved 2011-07-19.\n- \"From Calculators to AI: Overcoming Resistance to Technology in Academia\".\n- Banks, Sarah (16 May 2012). A Historical Analysis of Attitudes Toward the Use of Calculators in Junior High and High School Math Classrooms in the United States Since 1975 (Thesis). Cedarville University.\n- Thomas J. Bing; Edward F. Redish (7 December 2007). \"Symbolic Manipulators Affect Mathematical Mindsets\". American Journal of Physics. 76 (4): 418. arXiv:0712.1187. Bibcode:2008AmJPh..76..418B. doi:10.1119/1.2835053. S2CID 28555451.\n- \"Calculator Use in Elementary Grades\". NCTM. Archived from the original on 2015-09-05. Retrieved 2015-08-03.\n- Vasagar, Jeevan; Shepherd, Jessica (1 December 2011). \"Subtracting calculators adds to children's maths abilities, says minister\". The Guardian. London. Archived from the original on 2016-03-09. Retrieved 2011-12-07.\nThe use of calculators will be looked at as part of a national curriculum review, after the schools minister, Nick Gibb, expressed concern that children's mental and written arithmetic was suffering because of reliance on the devices. Gibb said: \"Children can become too dependent on calculators if they use them at too young an age. They shouldn't be reaching for a gadget every time they need to do a simple sum. [...]\"\n- Joint Council for Qualifications, Instructions for conducting examinations, section 10.9, September 2024, accessed on 27 December 2024\nSources\n- Chapman, S. (31 October 1942). \"Blaise Pascal (1623–1662) Tercentenary of the calculating machine\". Nature. 150 (3809). London: 508–509. Bibcode:1942Natur.150..508C. doi:10.1038/150508a0.\n- Hamrick, Kathy B. (October 1996). \"The History of the Hand-Held Electronic Calculator\". The American Mathematical Monthly. 103 (8): 633–639. doi:10.2307/2974875. JSTOR 2974875.\n- Houston, Keith (2023). Empire of the Sum: The Rise and Reign of the Pocket Calculator. Norton. ISBN 978-0-393-88214-8.\n- Ifrah, Georges (2001). The Universal History of Computing. John Wiley & Sons, Inc. ISBN 978-0-471-39671-0.\n- Marguin, Jean (1994). Histoire des instruments et machines à calculer, trois siècles de mécanique pensante 1642–1942 (in French). Hermann. ISBN 978-2-7056-6166-3.\n- Williams, Michael R. (1997). History of Computing Technology. Los Alamitos, California: IEEE Computer Society. ISBN 978-0-8186-7739-7.\nFurther reading\n- U.S. patent 2,668,661 – Complex computer – G. R. Stibitz, Bell Laboratories, 1954 (filed 1941, refiled 1944), electromechanical (relay) device that could calculate complex numbers, record, and print results.\n- U.S. patent 3,819,921 – Miniature electronic calculator – J. S. Kilby, Texas Instruments, 1974 (originally filed 1967), handheld (45 ounces (1.3 kg)) battery operated electronic device with thermal printer\n- U.S. patent 4,001,566 – Floating Point Calculator With RAM Shift Register – 1977 (originally filed GB March 1971, US July 1971), very early single chip calculator claim.\n- U.S. patent 5,623,433 – Extended Numerical Keyboard with Structured Data-Entry Capability – J. H. Redin, 1997 (originally filed 1996), Usage of Verbal Numerals as a way to enter a number.\n- European Patent Office Database – Many patents about mechanical calculators are in classifications G06C15/04, G06C15/06, G06G3/02, G06G3/04\n- Collectors Guide to Pocket Calculators. by Guy Ball and Bruce Flamm, 1997, ISBN 1-888840-14-5 – includes an extensive history of early pocket calculators and highlights over 1,500 different models from the early 1970s. Book still in print.\n- Suydam, Marilyn N. (December 1980). Calculators: A Categorized Compilation of References. Supplement 1 (PDF). Columbus, Ohio, US: Calculator Information Center, Ohio State University. ED199087. SE034434. Archived (PDF) from the original on 2021-09-19. Retrieved 2022-10-16.\nExternal links\n- 30th Anniversary of the Calculator – From Sharp's web presentation of its history; including a picture of the CS-10A desktop calculator\n- The Museum of HP calculators (Slide Rules and Mechanical Calculators section)\n- Microprocessor and single chip calculator history; foundations in Glenrothes, Scotland\n- HP-35 – A thorough analysis of the HP-35 firmware including the Cordic algorithms and the bugs in the early ROM\n- Bell Punch Company and the development of the Anita calculator – The story of the first electronic desktop calculator\n- Dentaku-Museum (in Japanese) – Shows mainly Japanese calculators but also others.",
    "chemical industry": "The chemical industry comprises the companies and other organizations that develop and produce industrial, specialty and other chemicals. Central to the modern world economy, the chemical industry converts raw materials (oil, natural gas, air, water, metals, and minerals) into commodity chemicals for industrial and consumer products. It includes industries for petrochemicals such as polymers for plastics and synthetic fibers; inorganic chemicals such as acids and alkalis; agricultural chemicals such as fertilizers, pesticides and herbicides; and other categories such as industrial gases, speciality chemicals and pharmaceuticals.\nVarious professionals are involved in the chemical industry including chemical engineers, chemists and lab technicians.\nAlthough chemicals were made and used throughout history, the birth of the heavy chemical industry (production of chemicals in large quantities for a variety of uses) coincided with the beginnings of the Industrial Revolution.\nOne of the first chemicals to be produced in large amounts through industrial processes was sulfuric acid. In 1736 pharmacist Joshua Ward developed a process for its production that involved heating sulfur with saltpeter, allowing the sulfur to oxidize and combine with water. It was the first practical production of sulphuric acid on a large scale. John Roebuck and Samuel Garbett were the first to establish a large-scale factory in Prestonpans, Scotland, in 1749, which used leaden condensing chambers for the manufacture of sulfuric acid.[1][2]\nIn the early 18th century, cloth was bleached by treating it with stale urine or sour milk and exposing it to sunlight for long periods of time, which created a severe bottleneck in production. Sulfuric acid began to be used as a more efficient agent as well as lime by the middle of the century, but it was the discovery of bleaching powder by Charles Tennant that spurred the creation of the first great chemical industrial enterprise. His powder was made by reacting chlorine with dry slaked lime and proved to be a cheap and successful product. He opened the St Rollox Chemical Works, north of Glasgow, and production went from just 52 tons in 1799 to almost 10,000 tons just five years later.[3]\nSoda ash was used since ancient times in the production of glass, textile, soap, and paper, and the source of the potash had traditionally been wood ashes in Western Europe. By the 18th century, this source was becoming uneconomical due to deforestation, and the French Academy of Sciences offered a prize of 2400 livres for a method to produce alkali from sea salt (sodium chloride). The Leblanc process was patented in 1791 by Nicolas Leblanc who then built a Leblanc plant at Saint-Denis.[4] He was denied his prize money because of the French Revolution.[5]\nIn Britain, the Leblanc process became popular.[5] William Losh built the first soda works in Britain at the Losh, Wilson and Bell works on the River Tyne in 1816, but it remained on a small scale due to large tariffs on salt production until 1824. When these tariffs were repealed, the British soda industry was able to rapidly expand. James Muspratt's chemical works in Liverpool and Charles Tennant's complex near Glasgow became the largest chemical production centres anywhere. By the 1870s, the British soda output of 200,000 tons annually exceeded that of all other nations in the world combined.\nThese huge factories began to produce a greater diversity of chemicals as the Industrial Revolution matured. Originally, large quantities of alkaline waste were vented into the environment from the production of soda, provoking one of the first pieces of environmental legislation to be passed in 1863. This provided for close inspection of the factories and imposed heavy fines on those exceeding the limits on pollution. Methods were devised to make useful byproducts from the alkali.\nThe Solvay process was developed by the Belgian industrial chemist Ernest Solvay in 1861. In 1864, Solvay and his brother Alfred constructed a plant in Charleroi Belgium. In 1874, they expanded into a larger plant in Nancy, France. The new process proved more economical and less polluting than the Leblanc method, and its use spread. In the same year, Ludwig Mond visited Solvay to acquire the rights to use his process, and he and John Brunner formed Brunner, Mond & Co., and built a Solvay plant at Winnington, England. Mond was instrumental in making the Solvay process a commercial success. He made several refinements between 1873 and 1880 that removed byproducts that could inhibit the production of sodium carbonate in the process.\nThe manufacture of chemical products from fossil fuels began at scale in the early 19th century. The coal tar and ammoniacal liquor residues of coal gas manufacture for gas lighting began to be processed in 1822 at the Bonnington Chemical Works in Edinburgh to make naphtha, pitch oil (later called creosote), pitch, lampblack (carbon black) and sal ammoniac (ammonium chloride).[6] Ammonium sulphate fertiliser, asphalt road surfacing, coke oil and coke were later added to the product line.\nThe late 19th century saw an explosion in both the quantity of production and the variety of chemicals that were manufactured. Large chemical industries arose in Germany and later in the United States.\nProduction of artificial manufactured fertilizer for agriculture was pioneered by Sir John Lawes at his purpose-built Rothamsted Research facility. In the 1840s he established large works near London for the manufacture of superphosphate of lime. Processes for the vulcanization of rubber were patented by Charles Goodyear in the United States and Thomas Hancock in England in the 1840s. The first synthetic dye was discovered by William Henry Perkin in London. He partly transformed aniline into a crude mixture which, when extracted with alcohol, produced a substance with an intense purple colour. He also developed the first synthetic perfumes. German industry quickly began to dominate the field of synthetic dyes. The three major firms BASF, Bayer, and Hoechst produced several hundred different dyes. By 1913, German industries produced almost 90% of the world's supply of dyestuffs and sold approximately 80% of their production abroad.[7] In the United States, Herbert Henry Dow's use of electrochemistry to produce chemicals from brine was a commercial success that helped to promote the country's chemical industry.[8]\nThe petrochemical industry can be traced back to the oil works of Scottish chemist James Young, and Canadian Abraham Pineo Gesner. The first plastic was invented by Alexander Parkes, an English metallurgist. In 1856, he patented Parkesine, a celluloid based on nitrocellulose treated with a variety of solvents.[9] This material, exhibited at the 1862 London International Exhibition, anticipated many of the modern aesthetic and utility uses of plastics. The industrial production of soap from vegetable oils was started by William Lever and his brother James in 1885 in Lancashire based on a modern chemical process invented by William Hough Watson that used glycerin and vegetable oils.[10]\nBy the 1920s, chemical firms consolidated into large conglomerates; IG Farben in Germany, Rhône-Poulenc in France and Imperial Chemical Industries in Britain. Dupont became a major chemicals firm in the early 20th century in America.\nPolymers and plastics such as polyethylene, polypropylene, polyvinyl chloride, polyethylene terephthalate, polystyrene and polycarbonate comprise about 80% of the industry's output worldwide.[11] Chemicals are used in many different consumer goods, and are also used in many different sectors. This includes agriculture manufacturing, construction, and service industries.[11] Major industrial customers include rubber and plastic products, textiles, apparel, petroleum refining, pulp and paper, and primary metals. Chemicals are nearly a $5 trillion global enterprise, and the EU and U.S. chemical companies are the world's largest producers.[12]\nSales of the chemical business can be divided into a few broad categories, including basic chemicals (about 35% – 37% of dollar output), life sciences (30%), specialty chemicals (20% – 25%) and consumer products (about 10%).[13]\nBasic chemicals, or \"commodity chemicals\" are a broad chemical category including polymers, bulk petrochemicals and intermediates, other derivatives and basic industrials, inorganic chemicals, and fertilizers.\nPolymers are the largest revenue segment and includes all categories of plastics and human-made fibers. The major markets for plastics are packaging, followed by home construction, containers, appliances, pipe, transportation, toys, and games.\n- The largest-volume polymer product, polyethylene (PE), is used mainly in packaging films and other markets such as milk bottles, containers, and pipe.\n- Polyvinyl chloride (PVC), another large-volume product, is principally used to make piping for construction markets as well as siding and, to a much smaller extent, transportation and packaging materials.\n- Polypropylene (PP), similar in volume to PVC, is used in markets ranging from packaging, appliances, and containers to clothing and carpeting.\n- Polystyrene (PS), another large-volume plastic, is used principally for appliances and packaging as well as toys and recreation.\n- The leading human-made fibers include polyester, nylon, polypropylene, and acrylics, with applications including apparel, home furnishings, and other industrial and consumer use.\nPrincipal raw materials for polymers are bulk petrochemicals like ethylene, propylene and benzene.\nPetrochemicals and intermediate chemicals are primarily made from liquefied petroleum gas (LPG), natural gas and crude oil fractions. Large volume products include ethylene, propylene, benzene, toluene, xylenes, methanol, vinyl chloride monomer (VCM), styrene, butadiene, and ethylene oxide. These basic or commodity chemicals are the starting materials used to manufacture many polymers and other more complex organic chemicals particularly those that are made for use in the specialty chemicals category.\nOther derivatives and basic industrials include synthetic rubber, surfactants, dyes and pigments, turpentine, resins, carbon black, explosives, and rubber products and contribute about 20 percent of the basic chemicals' external sales.\nInorganic chemicals (about 12% of the revenue output) make up the oldest of the chemical categories. Products include salt, chlorine, caustic soda, soda ash, acids (such as nitric acid, phosphoric acid, and sulfuric acid), titanium dioxide, and hydrogen peroxide.\nFertilizers are the smallest category (about 6 percent) and include phosphates, ammonia, and potash chemicals.\nLife sciences (about 30% of the dollar output of the chemistry business) include differentiated chemical and biological substances, pharmaceuticals, diagnostics, animal health products, vitamins, and pesticides. While much smaller in volume than other chemical sectors, their products tend to have high prices – over ten dollars per pound – growth rates of 1.5 to 6 times GDP, and research and development spending at 15 to 25% of sales. Life science products are usually produced with high specifications and are closely scrutinized by government agencies such as the Food and Drug Administration. Pesticides, also called \"crop protection chemicals\", are about 10% of this category and include herbicides, insecticides, and fungicides.[13]\nSpecialty chemicals are a category of relatively high-valued, rapidly growing chemicals with diverse end product markets. Typical growth rates are one to three times GDP with prices over a dollar per pound. They are generally characterized by their innovative aspects. Products are sold for what they can do rather than for what chemicals they contain. Products include electronic chemicals, industrial gases, adhesives and sealants as well as coatings, industrial and institutional cleaning chemicals, and catalysts. In 2012, excluding fine chemicals, the $546 billion global specialty chemical market was 33% Paints, Coating and Surface Treatments, 27% Advanced Polymer, 14% Adhesives and Sealants, 13% additives, and 13% pigments and inks.[14]\nSpeciality chemicals are sold as effect or performance chemicals. Sometimes they are mixtures of formulations, unlike \"fine chemicals\", which are almost always single-molecule products.\nConsumer products include direct product sales of chemicals such as soaps, detergents, and cosmetics. Typical growth rates are 0.8 to 1.0 times GDP.[citation needed]\nConsumers rarely come into contact with basic chemicals. Polymers and specialty chemicals are materials that they encounter everywhere daily. Examples are plastics, cleaning materials, cosmetics, paints and coatings, electronics, automobiles and the materials used in home construction.[14] These specialty products are marketed by chemical companies to the downstream manufacturing industries as pesticides, specialty polymers, electronic chemicals, surfactants, construction chemicals, industrial cleaners, flavours and fragrances, specialty coatings, printing inks, water-soluble polymers, food additives, paper chemicals, oil field chemicals, plastic adhesives, adhesives and sealants, cosmetic chemicals, water management chemicals, catalysts, and textile chemicals. Chemical companies rarely supply these products directly to the consumer.\nAnnually the American Chemistry Council tabulates the US production volume of the top 100 chemicals. In 2000, the aggregate production volume of the top 100 chemicals totaled 502 million tons, up from 397 million tons in 1990. Inorganic chemicals tend to be the largest volume but much smaller in dollar revenue due to their low prices. The top 11 of the 100 chemicals in 2000 were sulfuric acid (44 million tons), nitrogen (34), ethylene (28), oxygen (27), lime (22), ammonia (17), propylene (16), polyethylene (15), chlorine (13), phosphoric acid (13) and diammonium phosphates (12).[citation needed]\nThe largest chemical producers today are global companies with international operations and plants in numerous countries. Below is a list of the top 25 chemical companies by chemical sales in 2015. (Note: Chemical sales represent only a portion of total sales for some companies.)\nTop chemical companies by chemical sales in 2015.[15]\n| Rank | Company | 2015 Chemical Sales (USD in billions) | Headquarters |\n|---|---|---|---|\n| 1 | BASF | $63.7 | Ludwigshafen, Germany |\n| 2 | Dow Chemical Company | $48.8 | Midland, Michigan, United States |\n| 3 | China Petrochemical Corporation | $43.8 | Beijing, China |\n| 4 | SABIC | $34.3 | Riyadh, Saudi Arabia |\n| 5 | Formosa Plastics | $29.2 | Kaohsiung City, Taiwan |\n| 6 | Ineos | $28.5 | London, United Kingdom |\n| 7 | ExxonMobil | $28.1 | Irving, Texas, United States |\n| 8 | LyondellBasell | $26.7 | Houston, Texas, United States, and\nLondon, United Kingdom |\n| 9 | Mitsubishi Chemical | $24.3 | Tokyo, Japan |\n| 10 | DuPont | $20.7 | Wilmington, Delaware, United States |\n| 11 | LG Chem | $18.2 | Seoul, South Korea |\n| 12 | Air Liquide | $17.3 | Paris, France |\n| 13 | Linde Group | $16.8 | Munich, Germany and New Jersey, United States |\n| 14 | AkzoNobel | $16.5 | Amsterdam, Netherlands |\n| 15 | PTT Global Chemical | $16.2 | Bangkok, Thailand |\n| 16 | Toray Industries | $15.5 | Tokyo, Japan |\n| 17 | Evonik Industries | $15.0 | Essen, Germany |\n| 18 | PPG Industries | $14.2 | Pittsburgh, Pennsylvania, United States |\n| 19 | Braskem | $14.2 | São Paulo, Brazil |\n| 20 | Yara International | $13.9 | Oslo, Norway |\n| 21 | Covestro | $13.4 | Leverkusen, Germany |\n| 22 | Sumitomo Chemical | $13.3 | Tokyo, Japan |\n| 23 | Reliance Industries | $12.9 | Mumbai, India |\n| 24 | Solvay | $12.3 | Brussels, Belgium |\n| 25 | Bayer | $11.5 | Leverkusen, Germany |\nFrom the perspective of chemical engineers, the chemical industry involves the use of chemical processes such as chemical reactions and refining methods to produce a wide variety of solid, liquid, and gaseous materials. Most of these products serve to manufacture other items, although a smaller number go directly to consumers. Solvents, pesticides, lye, washing soda, and portland cement provide a few examples of products used by consumers.\nThe industry includes manufacturers of inorganic- and organic-industrial chemicals, ceramic products, petrochemicals, agrochemicals, polymers and rubber (elastomers), oleochemicals (oils, fats, and waxes), explosives, fragrances and flavors. Examples of these products are shown in the Table below.\n| Product Type | Examples |\n|---|---|\n| inorganic industrial | ammonia, chlorine, sodium hydroxide, sulfuric acid, nitric acid |\n| organic industrial | acrylonitrile, phenol, ethylene oxide, urea |\n| ceramic products | silica brick, frit |\n| petrochemicals | ethylene, propylene, benzene, styrene |\n| agrochemicals | fertilizers, insecticides, herbicides |\n| polymers | polyethylene, Bakelite, polyester |\n| elastomers | polyisoprene, neoprene, polyurethane |\n| oleochemicals | lard, soybean oil, stearic acid |\n| explosives | nitroglycerin, ammonium nitrate, nitrocellulose |\n| fragrances and flavors | benzyl benzoate, coumarin, vanillin |\n| industrial gases | nitrogen, oxygen, acetylene, nitrous oxide |\nRelated industries include petroleum, glass, paint, ink, sealant, adhesive, pharmaceuticals and food processing.\nChemical processes such as chemical reactions operate in chemical plants to form new substances in various types of reaction vessels. In many cases, the reactions take place in special corrosion-resistant equipment at elevated temperatures and pressures with the use of catalysts. The products of these reactions are separated using a variety of techniques including distillation especially fractional distillation, precipitation, crystallization, adsorption, filtration, sublimation, and drying.\nThe processes and products or products are usually tested during and after manufacture by dedicated instruments and on-site quality control laboratories to ensure safe operation and to assure that the product will meet required specifications. More organizations within the industry are implementing chemical compliance software to maintain quality products and manufacturing standards.[16] The products are packaged and delivered by many methods, including pipelines, tank-cars, and tank-trucks (for both solids and liquids), cylinders, drums, bottles, and boxes. Chemical companies often have a research-and-development laboratory for developing and testing products and processes. These facilities may include pilot plants and such research facilities may be located at a site separate from the production plant(s).\nThe scale of chemical manufacturing tends to be organized from largest in volume (petrochemicals and commodity chemicals), to specialty chemicals, and the smallest, fine chemicals.\nThe petrochemical and commodity chemical manufacturing units are on the whole single product continuous processing plants. Not all petrochemical or commodity chemical materials are made in one single location, but groups of related materials often are to induce industrial symbiosis as well as material, energy and utility efficiency and other economies of scale.\nThose chemicals made on the largest of scales are made in a few manufacturing locations around the world, for example in Texas and Louisiana along the Gulf Coast of the United States, on Teesside (United Kingdom), and in Rotterdam in the Netherlands. The large-scale manufacturing locations often have clusters of manufacturing units that share utilities and large-scale infrastructure such as power stations, port facilities, and road and rail terminals. To demonstrate the clustering and integration mentioned above, some 50% of the United Kingdom's petrochemical and commodity chemicals are produced by the Northeast of England Process Industry Cluster on Teesside.\nSpecialty chemical and fine chemical manufacturing are mostly made in discrete batch processes. These manufacturers are often found in similar locations but in many cases, they are to be found in multi-sector business parks.\nIn the U.S. there are 170 major chemical companies.[17] They operate internationally with more than 2,800 facilities outside the U.S. and 1,700 foreign subsidiaries or affiliates operating. The U.S. chemical output is $750 billion a year. The U.S. industry records large trade surpluses and employs more than a million people in the United States alone. The chemical industry is also the second largest consumer of energy in manufacturing and spends over $5 billion annually on pollution abatement.\nIn Europe, the chemical, plastics, and rubber sectors are among the largest industrial sectors.[18] Together they generate about 3.2 million jobs in more than 60,000 companies. Since 2000 the chemical sector alone has represented 2/3 of the entire manufacturing trade surplus of the EU.\nIn 2012, the chemical sector accounted for 12% of the EU manufacturing industry's added value. Europe remains the world's biggest chemical trading region with 43% of the world's exports and 37% of the world's imports, although the latest data shows that Asia is catching up with 34% of the exports and 37% of imports.[19] Even so, Europe still has a trading surplus with all regions of the world except Japan and China where in 2011 there was a chemical trade balance. Europe's trade surplus with the rest of the world today amounts to 41.7 billion Euros.[20]\nOver the 20 years between 1991 and 2011, the European Chemical industry saw its sales increase from 295 billion Euros to 539 billion Euros, a picture of constant growth. Despite this, the European industry's share of the world chemical market has fallen from 36% to 20%. This has resulted from the huge increase in production and sales in emerging markets like India and China.[21] The data suggest that 95% of this impact is from China alone. In 2012 the data from the European Chemical Industry Council shows that five European countries account for 71% of the EU's chemicals sales. These are Germany, France, the United Kingdom, Italy and the Netherlands.[22]\nThe chemical industry has seen growth in China, India, Korea, the Middle East, South East Asia, Nigeria and Brazil. The growth is driven by changes in feedstock availability and price, labor and energy costs, differential rates of economic growth and environmental pressures.\nJust as companies emerge as the main producers of the chemical industry, we can also look on a more global scale at how industrialized countries rank, with regard to the billions of dollars' worth of production a country or region could export. Though the business of chemistry is worldwide in scope, the bulk of the world's $3.7 trillion chemical output is accounted for by only a handful of industrialized nations. The United States alone produced $689 billion, 18.6 percent of the total world chemical output in 2008.[23]\n| Global Chemical Shipments by Country/Region (billions of dollars)[23] | 1998 | 1999 | 2000 | 2001 | 2002 | 2003 | 2004 | 2005 | 2006 | 2008 | 2009 |\n|---|---|---|---|---|---|---|---|---|---|---|---|\n| United States of America | 416.7 | 420.3 | 449.2 | 438.4 | 462.5 | 487.7 | 540.9 | 610.9 | 657.7 | 664.1 | 689.3 |\n| Canada | 21.1 | 21.8 | 25.0 | 24.8 | 25.8 | 30.5 | 36.2 | 40.2 | 43.7 | 45.4 | 47.4 |\n| Mexico | 19.1 | 21.0 | 23.8 | 24.4 | 24.3 | 23.5 | 25.6 | 29.2 | 32.0 | 33.4 | 37.8 |\n| North America | 456.9 | 463.1 | 498.0 | 487.6 | 512.6 | 541.7 | 602.7 | 680.3 | 733.4 | 742.8 | 774.6 |\n| Brazil | 46.5 | 40.0 | 45.7 | 41.5 | 39.6 | 47.4 | 60.2 | 71.1 | 82.8 | 96.4 | 126.7 |\n| Other | 59.2 | 58.1 | 60.8 | 63.4 | 58.6 | 62.9 | 69.9 | 77.2 | 84.6 | 89.5 | 102.1 |\n| Latin America | 105.7 | 98.1 | 106.5 | 104.9 | 98.2 | 110.3 | 130.0 | 148.3 | 167.4 | 185.9 | 228.8 |\n| Germany | 124.9 | 123.2 | 118.9 | 116.1 | 120.1 | 148.1 | 168.6 | 178.6 | 192.5 | 229.5 | 263.2 |\n| France | 79.1 | 78.5 | 76.5 | 76.8 | 80.5 | 99.6 | 111.1 | 117.5 | 121.3 | 138.4 | 158.9 |\n| United Kingdom | 70.3 | 70.1 | 66.8 | 66.4 | 69.9 | 77.3 | 91.3 | 95.2 | 107.8 | 118.2 | 123.4 |\n| Italy | 63.9 | 64.6 | 59.5 | 58.6 | 64.5 | 75.8 | 86.6 | 89.8 | 95.3 | 105.9 | 122.9 |\n| Spain | 31.0 | 30.8 | 30.8 | 31.9 | 33.4 | 42.0 | 48.9 | 52.7 | 56.7 | 63.7 | 74.8 |\n| Netherlands | 29.7 | 29.4 | 31.3 | 30.6 | 32.2 | 40.1 | 49.0 | 52.7 | 59.2 | 67.9 | 81.7 |\n| Belgium | 27.1 | 27.0 | 27.5 | 27.1 | 28.7 | 36.1 | 41.8 | 43.5 | 46.9 | 51.6 | 62.6 |\n| Switzerland | 22.1 | 22.2 | 19.4 | 21.1 | 25.5 | 30.3 | 33.8 | 35.4 | 37.8 | 42.7 | 53.1 |\n| Ireland | 16.9 | 20.1 | 22.6 | 22.9 | 29.1 | 32.3 | 33.9 | 34.9 | 37.5 | 46.0 | 54.8 |\n| Sweden | 11.1 | 11.4 | 11.2 | 11.0 | 12.5 | 15.9 | 18.2 | 19.3 | 21.2 | 21.2 | 22.6 |\n| Other | 27.1 | 26.8 | 25.9 | 26.4 | 27.9 | 33.5 | 38.6 | 42.9 | 46.2 | 50.3 | 58.9 |\n| Western Europe | 503.1 | 504.0 | 490.4 | 488.8 | 524.4 | 630.9 | 721.9 | 762.7 | 822.4 | 935.4 | 1,076.8 |\n| Russia | 23.8 | 24.6 | 27.4 | 29.1 | 30.3 | 33.4 | 37.5 | 40.9 | 53.1 | 63.0 | 77.6 |\n| Other | 22.3 | 20.3 | 21.9 | 23.4 | 25.3 | 31.4 | 39.6 | 46.2 | 55.0 | 68.4 | 87.5 |\n| Central/Eastern Europe | 46.1 | 44.9 | 49.3 | 52.5 | 55.6 | 64.8 | 77.1 | 87.1 | 108.0 | 131.3 | 165.1 |\n| Africa and Middle East | 52.7 | 53.2 | 59.2 | 57.4 | 60.4 | 73.0 | 86.4 | 99.3 | 109.6 | 124.2 | 160.4 |\n| Japan | 193.8 | 220.4 | 239.7 | 208.3 | 197.2 | 218.8 | 243.6 | 251.3 | 248.5 | 245.4 | 298.0 |\n| Asia-Pacific excluding Japan | 215.2 | 241.9 | 276.1 | 271.5 | 300.5 | 369.1 | 463.9 | 567.5 | 668.8 | 795.5 | 993.2 |\n| China | 80.9 | 87.8 | 103.6 | 111.0 | 126.5 | 159.9 | 205.0 | 269.0 | 331.4 | 406.4 | 549.4 |\n| India | 30.7 | 35.3 | 35.3 | 32.5 | 33.5 | 40.8 | 53.3 | 63.6 | 72.5 | 91.1 | 98.2 |\n| Australia | 11.3 | 12.1 | 11.2 | 10.8 | 11.3 | 14.9 | 17.0 | 18.7 | 19.1 | 22.8 | 27.1 |\n| Korea | 39.3 | 45.5 | 56.3 | 50.4 | 54.9 | 64.4 | 78.7 | 91.9 | 103.4 | 116.7 | 133.2 |\n| Singapore | 6.3 | 8.5 | 9.5 | 9.4 | 12.5 | 16.1 | 20.0 | 22.0 | 25.8 | 28.9 | 31.6 |\n| Taiwan | 21.9 | 23.7 | 29.2 | 26.8 | 28.4 | 34.3 | 44.5 | 49.5 | 53.8 | 57.4 | 62.9 |\n| Other Asia/Pacific | 24.8 | 29.1 | 30.9 | 30.8 | 33.3 | 38.8 | 45.5 | 52.9 | 62.9 | 72.2 | 90.8 |\n| Asia/Pacific | 409.0 | 462.3 | 515.7 | 479.7 | 497.7 | 587.8 | 707.5 | 818.8 | 917.3 | 1041.0 | 1291.2 |\n| Total world shipments | 1573.5 | 1625.5 | 1719.0 | 1670.9 | 1748.8 | 2008.5 | 2325.6 | 2596.4 | 2858.1 | 3160.7 | 3696.8 |\n- Chemical engineering\n- Chemical leasing\n- Pharmaceutical industry\n- Industrial gas\n- Prices of chemical elements\n- Responsible Care\n- Northeast of England Process Industry Cluster (NEPIC)\n- Derry, Thomas Kingston; Williams, Trevor I. (1993). A Short History of Technology: From the Earliest Times to A.D. 1900. New York: Dover.\n- Kiefer, David M. (2001). \"Sulfuric Acid: Pumping Up the Volume\". American Chemical Society. Retrieved 2008-04-21.\n- \"The Chemical Industries In The UK\". American Chemical Society. Retrieved 2013-04-21.\n- Aftalion 1991, pp. 11–13\n- Aftalion 1991, pp. 14–16\n- Ronalds, B.F. (2019). \"Bonnington Chemical Works (1822–1878): Pioneer Coal Tar Company\". International Journal for the History of Engineering & Technology. 89 (1–2): 73–91. doi:10.1080/17581206.2020.1787807. S2CID 221115202.\n- Aftalion 1991, p. 104, Chandler 2005, p. 475\n- \"Electrolytic Production of Bromine – National Historic Chemical Landmark – American Chemical Society\". American Chemical Society. Retrieved 2016-10-10.\n- Patents for inventions. UK Patent office. 1857. p. 255.\n- Jeannifer Filly Sumayku (22 March 2010). \"Unilever: Providing Enjoyable and Meaningful Life to Customers\". The President Post. Archived from the original on 2013-12-15.\n- Singh, Kirpal (July 2012). \"17.2\". Chemistry in Daily Life. PHI Learning Private Limited. p. 132. ISBN 978-81-203-4617-8.\n- \"Chemicals Market Size, Trends and Global Forecast To 2032\". www.thebusinessresearchcompany.com. Retrieved 2023-08-04.\n- \"Sectors of Chemical Industry\". Technofunc. Retrieved 16 September 2013.\n- \"Global Specialty Chemicals\" (PDF) (Report). Marketline. May 2012. Archived from the original (PDF) on 15 November 2012. Retrieved 16 September 2012 – via 2012e.igem.org.\n- Tullo, Alexander H. (July 25, 2016). \"C&EN's Global Top 50 chemical companies of 2015\". Chemical & Engineering News. Vol. 94, no. 30. Retrieved 2016-10-10.\n- \"Chemical and Agrochemical Enterprise Quality Management Software\". Sparta Systems, Inc. Archived from the original on 7 October 2015. Retrieved 20 March 2015.\n- SINGH, KIRPAL (2012-07-07). CHEMISTRY IN DAILY LIFE. PHI Learning Pvt. Ltd. ISBN 978-81-203-4617-8.\n- \"Our contribution to EU27 industry\". cefic.org. Retrieved 28 October 2022.\n- \"Facts and Figures 2012:The European chemicals industry in a worldwide perspective\" (PDF). CEFIC. Archived from the original (PDF) on 4 March 2016. Retrieved 5 August 2013.\n- Higgins, Stan (April 2013). \"European Chemicals Industry: A review\" (PDF). Chemical News. pp. 18–20. Archived from the original (PDF) on 2015-07-23. Retrieved 2013-08-05.\n- \"Facts and Figures 2012:The European chemicals industry in a worldwide perspective\" (PDF). CEFIC. p. 6. Archived from the original (PDF) on 4 March 2016. Retrieved 5 August 2013.\n- \"Facts and Figures 2012:The European chemicals industry in a worldwide perspective\" (PDF). CEFIC. p. 7. Archived from the original (PDF) on 4 March 2016. Retrieved 5 August 2013.\n- \"Global Business of Chemistry\". Archived from the original on 2010-10-19. Retrieved 26 February 2016.\n- Aftalion, Fred (1991). A History of the International Chemical Industry. University of Pennsylvania Press. ISBN 978-0-8122-1297-6.online version Archived 2011-06-04 at the Wayback Machine\n- Brandt, E. N. (1997). Growth Company: Dow Chemical's First Century. Michigan State University Press. ISBN 0-87013-426-4.online review\n- Chandler, Alfred D. (2005). Shaping the Industrial Century: The Remarkable Story of the Evolution of the Modern Chemical and Pharmaceutical Industries. Harvard University Press. ISBN 0-674-01720-X.\n- McCoy, Micheal; et al. (July 10, 2006). \"Facts & Figures of the Chemical Industry\". Chemical & Engineering News. 84 (28): 35–72.\n- Shreve, R. Norris; Brink, Joseph A. Jr. (1977). The Chemical Process Industries (4th ed.). New York: McGraw Hill.\n- Woytinsky, W. S.; Woytinsky, E. S. (1953). World Population and Production Trends and Outlooks. pp. 1176–1205.\n- Chemical refinery resources: ccc-group.com",
    "commercial property": "Commercial property, also called commercial real estate, investment property or income property, is real estate (buildings or land) intended to generate a profit, either from capital gains or rental income.[1] Commercial property includes office buildings, medical centers, hotels, malls, retail stores, multifamily housing buildings, farm land, warehouses, and garages. In many U.S. states, residential property containing more than a certain number of units qualifies as commercial property for borrowing and tax purposes.\nCommercial buildings are buildings that are used for commercial purposes, and include office buildings, warehouses, and retail buildings (e.g. convenience stores, 'big box' stores, and shopping malls). In urban locations, a commercial building may combine functions, such as offices on levels 2–10, with retail on floor 1. When space allocated to multiple functions is significant, these buildings can be called multi-use. Local authorities commonly maintain strict regulations on commercial zoning, and have the authority to designate any zoned area as such; a business must be located in a commercial area or area zoned at least partially for commerce.\nCommercial real estate is commonly divided into six categories:\n- Office buildings – This category includes single-tenant properties, small professional office buildings, downtown skyscrapers, and everything in between.\n- Retail Shops/Restaurants – This category includes pad sites on highway frontages, single tenant retail buildings, inline multi-tenant retail, small neighborhood shopping centers, larger community centers with grocery store anchor tenants, lifestyle centers that blend both indoor and outdoor shopping, \"power centers\" with large anchor stores such as Best Buy, PetSmart, OfficeMax, and Shopping Malls that usually house many indoor stores.[2]\n- Multifamily residential – This category includes apartment complexes or high-rise apartment buildings. Generally, anything larger than a fourplex is considered commercial real estate.[3]\n- Land – This category includes investment properties on undeveloped, raw, rural land in the path of future development. Or, infill land with an urban area, pad sites, and more.\n- Industrial - This category includes warehouses, large R&D facilities, cold storage or cold chain properties, and distribution centers.\n- Miscellaneous – This catch all category would include any other nonresidential properties such as hotel, hospitality, medical, and self-storage developments, as well as many more.\n| Category | Examples |\n|---|---|\n| Hospitality | hotels, motels, public houses, bars, restaurants, cafes, diners, stadiums, sports venues, truck stops, nightclubs, amusement parks, movie studios, movie theaters |\n| Retail | retail stores, convenience stores, big-box stores, grocery stores, supermarkets, shopping malls, shops, showrooms |\n| Office | office buildings, serviced offices |\n| Healthcare | medical centers, hospitals, nursing homes, clinics, dispensaries |\n| Multifamily (apartments) | multifamily residential housing buildings, student housing or dormitory |\n| Educational | cram schools, schools, colleges, universities |\n| Industrial | factories, machine shops, warehouses, workshops, automobile repair shops |\n| Agricultural | farms, fields, orchards, ranches, barns, stables, dairy farms, pig farms, poultry farms, fish farms |\nOf these, only the first five are classified as being commercial buildings. Residential income property may also signify multifamily apartments.\nThe basic elements of an investment are cash inflows, outflows, timing of cash flows, and risk. The ability to analyze these elements is key in providing services to investors in commercial real estate.\nCash inflows and outflows are the money that is put into, or received from, the property including the original purchase cost and sale revenue over the entire life of the investment. An example of this sort of investment is a real estate fund.\nCash inflows include the following:\n- Rent\n- Operating expense recoveries\n- Fees: Parking, vending, services, etc.\n- Proceeds from sale\n- Tax Benefits\n- Depreciation\n- Tax credits (e.g., historical)\nCash outflows include:\n- Initial investment (down payment)\n- All operating expenses and taxes\n- Debt service (mortgage payment)\n- Capital expenses and tenant leasing costs Costs upon sale\nThe timing of cash inflows and outflows is important to know in order to project periods of positive and negative cash flows. Risk is dependent on market conditions, current tenants, and the likelihood that they will renew their leases year-over-year. It is important to be able to predict the probability that the cash inflows and outflows will be in the amounts predicted, what is the probability that the timing of them will be as predicted, and what the probability is that there may be unexpected cash flows, and in what amounts they might occur.\nThe total value of commercial property in the United States was approximately $6 trillion in 2018.[4] The relative strength of the market is measured by the US Commercial Real Estate Index which is composed of eight economic drivers and is calculated weekly.\nAccording to Real Capital Analytics, a New York real estate research firm and subsidiary of MSCI, more than $160 billion of commercial properties in the United States are now in default, foreclosure, or bankruptcy. In 2024, office leasing volume rose to its highest level since 2020, but roughly 60% of active office leases went into effect prior to the pandemic.[5] In Europe, approximately half of the €960 billion of debt backed by European commercial real estate is expected to require refinancing in the next three years, according to PropertyMall, a UK‑based commercial property news provider. Additionally, the economic conditions surrounding future interest rate hikes; which could put renewed pressure on valuations, complicate loan refinancing, and impede debt servicing could cause major dislocation in commercial real estate markets.\nHowever, the contribution to Europe's economy in 2012 can be estimated at €285 billion according to EPRA and INREV, not to mention social benefits of an efficient real estate sector.[6] It is estimated that commercial property is responsible for securing around 4 million jobs across Europe.\nAs of April 2025, commercial real estate confidence experienced its sharpest drop since the COVID-19 pandemic amid the Trump Administration's latest tariff policies, with positive sentiment falling from 126.5% in the latter half of 2024 to 87.9%, according to the 1Q 2025 Board of Governors Sentiment Index.[7]\nTypically, a broker will market a property on behalf of the seller. Brokers representing buyers or buyers' representatives identify property meeting a set of criteria set out by the buyer. Types of buyers may include an owner-user, private investor, acquisitions, capital investment, or private equity firms. The buyer or its agents will perform an initial assessment of the physical property, location and potential profitability (if for investment) or adequacy of property for its intended use (if for owner-user).\nIf it is determined the prospective investment meets the buyer's criteria, they may signal their intent to move forward with a letter of intent (LOI). Letters of Intent are used to outline the major terms of an offer in order to avoid unnecessary costs of drafting legal documents in the event the parties do not agree to the terms as drafted. Once a Letter of Intent is signed by both parties, a purchase and sale agreement (PSA) is drafted. Not all commercial property transactions utilize a Letter of Intent although it is common. A PSA is a legal agreement between the seller and a single interested buyer which establishes the terms, conditions and timeline of the sale between the buyer and seller. A PSA may be a highly negotiated document with customized terms or may be a standardized contract similar to those used in residential transactions.[8]\nOnce a PSA is executed, the buyer is commonly required to submit an escrow deposit, which may be refundable under certain conditions, to a title company office or held by a brokerage in escrow. The transaction moves to the due diligence phase, where the buyer makes a more detailed assessment of the property. Purchase and sale agreements will generally include clauses which require the seller to disclose certain information for buyer's review to determine if the terms of the agreement are still acceptable. The buyer may have the right to terminate the transaction and/or renegotiate the terms, often referred to as \"contingencies\". Many purchase agreements are contingent on the buyer's ability to obtain mortgage financing and buyer's satisfactory review of specific due diligence items. Common due diligence items include property financial statements, rent rolls, vendor contracts, zoning and legal uses, physical and environmental condition, traffic patterns and other relevant information to the buyer's purchase decision specified in the PSA. In competitive real estate markets, buyers may waive contingencies in order to make an offer more appealing to a buyer. The PSA will usually require the seller to provide due diligence information to the seller in a timely manner and limit the buyer's time to terminate the deal based on its due diligence review findings. If the buyer terminates the transaction within the due diligence timeframe, the escrow deposit is commonly returned to the buyer. If the buyer has not terminated the agreement pursuant to the PSA contingencies, the escrow deposit becomes non-refundable and failure to complete the purchase will result in the escrow deposit funds to be transferred to the seller as a fee for failure to close. The parties will proceed to close the transaction in which funds and title are exchanged.\nWhen a deal closes, post-closing processes may begin, including notifying tenants of an ownership change, transferring vendor relationships, and handing over relevant information to the asset management team.[citation needed]\n- Corporate real estate\n- Class A office space\n- Commercial Information Exchange\n- Commercialrealestate.com.au\n- Estoppel certificate, a document used in\n- International real estate\n- Owner Occupied Commercial Real Estate\n- Real estate\n- Real estate investing\n- Real estate economics\n- Maliene, V.; Deveikis, S.; Kirsten, L.; Malys, N. (2010). \"Commercial Leisure Property Valuation: A Comparison of the Case Studies in UK and Lithuania\". International Journal of Strategic Property Management. 14 (1): 35–48. doi:10.3846/ijspm.2010.04.\n- Investopedia Definition\n- An, Xudong; Pivo, Gary (2018-01-03). \"Green Buildings in Commercial Mortgage-Backed Securities: The Effects of LEED and Energy Star Certification on Default Risk and Loan Terms\". Real Estate Economics. 48 (1): 7–42. doi:10.1111/1540-6229.12228. ISSN 1080-8620. S2CID 158506082.\n- Plazzi, Alberto (26 August 2010). \"Expected Returns and Expected Growth in Rents of Commercial Real Estate\". The Review of Financial Studies. 23 (9): 3469–3519. doi:10.1093/rfs/hhq069.\n- Amadeo, Kimberly (July 31, 2018). \"Commercial Real Estate and the Economy\". Dotdash.\n- \"US Office Market Dynamics - Q2 2024\". 23 July 2024.\n- Gareth, Lewis (2012). \"Real estate in the real economy\" (PDF). EPRA. Archived from the original (PDF) on 2013-05-17.\n- \"Tariffs Trigger Sharpest Drop in CRE Confidence Since Pandemic\". benefitspro.com. Retrieved 2025-04-27.\n- Gosfield, Gregory G. (2000). \"A Primer on Real Estate Options\". Real Property, Probate and Trust Journal. 35 (1): 129–195. ISSN 0034-0855. JSTOR 20782208.\n- Media related to Commercial real estate at Wikimedia Commons",
    "computer industry": "| Information science |\n|---|\n| General aspects |\n| Related fields and subfields |\nInformation technology (IT) is the study or use of computers, telecommunication systems and other devices to create, process, store, retrieve and transmit information.[1] While the term is commonly used to refer to computers and computer networks, it also encompasses other information distribution technologies such as television and telephones. Information technology is an application of computer science and computer engineering.\nAn information technology system (IT system) is generally an information system, a communications system, or, more specifically speaking, a computer system — including all hardware, software, and peripheral equipment — operated by a limited group of IT users, and an IT project usually refers to the commissioning and implementation of an IT system.[2] IT systems play a vital role in facilitating efficient data management, enhancing communication networks, and supporting organizational processes across various industries. Successful IT projects require meticulous planning and ongoing maintenance to ensure optimal functionality and alignment with organizational objectives.[3]\nAlthough humans have been storing, retrieving, manipulating, analysing and communicating information since the earliest writing systems were developed,[4] the term information technology in its modern sense first appeared in a 1958 article published in the Harvard Business Review; authors Harold J. Leavitt and Thomas L. Whisler commented that \"the new technology does not yet have a single established name. We shall call it information technology (IT).\"[5] Their definition consists of three categories: techniques for processing, the application of statistical and mathematical methods to decision-making, and the simulation of higher-order thinking through computer programs.[5]\nBased on the storage and processing technologies employed, it is possible to distinguish four distinct phases of IT development: pre-mechanical (3000 BC – 1450 AD), mechanical (1450 – 1840), electromechanical (1840 – 1940), and electronic (1940 to present).[4]\nIdeas of computer science were first mentioned before the 1950s under the Massachusetts Institute of Technology (MIT) and Harvard University, where they had discussed and began thinking of computer circuits and numerical calculations. As time went on, the field of information technology and computer science became more complex and was able to handle the processing of more data. Scholarly articles began to be published from different organizations.[6]\nDuring the mid-1900s, Alan Turing, J. Presper Eckert, and John Mauchly were some of the pioneers of early computer technology. While their main efforts focused on designing the first digital computer, Turing also began to raise questions about artificial intelligence.[7]\nDevices have been used to aid computation for thousands of years, probably initially in the form of a tally stick.[8] The Antikythera mechanism, dating from about the beginning of the first century BC, is generally considered the earliest known mechanical analog computer, and the earliest known geared mechanism.[9] Comparable geared devices did not emerge in Europe until the 16th century, and it was not until 1645 that the first mechanical calculator capable of performing the four basic arithmetical operations was developed.[10]\nElectronic computers, using either relays or thermionic valves, began to appear in the early 1940s. The electromechanical Zuse Z3, completed in 1941, was the world's first programmable computer, and by modern standards one of the first machines that could be considered a complete computing machine. During the Second World War, Colossus developed the first electronic digital computer to decrypt German messages. Although it was programmable, it was not general-purpose, being designed to perform only a single task. It could not also store its program in memory; programming was carried out using plugs and switches to alter the internal wiring.[11] The first recognizably modern electronic digital stored-program computer was the Manchester Baby, which ran its first program on 21 June 1948.[12]\nThe development of transistors in the late 1940s at Bell Laboratories allowed a new generation of computers to be designed with greatly reduced power consumption. The first commercially available stored-program computer, the Ferranti Mark I, contained 4050 valves and had a power consumption of 25 kilowatts. By comparison, the first transistorized computer developed at the University of Manchester and operational by November 1953, consumed only 150 watts in its final version.[13]\nSeveral other breakthroughs in semiconductor technology include the integrated circuit (IC) invented by Jack Kilby at Texas Instruments and Robert Noyce at Fairchild Semiconductor in 1959, silicon dioxide surface passivation by Carl Frosch and Lincoln Derick in 1955,[14] the first planar silicon dioxide transistors by Frosch and Derick in 1957,[15] the MOSFET demonstration by a Bell Labs team,[16][17][18][19] the planar process by Jean Hoerni in 1959,[20][21][22] and the microprocessor invented by Ted Hoff, Federico Faggin, Masatoshi Shima, and Stanley Mazor at Intel in 1971. These important inventions led to the development of the personal computer (PC) in the 1970s, and the emergence of information and communications technology (ICT).[23]\nBy 1984, according to the National Westminster Bank Quarterly Review, the term information technology had been redefined as \"the convergence of telecommunications and computing technology (...generally known in Britain as information technology).\" We then begin to see the appearance of the term in 1990, contained within documents for the International Organization for Standardization (ISO).[24]\nInnovations in technology have already revolutionized the world by the twenty-first century as people have gained access to different online services. This has changed the workforce drastically, as thirty percent of U.S. workers were already in careers in this profession. 136.9 million people were personally connected to the Internet, which was equivalent to 51 million households.[25] Along with the Internet, new types of technology were also being introduced across the globe, which have improved efficiency and made things easier across the globe.\nAs technology revolutionized society, millions of processes could be completed in seconds. Innovations in communication were crucial as people increasingly relied on computers to communicate via telephone lines and cable networks. The introduction of the email was considered revolutionary as \"companies in one part of the world could communicate by e-mail with suppliers and buyers in another part of the world...\".[26]\nComputers and technology have also revolutionized the marketing industry, resulting in more buyers of their products. In 2002, Americans exceeded $28 billion in goods just over the Internet alone, while e-commerce a decade later resulted in $289 billion in sales.[26] And as computers are rapidly becoming more sophisticated by the day, they are becoming more widely used as people are becoming more reliant on them during the twenty-first century.\nElectronic data processing or business information processing can refer to the use of automated methods to process commercial data. Typically, this uses relatively simple, repetitive activities to process large volumes of similar information. For example: stock updates applied to an inventory, banking transactions applied to account and customer master files, booking and ticketing transactions to an airline's reservation system, and billing for utility services. The modifier \"electronic\" or \"automatic\" was used with \"data processing\" (DP), especially c. 1960, to distinguish human clerical data processing from that done by computer.[27][28]\nEarly electronic computers such as Colossus made use of punched tape, a long strip of paper on which data was represented by a series of holes, a technology now obsolete.[29] Electronic data storage, which is used in modern computers, dates from World War II, when a form of delay-line memory was developed to remove the clutter from radar signals, the first practical application of which was the mercury delay line.[30] The first random-access digital storage device was the Williams tube, which was based on a standard cathode ray tube.[31] However, the information stored in it and the delay-line memory was volatile in the fact that it had to be continuously refreshed, and thus was lost once power was removed. The earliest form of non-volatile computer storage was the magnetic drum, invented in 1932[32] and used in the Ferranti Mark 1, the world's first commercially available general-purpose electronic computer.[33]\nIBM introduced the first hard disk drive in 1956, as a component of their 305 RAMAC computer system.[34]: 6 Most digital data today is still stored magnetically on hard disks, or optically on media such as CD-ROMs.[35]: 4–5 Until 2002, most information was stored on analog devices, but that year digital storage capacity exceeded analog for the first time. As of 2007[update], almost 94% of the data stored worldwide was held digitally:[36] 52% on hard disks, 28% on optical devices, and 11% on digital magnetic tape. It has been estimated that the worldwide capacity to store information on electronic devices grew from less than 3 exabytes in 1986 to 295 exabytes in 2007,[37] doubling roughly every 3 years.[38]\nDatabase Management Systems (DMS) emerged in the 1960s to address the problem of storing and retrieving large amounts of data accurately and quickly. An early such system was IBM's Information Management System (IMS),[39] which is still widely deployed more than 50 years later.[40] IMS stores data hierarchically,[39] but in the 1970s Ted Codd proposed an alternative relational storage model based on set theory and predicate logic and the familiar concepts of tables, rows, and columns. In 1981, the first commercially available relational database management system (RDBMS) was released by Oracle.[41]\nAll DMS consist of components; they allow the data they store to be accessed simultaneously by many users while maintaining its integrity.[42] All databases have a common one point in that the structure of the data they contain is defined and stored separately from the data itself, in a database schema.[39]\nIn the late 2000s (decade), the extensible markup language (XML) became a popular format for data representation. Although XML data can be stored in normal file systems, it is commonly held in relational databases to take advantage of their \"robust implementation verified by years of both theoretical and practical effort.\"[43] As an evolution of the Standard Generalized Markup Language (SGML), XML's text-based structure offers the advantage of being both machine- and human-readable.[44]\nData transmission has three aspects: transmission, propagation, and reception.[45] It can be broadly categorized as broadcasting, in which information is transmitted unidirectionally downstream, or telecommunications, with bidirectional upstream and downstream channels.[37]\nXML has been increasingly employed as a means of data interchange since the early 2000s,[46] particularly for machine-oriented interactions such as those involved in web-oriented protocols such as SOAP,[44] describing \"data-in-transit rather than... data-at-rest\".[46]\nHilbert and Lopez identify the exponential pace of technological change (a kind of Moore's law): machines' application-specific capacity to compute information per capita roughly doubled every 14 months between 1986 and 2007; the per capita capacity of the world's general-purpose computers doubled every 18 months during the same two decades; the global telecommunication capacity per capita doubled every 34 months; the world's storage capacity per capita required roughly 40 months to double (every 3 years); and per capita broadcast information has doubled every 12.3 years.[37]\nMassive amounts of data are stored worldwide every day, but unless it can be analyzed and presented effectively it essentially resides in what have been called data tombs: \"data archives that are seldom visited\".[47] To address that issue, the field of data mining — \"the process of discovering interesting patterns and knowledge from large amounts of data\"[48] — emerged in the late 1980s.[49]\nThe technology and services IT provides for sending and receiving electronic messages (called \"letters\" or \"electronic letters\") over a distributed (including global) computer network. In terms of the composition of elements and the principle of operation, electronic mail practically repeats the system of regular (paper) mail, borrowing both terms (mail, letter, envelope, attachment, box, delivery, and others) and characteristic features — ease of use, message transmission delays, sufficient reliability, and at the same time no guarantee of delivery. The advantages of e-mail are: easily perceived and remembered by a person addresses of the form user_name@domain_name (for example, somebody@example.com); the ability to transfer both plain text and formatted, as well as arbitrary files; independence of servers (in the general case, they address each other directly); sufficiently high reliability of message delivery; ease of use by humans and programs.\nThe disadvantages of e-mail include: the presence of such a phenomenon as spam (massive advertising and viral mailings); the theoretical impossibility of guaranteed delivery of a particular letter; possible delays in message delivery (up to several days); limits on the size of one message and on the total size of messages in the mailbox (personal for users).\nA search system is a software and hardware complex with a web interface that provides the ability to look for information on the Internet. A search engine usually means a site that hosts the interface (front-end) of the system. The software part of a search engine is a search engine (search engine) — a set of programs that provides the functionality of a search engine and is usually a trade secret of the search engine developer company. Most search engines look for information on World Wide Web sites, but some systems can look for files on FTP servers, items in online stores, and information on Usenet newsgroups. Improving search is one of the priorities of the modern Internet (see the Deep Web article about the main problems in the work of search engines).\nCompanies in the information technology field are often discussed as a group as the \"tech sector\" or the \"tech industry.\"[50][51][52] These titles can be misleading at times and should not be mistaken for \"tech companies,\" which are generally large scale, for-profit corporations that sell consumer technology and software. From a business perspective, information technology departments are a \"cost center\" the majority of the time. A cost center is a department or staff that incurs expenses, or \"costs,\" within a company rather than generating profits or revenue streams. Modern businesses rely heavily on technology for their day-to-day operations, so the expenses delegated to cover technology that facilitates business in a more efficient manner are usually seen as \"just the cost of doing business.\" IT departments are allocated funds by senior leadership and must attempt to achieve the desired deliverables while staying within that budget. Government and the private sector might have different funding mechanisms, but the principles are more or less the same. This is an often overlooked reason for the rapid interest in automation and artificial intelligence, but the constant pressure to do more with less is opening the door for automation to take control of at least some minor operations in large companies.\nMany companies now have IT departments for managing the computers, networks, and other technical areas of their businesses. Companies have also sought to integrate IT with business outcomes and decision-making through a BizOps or business operations department.[53]\nIn a business context, the Information Technology Association of America has defined information technology as \"the study, design, development, application, implementation, support, or management of computer-based information systems\".[54][page needed] The responsibilities of those working in the field include network administration, software development and installation, and the planning and management of an organization's technology life cycle, by which hardware and software are maintained, upgraded, and replaced.\nInformation services is a term somewhat loosely applied to a variety of IT-related services offered by commercial companies,[55][56][57] as well as data brokers.\nThe field of information ethics was established by mathematician Norbert Wiener in the 1940s.[59]: 9 Some of the ethical issues associated with the use of information technology include:[60]: 20–21\n- Breaches of copyright by those downloading files stored without the permission of the copyright holders\n- Employers monitoring their employees' emails and other Internet usage\n- Unsolicited emails\n- Hackers accessing online databases\n- Websites installing cookies or spyware to monitor a user's online activities, which may be used by data brokers\nResearch suggests that IT projects in business and public administration can easily become significant in scale. Research conducted by McKinsey in collaboration with the University of Oxford suggested that half of all large-scale IT projects (those with initial cost estimates of $15 million or more) often failed to maintain costs within their initial budgets or to complete on time.[61]\n- Information and communications technology (ICT)\n- IT infrastructure\n- Outline of information technology\n- Knowledge society\n- \"Information Technology – Oxford Reference\". Oxford Reference. Oxford University Press.\n- Forbes Technology Council, 16 Key Steps To Successful IT Project Management, published 10 September 2020, accessed 23 June 2023\n- Hindarto, Djarot (30 August 2023). \"The Management of Projects is Improved Through Enterprise Architecture on Project Management Application Systems\". International Journal Software Engineering and Computer Science. 3 (2): 151–161. doi:10.35870/ijsecs.v3i2.1512. ISSN 2776-3242.\n- Butler, Jeremy G., A History of Information Technology and Systems, University of Arizona, archived from the original on 5 August 2012, retrieved 2 August 2012\n- Leavitt, Harold J.; Whisler, Thomas L. (1958), \"Management in the 1980s\", Harvard Business Review, 11\n- Slotten, Hugh Richard (1 January 2014). The Oxford Encyclopedia of the History of American Science, Medicine, and Technology. Oxford University Press. doi:10.1093/acref/9780199766666.001.0001. ISBN 978-0-19-976666-6.\n- Henderson, H. (2017). computer science. In H. Henderson, Facts on File science library: Encyclopedia of computer science and technology. (3rd ed.). [Online]. New York: Facts On File.\n- Schmandt-Besserat, Denise (1981), \"Decipherment of the earliest tablets\", Science, 211 (4479): 283–285, Bibcode:1981Sci...211..283S, doi:10.1126/science.211.4479.283, ISSN 0036-8075, PMID 17748027\n- Wright (2012), p. 279.\n- Chaudhuri (2004), p. 3.\n- Lavington (1980), p. 11.\n- Enticknap, Nicholas (Summer 1998), \"Computing's Golden Jubilee\", Resurrection (20), ISSN 0958-7403, archived from the original on 9 January 2012, retrieved 19 April 2008\n- Cooke-Yarborough, E. H. (June 1998), \"Some early transistor applications in the UK\", Engineering Science & Education Journal, 7 (3): 100–106, doi:10.1049/esej:19980301 (inactive 12 July 2025), ISSN 0963-7346\n{{citation}}\n: CS1 maint: DOI inactive as of July 2025 (link). - US2802760A, Lincoln, Derick & Frosch, Carl J., \"Oxidation of semiconductive surfaces for controlled diffusion\", issued 13 August 1957\n- Frosch, C. J.; Derick, L (1957). \"Surface Protection and Selective Masking during Diffusion in Silicon\". Journal of the Electrochemical Society. 104 (9): 547. doi:10.1149/1.2428650.\n- KAHNG, D. (1961). \"Silicon-Silicon Dioxide Surface Device\". Technical Memorandum of Bell Laboratories: 583–596. doi:10.1142/9789814503464_0076. ISBN 978-981-02-0209-5.\n{{cite journal}}\n: ISBN / Date incompatibility (help) - Lojek, Bo (2007). History of Semiconductor Engineering. Berlin, Heidelberg: Springer-Verlag Berlin Heidelberg. p. 321. ISBN 978-3-540-34258-8.\n- Ligenza, J.R.; Spitzer, W.G. (1960). \"The mechanisms for silicon oxidation in steam and oxygen\". Journal of Physics and Chemistry of Solids. 14: 131–136. Bibcode:1960JPCS...14..131L. doi:10.1016/0022-3697(60)90219-5.\n- Lojek, Bo (2007). History of Semiconductor Engineering. Springer Science & Business Media. p. 120. ISBN 9783540342588.\n- Lojek, Bo (2007). History of Semiconductor Engineering. Springer Science & Business Media. pp. 120 & 321–323. ISBN 9783540342588.\n- Bassett, Ross Knox (2007). To the Digital Age: Research Labs, Start-up Companies, and the Rise of MOS Technology. Johns Hopkins University Press. p. 46. ISBN 9780801886393.\n- US 3025589 Hoerni, J. A.: \"Method of Manufacturing Semiconductor Devices\" filed May 1, 1959\n- \"Advanced information on the Nobel Prize in Physics 2000\" (PDF). Nobel Prize. June 2018. Archived (PDF) from the original on 17 August 2019. Retrieved 17 December 2019.\n- Information technology. (2003). In E.D. Reilly, A. Ralston & D. Hemmendinger (Eds.), Encyclopedia of computer science. (4th ed.).\n- Stewart, C.M. (2018). Computers. In S. Bronner (Ed.), Encyclopedia of American Studies. [Online]. Johns Hopkins University Press.\n- Northrup, C.C. (2013). Computers. In C. Clark Northrup (Ed.), Encyclopedia of world trade: from ancient times to the present. [Online]. London: Routledge.\n- Illingworth, Valerie (11 December 1997). Dictionary of Computing. Oxford Paperback Reference (4th ed.). Oxford University Press. p. 126. ISBN 9780192800466.\n- Anthony Ralston. Encyclopedia of Computer Science 4ed. Nature group. p. 502.\n- Alavudeen & Venkateshwaran (2010), p. 178.\n- Lavington (1998), p. 1.\n- \"Early computers at Manchester University\", Resurrection, 1 (4), Summer 1992, ISSN 0958-7403, archived from the original on 28 August 2017, retrieved 19 April 2008\n- Universität Klagenfurt (ed.), \"Magnetic drum\", Virtual Exhibitions in Informatics, archived from the original on 21 June 2006, retrieved 21 August 2011\n- The Manchester Mark 1, University of Manchester, archived from the original on 21 November 2008, retrieved 24 January 2009\n- Khurshudov, Andrei (2001), The Essential Guide to Computer Data Storage: From Floppy to DVD, Prentice Hall, ISBN 978-0-130-92739-2\n- Wang, Shan X.; Taratorin, Aleksandr Markovich (1999), Magnetic Information Storage Technology, Academic Press, ISBN 978-0-12-734570-3\n- Wu, Suzanne, \"How Much Information Is There in the World?\", USC News, University of Southern California, retrieved 10 September 2013\n- Hilbert, Martin; López, Priscila (1 April 2011), \"The World's Technological Capacity to Store, Communicate, and Compute Information\", Science, 332 (6025): 60–65, Bibcode:2011Sci...332...60H, doi:10.1126/science.1200970, PMID 21310967, S2CID 206531385\n- \"Americas events – Video animation on The World's Technological Capacity to Store, Communicate, and Compute Information from 1986 to 2010\". The Economist. Archived from the original on 18 January 2012.\n- Ward & Dafoulas (2006), p. 2.\n- Olofson, Carl W. (October 2009), A Platform for Enterprise Data Services (PDF), IDC, archived from the original (PDF) on 25 December 2013, retrieved 7 August 2012\n- Ward & Dafoulas (2006), p. 3.\n- Silberschatz, Abraham (2010). Database System Concepts. McGraw-Hill Higher Education. ISBN 978-0-07-741800-7.\n- Pardede (2009), p. 2.\n- Pardede (2009), p. 4.\n- Weik (2000), p. 361.\n- Pardede (2009), p. xiii.\n- Han, Kamber & Pei (2011), p. 5.\n- Han, Kamber & Pei (2011), p. 8.\n- Han, Kamber & Pei (2011), p. xxiii.\n- \"Technology Sector Snapshot\". The New York Times. Archived from the original on 13 January 2017. Retrieved 12 January 2017.\n- \"Our programmes, campaigns and partnerships\". TechUK. Retrieved 12 January 2017.\n- \"Cyberstates 2016\". CompTIA. Archived from the original on 6 November 2018. Retrieved 12 January 2017.\n- \"Manifesto Hatched to Close Gap Between Business and IT\". TechNewsWorld. 22 October 2020. Retrieved 22 March 2021.\n- Proctor, K. Scott (2011), Optimizing and Assessing Information Technology: Improving Business Project Execution, John Wiley & Sons, ISBN 978-1-118-10263-3\n- \"Top Information Services companies\". VentureRadar. Retrieved 8 March 2021.\n- \"Follow Information Services on Index.co\". Index.co. Retrieved 8 March 2021.[permanent dead link]\n- Publishing, Value Line. \"Industry Overview: Information Services\". Value Line. Archived from the original on 20 June 2021. Retrieved 8 March 2021.\n- Lauren Csorny (9 April 2013). \"U.S. Careers in the growing field of information technology services\". U.S. Bureau of Labor Statistics.\n- Bynum, Terrell Ward (2008), \"Norbert Wiener and the Rise of Information Ethics\", in van den Hoven, Jeroen; Weckert, John (eds.), Information Technology and Moral Philosophy, Cambridge University Press, ISBN 978-0-521-85549-5\n- Reynolds, George (2009), Ethics in Information Technology, Cengage Learning, ISBN 978-0-538-74622-9\n- Bloch, M., Blumberg, S. and Laartz, J., Delivering large-scale IT projects on time, on budget, and on value, published 1 October 2012, accessed 23 June 2023\n- Alavudeen, A.; Venkateshwaran, N. (2010), Computer Integrated Manufacturing, PHI Learning, ISBN 978-81-203-3345-1\n- Chaudhuri, P. Pal (2004), Computer Organization and Design, PHI Learning, ISBN 978-81-203-1254-8\n- Han, Jiawei; Kamber, Micheline; Pei, Jian (2011), Data Mining: Concepts and Techniques (3rd ed.), Morgan Kaufmann, ISBN 978-0-12-381479-1\n- Lavington, Simon (1980), Early British Computers, Manchester University Press, ISBN 978-0-7190-0810-8\n- Lavington, Simon (1998), A History of Manchester Computers (2nd ed.), The British Computer Society, ISBN 978-1-902505-01-5\n- Pardede, Eric (2009), Open and Novel Issues in XML Database Applications, Information Science Reference, ISBN 978-1-60566-308-1\n- Ralston, Anthony; Hemmendinger, David; Reilly, Edwin D., eds. (2000), Encyclopedia of Computer Science (4th ed.), Nature Publishing Group, ISBN 978-1-56159-248-7\n- van der Aalst, Wil M. P. (2011), Process Mining: Discovery, Conformance and Enhancement of Business Processes, Springer, ISBN 978-3-642-19344-6\n- Ward, Patricia; Dafoulas, George S. (2006), Database Management Systems, Cengage Learning EMEA, ISBN 978-1-84480-452-8\n- Weik, Martin (2000), Computer Science and Communications Dictionary, vol. 2, Springer, ISBN 978-0-7923-8425-0\n- Wright, Michael T. (2012), \"The Front Dial of the Antikythera Mechanism\", in Koetsier, Teun; Ceccarelli, Marco (eds.), Explorations in the History of Machines and Mechanisms: Proceedings of HMM2012, Springer, pp. 279–292, ISBN 978-94-007-4131-7\n- Allen, T.; Morton, M. S. Morton, eds. (1994), Information Technology and the Corporation of the 1990s, Oxford University Press\n- Gitta, Cosmas and South, David (2011). Southern Innovator Magazine Issue 1: Mobile Phones and Information Technology: United Nations Office for South-South Cooperation. ISSN 2222-9280.\n- Gleick, James (2011).The Information: A History, a Theory, a Flood. New York: Pantheon Books.\n- Price, Wilson T. (1981), Introduction to Computer Data Processing, Holt-Saunders International Editions, ISBN 978-4-8337-0012-2\n- Shelly, Gary, Cashman, Thomas, Vermaat, Misty, and Walker, Tim. (1999). Discovering Computers 2000: Concepts for a Connected World. Cambridge, Massachusetts: Course Technology.\n- Webster, Frank, and Robins, Kevin. (1986). Information Technology — A Luddite Analysis. Norwood, NJ: Ablex.\n- Learning materials related to Information technology at Wikiversity\n- Media related to Information technology at Wikimedia Commons\n- Quotations related to Information technology at Wikiquote",
    "computer security": "| Part of a series on |\n| Computer hacking |\n|---|\n| Operating systems |\n|---|\n| Common features |\nComputer security (also cybersecurity, digital security, or information technology (IT) security) is a subdiscipline within the field of information security. It focuses on protecting computer software, systems, and networks from threats that can lead to unauthorized information disclosure, theft or damage to hardware, software, or data, as well as from the disruption or misdirection of the services they provide.[1][2]\nThe growing significance of computer insecurity reflects the increasing dependence on computer systems, the Internet,[3] and evolving wireless network standards. This reliance has expanded with the proliferation of smart devices, including smartphones, televisions, and other components of the Internet of things (IoT).\nAs digital infrastructure becomes more embedded in everyday life, cybersecurity has emerged as a critical concern. The complexity of modern information systems—and the societal functions they underpin—has introduced new vulnerabilities. Systems that manage essential services, such as power grids, electoral processes, and finance, are particularly sensitive to security breaches.[4][5]\nAlthough many aspects of computer security involve digital security, such as electronic passwords and encryption, physical security measures, such as metal locks are still used to prevent unauthorized tampering. IT security is not a perfect subset of information security, therefore does not completely align with the security convergence schema.\nA vulnerability refers to a flaw in the structure, execution, functioning, or internal oversight of a computer or system that compromises its security. Most of the vulnerabilities that have been discovered are documented in the Common Vulnerabilities and Exposures (CVE) database.[6] An exploitable vulnerability is one for which at least one working attack or exploit exists.[7] Actors maliciously seeking vulnerabilities are known as threats. Vulnerabilities can be researched, reverse-engineered, hunted, or exploited using automated tools or customized scripts.[8][9]\nVarious people or parties are vulnerable to cyber attacks; however, different groups are likely to experience different types of attacks more than others.[10]\nIn April 2023, the United Kingdom Department for Science, Innovation & Technology released a report on cyber attacks over the previous 12 months.[11] They surveyed 2,263 UK businesses, 1,174 UK registered charities, and 554 education institutions. The research found that \"32% of businesses and 24% of charities overall recall any breaches or attacks from the last 12 months.\" These figures were much higher for \"medium businesses (59%), large businesses (69%), and high-income charities with £500,000 or more in annual income (56%).\"[11] Yet, although medium or large businesses are more often the victims, since larger companies have generally improved their security over the last decade, small and midsize businesses (SMBs) have also become increasingly vulnerable as they often \"do not have advanced tools to defend the business.\"[10] SMBs are most likely to be affected by malware, ransomware, phishing, man-in-the-middle attacks, and Denial-of Service (DoS) Attacks.[10]\nNormal internet users are most likely to be affected by untargeted cyberattacks.[12] These are where attackers indiscriminately target as many devices, services, or users as possible. They do this using techniques that take advantage of the openness of the Internet. These strategies mostly include phishing, ransomware, water holing and scanning.[12]\nTo secure a computer system, it is important to understand the attacks that can be made against it, and these threats can typically be classified into one of the following categories:\nA backdoor in a computer system, a cryptosystem, or an algorithm is any secret method of bypassing normal authentication or security controls. These weaknesses may exist for many reasons, including original design or poor configuration.[13] Due to the nature of backdoors, they are of greater concern to companies and databases as opposed to individuals.\nBackdoors may be added by an authorized party to allow some legitimate access or by an attacker for malicious reasons. Criminals often use malware to install backdoors, giving them remote administrative access to a system.[14] Once they have access, cybercriminals can \"modify files, steal personal information, install unwanted software, and even take control of the entire computer.\"[14]\nBackdoors can be difficult to detect, as they often remain hidden within the source code or system firmware intimate knowledge of the operating system of the computer.\nDenial-of-service attacks (DoS) are designed to make a machine or network resource unavailable to its intended users.[15] Attackers can deny service to individual victims, such as by deliberately entering a wrong password enough consecutive times to cause the victim's account to be locked, or they may overload the capabilities of a machine or network and block all users at once. While a network attack from a single IP address can be blocked by adding a new firewall rule, many forms of distributed denial-of-service (DDoS) attacks are possible, where the attack comes from a large number of points. In this case, defending against these attacks is much more difficult. Such attacks can originate from the zombie computers of a botnet or from a range of other possible techniques, including distributed reflective denial-of-service (DRDoS), where innocent systems are fooled into sending traffic to the victim.[15] With such attacks, the amplification factor makes the attack easier for the attacker because they have to use little bandwidth themselves. To understand why attackers may carry out these attacks, see the 'attacker motivation' section.\nA direct-access attack is when an unauthorized user (an attacker) gains physical access to a computer, most likely to directly copy data from it or steal information.[16] Attackers may also compromise security by making operating system modifications, installing software worms, keyloggers, covert listening devices or using wireless microphones. Even when the system is protected by standard security measures, these may be bypassed by booting another operating system or tool from a CD-ROM or other bootable media. Disk encryption and the Trusted Platform Module standard are designed to prevent these attacks.\nDirect service attackers are related in concept to direct memory attacks which allow an attacker to gain direct access to a computer's memory.[17] The attacks \"take advantage of a feature of modern computers that allows certain devices, such as external hard drives, graphics cards, or network cards, to access the computer's memory directly.\"[17]\nEavesdropping is the act of surreptitiously listening to a private computer conversation (communication), usually between hosts on a network. It typically occurs when a user connects to a network where traffic is not secured or encrypted and sends sensitive business data to a colleague, which, when listened to by an attacker, could be exploited.[18] Data transmitted across an open network allows an attacker to exploit a vulnerability and intercept it via various methods.\nUnlike malware, direct-access attacks, or other forms of cyber attacks, eavesdropping attacks are unlikely to negatively affect the performance of networks or devices, making them difficult to notice.[18] In fact, \"the attacker does not need to have any ongoing connection to the software at all. The attacker can insert the software onto a compromised device, perhaps by direct insertion or perhaps by a virus or other malware, and then come back some time later to retrieve any data that is found or trigger the software to send the data at some determined time.\"[19]\nUsing a virtual private network (VPN), which encrypts data between two points, is one of the most common forms of protection against eavesdropping. Using the best form of encryption possible for wireless networks is best practice, as well as using HTTPS instead of an unencrypted HTTP.[20]\nPrograms such as Carnivore and NarusInSight have been used by the Federal Bureau of Investigation (FBI) and the NSA to eavesdrop on the systems of internet service providers. Even machines that operate as a closed system (i.e., with no contact with the outside world) can be eavesdropped upon by monitoring the faint electromagnetic transmissions generated by the hardware. TEMPEST is a specification by the NSA referring to these attacks.\nMalicious software (malware) is any software code or computer program \"intentionally written to harm a computer system or its users.\"[21] Once present on a computer, it can leak sensitive details such as personal information, business information and passwords, can give control of the system to the attacker, and can corrupt or delete data permanently.[22][23]\n- Viruses are a specific type of malware, and are normally a malicious code that hijacks software with the intention to \"do damage and spread copies of itself.\" Copies are made with the aim of spreading to other programs on a computer.[21]\n- Worms are similar to viruses, however viruses can only function when a user runs (opens) a compromised program. Worms are self-replicating malware that spread between programs, apps and devices without the need for human interaction.[21]\n- Trojan horses are programs that pretend to be helpful or hide themselves within desired or legitimate software to \"trick users into installing them.\" Once installed, a RAT (Remote Access Trojan) can create a secret backdoor on the affected device to cause damage.[21]\n- Spyware is a type of malware that secretly gathers information from an infected computer and transmits the sensitive information back to the attacker. One of the most common forms of spyware is keyloggers, which record all of a user's keyboard inputs/keystrokes, to \"allow hackers to harvest usernames, passwords, bank account and credit card numbers.\"[21]\n- Scareware, as the name suggests, is a form of malware that uses social engineering (manipulation) to scare, shock, trigger anxiety, or suggest the perception of a threat in order to manipulate users into buying or installing unwanted software. These attacks often begin with a \"sudden pop-up with an urgent message, usually warning the user that they've broken the law or their device has a virus.\"[21]\n- Ransomware is when malware installs itself onto a victim's machine, encrypts their files, and then turns around and demands a ransom (usually in Bitcoin) to return that data to the user.\nMan-in-the-middle attacks (MITM) involve a malicious attacker trying to intercept, surveil or modify communications between two parties by spoofing one or both party's identities and injecting themselves in-between.[24] Types of MITM attacks include:\n- IP address spoofing is where the attacker hijacks routing protocols to reroute the targets traffic to a vulnerable network node for traffic interception or injection.\n- Message spoofing (via email, SMS or OTT messaging) is where the attacker spoofs the identity or carrier service while the target is using messaging protocols like email, SMS or OTT (IP-based) messaging apps. The attacker can then monitor conversations, launch social attacks or trigger zero-day-vulnerabilities to allow for further attacks.\n- WiFi SSID spoofing is where the attacker simulates a WIFI base station SSID to capture and modify internet traffic and transactions. The attacker can also use local network addressing and reduced network defenses to penetrate the target's firewall by breaching known vulnerabilities. Sometimes known as a Pineapple attack thanks to a popular device. See also Malicious association.\n- DNS spoofing is where attackers hijack domain name assignments to redirect traffic to systems under the attackers control, in order to surveil traffic or launch other attacks.\n- SSL hijacking, typically coupled with another media-level MITM attack, is where the attacker spoofs the SSL authentication and encryption protocol by way of Certificate Authority injection in order to decrypt, surveil and modify traffic. See also TLS interception[24]\nSurfacing in 2017, a new class of multi-vector,[25] polymorphic[26] cyber threats combine several types of attacks and change form to avoid cybersecurity controls as they spread.\nMulti-vector polymorphic attacks, as the name describes, are both multi-vectored and polymorphic.[27] Firstly, they are a singular attack that involves multiple methods of attack. In this sense, they are \"multi-vectored\" (i.e. the attack can use multiple means of propagation such as via the Web, email and applications). However, they are also multi-staged, meaning that \"they can infiltrate networks and move laterally inside the network.\"[27] The attacks can be polymorphic, meaning that the cyberattacks used such as viruses, worms or trojans \"constantly change (\"morph\") making it nearly impossible to detect them using signature-based defences.\"[27]\nPhishing is the attempt to acquire sensitive information such as usernames, passwords, and credit card details directly from users by deceiving the users.[28] Phishing is typically carried out by email spoofing, instant messaging, text message, or on a phone call. They often direct users to enter details at a fake website whose look and feel are almost identical to the legitimate one.[29] The fake website often asks for personal information, such as login details and passwords. This information can then be used to gain access to the individual's real account on the real website.\nPreying on a victim's trust, phishing can be classified as a form of social engineering. Attackers can use creative ways to gain access to real accounts. A common scam is for attackers to send fake electronic invoices[30] to individuals showing that they recently purchased music, apps, or others, and instructing them to click on a link if the purchases were not authorized. A more strategic type of phishing is spear-phishing which leverages personal or organization-specific details to make the attacker appear like a trusted source. Spear-phishing attacks target specific individuals, rather than the broad net cast by phishing attempts.[31]\nPrivilege escalation describes a situation where an attacker with some level of restricted access is able to, without authorization, elevate their privileges or access level.[32] For example, a standard computer user may be able to exploit a vulnerability in the system to gain access to restricted data; or even become root and have full unrestricted access to a system. The severity of attacks can range from attacks simply sending an unsolicited email to a ransomware attack on large amounts of data. Privilege escalation usually starts with social engineering techniques, often phishing.[32]\nPrivilege escalation can be separated into two strategies, horizontal and vertical privilege escalation:\n- Horizontal escalation (or account takeover) is where an attacker gains access to a normal user account that has relatively low-level privileges. This may be through stealing the user's username and password. Once they have access, they have gained a foothold, and using this foothold the attacker then may move around the network of users at this same lower level, gaining access to information of this similar privilege.[32]\n- Vertical escalation, however, targets people higher up in a company and often with more administrative power, such as an employee in IT with a higher privilege. Using this privileged account will then enable the attacker to invade other accounts.[32]\nAny computational system affects its environment in some form. This effect it has on its environment can range from electromagnetic radiation, to residual effect on RAM cells which as a consequence make a Cold boot attack possible, to hardware implementation faults that allow for access or guessing of other values that normally should be inaccessible. In Side-channel attack scenarios, the attacker would gather such information about a system or network to guess its internal state and as a result access the information which is assumed by the victim to be secure. The target information in a side channel can be challenging to detect due to its low amplitude when combined with other signals [33]\nSocial engineering, in the context of computer security, aims to convince a user to disclose secrets such as passwords, card numbers, etc. or grant physical access by, for example, impersonating a senior executive, bank, a contractor, or a customer.[34] This generally involves exploiting people's trust, and relying on their cognitive biases. A common scam involves emails sent to accounting and finance department personnel, impersonating their CEO and urgently requesting some action. One of the main techniques of social engineering are phishing attacks.\nIn early 2016, the FBI reported that such business email compromise (BEC) scams had cost US businesses more than $2 billion in about two years.[35]\nIn May 2016, the Milwaukee Bucks NBA team was the victim of this type of cyber scam with a perpetrator impersonating the team's president Peter Feigin, resulting in the handover of all the team's employees' 2015 W-2 tax forms.[36]\nSpoofing is an act of pretending to be a valid entity through the falsification of data (such as an IP address or username), in order to gain access to information or resources that one is otherwise unauthorized to obtain. Spoofing is closely related to phishing.[37][38] There are several types of spoofing, including:\n- Email spoofing is where an attacker forges the sending (From, or source) address of an email.\n- IP address spoofing, where an attacker alters the source IP address in a network packet to hide their identity or impersonate another computing system.\n- MAC spoofing, where an attacker modifies the Media Access Control (MAC) address of their network interface controller to obscure their identity, or to pose as another.\n- Biometric spoofing, where an attacker produces a fake biometric sample to pose as another user.[39]\n- Address Resolution Protocol (ARP) spoofing, where an attacker sends spoofed address resolution protocol onto a local area network to associate their Media Access Control address with a different host's IP address. This causes data to be sent to the attacker rather than the intended host.\nIn 2018, the cybersecurity firm Trellix published research on the life-threatening risk of spoofing in the healthcare industry.[40]\nTampering describes a malicious modification or alteration of data. It is an intentional but unauthorized act resulting in the modification of a system, components of systems, its intended behavior, or data. So-called Evil Maid attacks and security services planting of surveillance capability into routers are examples.[41]\nHTML smuggling allows an attacker to smuggle a malicious code inside a particular HTML or web page.[42] HTML files can carry payloads concealed as benign, inert data in order to defeat content filters. These payloads can be reconstructed on the other side of the filter.[43]\nWhen a target user opens the HTML, the malicious code is activated; the web browser then decodes the script, which then unleashes the malware onto the target's device.[42]\nEmployee behavior can have a big impact on information security in organizations. Cultural concepts can help different segments of the organization work effectively or work against effectiveness toward information security within an organization. Information security culture is the \"...totality of patterns of behavior in an organization that contributes to the protection of information of all kinds.\"[44]\nAndersson and Reimers (2014) found that employees often do not see themselves as part of their organization's information security effort and often take actions that impede organizational changes.[45] Indeed, the Verizon Data Breach Investigations Report 2020, which examined 3,950 security breaches, discovered 30% of cybersecurity incidents involved internal actors within a company.[46] Research shows information security culture needs to be improved continuously. In \"Information Security Culture from Analysis to Change\", authors commented, \"It's a never-ending process, a cycle of evaluation and change or maintenance.\" To manage the information security culture, five steps should be taken: pre-evaluation, strategic planning, operative planning, implementation, and post-evaluation.[47]\n- Pre-evaluation: To identify the awareness of information security within employees and to analyze the current security policies.\n- Strategic planning: To come up with a better awareness program, clear targets need to be set. Assembling a team of skilled professionals is helpful to achieve it.\n- Operative planning: A good security culture can be established based on internal communication, management buy-in, security awareness and a training program.[47]\n- Implementation: Four stages should be used to implement the information security culture. They are:\n- Commitment of the management\n- Communication with organizational members\n- Courses for all organizational members\n- Commitment of the employees[47]\n- Post-evaluation: To assess the success of the planning and implementation, and to identify unresolved areas of concern.\nIn computer security, a countermeasure is an action, device, procedure or technique that reduces a threat, a vulnerability, or an attack by eliminating or preventing it, by minimizing the harm it can cause, or by discovering and reporting it so that corrective action can be taken.[48][49][50]\nSome common countermeasures are listed in the following sections:\nSecurity by design, or alternately secure by design, means that the software has been designed from the ground up to be secure. In this case, security is considered a main feature.\nThe UK government's National Cyber Security Centre separates secure cyber design principles into five sections:[51]\n- Before a secure system is created or updated, companies should ensure they understand the fundamentals and the context around the system they are trying to create and identify any weaknesses in the system.\n- Companies should design and centre their security around techniques and defences which make attacking their data or systems inherently more challenging for attackers.\n- Companies should ensure that their core services that rely on technology are protected so that the systems are essentially never down.\n- Although systems can be created which are safe against a multitude of attacks, that does not mean that attacks will not be attempted. Despite one's security, all companies' systems should aim to be able to detect and spot attacks as soon as they occur to ensure the most effective response to them.\n- Companies should create secure systems designed so that any attack that is successful has minimal severity.\nThese design principles of security by design can include some of the following techniques:\n- The principle of least privilege, where each part of the system has only the privileges that are needed for its function. That way, even if an attacker gains access to that part, they only have limited access to the whole system.\n- Automated theorem proving to prove the correctness of crucial software subsystems.\n- Code reviews and unit testing, approaches to make modules more secure where formal correctness proofs are not possible.\n- Defense in depth, where the design is such that more than one subsystem needs to be violated to compromise the integrity of the system and the information it holds.\n- Default secure settings, and design to fail secure rather than fail insecure (see fail-safe for the equivalent in safety engineering). Ideally, a secure system should require a deliberate, conscious, knowledgeable and free decision on the part of legitimate authorities in order to make it insecure.\n- Audit trails track system activity so that when a security breach occurs, the mechanism and extent of the breach can be determined. Storing audit trails remotely, where they can only be appended to, can keep intruders from covering their tracks.\n- Full disclosure of all vulnerabilities, to ensure that the window of vulnerability is kept as short as possible when bugs are discovered.\nSecurity architecture can be defined as the \"practice of designing computer systems to achieve security goals.\"[52] These goals have overlap with the principles of \"security by design\" explored above, including to \"make initial compromise of the system difficult,\" and to \"limit the impact of any compromise.\"[52] In practice, the role of a security architect would be to ensure the structure of a system reinforces the security of the system, and that new changes are safe and meet the security requirements of the organization.[53][54]\nSimilarly, Techopedia defines security architecture as \"a unified security design that addresses the necessities and potential risks involved in a certain scenario or environment. It also specifies when and where to apply security controls. The design process is generally reproducible.\" The key attributes of security architecture are:[55]\n- the relationship of different components and how they depend on each other.\n- determination of controls based on risk assessment, good practices, finances, and legal matters.\n- the standardization of controls.\nPracticing security architecture provides the right foundation to systematically address business, IT and security concerns in an organization.\nA state of computer security is the conceptual ideal, attained by the use of three processes: threat prevention, detection, and response. These processes are based on various policies and system components, which include the following:\n- Limiting the access of individuals using user account access controls and using cryptography can protect systems files and data, respectively.\n- Firewalls are by far the most common prevention systems from a network security perspective as they can (if properly configured) shield access to internal network services and block certain kinds of attacks through packet filtering. Firewalls can be both hardware and software-based. Firewalls monitor and control incoming and outgoing traffic of a computer network and establish a barrier between a trusted network and an untrusted network.[56]\n- Intrusion Detection System (IDS) products are designed to detect network attacks in-progress and assist in post-attack forensics, while audit trails and logs serve a similar function for individual systems.\n- Response is necessarily defined by the assessed security requirements of an individual system and may cover the range from simple upgrade of protections to notification of legal authorities, counter-attacks, and the like. In some special cases, the complete destruction of the compromised system is favored, as it may happen that not all the compromised resources are detected.\n- Cyber security awareness training to cope with cyber threats and attacks.[57]\n- Forward web proxy solutions can prevent the client to visit malicious web pages and inspect the content before downloading to the client machines.\nToday, computer security consists mainly of preventive measures, like firewalls or an exit procedure. A firewall can be defined as a way of filtering network data between a host or a network and another network, such as the Internet. They can be implemented as software running on the machine, hooking into the network stack (or, in the case of most UNIX-based operating systems such as Linux, built into the operating system kernel) to provide real-time filtering and blocking.[56] Another implementation is a so-called physical firewall, which consists of a separate machine filtering network traffic. Firewalls are common amongst machines that are permanently connected to the Internet.\nSome organizations are turning to big data platforms, such as Apache Hadoop, to extend data accessibility and machine learning to detect advanced persistent threats.[58]\nIn order to ensure adequate security, the confidentiality, integrity and availability of a network, better known as the CIA triad, must be protected and is considered the foundation to information security.[59] To achieve those objectives, administrative, physical and technical security measures should be employed. The amount of security afforded to an asset can only be determined when its value is known.[60]\nVulnerability management is the cycle of identifying, fixing or mitigating vulnerabilities,[61] especially in software and firmware. Vulnerability management is integral to computer security and network security.\nVulnerabilities can be discovered with a vulnerability scanner, which analyzes a computer system in search of known vulnerabilities,[62] such as open ports, insecure software configuration, and susceptibility to malware. In order for these tools to be effective, they must be kept up to date with every new update the vendor releases. Typically, these updates will scan for the new vulnerabilities that were introduced recently.\nBeyond vulnerability scanning, many organizations contract outside security auditors to run regular penetration tests against their systems to identify vulnerabilities. In some sectors, this is a contractual requirement.[63]\nThe act of assessing and reducing vulnerabilities to cyber attacks is commonly referred to as information technology security assessments. They aim to assess systems for risk and to predict and test for their vulnerabilities. While formal verification of the correctness of computer systems is possible,[64][65] it is not yet common. Operating systems formally verified include seL4,[66] and SYSGO's PikeOS[67][68] – but these make up a very small percentage of the market.\nIt is possible to reduce an attacker's chances by keeping systems up to date with security patches and updates and by hiring people with expertise in security. Large companies with significant threats can hire Security Operations Centre (SOC) Analysts. These are specialists in cyber defences, with their role ranging from \"conducting threat analysis to investigating reports of any new issues and preparing and testing disaster recovery plans.\"[69]\nWhilst no measures can completely guarantee the prevention of an attack, these measures can help mitigate the damage of possible attacks. The effects of data loss/damage can be also reduced by careful backing up and insurance.\nOutside of formal assessments, there are various methods of reducing vulnerabilities, including hardening systems.[70] Two factor authentication is a method for mitigating unauthorized access to a system or sensitive information.[71] It requires something you know: a password or PIN, and something you have: a card, dongle, cellphone, or another piece of hardware. This increases security as an unauthorized person needs both of these to gain access.\nProtecting against social engineering and direct computer access (physical) attacks can only happen by non-computer means, which can be difficult to enforce, relative to the sensitivity of the information. Training is often involved to help mitigate this risk by improving people's knowledge of how to protect themselves and by increasing people's awareness of threats.[72] However, even in highly disciplined environments (e.g. military organizations), social engineering attacks can still be difficult to foresee and prevent.\nInoculation, derived from inoculation theory, seeks to prevent social engineering and other fraudulent tricks and traps by instilling a resistance to persuasion attempts through exposure to similar or related attempts.[73]\nHardware-based or assisted computer security also offers an alternative to software-only computer security. Using devices and methods such as dongles, trusted platform modules, intrusion-aware cases, drive locks, disabling USB ports, and mobile-enabled access may be considered more secure due to the physical access (or sophisticated backdoor access) required in order to be compromised. Each of these is covered in more detail below.\n- USB dongles are typically used in software licensing schemes to unlock software capabilities,[74] but they can also be seen as a way to prevent unauthorized access to a computer or other device's software. The dongle, or key, essentially creates a secure encrypted tunnel between the software application and the key. The principle is that an encryption scheme on the dongle, such as Advanced Encryption Standard (AES) provides a stronger measure of security since it is harder to hack and replicate the dongle than to simply copy the native software to another machine and use it. Another security application for dongles is to use them for accessing web-based content such as cloud software or Virtual Private Networks (VPNs).[75] In addition, a USB dongle can be configured to lock or unlock a computer.[76]\n- Trusted platform modules (TPMs) secure devices by integrating cryptographic capabilities onto access devices, through the use of microprocessors, or so-called computers-on-a-chip. TPMs used in conjunction with server-side software offer a way to detect and authenticate hardware devices, preventing unauthorized network and data access.[77]\n- Computer case intrusion detection refers to a device, typically a push-button switch, which detects when a computer case is opened. The firmware or BIOS is programmed to show an alert to the operator when the computer is booted up the next time.\n- Drive locks are essentially software tools to encrypt hard drives, making them inaccessible to thieves.[78] Tools exist specifically for encrypting external drives as well.[79]\n- Disabling USB ports is a security option for preventing unauthorized and malicious access to an otherwise secure computer. Infected USB dongles connected to a network from a computer inside the firewall are considered by the magazine Network World as the most common hardware threat facing computer networks.\n- Disconnecting or disabling peripheral devices (like camera, GPS, removable storage, etc.), that are not in use.[80]\n- Mobile-enabled access devices are growing in popularity due to the ubiquitous nature of cell phones.[81] Built-in capabilities such as Bluetooth, the newer Bluetooth low-energy (LE), near-field communication (NFC) on non-iOS devices and biometric validation such as thumbprint readers, as well as QR code reader software designed for mobile devices, offer new, secure ways for mobile phones to connect to access control systems. These control systems provide computer security and can also be used for controlling access to secure buildings.[82]\n- IOMMUs allow for hardware-based sandboxing of components in mobile and desktop computers by utilizing direct memory access protections.[83][84]\n- Physical Unclonable Functions (PUFs) can be used as a digital fingerprint or a unique identifier to integrated circuits and hardware, providing users the ability to secure the hardware supply chains going into their systems.[85][86]\nOne use of the term computer security refers to technology that is used to implement secure operating systems. Using secure operating systems is a good way of ensuring computer security. These are systems that have achieved certification from an external security-auditing organization, the most popular evaluations are Common Criteria (CC).[87]\nIn software engineering, secure coding aims to guard against the accidental introduction of security vulnerabilities. It is also possible to create software designed from the ground up to be secure. Such systems are secure by design. Beyond this, formal verification aims to prove the correctness of the algorithms underlying a system;[88] important for cryptographic protocols for example.\nWithin computer systems, two of the main security models capable of enforcing privilege separation are access control lists (ACLs) and role-based access control (RBAC).\nAn access-control list (ACL), with respect to a computer file system, is a list of permissions associated with an object. An ACL specifies which users or system processes are granted access to objects, as well as what operations are allowed on given objects.\nRole-based access control is an approach to restricting system access to authorized users,[89][90][91] used by the majority of enterprises with more than 500 employees,[92] and can implement mandatory access control (MAC) or discretionary access control (DAC).\nA further approach, capability-based security has been mostly restricted to research operating systems. Capabilities can, however, also be implemented at the language level, leading to a style of programming that is essentially a refinement of standard object-oriented design. An open-source project in the area is the E language.\nThe end-user is widely recognized as the weakest link in the security chain[93] and it is estimated that more than 90% of security incidents and breaches involve some kind of human error.[94][95] Among the most commonly recorded forms of errors and misjudgment are poor password management, sending emails containing sensitive data and attachments to the wrong recipient, the inability to recognize misleading URLs and to identify fake websites and dangerous email attachments. A common mistake that users make is saving their user id/password in their browsers to make it easier to log in to banking sites. This is a gift to attackers who have obtained access to a machine by some means. The risk may be mitigated by the use of two-factor authentication.[96]\nAs the human component of cyber risk is particularly relevant in determining the global cyber risk[97] an organization is facing, security awareness training, at all levels, not only provides formal compliance with regulatory and industry mandates but is considered essential[98] in reducing cyber risk and protecting individuals and companies from the great majority of cyber threats.\nThe focus on the end-user represents a profound cultural change for many security practitioners, who have traditionally approached cybersecurity exclusively from a technical perspective, and moves along the lines suggested by major security centers[99] to develop a culture of cyber awareness within the organization, recognizing that a security-aware user provides an important line of defense against cyber attacks.\nRelated to end-user training, digital hygiene or cyber hygiene is a fundamental principle relating to information security and, as the analogy with personal hygiene shows, is the equivalent of establishing simple routine measures to minimize the risks from cyber threats. The assumption is that good cyber hygiene practices can give networked users another layer of protection, reducing the risk that one vulnerable node will be used to either mount attacks or compromise another node or network, especially from common cyberattacks.[100] Cyber hygiene should also not be mistaken for proactive cyber defence, a military term.[101]\nThe most common acts of digital hygiene can include updating malware protection, cloud back-ups, passwords, and ensuring restricted admin rights and network firewalls.[102] As opposed to a purely technology-based defense against threats, cyber hygiene mostly regards routine measures that are technically simple to implement and mostly dependent on discipline[103] or education.[104] It can be thought of as an abstract list of tips or measures that have been demonstrated as having a positive effect on personal or collective digital security. As such, these measures can be performed by laypeople, not just security experts.\nCyber hygiene relates to personal hygiene as computer viruses relate to biological viruses (or pathogens). However, while the term computer virus was coined almost simultaneously with the creation of the first working computer viruses,[105] the term cyber hygiene is a much later invention, perhaps as late as 2000[106] by Internet pioneer Vint Cerf. It has since been adopted by the Congress[107] and Senate of the United States,[108] the FBI,[109] EU institutions[100] and heads of state.[101]\nResponding to attempted security breaches is often very difficult for a variety of reasons, including:\n- Identifying attackers is difficult, as they may operate through proxies, temporary anonymous dial-up accounts, wireless connections, and other anonymizing procedures which make back-tracing difficult – and are often located in another jurisdiction. If they successfully breach security, they have also often gained enough administrative access to enable them to delete logs to cover their tracks.\n- The sheer number of attempted attacks, often by automated vulnerability scanners and computer worms, is so large that organizations cannot spend time pursuing each.\n- Law enforcement officers often lack the skills, interest or budget to pursue attackers. Furthermore, identifying attackers across a network may necessitate collecting logs from multiple locations within the network and across various countries, a process that can be both difficult and time-consuming.\nWhere an attack succeeds and a breach occurs, many jurisdictions now have in place mandatory security breach notification laws.\n- Access control\n- Anti-keyloggers\n- Anti-malware\n- Anti-spyware\n- Anti-subversion software\n- Anti-tamper software\n- Anti-theft\n- Antivirus software\n- Cryptographic software\n- Computer-aided dispatch (CAD)\n- Data loss prevention software\n- Firewall\n- Intrusion detection system (IDS)\n- Intrusion prevention system (IPS)\n- Log management software\n- Parental control\n- Records management\n- Sandbox\n- Security information management\n- Security information and event management (SIEM)\n- Software and operating system updating\n- Vulnerability Management\nThe growth in the number of computer systems and the increasing reliance upon them by individuals, businesses, industries, and governments means that there are an increasing number of systems at risk.\nThe computer systems of financial regulators and financial institutions like the U.S. Securities and Exchange Commission, SWIFT, investment banks, and commercial banks are prominent hacking targets for cybercriminals interested in manipulating markets and making illicit gains.[110] Websites and apps that accept or store credit card numbers, brokerage accounts, and bank account information are also prominent hacking targets, because of the potential for immediate financial gain from transferring money, making purchases, or selling the information on the black market.[111] In-store payment systems and ATMs have also been tampered with in order to gather customer account data and PINs.\nThe UCLA Internet Report: Surveying the Digital Future (2000) found that the privacy of personal data created barriers to online sales and that more than nine out of 10 internet users were somewhat or very concerned about credit card security.[112]\nThe most common web technologies for improving security between browsers and websites are named SSL (Secure Sockets Layer), and its successor TLS (Transport Layer Security), identity management and authentication services, and domain name services allow companies and consumers to engage in secure communications and commerce. Several versions of SSL and TLS are commonly used today in applications such as web browsing, e-mail, internet faxing, instant messaging, and VoIP (voice-over-IP). There are various interoperable implementations of these technologies, including at least one implementation that is open source. Open source allows anyone to view the application's source code, and look for and report vulnerabilities.\nThe credit card companies Visa and MasterCard cooperated to develop the secure EMV chip which is embedded in credit cards. Further developments include the Chip Authentication Program where banks give customers hand-held card readers to perform online secure transactions. Other developments in this arena include the development of technology such as Instant Issuance which has enabled shopping mall kiosks acting on behalf of banks to issue on-the-spot credit cards to interested customers.\nComputers control functions at many utilities, including coordination of telecommunications, the power grid, nuclear power plants, and valve opening and closing in water and gas networks. The Internet is a potential attack vector for such machines if connected, but the Stuxnet worm demonstrated that even equipment controlled by computers not connected to the Internet can be vulnerable. In 2014, the Computer Emergency Readiness Team, a division of the Department of Homeland Security, investigated 79 hacking incidents at energy companies.[113]\nThe aviation industry is very reliant on a series of complex systems which could be attacked.[114] A simple power outage at one airport can cause repercussions worldwide,[115] much of the system relies on radio transmissions which could be disrupted,[116] and controlling aircraft over oceans is especially dangerous because radar surveillance only extends 175 to 225 miles offshore.[117] There is also potential for attack from within an aircraft.[118]\nImplementing fixes in aerospace systems poses a unique challenge because efficient air transportation is heavily affected by weight and volume. Improving security by adding physical devices to airplanes could increase their unloaded weight, and could potentially reduce cargo or passenger capacity.[119]\nIn Europe, with the (Pan-European Network Service)[120] and NewPENS,[121] and in the US with the NextGen program,[122] air navigation service providers are moving to create their own dedicated networks.\nMany modern passports are now biometric passports, containing an embedded microchip that stores a digitized photograph and personal information such as name, gender, and date of birth. In addition, more countries[which?] are introducing facial recognition technology to reduce identity-related fraud. The introduction of the ePassport has assisted border officials in verifying the identity of the passport holder, thus allowing for quick passenger processing.[123] Plans are under way in the US, the UK, and Australia to introduce SmartGate kiosks with both retina and fingerprint recognition technology.[124] The airline industry is moving from the use of traditional paper tickets towards the use of electronic tickets (e-tickets). These have been made possible by advances in online credit card transactions in partnership with the airlines. Long-distance bus companies[which?] are also switching over to e-ticketing transactions today.\nThe consequences of a successful attack range from loss of confidentiality to loss of system integrity, air traffic control outages, loss of aircraft, and even loss of life.\nDesktop computers and laptops are commonly targeted to gather passwords or financial account information or to construct a botnet to attack another target. Smartphones, tablet computers, smart watches, and other mobile devices such as quantified self devices like activity trackers have sensors such as cameras, microphones, GPS receivers, compasses, and accelerometers which could be exploited, and may collect personal information, including sensitive health information. WiFi, Bluetooth, and cell phone networks on any of these devices could be used as attack vectors, and sensors might be remotely activated after a successful breach.[125]\nThe increasing number of home automation devices such as the Nest thermostat are also potential targets.[125]\nToday many healthcare providers and health insurance companies use the internet to provide enhanced products and services. Examples are the use of tele-health to potentially offer better quality and access to healthcare, or fitness trackers to lower insurance premiums.[126] Patient records are increasingly being placed on secure in-house networks, alleviating the need for extra storage space.[127]\nLarge corporations are common targets. In many cases attacks are aimed at financial gain through identity theft and involve data breaches. Examples include the loss of millions of clients' credit card and financial details by Home Depot,[128] Staples,[129] Target Corporation,[130] and Equifax.[131]\nMedical records have been targeted in general identify theft, health insurance fraud, and impersonating patients to obtain prescription drugs for recreational purposes or resale.[132] Although cyber threats continue to increase, 62% of all organizations did not increase security training for their business in 2015.[133]\nNot all attacks are financially motivated, however: security firm HBGary Federal had a serious series of attacks in 2011 from hacktivist group Anonymous in retaliation for the firm's CEO claiming to have infiltrated their group,[134][135] and Sony Pictures was hacked in 2014 with the apparent dual motive of embarrassing the company through data leaks and crippling the company by wiping workstations and servers.[136][137]\nVehicles are increasingly computerized, with engine timing, cruise control, anti-lock brakes, seat belt tensioners, door locks, airbags and advanced driver-assistance systems on many models. Additionally, connected cars may use WiFi and Bluetooth to communicate with onboard consumer devices and the cell phone network.[138] Self-driving cars are expected to be even more complex. All of these systems carry some security risks, and such issues have gained wide attention.[139][140][141]\nSimple examples of risk include a malicious compact disc being used as an attack vector,[142] and the car's onboard microphones being used for eavesdropping. However, if access is gained to a car's internal controller area network, the danger is much greater[138] – and in a widely publicized 2015 test, hackers remotely carjacked a vehicle from 10 miles away and drove it into a ditch.[143][144]\nManufacturers are reacting in numerous ways, with Tesla in 2016 pushing out some security fixes over the air into its cars' computer systems.[145] In the area of autonomous vehicles, in September 2016 the United States Department of Transportation announced some initial safety standards, and called for states to come up with uniform policies.[146][147][148]\nAdditionally, e-Drivers' licenses are being developed using the same technology. For example, Mexico's licensing authority (ICV) has used a smart card platform to issue the first e-Drivers' licenses to the city of Monterrey, in the state of Nuevo León.[149]\nShipping companies[150] have adopted RFID (Radio Frequency Identification) technology as an efficient, digitally secure, tracking device. Unlike a barcode, RFID can be read up to 20 feet away. RFID is used by FedEx[151] and UPS.[152]\nGovernment and military computer systems are commonly attacked by activists[153][154][155] and foreign powers.[156][157][158][159] Local and regional government infrastructure such as traffic light controls, police and intelligence agency communications, personnel records, as well as student records.[160]\nThe FBI, CIA, and Pentagon, all utilize secure controlled access technology for any of their buildings. However, the use of this form of technology is spreading into the entrepreneurial world. More and more companies are taking advantage of the development of digitally secure controlled access technology. GE's ACUVision, for example, offers a single panel platform for access control, alarm monitoring and digital recording.[161]\nThe Internet of things (IoT) is the network of physical objects such as devices, vehicles, and buildings that are embedded with electronics, software, sensors, and network connectivity that enables them to collect and exchange data.[162] Concerns have been raised that this is being developed without appropriate consideration of the security challenges involved.[163][164]\nWhile the IoT creates opportunities for more direct integration of the physical world into computer-based systems,[165][166] it also provides opportunities for misuse. In particular, as the Internet of Things spreads widely, cyberattacks are likely to become an increasingly physical (rather than simply virtual) threat.[167] If a front door's lock is connected to the Internet, and can be locked/unlocked from a phone, then a criminal could enter the home at the press of a button from a stolen or hacked phone. People could stand to lose much more than their credit card numbers in a world controlled by IoT-enabled devices. Thieves have also used electronic means to circumvent non-Internet-connected hotel door locks.[168]\nAn attack aimed at physical infrastructure or human lives is often called a cyber-kinetic attack. As IoT devices and appliances become more widespread, the prevalence and potential damage of cyber-kinetic attacks can increase substantially.\nMedical devices have either been successfully attacked or had potentially deadly vulnerabilities demonstrated, including both in-hospital diagnostic equipment[169] and implanted devices including pacemakers[170] and insulin pumps.[171] There are many reports of hospitals and hospital organizations getting hacked, including ransomware attacks,[172][173][174][175] Windows XP exploits,[176][177] viruses,[178][179] and data breaches of sensitive data stored on hospital servers.[180][173][181][182] On 28 December 2016 the US Food and Drug Administration released its recommendations for how medical device manufacturers should maintain the security of Internet-connected devices – but no structure for enforcement.[183][184]\nIn distributed generation systems, the risk of a cyber attack is real, according to Daily Energy Insider. An attack could cause a loss of power in a large area for a long period of time, and such an attack could have just as severe consequences as a natural disaster. The District of Columbia is considering creating a Distributed Energy Resources (DER) Authority within the city, with the goal being for customers to have more insight into their own energy use and giving the local electric utility, Pepco, the chance to better estimate energy demand. The D.C. proposal, however, would \"allow third-party vendors to create numerous points of energy distribution, which could potentially create more opportunities for cyber attackers to threaten the electric grid.\"[185]\nPerhaps the most widely known digitally secure telecommunication device is the SIM (Subscriber Identity Module) card, a device that is embedded in most of the world's cellular devices before any service can be obtained. The SIM card is just the beginning of this digitally secure environment.\nThe Smart Card Web Servers draft standard (SCWS) defines the interfaces to an HTTP server in a smart card.[186] Tests are being conducted to secure OTA (\"over-the-air\") payment and credit card information from and to a mobile phone. Combination SIM/DVD devices are being developed through Smart Video Card technology which embeds a DVD-compliant optical disc into the card body of a regular SIM card.\nOther telecommunication developments involving digital security include mobile signatures, which use the embedded SIM card to generate a legally binding electronic signature.\nSerious financial damage has been caused by security breaches, but because there is no standard model for estimating the cost of an incident, the only data available is that which is made public by the organizations involved. \"Several computer security consulting firms produce estimates of total worldwide losses attributable to virus and worm attacks and to hostile digital acts in general. The 2003 loss estimates by these firms range from $13 billion (worms and viruses only) to $226 billion (for all forms of covert attacks). The reliability of these estimates is often challenged; the underlying methodology is basically anecdotal.\"[187]\nHowever, reasonable estimates of the financial cost of security breaches can actually help organizations make rational investment decisions. According to the classic Gordon-Loeb Model analyzing the optimal investment level in information security, one can conclude that the amount a firm spends to protect information should generally be only a small fraction of the expected loss (i.e., the expected value of the loss resulting from a cyber/information security breach).[188]\nAs with physical security, the motivations for breaches of computer security vary between attackers. Some are thrill-seekers or vandals, some are activists, others are criminals looking for financial gain. State-sponsored attackers are now common and well resourced but started with amateurs such as Markus Hess who hacked for the KGB, as recounted by Clifford Stoll in The Cuckoo's Egg.\nAttackers motivations can vary for all types of attacks from pleasure to political goals.[15] For example, hacktivists may target a company or organization that carries out activities they do not agree with. This would be to create bad publicity for the company by having its website crash.\nHigh capability hackers, often with larger backing or state sponsorship, may attack based on the demands of their financial backers. These attacks are more likely to attempt more serious attack. An example of a more serious attack was the 2015 Ukraine power grid hack, which reportedly utilised the spear-phising, destruction of files, and denial-of-service attacks to carry out the full attack.[189][190]\nAdditionally, recent attacker motivations can be traced back to extremist organizations seeking to gain political advantage or disrupt social agendas.[191] The growth of the internet, mobile technologies, and inexpensive computing devices have led to a rise in capabilities but also to the risk to environments that are deemed as vital to operations. All critical targeted environments are susceptible to compromise and this has led to a series of proactive studies on how to migrate the risk by taking into consideration motivations by these types of actors. Several stark differences exist between the hacker motivation and that of nation state actors seeking to attack based on an ideological preference.[192]\nA key aspect of threat modeling for any system is identifying the motivations behind potential attacks and the individuals or groups likely to carry them out. The level and detail of security measures will differ based on the specific system being protected. For instance, a home personal computer, a bank, and a classified military network each face distinct threats, despite using similar underlying technologies.[193]\nComputer security incident management is an organized approach to addressing and managing the aftermath of a computer security incident or compromise with the goal of preventing a breach or thwarting a cyberattack. An incident that is not identified and managed at the time of intrusion typically escalates to a more damaging event such as a data breach or system failure. The intended outcome of a computer security incident response plan is to contain the incident, limit damage and assist recovery to business as usual. Responding to compromises quickly can mitigate exploited vulnerabilities, restore services and processes and minimize losses.[194] Incident response planning allows an organization to establish a series of best practices to stop an intrusion before it causes damage. Typical incident response plans contain a set of written instructions that outline the organization's response to a cyberattack. Without a documented plan in place, an organization may not successfully detect an intrusion or compromise and stakeholders may not understand their roles, processes and procedures during an escalation, slowing the organization's response and resolution.\nThere are four key components of a computer security incident response plan:\n- Preparation: Preparing stakeholders on the procedures for handling computer security incidents or compromises\n- Detection and analysis: Identifying and investigating suspicious activity to confirm a security incident, prioritizing the response based on impact and coordinating notification of the incident\n- Containment, eradication and recovery: Isolating affected systems to prevent escalation and limit impact, pinpointing the genesis of the incident, removing malware, affected systems and bad actors from the environment and restoring systems and data when a threat no longer remains\n- Post incident activity: Post mortem analysis of the incident, its root cause and the organization's response with the intent of improving the incident response plan and future response efforts.[195]\nSome illustrative examples of different types of computer security breaches are given below.\nIn 1988, 60,000 computers were connected to the Internet, and most were mainframes, minicomputers and professional workstations. On 2 November 1988, many started to slow down, because they were running a malicious code that demanded processor time and that spread itself to other computers – the first internet computer worm.[196] The software was traced back to 23-year-old Cornell University graduate student Robert Tappan Morris who said \"he wanted to count how many machines were connected to the Internet\".[196]\nIn 1994, over a hundred intrusions were made by unidentified crackers into the Rome Laboratory, the US Air Force's main command and research facility. Using trojan horses, hackers were able to obtain unrestricted access to Rome's networking systems and remove traces of their activities. The intruders were able to obtain classified files, such as air tasking order systems data and furthermore able to penetrate connected networks of National Aeronautics and Space Administration's Goddard Space Flight Center, Wright-Patterson Air Force Base, some Defense contractors, and other private sector organizations, by posing as a trusted Rome center user.[197]\nIn early 2007, American apparel and home goods company TJX announced that it was the victim of an unauthorized computer systems intrusion[198] and that the hackers had accessed a system that stored data on credit card, debit card, check, and merchandise return transactions.[199]\nIn 2010, the computer worm known as Stuxnet reportedly ruined almost one-fifth of Iran's nuclear centrifuges.[200] It did so by disrupting industrial programmable logic controllers (PLCs) in a targeted attack. This is generally believed to have been launched by Israel and the United States to disrupt Iran's nuclear program[201][202][203][204] – although neither has publicly admitted this.\nIn early 2013, documents provided by Edward Snowden were published by The Washington Post and The Guardian[205][206] exposing the massive scale of NSA global surveillance. There were also indications that the NSA may have inserted a backdoor in a NIST standard for encryption.[207] This standard was later withdrawn due to widespread criticism.[208] The NSA additionally were revealed to have tapped the links between Google's data centers.[209]\nA Ukrainian hacker known as Rescator broke into Target Corporation computers in 2013, stealing roughly 40 million credit cards,[210] and then Home Depot computers in 2014, stealing between 53 and 56 million credit card numbers.[211] Warnings were delivered at both corporations, but ignored; physical security breaches using self checkout machines are believed to have played a large role. \"The malware utilized is absolutely unsophisticated and uninteresting,\" says Jim Walter, director of threat intelligence operations at security technology company McAfee – meaning that the heists could have easily been stopped by existing antivirus software had administrators responded to the warnings. The size of the thefts has resulted in major attention from state and Federal United States authorities and the investigation is ongoing.\nIn April 2015, the Office of Personnel Management discovered it had been hacked more than a year earlier in a data breach, resulting in the theft of approximately 21.5 million personnel records handled by the office.[212] The Office of Personnel Management hack has been described by federal officials as among the largest breaches of government data in the history of the United States.[213] Data targeted in the breach included personally identifiable information such as Social Security numbers, names, dates and places of birth, addresses, and fingerprints of current and former government employees as well as anyone who had undergone a government background check.[214][215] It is believed the hack was perpetrated by Chinese hackers.[216]\nIn July 2015, a hacker group known as The Impact Team successfully breached the extramarital relationship website Ashley Madison, created by Avid Life Media. The group claimed that they had taken not only company data but user data as well. After the breach, The Impact Team dumped emails from the company's CEO, to prove their point, and threatened to dump customer data unless the website was taken down permanently.[217] When Avid Life Media did not take the site offline the group released two more compressed files, one 9.7GB and the second 20GB. After the second data dump, Avid Life Media CEO Noel Biderman resigned; but the website remained to function.\nIn June 2021, the cyber attack took down the largest fuel pipeline in the U.S. and led to shortages across the East Coast.[218]\nInternational legal issues of cyber attacks are complicated in nature. There is no global base of common rules to judge, and eventually punish, cybercrimes and cybercriminals - and where security firms or agencies do locate the cybercriminal behind the creation of a particular piece of malware or form of cyber attack, often the local authorities cannot take action due to lack of laws under which to prosecute.[219][220] Proving attribution for cybercrimes and cyberattacks is also a major problem for all law enforcement agencies. \"Computer viruses switch from one country to another, from one jurisdiction to another – moving around the world, using the fact that we don't have the capability to globally police operations like this. So the Internet is as if someone [had] given free plane tickets to all the online criminals of the world.\"[219] The use of techniques such as dynamic DNS, fast flux and bullet proof servers add to the difficulty of investigation and enforcement.\nThe role of the government is to make regulations to force companies and organizations to protect their systems, infrastructure and information from any cyberattacks, but also to protect its own national infrastructure such as the national power-grid.[221]\nThe government's regulatory role in cyberspace is complicated. For some, cyberspace was seen as a virtual space that was to remain free of government intervention, as can be seen in many of today's libertarian blockchain and bitcoin discussions.[222]\nMany government officials and experts think that the government should do more and that there is a crucial need for improved regulation, mainly due to the failure of the private sector to solve efficiently the cybersecurity problem. R. Clarke said during a panel discussion at the RSA Security Conference in San Francisco, he believes that the \"industry only responds when you threaten regulation. If the industry doesn't respond (to the threat), you have to follow through.\"[223] On the other hand, executives from the private sector agree that improvements are necessary, but think that government intervention would affect their ability to innovate efficiently. Daniel R. McCarthy analyzed this public-private partnership in cybersecurity and reflected on the role of cybersecurity in the broader constitution of political order.[224]\nOn 22 May 2020, the UN Security Council held its second ever informal meeting on cybersecurity to focus on cyber challenges to international peace. According to UN Secretary-General António Guterres, new technologies are too often used to violate rights.[225]\nMany different teams and organizations exist, including:\n- The Forum of Incident Response and Security Teams (FIRST) is the global association of CSIRTs.[226] The US-CERT, AT&T, Apple, Cisco, McAfee, Microsoft are all members of this international team.[227]\n- The Council of Europe helps protect societies worldwide from the threat of cybercrime through the Convention on Cybercrime.[228]\n- The purpose of the Messaging Anti-Abuse Working Group (MAAWG) is to bring the messaging industry together to work collaboratively and to successfully address the various forms of messaging abuse, such as spam, viruses, denial-of-service attacks and other messaging exploitations.[229] France Telecom, Facebook, AT&T, Apple, Cisco, Sprint are some of the members of the MAAWG.[230]\n- ENISA : The European Network and Information Security Agency (ENISA) is an agency of the European Union with the objective to improve network and information security in the European Union.\nOn 14 April 2016, the European Parliament and the Council of the European Union adopted the General Data Protection Regulation (GDPR). The GDPR, which came into force on 25 May 2018, grants individuals within the European Union (EU) and the European Economic Area (EEA) the right to the protection of personal data. The regulation requires that any entity that processes personal data incorporate data protection by design and by default. It also requires that certain organizations appoint a Data Protection Officer (DPO).\nThe IT Security Association TeleTrusT exist in Germany since June 1986, which is an international competence network for IT security.\nMost countries have their own computer emergency response team to protect network security.\nSince 2010, Canada has had a cybersecurity strategy.[231][232] This functions as a counterpart document to the National Strategy and Action Plan for Critical Infrastructure.[233] The strategy has three main pillars: securing government systems, securing vital private cyber systems, and helping Canadians to be secure online.[232][233] There is also a Cyber Incident Management Framework to provide a coordinated response in the event of a cyber incident.[234][235]\nThe Canadian Cyber Incident Response Centre (CCIRC) is responsible for mitigating and responding to threats to Canada's critical infrastructure and cyber systems. It provides support to mitigate cyber threats, technical support to respond & recover from targeted cyber attacks, and provides online tools for members of Canada's critical infrastructure sectors.[236] It posts regular cybersecurity bulletins[237] & operates an online reporting tool where individuals and organizations can report a cyber incident.[238]\nTo inform the general public on how to protect themselves online, Public Safety Canada has partnered with STOP.THINK.CONNECT, a coalition of non-profit, private sector, and government organizations,[239] and launched the Cyber Security Cooperation Program.[240][241] They also run the GetCyberSafe portal for Canadian citizens, and Cyber Security Awareness Month during October.[242]\nPublic Safety Canada aims to begin an evaluation of Canada's cybersecurity strategy in early 2015.[233]\nAustralian federal government announced an $18.2 million investment to fortify the cybersecurity resilience of small and medium enterprises (SMEs) and enhance their capabilities in responding to cyber threats. This financial backing is an integral component of the 2023-2030 Australian Cyber Security Strategy. A substantial allocation of $7.2 million is earmarked for the establishment of a voluntary cyber health check program, facilitating businesses in conducting a comprehensive and tailored self-assessment of their cybersecurity upskill.\nThis avant-garde health assessment serves as a diagnostic tool, enabling enterprises to ascertain the robustness of Australia's cyber security regulations. Furthermore, it affords them access to a repository of educational resources and materials, fostering the acquisition of skills necessary for an elevated cybersecurity posture. This groundbreaking initiative was jointly disclosed by Minister for Cyber Security Clare O'Neil and Minister for Small Business Julie Collins.[243]\nSome provisions for cybersecurity have been incorporated into rules framed under the Information Technology Act 2000.[244]\nThe National Cyber Security Policy 2013 is a policy framework by the Ministry of Electronics and Information Technology (MeitY) which aims to protect the public and private infrastructure from cyberattacks, and safeguard \"information, such as personal information (of web users), financial and banking information and sovereign data\". CERT- In is the nodal agency which monitors the cyber threats in the country. The post of National Cyber Security Coordinator has also been created in the Prime Minister's Office (PMO).\nThe Indian Companies Act 2013 has also introduced cyber law and cybersecurity obligations on the part of Indian directors. Some provisions for cybersecurity have been incorporated into rules framed under the Information Technology Act 2000 Update in 2013.[245]\nFollowing cyberattacks in the first half of 2013, when the government, news media, television stations, and bank websites were compromised, the national government committed to the training of 5,000 new cybersecurity experts by 2017. The South Korean government blamed its northern counterpart for these attacks, as well as incidents that occurred in 2009, 2011,[246] and 2012, but Pyongyang denies the accusations.[247]\nThe United States has its first fully formed cyber plan in 15 years, as a result of the release of this National Cyber plan.[248] In this policy, the US says it will: Protect the country by keeping networks, systems, functions, and data safe; Promote American wealth by building a strong digital economy and encouraging strong domestic innovation; Peace and safety should be kept by making it easier for the US to stop people from using computer tools for bad things, working with friends and partners to do this; and increase the United States' impact around the world to support the main ideas behind an open, safe, reliable, and compatible Internet.[249]\nThe new U.S. cyber strategy[250] seeks to allay some of those concerns by promoting responsible behavior in cyberspace, urging nations to adhere to a set of norms, both through international law and voluntary standards. It also calls for specific measures to harden U.S. government networks from attacks, like the June 2015 intrusion into the U.S. Office of Personnel Management (OPM), which compromised the records of about 4.2 million current and former government employees. And the strategy calls for the U.S. to continue to name and shame bad cyber actors, calling them out publicly for attacks when possible, along with the use of economic sanctions and diplomatic pressure.[251]\nThe 1986 18 U.S.C. § 1030, the Computer Fraud and Abuse Act is the key legislation. It prohibits unauthorized access or damage of protected computers as defined in . Although various other measures have been proposed[252][253] – none have succeeded.\nIn 2013, executive order 13636 Improving Critical Infrastructure Cybersecurity was signed, which prompted the creation of the NIST Cybersecurity Framework.\nIn response to the Colonial Pipeline ransomware attack[254] President Joe Biden signed Executive Order 14028[255] on May 12, 2021, to increase software security standards for sales to the government, tighten detection and security on existing systems, improve information sharing and training, establish a Cyber Safety Review Board, and improve incident response.\nThe General Services Administration (GSA) has[when?] standardized the penetration test service as a pre-vetted support service, to rapidly address potential vulnerabilities, and stop adversaries before they impact US federal, state and local governments. These services are commonly referred to as Highly Adaptive Cybersecurity Services (HACS).\nThe Department of Homeland Security has a dedicated division responsible for the response system, risk management program and requirements for cybersecurity in the United States called the National Cyber Security Division.[256][257] The division is home to US-CERT operations and the National Cyber Alert System.[257] The National Cybersecurity and Communications Integration Center brings together government organizations responsible for protecting computer networks and networked infrastructure.[258]\nThe third priority of the FBI is to: \"Protect the United States against cyber-based attacks and high-technology crimes\",[259] and they, along with the National White Collar Crime Center (NW3C), and the Bureau of Justice Assistance (BJA) are part of the multi-agency task force, The Internet Crime Complaint Center, also known as IC3.[260]\nIn addition to its own specific duties, the FBI participates alongside non-profit organizations such as InfraGard.[261][262]\nThe Computer Crime and Intellectual Property Section (CCIPS) operates in the United States Department of Justice Criminal Division. The CCIPS is in charge of investigating computer crime and intellectual property crime and is specialized in the search and seizure of digital evidence in computers and networks.[263] In 2017, CCIPS published A Framework for a Vulnerability Disclosure Program for Online Systems to help organizations \"clearly describe authorized vulnerability disclosure and discovery conduct, thereby substantially reducing the likelihood that such described activities will result in a civil or criminal violation of law under the Computer Fraud and Abuse Act (18 U.S.C. § 1030).\"[264]\nThe United States Cyber Command, also known as USCYBERCOM, \"has the mission to direct, synchronize, and coordinate cyberspace planning and operations to defend and advance national interests in collaboration with domestic and international partners.\"[265] It has no role in the protection of civilian networks.[266][267]\nThe U.S. Federal Communications Commission's role in cybersecurity is to strengthen the protection of critical communications infrastructure, to assist in maintaining the reliability of networks during disasters, to aid in swift recovery after, and to ensure that first responders have access to effective communications services.[268]\nThe Food and Drug Administration has issued guidance for medical devices,[269] and the National Highway Traffic Safety Administration[270] is concerned with automotive cybersecurity. After being criticized by the Government Accountability Office,[271] and following successful attacks on airports and claimed attacks on airplanes, the Federal Aviation Administration has devoted funding to securing systems on board the planes of private manufacturers, and the Aircraft Communications Addressing and Reporting System.[272] Concerns have also been raised about the future Next Generation Air Transportation System.[273]\nThe US Department of Defense (DoD) issued DoD Directive 8570 in 2004, supplemented by DoD Directive 8140, requiring all DoD employees and all DoD contract personnel involved in information assurance roles and activities to earn and maintain various industry Information Technology (IT) certifications in an effort to ensure that all DoD personnel involved in network infrastructure defense have minimum levels of IT industry recognized knowledge, skills and abilities (KSA). Andersson and Reimers (2019) report these certifications range from CompTIA's A+ and Security+ through the ICS2.org's CISSP, etc.[274]\nComputer emergency response team is a name given to expert groups that handle computer security incidents. In the US, two distinct organizations exist, although they do work closely together.\n- US-CERT: part of the National Cyber Security Division of the United States Department of Homeland Security.[275]\n- CERT/CC: created by the Defense Advanced Research Projects Agency (DARPA) and run by the Software Engineering Institute (SEI).\nIn the context of U.S. nuclear power plants, the U.S. Nuclear Regulatory Commission (NRC) outlines cybersecurity requirements under 10 CFR Part 73, specifically in §73.54.[276]\nThe Nuclear Energy Institute's NEI 08-09 document, Cyber Security Plan for Nuclear Power Reactors,[277] outlines a comprehensive framework for cybersecurity in the nuclear power industry. Drafted with input from the U.S. NRC, this guideline is instrumental in aiding licensees to comply with the Code of Federal Regulations (CFR), which mandates robust protection of digital computers and equipment and communications systems at nuclear power plants against cyber threats.[278]\nThere is growing concern that cyberspace will become the next theater of warfare. As Mark Clayton from The Christian Science Monitor wrote in a 2015 article titled \"The New Cyber Arms Race\":\nIn the future, wars will not just be fought by soldiers with guns or with planes that drop bombs. They will also be fought with the click of a mouse a half a world away that unleashes carefully weaponized computer programs that disrupt or destroy critical industries like utilities, transportation, communications, and energy. Such attacks could also disable military networks that control the movement of troops, the path of jet fighters, the command and control of warships.[279]\nThis has led to new terms such as cyberwarfare and cyberterrorism. The United States Cyber Command was created in 2009[280] and many other countries have similar forces.\nThere are a few critical voices that question whether cybersecurity is as significant a threat as it is made out to be.[281][282][283]\nCybersecurity is a fast-growing field of IT concerned with reducing organizations' risk of hack or data breaches.[284] According to research from the Enterprise Strategy Group, 46% of organizations say that they have a \"problematic shortage\" of cybersecurity skills in 2016, up from 28% in 2015.[285] Commercial, government and non-governmental organizations all employ cybersecurity professionals. The fastest increases in demand for cybersecurity workers are in industries managing increasing volumes of consumer data such as finance, health care, and retail.[286] However, the use of the term cybersecurity is more prevalent in government job descriptions.[287]\nTypical cybersecurity job titles and descriptions include:[288]\n- Analyzes and assesses vulnerabilities in the infrastructure (software, hardware, networks), investigates using available tools and countermeasures to remedy the detected vulnerabilities and recommends solutions and best practices. Analyzes and assesses damage to the data/infrastructure as a result of security incidents, examines available recovery tools and processes, and recommends solutions. Tests for compliance with security policies and procedures. May assist in the creation, implementation, or management of security solutions.\n- Performs security monitoring, security and data/logs analysis, and forensic analysis, to detect security incidents, and mount the incident response. Investigates and utilizes new technologies and processes to enhance security capabilities and implement improvements. May also review code or perform other security engineering methodologies.\n- Designs a security system or major components of a security system, and may head a security design team building a new security system.[289]\n- A high-level management position responsible for the entire information security division/staff. The position may include hands-on technical work.[290]\n- A high-level management position responsible for the entire security division/staff. A newer position is now deemed needed as security risks grow.\n- A DPO is tasked with monitoring compliance with data protection laws (such as GDPR), data protection policies, awareness-raising, training, and audits.[291]\n- Broad titles that encompass any one or all of the other roles or titles tasked with protecting computers, networks, software, data or information systems against viruses, worms, spyware, malware, intrusion detection, unauthorized access, denial-of-service attacks, and an ever-increasing list of attacks by hackers acting as individuals or as part of organized crime or foreign governments.\nStudent programs are also available for people interested in beginning a career in cybersecurity.[292][293] Meanwhile, a flexible and effective option for information security professionals of all experience levels to keep studying is online security training, including webcasts.[294][295] A wide range of certified courses are also available.[296]\nIn the United Kingdom, a nationwide set of cybersecurity forums, known as the U.K Cyber Security Forum, were established supported by the Government's cybersecurity strategy[297] in order to encourage start-ups and innovation and to address the skills gap[298] identified by the U.K Government.\nIn Singapore, the Cyber Security Agency has issued a Singapore Operational Technology (OT) Cybersecurity Competency Framework (OTCCF). The framework defines emerging cybersecurity roles in Operational Technology. The OTCCF was endorsed by the Infocomm Media Development Authority (IMDA). It outlines the different OT cybersecurity job positions as well as the technical skills and core competencies necessary. It also depicts the many career paths available, including vertical and lateral advancement opportunities.[299]\nThe following terms used with regards to computer security are explained below:\n- Access authorization restricts access to a computer to a group of users through the use of authentication systems. These systems can protect either the whole computer, such as through an interactive login screen, or individual services, such as a FTP server. There are many methods for identifying and authenticating users, such as passwords, identification cards, smart cards, and biometric systems.\n- Anti-virus software consists of computer programs that attempt to identify, thwart, and eliminate computer viruses and other malicious software (malware).\n- Applications are executable code, so general corporate practice is to restrict or block users the power to install them; to install them only when there is a demonstrated need (e.g. software needed to perform assignments); to install only those which are known to be reputable (preferably with access to the computer code used to create the application), and to reduce the attack surface by installing as few as possible. They are typically run with least privilege, with a robust process in place to identify, test and install any released security patches or updates for them.\n- For example, programs can be installed into an individual user's account, which limits the program's potential access, as well as being a means control which users have specific exceptions to policy. In Linux, FreeBSD, OpenBSD, and other Unix-like operating systems there is an option to further restrict an application using chroot or other means of restricting the application to its own 'sandbox'. For example. Linux provides namespaces, and Cgroups to further restrict the access of an application to system resources.\n- Generalized security frameworks such as SELinux or AppArmor help administrators control access.\n- Java and other languages which compile to Java byte code and run in the Java virtual machine can have their access to other applications controlled at the virtual machine level.\n- Some software can be run in software containers which can even provide their own set of system libraries, limiting the software's, or anyone controlling it, access to the server's versions of the libraries.\n- Authentication techniques can be used to ensure that communication end-points are who they say they are.\n- Automated theorem proving and other verification tools can be used to enable critical algorithms and code used in secure systems to be mathematically proven to meet their specifications.\n- Backups are one or more copies kept of important computer files. Typically, multiple copies will be kept at different locations so that if a copy is stolen or damaged, other copies will still exist.\n- Capability and access control list techniques can be used to ensure privilege separation and mandatory access control. Capabilities vs. ACLs discusses their use.\n- Chain of trust techniques can be used to attempt to ensure that all software loaded has been certified as authentic by the system's designers.\n- Confidentiality is the nondisclosure of information except to another authorized person.[300]\n- Cryptographic techniques can be used to defend data in transit between systems, reducing the probability that the data exchange between systems can be intercepted or modified.\n- Cyber attribution, is an attribution of cybercrime, i.e., finding who perpetrated a cyberattack.\n- Cyberwarfare is an Internet-based conflict that involves politically motivated attacks on information and information systems. Such attacks can, for example, disable official websites and networks, disrupt or disable essential services, steal or alter classified data, and cripple financial systems.\n- Data integrity is the accuracy and consistency of stored data, indicated by an absence of any alteration in data between two updates of a data record.[301]\n- Encryption is used to protect the confidentiality of a message. Cryptographically secure ciphers are designed to make any practical attempt of breaking them infeasible. Symmetric-key ciphers are suitable for bulk encryption using shared keys, and public-key encryption using digital certificates can provide a practical solution for the problem of securely communicating when no key is shared in advance.\n- Endpoint security software aids networks in preventing malware infection and data theft at network entry points made vulnerable by the prevalence of potentially infected devices such as laptops, mobile devices, and USB drives.[302]\n- Firewalls serve as a gatekeeper system between networks, allowing only traffic that matches defined rules. They often include detailed logging, and may include intrusion detection and intrusion prevention features. They are near-universal between company local area networks and the Internet, but can also be used internally to impose traffic rules between networks if network segmentation is configured.\n- A hacker is someone who seeks to breach defenses and exploit weaknesses in a computer system or network.\n- Honey pots are computers that are intentionally left vulnerable to attack by crackers. They can be used to catch crackers and to identify their techniques.\n- Intrusion-detection systems are devices or software applications that monitor networks or systems for malicious activity or policy violations.\n- A microkernel is an approach to operating system design which has only the near-minimum amount of code running at the most privileged level – and runs other elements of the operating system such as device drivers, protocol stacks and file systems, in the safer, less privileged user space.\n- Pinging. The standard ping application can be used to test if an IP address is in use. If it is, attackers may then try a port scan to detect which services are exposed.\n- A port scan is used to probe an IP address for open ports to identify accessible network services and applications.\n- A key logger is spyware that silently captures and stores each keystroke that a user types on the computer's keyboard.\n- Social engineering is the use of deception to manipulate individuals to breach security.\n- Logic bombs is a type of malware added to a legitimate program that lies dormant until it is triggered by a specific event.\n- A unikernel is a computer program that runs on a minimalistic operating system where a single application is allowed to run (as opposed to a general purpose operating system where many applications can run at the same time). This approach to minimizing the attack surface is adopted mostly in cloud environments where software is deployed in virtual machines.\n- Zero trust security means that no one is trusted by default from inside or outside the network, and verification is required from everyone trying to gain access to resources on the network.\nSince the Internet's arrival and with the digital transformation initiated in recent years, the notion of cybersecurity has become a familiar subject in both our professional and personal lives. Cybersecurity and cyber threats have been consistently present for the last 60 years of technological change. In the 1970s and 1980s, computer security was mainly limited to academia until the conception of the Internet, where, with increased connectivity, computer viruses and network intrusions began to take off. After the spread of viruses in the 1990s, the 2000s marked the institutionalization of organized attacks such as distributed denial of service.[303] This led to the formalization of cybersecurity as a professional discipline.[304]\nThe April 1967 session organized by Willis Ware at the Spring Joint Computer Conference, and the later publication of the Ware Report, were foundational moments in the history of the field of computer security.[305] Ware's work straddled the intersection of material, cultural, political, and social concerns.[305]\nA 1977 NIST publication[306] introduced the CIA triad of confidentiality, integrity, and availability as a clear and simple way to describe key security goals.[307] While still relevant, many more elaborate frameworks have since been proposed.[308][309]\nHowever, in the 1970s and 1980s, there were no grave computer threats because computers and the internet were still in the early stages of development, and security threats were easily identifiable. More often, threats came from malicious insiders who gained unauthorized access to sensitive documents and files. Although malware and network breaches existed during the early years, they did not use them for financial gain. By the second half of the 1970s, established computer firms like IBM started offering commercial access control systems and computer security software products.[310]\nOne of the earliest examples of an attack on a computer network was the computer worm Creeper written by Bob Thomas at BBN, which propagated through the ARPANET in 1971.[311] The program was purely experimental in nature and carried no malicious payload. A later program, Reaper, was created by Ray Tomlinson in 1972 and used to destroy Creeper.[312]\nBetween September 1986 and June 1987, a group of German hackers performed the first documented case of cyber espionage.[313] The group hacked into American defense contractors, universities, and military base networks and sold gathered information to the Soviet KGB. The group was led by Markus Hess, who was arrested on 29 June 1987. He was convicted of espionage (along with two co-conspirators) on 15 Feb 1990.\nIn 1988, one of the first computer worms, called the Morris worm, was distributed via the Internet. It gained significant mainstream media attention.[314]\nNetscape started developing the protocol SSL, shortly after the National Center for Supercomputing Applications (NCSA) launched Mosaic 1.0, the first web browser, in 1993.[315][316] Netscape had SSL version 1.0 ready in 1994, but it was never released to the public due to many serious security vulnerabilities.[315] However, in 1995, Netscape launched Version 2.0.[317]\nThe National Security Agency (NSA) is responsible for the protection of U.S. information systems and also for collecting foreign intelligence.[318] The agency analyzes commonly used software and system configurations to find security flaws, which it can use for offensive purposes against competitors of the United States.[319]\nNSA contractors created and sold click-and-shoot attack tools to US agencies and close allies, but eventually, the tools made their way to foreign adversaries.[320] In 2016, NSAs own hacking tools were hacked, and Russia and North Korea have used it.[321] NSA's employees and contractors have been recruited at high salaries by adversaries, anxious to compete in cyberwarfare.[322] In 2007, the United States and Israel began exploiting security flaws in the Microsoft Windows operating system to attack and damage equipment used in Iran to refine nuclear materials. Iran responded by heavily investing in their own cyberwarfare capability, which it began using against the United States.[319]\n- Ross J. Anderson\n- Annie Anton\n- Adam Back\n- Daniel J. Bernstein\n- Matt Blaze\n- Stefan Brands\n- Josh Brunty\n- L. Jean Camp\n- Lorrie Cranor\n- Dorothy E. Denning\n- Peter J. Denning\n- Cynthia Dwork\n- Chuck Easttom\n- Deborah Estrin\n- Joan Feigenbaum\n- Ian Goldberg\n- Shafi Goldwasser\n- Lawrence A. Gordon\n- Peter Gutmann\n- Paul Kocher\n- Monica S. Lam\n- Butler Lampson\n- Brian LaMacchia\n- Susan Landau\n- Carl Landwehr\n- Kevin Mitnick\n- Peter G. Neumann\n- Susan Nycum\n- Paul C. van Oorschot\n- Fred Piper\n- Ron Ross\n- Tony Sager\n- Roger R. Schell\n- Bruce Schneier\n- Dawn Song\n- Gene Spafford\n- Salvatore J. Stolfo\n- Willis Ware\n- Moti Yung\n- Attack tree – Conceptual diagrams showing how an asset, or target, might be attacked\n- Bicycle attack – Method of discovering password length\n- CAPTCHA – Test to determine whether a user is human\n- Center for Internet Security – Nonprofit organization focused on cybersecurity\n- Cloud computing security – Methods used to protect cloud based assets\n- Comparison of antivirus software\n- Content Disarm & Reconstruction – Policy-based removal of components\n- Content Security Policy – Computer security standard to prevent cross-site scripting and related attacks\n- Countermeasure (computer) – Process to reduce a security threat\n- Cyber insurance – Information technology risk insurance\n- Cyber self-defense – Protection of computer systems from information disclosure, theft or damage\n- Cyberbiosecurity – Emerging field of computer security\n- Cybersecurity information technology list\n- Dancing pigs – Users' disregard for IT security\n- Data security – Process of securing digital information\n- Defense strategy (computing) – Concept to reduce computer security risks\n- Fault tolerance – Resilience of systems to component failures or errors\n- Hardware security – Security architecture implemented in hardware\n- Human–computer interaction (security)\n- Identity management – Systems to give users appropriate access\n- Identity-based security – Access control by authenticated ID\n- Information security awareness\n- Internet privacy – Right or mandate of personal privacy concerning the internet\n- Internet safety – Being aware of safety and security risks on the Internet\n- Internet security – Branch of computer security\n- IT risk – Any risk related to information technology\n- IT security standards – Technology standards and techniques\n- Cyber kill chain – Process of carrying out a cyberattack\n- List of computer security certifications\n- List of cyber warfare forces – List of national military and government units specializing in cyber warfare\n- Open security – Open source approach to computer security\n- Outline of computer security – Overview of and topical guide to computer security\n- OWASP – Computer security organization\n- Physical information security – Common ground of physical and information security\n- Privacy software – Layer to protect users' privacy\n- Security engineering – Process of incorporating security controls into an information system\n- Security through obscurity – Reliance on design or implementation secrecy for security\n- Software-defined perimeter – Method of enhancing computer security\n- Schatz, Daniel; Bashroush, Rabih; Wall, Julie (2017). \"Towards a More Representative Definition of Cyber Security\". Journal of Digital Forensics, Security and Law. 12 (2). ISSN 1558-7215.\n- Computer security at the Encyclopædia Britannica\n- Tate, Nick (7 May 2013). \"Reliance spells end of road for ICT amateurs\". The Australian.\n- Kianpour, Mazaher; Kowalski, Stewart; Øverby, Harald (2021). \"Systematically Understanding Cybersecurity Economics: A Survey\". Sustainability. 13 (24) 13677. Bibcode:2021Sust...1313677K. doi:10.3390/su132413677. hdl:11250/2978306. ISSN 2071-1050.\n- Stevens, Tim (11 June 2018). \"Global Cybersecurity: New Directions in Theory and Methods\" (PDF). Politics and Governance. 6 (2): 1–4. doi:10.17645/pag.v6i2.1569. Archived (PDF) from the original on 4 September 2019.\n- \"About the CVE Program\". www.cve.org. Retrieved 12 April 2023.\n- Zlatanov, Nikola (3 December 2015). Computer Security and Mobile Security Challenges. Tech Security Conference At: San Francisco, CA.\n- \"Ghidra\". nsa.gov. 1 August 2018. Archived from the original on 15 August 2020. Retrieved 17 August 2020.\n- Larabel, Michael (28 December 2017). \"Syzbot: Google Continuously Fuzzing The Linux Kernel\". www.phoronix.com/. Retrieved 25 March 2021.\n- \"Cyber attacks on SMBs: Current Stats and How to Prevent Them\". crowdstrike.com. Retrieved 30 November 2023.\n- \"Cyber security breaches survey 2023\". GOV.UK. Retrieved 30 November 2023.\n- \"How cyber attacks work\". www.ncsc.gov.uk. Retrieved 30 November 2023.\n- \"What is a backdoor attack? Definition and prevention | NordVPN\". nordvpn.com. 30 November 2023. Retrieved 3 January 2024.\n- \"What is a backdoor attack?\". McAfee. 4 December 2023. Retrieved 4 December 2023.\n- \"Denial of Service (DoS) guidance\". www.ncsc.gov.uk. Retrieved 4 December 2023.\n- \"Computer Security\". www.interelectronix.com. Retrieved 30 November 2023.\n- \"What Is a DMA Attack? Analysis & Mitigation\". Kroll. Retrieved 4 December 2023.\n- \"What Are Eavesdropping Attacks?\". Fortinet. Retrieved 5 December 2023.\n- York, Dan (1 January 2010), York, Dan (ed.), \"Chapter 3 – Eavesdropping and Modification\", Seven Deadliest Unified Communications Attacks, Boston: Syngress, pp. 41–69, ISBN 978-1-59749-547-9, retrieved 5 December 2023\n- \"What Are Eavesdropping Attacks & How To Prevent Them\". Verizon Enterprise. Retrieved 5 December 2023.\n- \"What is Malware? | IBM\". www.ibm.com. 14 April 2022. Retrieved 6 December 2023.\n- Bendovschi, Andreea (2015). \"Cyber-Attacks – Trends, Patterns and Security Countermeasures\". Procedia Economics and Finance. 28: 24–31. doi:10.1016/S2212-5671(15)01077-1.\n- \"What is malware?\". McAfee. Retrieved 30 November 2023.\n- \"What is a man-in-the-middle attack and how can I protect my organization?\". verizon.com.\n- \"Multi-Vector Attacks Demand Multi-Vector Protection\". MSSP Alert. 24 July 2017.\n- Millman, Renee (15 December 2017). \"New polymorphic malware evades three-quarters of AV scanners\". SC Magazine UK. Archived from the original on 14 June 2018. Retrieved 13 July 2018.\n- Tounsi, Wiem (15 May 2019), Tounsi, Wiem (ed.), \"What is Cyber Threat Intelligence and How is it Evolving?\", Cyber-Vigilance and Digital Trust (1 ed.), Wiley, pp. 1–49, doi:10.1002/9781119618393.ch1, ISBN 978-1-78630-448-3, S2CID 187294508, retrieved 6 December 2023\n- \"Identifying Phishing Attempts\". Case. Archived from the original on 13 September 2015. Retrieved 4 July 2016.\n- \"Protect yourself from phishing – Microsoft Support\". support.microsoft.com. Retrieved 6 December 2023.\n- Lazarus, Ari (23 February 2018). \"Phishers send fake invoices\". Consumer Information. Retrieved 17 February 2020.\n- \"Email Security\". Trellix. 17 May 2022. Archived from the original on 22 May 2022. Retrieved 24 October 2022.\n- \"What is Privilege Escalation? – CrowdStrike\". crowdstrike.com. Retrieved 7 December 2023.\n- Spence, Aaron; Bangay, Shaun (June 2022). \"Security beyond cybersecurity: side-channel attacks against non-cyber systems and their countermeasures\". International Journal of Information Security. 21 (3): 437–453. doi:10.1007/s10207-021-00563-6. ISSN 1615-5262.\n- Arcos Sergio. \"Social Engineering\" (PDF). upc.edu. Archived (PDF) from the original on 3 December 2013. Retrieved 16 April 2019.\n- Scannell, Kara (24 February 2016). \"CEO email scam costs companies $2bn\". Financial Times. No. 25 February 2016. Archived from the original on 23 June 2016. Retrieved 7 May 2016.\n- \"Bucks leak tax info of players, employees as result of email scam\". Associated Press. 20 May 2016. Archived from the original on 20 May 2016. Retrieved 20 May 2016.\n- \"What is Spoofing? – Definition from Techopedia\". techopedia.com. Archived from the original on 30 June 2016. Retrieved 16 January 2022.\n- Butterfield, Andrew; Ngondi, Gerard Ekembe, eds. (21 January 2016). \"spoofing\". A Dictionary of Computer Science. Oxford University Press. doi:10.1093/acref/9780199688975.001.0001. ISBN 978-0-19-968897-5. Retrieved 8 October 2017.\n- Marcel, Sébastien; Nixon, Mark; Li, Stan, eds. (2014). Handbook of Biometric Anti-Spoofing: Trusted Biometrics under Spoofing Attacks. Advances in Computer Vision and Pattern Recognition. London: Springer. doi:10.1007/978-1-4471-6524-8. ISBN 978-1-4471-6524-8. ISSN 2191-6594. LCCN 2014942635. S2CID 27594864.\n- \"80 to 0 in Under 5 Seconds: Falsifying a Medical Patient's Vitals\". www.trellix.com. Retrieved 9 February 2023.\n- Gallagher, Sean (14 May 2014). \"Photos of an NSA \"upgrade\" factory show Cisco router getting implant\". Ars Technica. Archived from the original on 4 August 2014. Retrieved 3 August 2014.\n- Intelligence, Microsoft Threat (11 November 2021). \"HTML smuggling surges: Highly evasive loader technique increasingly used in banking malware, targeted attacks\". Microsoft Security Blog. Retrieved 7 December 2023.\n- \"Obfuscated Files or Information: HTML Smuggling, Sub-technique T1027.006 – Enterprise | MITRE ATT&CK®\". attack.mitre.org. Retrieved 22 February 2023.\n- Lim, Joo S.; Chang, Shanton; Maynard, Sean; Ahmad, Atif (2009). \"Exploring the Relationship between Organizational Culture and Information Security Culture\". Proceedings of the 7th Australian Information Security Management Conference. Security Research Institute (SRI), Edith Cowan University. doi:10.4225/75/57B4065130DEF.\n- Reimers, Karl; Andersson, David (2017). Post-secondary Education Network Security: the End User Challenge and Evolving Threats. ICERI2017 Proceedings. Vol. 1. IATED. pp. 1787–1796. doi:10.21125/iceri.2017.0554. ISBN 978-84-697-6957-7. ISSN 2340-1095.\n- Verizon Data Breach Investigations Report 2020 (PDF). verizon.com (Report). Archived (PDF) from the original on 19 May 2020. Retrieved 17 September 2021.\n- Schlienger, Thomas; Teufel, Stephanie (2003). \"Information security culture-from analysis to change\". South African Computer Journal. 31: 46–52. hdl:10520/EJC27949.\n- Internet Security Glossary. doi:10.17487/RFC2828. RFC 2828.\n- \"CNSS Instruction No. 4009\" (PDF). 26 April 2010. Archived from the original (PDF) on 27 February 2012.\n- \"InfosecToday Glossary\" (PDF). Archived (PDF) from the original on 20 November 2014.\n- \"Cyber security design principles\". www.ncsc.gov.uk. Retrieved 11 December 2023.\n- \"How the NCSC thinks about security architecture\". www.ncsc.gov.uk. Retrieved 18 December 2023.\n- \"Secure System Architecture and Design\". UK Cyber Security Council. 2024. Retrieved 4 January 2024.\n- \"security architecture – Glossary | CSRC\". csrc.nist.gov. Retrieved 18 December 2023.\n- Jannsen, Cory. \"Security Architecture\". Techopedia. Janalta Interactive Inc. Archived from the original on 3 October 2014. Retrieved 9 October 2014.\n- Oppliger, Rolf (1 May 1997). \"Internet security: firewalls and beyond\". Communications of the ACM. 40 (5): 92–102. doi:10.1145/253769.253802. ISSN 0001-0782.\n- \"How to Increase Cybersecurity Awareness\". ISACA. Retrieved 25 February 2023.\n- Woodie, Alex (9 May 2016). \"Why ONI May Be Our Best Hope for Cyber Security Now\". Archived from the original on 20 August 2016. Retrieved 13 July 2016.\n- Walkowski, Debbie (9 July 2019). \"What Is The CIA Triad?\". F5 Labs. Retrieved 25 February 2020.[dead link]\n- \"Knowing Value of Data Assets is Crucial to Cybersecurity Risk Management | SecurityWeek.Com\". www.securityweek.com. 3 December 2018. Retrieved 25 February 2020.\n- Foreman, Park (2009). Vulnerability Management. Boca Raton, Fla.: Auerbach Publications. p. 1. ISBN 978-1-4398-0150-5.\n- Johnson, A. (2018). CCNA Cybersecurity Operations Companion Guide. Cisco Press. ISBN 978-0-13-516624-6.\n- Calder, Alan; Williams, Geraint (2014). PCI DSS: A Pocket Guide (3rd ed.). IT Governance Limited. ISBN 978-1-84928-554-4.\nnetwork vulnerability scans at least quarterly and after any significant change in the network\n- Harrison, J. (2003). Formal verification at Intel. 18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings. pp. 45–54. doi:10.1109/LICS.2003.1210044. ISBN 978-0-7695-1884-8. S2CID 44585546.\n- Umrigar, Zerksis D.; Pitchumani, Vijay (1983). Formal verification of a real-time hardware design. Proceeding DAC '83 Proceedings of the 20th Design Automation Conference. IEEE Press. pp. 221–227. ISBN 978-0-8186-0026-5.\n- \"Abstract Formal Specification of the seL4/ARMv6 API\" (PDF). Archived from the original (PDF) on 21 May 2015. Retrieved 19 May 2015.\n- Baumann, Christoph; Beckert, Bernhard; Blasum, Holger; Bormer, Thorsten. Ingredients of Operating System Correctness? Lessons Learned in the Formal Verification of PikeOS (PDF). Embedded World Conference, Nuremberg, Germany. Archived from the original (PDF) on 19 July 2011.\n- Ganssle, Jack. \"Getting it Right\". Archived from the original on 4 May 2013.\n- \"Everything you need for a career as a SOC analyst\". www.cybersecurityjobsite.com. Retrieved 19 December 2023.\n- CISM, John Rittinghouse PhD; CISM, William M. Hancock PhD CISSP (2 October 2003). Cybersecurity Operations Handbook. Digital Press. p. 436-437. ISBN 978-0-08-053018-5. Retrieved 4 September 2025.\n- \"Turn on 2-step verification (2SV)\". www.ncsc.gov.uk. Retrieved 19 December 2023.\n- \"NCSC's cyber security training for staff now available\". www.ncsc.gov.uk. Retrieved 19 December 2023.\n- Treglia, J.; Delia, M. (2017). Cyber Security Inoculation. NYS Cyber Security Conference, Empire State Plaza Convention Center, Albany, NY, 3–4 June.\n- \"What is a license dongle?\". www.revenera.com. Retrieved 12 June 2024.\n- \"Token-based authentication\". SafeNet.com. Archived from the original on 20 March 2014. Retrieved 20 March 2014.\n- \"Lock and protect your Windows PC\". TheWindowsClub.com. 10 February 2010. Archived from the original on 20 March 2014. Retrieved 20 March 2014.\n- Greene, James (2012). \"Intel Trusted Execution Technology: White Paper\" (PDF). Intel Corporation. Archived (PDF) from the original on 11 June 2014. Retrieved 18 December 2013.\n- \"SafeNet ProtectDrive 8.4\". SCMagazine.com. 4 October 2008. Archived from the original on 20 March 2014. Retrieved 20 March 2014.\n- \"Secure Hard Drives: Lock Down Your Data\". PCMag.com. 11 May 2009. Archived from the original on 21 June 2017.\n- Souppaya, Murugiah P.; Scarfone, Karen (2013). \"Guidelines for Managing the Security of Mobile Devices in the Enterprise\". National Institute of Standards and Technology. Special Publication (NIST SP). Gaithersburg, MD. doi:10.6028/NIST.SP.800-124r1.\n- \"Access Control Statistics: Trends & Insights\". 23 February 2024. Retrieved 26 April 2024.\n- \"Forget IDs, use your phone as credentials\". Fox Business Network. 4 November 2013. Archived from the original on 20 March 2014. Retrieved 20 March 2014.\n- \"Direct memory access protections for Mac computers\". Apple. Retrieved 16 November 2022.\n- \"Using IOMMU for DMA Protection in UEFI Firmware\" (PDF). Intel Corporation. Archived (PDF) from the original on 9 December 2021. Retrieved 16 November 2022.\n- Babaei, Armin; Schiele, Gregor; Zohner, Michael (26 July 2022). \"Reconfigurable Security Architecture (RESA) Based on PUF for FPGA-Based IoT Devices\". Sensors. 22 (15): 5577. Bibcode:2022Senso..22.5577B. doi:10.3390/s22155577. ISSN 1424-8220. PMC 9331300. PMID 35898079.\n- Hassija, Vikas; Chamola, Vinay; Gupta, Vatsal; Jain, Sarthak; Guizani, Nadra (15 April 2021). \"A Survey on Supply Chain Security: Application Areas, Security Threats, and Solution Architectures\". IEEE Internet of Things Journal. 8 (8): 6222–6246. Bibcode:2021IITJ....8.6222H. doi:10.1109/JIOT.2020.3025775. ISSN 2327-4662. S2CID 226767829.\n- \"The Most Secure OS: What is the Safest OS Available?\". Tech.co. Retrieved 19 December 2023.\n- Sanghavi, Alok (21 May 2010). \"What is formal verification?\". EE Times_Asia.\n- Ferraiolo, D.F. & Kuhn, D.R. (October 1992). \"Role-Based Access Control\" (PDF). 15th National Computer Security Conference: 554–563.\n- Sandhu, R; Coyne, EJ; Feinstein, HL; Youman, CE (August 1996). \"Role-Based Access Control Models\" (PDF). IEEE Computer. 29 (2): 38–47. Bibcode:1996Compr..29b..38S. CiteSeerX 10.1.1.50.7649. doi:10.1109/2.485845. S2CID 1958270.\n- Abreu, Vilmar; Santin, Altair O.; Viegas, Eduardo K.; Stihler, Maicon (2017). A multi-domain role activation model (PDF). 2017 IEEE International Conference on Communications (ICC). IEEE Press. pp. 1–6. doi:10.1109/ICC.2017.7997247. ISBN 978-1-4673-8999-0. S2CID 6185138.\n- A.C. O'Connor & R.J. Loomis (2002). Economic Analysis of Role-Based Access Control (PDF). Research Triangle Institute. p. 145.\n- \"Studies prove once again that users are the weakest link in the security chain\". CSO Online. 22 January 2014. Retrieved 8 October 2018.\n- \"The Role of Human Error in Successful Security Attacks\". IBM Security Intelligence. 2 September 2014. Retrieved 8 October 2018.\n- \"90% of security incidents trace back to PEBKAC and ID10T errors\". Computerworld. 15 April 2015. Retrieved 8 October 2018.\n- \"Protect your online banking with 2FA\". NZ Bankers Association. 7 October 2018. Archived from the original on 21 January 2020. Retrieved 7 September 2019.\n- \"IBM Security Services 2014 Cyber Security Intelligence Index\" (PDF). PcSite. 2014. Retrieved 9 October 2020.\n- Caldwell, Tracey (12 February 2013). \"Risky business: why security awareness is crucial for employees\". The Guardian. Retrieved 8 October 2018.\n- \"Developing a Security Culture\". CPNI – Centre for the Protection of National Infrastructure. Archived from the original on 9 October 2018. Retrieved 8 October 2018.\n- \"Cyber Hygiene – ENISA\". Retrieved 27 September 2018.\n- Kaljulaid, Kersti (16 October 2017). \"President of the Republic at the Aftenposten's Technology Conference\". Retrieved 27 September 2018.\n- \"Cyber security breaches survey 2023\". GOV.UK. Retrieved 27 December 2023.\n- Kuchler, Hannah (27 April 2015). \"Security execs call on companies to improve 'cyber hygiene'. Financial Times. Archived from the original on 10 December 2022. Retrieved 27 September 2018.\n- \"From AI to Russia, Here's How Estonia's President Is Planning for the Future\". Wired. Retrieved 28 September 2018.\n- \"Professor Len Adleman explains how he coined the term \"computer virus\". WeLiveSecurity. 1 November 2017. Retrieved 28 September 2018.\n- \"Statement of Dr. Vinton G. Cerf\". www.jec.senate.gov. Retrieved 28 September 2018.\n- Promoting Good Cyber Hygiene Act of 2017 at Congress.gov\n- \"Analysis | The Cybersecurity 202: Agencies struggling with basic cybersecurity despite Trump's pledge to prioritize it\". The Washington Post. Retrieved 28 September 2018.\n- \"Protected Voices\". Federal Bureau of Investigation. Retrieved 28 September 2018.\n- Lin, Tom C. W. (3 July 2017). \"The New Market Manipulation\". Emory Law Journal. 66: 1253. SSRN 2996896.\n- Lin, Tom C. W. (2016). \"Financial Weapons of War\". Minnesota Law Review. SSRN 2765010.\n- Cole, Jeffrey I.; Suman, Michael; Schramm, Phoebe; van Bel, Daniel; Lunn, B.; Maguire, Phyllisane; Hanson, Koran; Singh, Rajesh; Aquino, Jedrix-Sean; Lebo, Harlan (2000). The UCLA Internet report: Surveying the digital future (PDF). ccp.ucla.edu (Report). Archived from the original (PDF) on 23 April 2003. Retrieved 15 September 2023.\n- Pagliery, Jose (18 November 2014). \"Hackers attacked the U.S. energy grid 79 times this year\". CNN Money. Cable News Network. Archived from the original on 18 February 2015. Retrieved 16 April 2015.\n- Neumann, P. G. (1997). Computer Security in Aviation: Vulnerabilities, Threats, and Risks. International Conference on Aviation Safety and Security in the 21st Century, White House Commission on Safety and Security.\n- Dillingham, Gerald L. (20 September 2001). Aviation security: terrorist acts demonstrate urgent need to improve security at the nation's airports (Report). United States. General Accounting Office.\n- \"Air Traffic Control Systems Vulnerabilities Could Make for Unfriendly Skies [Black Hat] – SecurityWeek.Com\". 27 July 2012. Archived from the original on 8 February 2015.\n- \"Hacker Says He Can Break into Airplane Systems Using In-Flight Wi-Fi\". NPR. 4 August 2014. Archived from the original on 8 February 2015. Retrieved 19 March 2020.\n- Finkle, Jim (4 August 2014). \"Hacker says to show passenger jets at risk of cyber attack\". Reuters. Archived from the original on 13 October 2015. Retrieved 21 November 2021.\n- Cesar, Alan (15 December 2023). \"Online course bolsters cybersecurity in aviation\". Aerogram. Purdue University School of Aeronautics and Astronautics. Retrieved 9 January 2024.\n- \"Pan-European Network Services (PENS) – Eurocontrol.int\". Archived from the original on 12 December 2016.\n- \"Centralised Services: NewPENS moves forward – Eurocontrol.int\". Eurocontrol. 17 January 2016. Archived from the original on 19 March 2017.\n- \"NextGen Data Communication\". FAA. Archived from the original on 13 March 2015. Retrieved 15 June 2017.\n- \"e-Passports | Homeland Security\". www.dhs.gov. Retrieved 3 February 2023.\n- \"The Australian ePassport. Australian Government Department of Foreign Affairs and Trade website\". Archived from the original on 9 January 2015. Retrieved 1 May 2023.\n- \"Is Your Watch Or Thermostat A Spy? Cybersecurity Firms Are On It\". NPR. 6 August 2014. Archived from the original on 11 February 2015.\n- O'Neill, Stephanie (19 November 2018). \"As Insurers Offer Discounts For Fitness Trackers, Wearers Should Step With Caution\". NPR. Retrieved 10 October 2025.\n- Kruse, CB; Smith, B; Vanderlinden, H; Nealand, A (21 July 2017). \"Security Techniques for the Electronic Health Records\". Journal of Medical Systems. 41 (8): 127. doi:10.1007/s10916-017-0778-4. PMC 5522514. PMID 28733949.\n- Backman, Melvin (18 September 2014). \"Home Depot: 56 million cards exposed in breach\". CNNMoney. Archived from the original on 18 December 2014.\n- \"Staples: Breach may have affected 1.16 million customers' cards\". Fortune.com. 19 December 2014. Archived from the original on 21 December 2014. Retrieved 21 December 2014.\n- \"Target: 40 million credit cards compromised\". CNN. 19 December 2013. Archived from the original on 1 December 2017. Retrieved 29 November 2017.\n- Cowley, Stacy (2 October 2017). \"2.5 Million More People Potentially Exposed in Equifax Breach\". The New York Times. Archived from the original on 1 December 2017. Retrieved 29 November 2017.\n- Finkle, Jim (23 April 2014). \"Exclusive: FBI warns healthcare sector vulnerable to cyber attacks\". Reuters. Archived from the original on 4 June 2016. Retrieved 23 May 2016.\n- Seals, Tara (6 November 2015). \"Lack of Employee Security Training Plagues US Businesses\". Infosecurity Magazine. Archived from the original on 9 November 2017. Retrieved 8 November 2017.\n- Bright, Peter (15 February 2011). \"Anonymous speaks: the inside story of the HBGary hack\". Arstechnica.com. Archived from the original on 27 March 2011. Retrieved 29 March 2011.\n- Anderson, Nate (9 February 2011). \"How one man tracked down Anonymous – and paid a heavy price\". Arstechnica.com. Archived from the original on 29 March 2011. Retrieved 29 March 2011.\n- Palilery, Jose (24 December 2014). \"What caused Sony hack: What we know now\". CNN Money. Archived from the original on 4 January 2015. Retrieved 4 January 2015.\n- Cook, James (16 December 2014). \"Sony Hackers Have Over 100 Terabytes Of Documents. Only Released 200 Gigabytes So Far\". Business Insider. Archived from the original on 17 December 2014. Retrieved 18 December 2014.\n- Lee, Timothy B. (18 January 2015). \"The next frontier of hacking: your car\". Vox. Archived from the original on 17 March 2017.\n- Tracking & Hacking: Security & Privacy Gaps Put American Drivers at Risk (PDF) (Report). 6 February 2015. Archived (PDF) from the original on 9 November 2016. Retrieved 4 November 2016.\n- \"Cybersecurity expert: It will take a 'major event' for companies to take this issue seriously\". AOL.com. 5 January 2017. Archived from the original on 20 January 2017. Retrieved 22 January 2017.\n- \"The problem with self-driving cars: who controls the code?\". The Guardian. 23 December 2015. Archived from the original on 16 March 2017. Retrieved 22 January 2017.\n- Checkoway, Stephen; McCoy, Damon; Kantor, Brian; Anderson, Danny; Shacham, Hovav; Savage, Stefan; Koscher, Karl; Czeskis, Alexei; Roesner, Franziska; Kohno, Tadayoshi (2011). Comprehensive Experimental Analyses of Automotive Attack Surfaces (PDF). SEC'11 Proceedings of the 20th USENIX conference on Security. Berkeley, California, US: USENIX Association. p. 6. Archived (PDF) from the original on 21 February 2015.\n- Greenberg, Andy (21 July 2015). \"Hackers Remotely Kill a Jeep on the Highway – With Me in It\". Wired. Archived from the original on 19 January 2017. Retrieved 22 January 2017.\n- \"Hackers take control of car, drive it into a ditch\". The Independent. 22 July 2015. Archived from the original on 2 February 2017. Retrieved 22 January 2017.\n- \"Tesla fixes software bug that allowed Chinese hackers to control car remotely\". The Telegraph. 21 September 2016. Archived from the original on 2 February 2017. Retrieved 22 January 2017.\n- Kang, Cecilia (19 September 2016). \"Self-Driving Cars Gain Powerful Ally: The Government\". The New York Times. Archived from the original on 14 February 2017. Retrieved 22 January 2017.\n- \"Federal Automated Vehicles Policy\" (PDF). Archived (PDF) from the original on 21 January 2017. Retrieved 22 January 2017.\n- \"Vehicle Cybersecurity\". nhtsa.gov. Retrieved 25 November 2022.\n- \"Thales supplies smart driver license to 4 states in Mexico\". Thales Group.\n- \"4 Companies Using RFID for Supply Chain Management\". atlasRFIDstore. Retrieved 3 February 2023.\n- \"The Cutting Edge of RFID Technology and Applications for Manufacturing and Distribution\". Supply Chain Market.\n- Rahman, Mohammad Anwar; Khadem, Mohammad Miftaur; Sarder, MD. Application of RFID in Supply Chain System. Proceedings of the 2010 International Conference on Industrial Engineering and Operations Management Dhaka, Bangladesh, January 9 – 10, 2010. CiteSeerX 10.1.1.397.7831.\n- \"Gary McKinnon profile: Autistic 'hacker' who started writing computer programs at 14\". The Daily Telegraph. London. 23 January 2009. Archived from the original on 2 June 2010.\n- \"Gary McKinnon extradition ruling due by 16 October\". BBC News. 6 September 2012. Archived from the original on 6 September 2012. Retrieved 25 September 2012.\n- Mckinnon V Government of The United States of America and Another (House of Lords 16 June 2008) (\"15. ... alleged to total over $700,000\"), Text.\n- \"Fresh Leak on US Spying: NSA Accessed Mexican President's Email\". SPIEGEL ONLINE. 20 October 2013. Archived from the original on 6 November 2015.\n- Sanders, Sam (4 June 2015). \"Massive Data Breach Puts 4 Million Federal Employees' Records at Risk\". NPR. Archived from the original on 5 June 2015. Retrieved 5 June 2015.\n- Liptak, Kevin (4 June 2015). \"U.S. government hacked; feds think China is the culprit\". CNN. Archived from the original on 6 June 2015. Retrieved 5 June 2015.\n- Gallagher, Sean. \"Encryption \"would not have helped\" at OPM, says DHS official\". Archived from the original on 24 June 2017.\n- Davis, Michelle R. (19 October 2015). \"Schools Learn Lessons From Security Breaches\". Education Week. Archived from the original on 10 June 2016. Retrieved 23 May 2016.\n- \"GE's Introduces ACUVision as a Single Panel Solution\". www.securityinfowatch.com. Security Info Watch. 11 August 2005. Retrieved 24 September 2019.\n- \"Internet of Things Global Standards Initiative\". ITU. Archived from the original on 26 June 2015. Retrieved 26 June 2015.\n- Singh, Jatinder; Pasquier, Thomas; Bacon, Jean; Ko, Hajoon; Eyers, David (2015). \"Twenty Cloud Security Considerations for Supporting the Internet of Things\" (PDF). IEEE Internet of Things Journal. 3 (3): 269–284. doi:10.1109/JIOT.2015.2460333. S2CID 4732406.\n- Clearfield, Chris. \"Why The FTC Can't Regulate The Internet Of Things\". Forbes. Archived from the original on 27 June 2015. Retrieved 26 June 2015.\n- \"Internet of Things: Science Fiction or Business Fact?\" (PDF). Harvard Business Review. Archived (PDF) from the original on 17 March 2015. Retrieved 4 November 2016.\n- Vermesan, Ovidiu; Friess, Peter. \"Internet of Things: Converging Technologies for Smart Environments and Integrated Ecosystems\" (PDF). River Publishers. Archived (PDF) from the original on 12 October 2016. Retrieved 4 November 2016.\n- Clearfield, Chris (20 June 2013). \"Rethinking Security for the Internet of Things\". Harvard Business Review. Archived from the original on 20 September 2013.\n- \"Hotel room burglars exploit critical flaw in electronic door locks\". Ars Technica. 26 November 2012. Archived from the original on 14 May 2016. Retrieved 23 May 2016.\n- \"Hospital Medical Devices Used As Weapons in Cyberattacks\". Dark Reading. 6 August 2015. Archived from the original on 29 May 2016. Retrieved 23 May 2016.\n- Kirk, Jeremy (17 October 2012). \"Pacemaker hack can deliver deadly 830-volt jolt\". Computerworld. Archived from the original on 4 June 2016. Retrieved 23 May 2016.\n- \"How Your Pacemaker Will Get Hacked\". The Daily Beast. Kaiser Health News. 17 November 2014. Archived from the original on 20 May 2016. Retrieved 23 May 2016.\n- Leetaru, Kalev. \"Hacking Hospitals And Holding Hostages: Cybersecurity In 2016\". Forbes. Archived from the original on 29 December 2016. Retrieved 29 December 2016.\n- \"Cyber-Angriffe: Krankenhäuser rücken ins Visier der Hacker\". Wirtschafts Woche. 7 December 2016. Archived from the original on 29 December 2016. Retrieved 29 December 2016.\n- \"Hospitals keep getting attacked by ransomware – Here's why\". Business Insider. Archived from the original on 29 December 2016. Retrieved 29 December 2016.\n- \"MedStar Hospitals Recovering After 'Ransomware' Hack\". NBC News. 31 March 2016. Archived from the original on 29 December 2016. Retrieved 29 December 2016.\n- Pauli, Darren. \"US hospitals hacked with ancient exploits\". The Register. Archived from the original on 16 November 2016. Retrieved 29 December 2016.\n- Pauli, Darren. \"Zombie OS lurches through Royal Melbourne Hospital spreading virus\". The Register. Archived from the original on 29 December 2016. Retrieved 29 December 2016.\n- \"Hacked Lincolnshire hospital computer systems 'back up'. BBC News. 2 November 2016. Archived from the original on 29 December 2016. Retrieved 29 December 2016.\n- \"Lincolnshire operations cancelled after network attack\". BBC News. 31 October 2016. Archived from the original on 29 December 2016. Retrieved 29 December 2016.\n- \"Legion cyber-attack: Next dump is sansad.nic.in, say hackers\". The Indian Express. 12 December 2016. Archived from the original on 29 December 2016. Retrieved 29 December 2016.\n- \"Former New Hampshire Psychiatric Hospital Patient Accused Of Data Breach\". CBS Boston. 27 December 2016. Archived from the original on 29 September 2017. Retrieved 29 December 2016.\n- \"Texas Hospital hacked, affects nearly 30,000 patient records\". Healthcare IT News. 4 November 2016. Archived from the original on 29 December 2016. Retrieved 29 December 2016.\n- Becker, Rachel (27 December 2016). \"New cybersecurity guidelines for medical devices tackle evolving threats\". The Verge. Archived from the original on 28 December 2016. Retrieved 29 December 2016.\n- \"Postmarket Management of Cybersecurity in Medical Devices\" (PDF). Food and Drug Administration. 28 December 2016. Archived from the original (PDF) on 29 December 2016. Retrieved 29 December 2016.\n- Brandt, Jaclyn (18 June 2018). \"D.C. distributed energy proposal draws concerns of increased cybersecurity risks\". Daily Energy Insider. Retrieved 4 July 2018.\n- \"Current Releases - The Open Mobile Alliance\". openmobilealliance.org.\n- Cashell, B.; Jackson, W. D.; Jickling, M.; Webel, B. (2004). The Economic Impact of Cyber-Attacks (PDF) (Report). Washington DC: Congressional Research Service, Government, and Finance Division. RL32331.\n- Gordon, Lawrence; Loeb, Martin (November 2002). \"The Economics of Information Security Investment\". ACM Transactions on Information and System Security. 5 (4): 438–457. doi:10.1145/581271.581274. S2CID 1500788.\n- Sanger, David E.; Barnes, Julian E. (20 December 2021). \"U.S. and Britain Help Ukraine Prepare for Potential Russian Cyberassault\". The New York Times. ISSN 0362-4331. Retrieved 4 December 2023.\n- \"Cyber-Attack Against Ukrainian Critical Infrastructure | CISA\". www.cisa.gov. 20 July 2021. Retrieved 4 December 2023.\n- Han, Chen; Dongre, Rituja (2014). \"Q&A. What Motivates Cyber-Attackers?\". Technology Innovation Management Review. 4 (10): 40–42. doi:10.22215/timreview/838. ISSN 1927-0321.\n- Chermick, Steven; Freilich, Joshua; Holt, Thomas (April 2017). \"Exploring the Subculture of Ideologically Motivated Cyber-Attackers\". Journal of Contemporary Criminal Justice. 33 (3): 212–233. doi:10.1177/1043986217699100. S2CID 152277480.\n- Anderson, Ross (2020). Security engineering: a guide to building dependable distributed systems (3rd ed.). Indianapolis, IN: John Wiley & Sons. ISBN 978-1-119-64281-7. OCLC 1224516855.\n- \"The Leading Cloud Recruiting Software\". iCIMS. Retrieved 13 March 2021.\n- Wilcox, S. and Brown, B. (2005) 'Responding to Security Incidents – Sooner or Later Your Systems Will Be Compromised', Journal of Health Care Compliance, 7(2), pp. 41–48\n- Jonathan Zittrain, 'The Future of The Internet', Penguin Books, 2008\n- Information Security Archived 6 March 2016 at the Wayback Machine. United States Department of Defense, 1986\n- \"The TJX Companies, Inc. Victimized by Computer System Intrusion; Provides Information to Help Protect Customers\" (Press release). The TJX Companies, Inc. 17 January 2007. Archived from the original on 27 September 2012. Retrieved 12 December 2009.\n- Largest Customer Info Breach Grows Archived 28 September 2007 at the Wayback Machine. MyFox Twin Cities, 29 March 2007.\n- \"The Stuxnet Attack On Iran's Nuclear Plant Was 'Far More Dangerous' Than Previously Thought\". Business Insider. 20 November 2013. Archived from the original on 9 May 2014.\n- Reals, Tucker (24 September 2010). \"Stuxnet Worm a U.S. Cyber-Attack on Iran Nukes?\". CBS News. Archived from the original on 16 October 2013.\n- Zetter, Kim (17 February 2011). \"Cyberwar Issues Likely to Be Addressed Only After a Catastrophe\". Wired. Archived from the original on 18 February 2011. Retrieved 18 February 2011.\n- Carroll, Chris (18 October 2011). \"Cone of silence surrounds U.S. cyberwarfare\". Stars and Stripes. Archived from the original on 7 March 2012. Retrieved 30 October 2011.\n- Bumgarner, John (27 April 2010). \"Computers as Weapons of War\" (PDF). IO Journal. Archived from the original (PDF) on 19 December 2011. Retrieved 30 October 2011.\n- Greenwald, Glenn (6 June 2013). \"NSA collecting phone records of millions of Verizon customers daily\". The Guardian. Archived from the original on 16 August 2013. Retrieved 16 August 2013.\n- Seipel, Hubert. \"Transcript: ARD interview with Edward Snowden\". La Foundation Courage. Archived from the original on 14 July 2014. Retrieved 11 June 2014.\n- Newman, Lily Hay (9 October 2013). \"Can You Trust NIST?\". IEEE Spectrum. Archived from the original on 1 February 2016.\n- \"NIST Removes Cryptography Algorithm from Random Number Generator Recommendations\". National Institute of Standards and Technology. 21 April 2014.\n- \"New Snowden Leak: NSA Tapped Google, Yahoo Data Centers\" Archived 9 July 2014 at the Wayback Machine, 31 October 2013, Lorenzo Franceschi-Bicchierai, mashable.com\n- Riley, Michael; Elgin, Ben; Lawrence, Dune; Matlack, Carol (17 March 2014). \"Target Missed Warnings in Epic Hack of Credit Card Data\". Businessweek. Archived from the original on 27 January 2015.\n- Rosenblatt, Seth (6 November 2014). \"Home Depot says 53 million emails stolen\". CNET. CBS Interactive. Archived from the original on 9 December 2014.\n- \"Millions more Americans hit by government personnel data hack\". Reuters. 9 July 2017. Archived from the original on 28 February 2017. Retrieved 25 February 2017.\n- Barrett, Devlin (4 June 2015). \"U.S. Suspects Hackers in China Breached About four (4) Million People's Records, Officials Say\". The Wall Street Journal. Archived from the original on 4 June 2015.\n- Risen, Tom (5 June 2015). \"China Suspected in Theft of Federal Employee Records\". U.S. News & World Report. Archived from the original on 6 June 2015.\n- Zengerle, Patricia (19 July 2015). \"Estimate of Americans hit by government personnel data hack skyrockets\". Reuters. Archived from the original on 10 July 2015.\n- Sanger, David (5 June 2015). \"Hacking Linked to China Exposes Millions of U.S. Workers\". The New York Times. Archived from the original on 5 June 2015.\n- Mansfield-Devine, Steve (1 September 2015). \"The Ashley Madison affair\". Network Security. 2015 (9): 8–16. doi:10.1016/S1353-4858(15)30080-5.\n- Turton, W.; Mehrotra, K. (4 June 2021). \"Hackers Breached Colonial Pipeline Using Compromised Password\". Bloomberg L.P. Retrieved 3 December 2023.\n- \"Mikko Hypponen: Fighting viruses, defending the net\". TED. 19 July 2011. Archived from the original on 16 January 2013.\n- \"Mikko Hypponen – Behind Enemy Lines\". Hack in the Box Security Conference. 9 December 2012. Archived from the original on 25 November 2016.\n- \"Ensuring the Security of Federal Information Systems and Cyber Critical Infrastructure and Protecting the Privacy of Personally Identifiable Information\". Government Accountability Office. Archived from the original on 19 November 2015. Retrieved 3 November 2015.\n- King, Georgia (23 May 2018). \"The Venn diagram between libertarians and crypto bros is so close it's basically a circle\". Quartz.\n- Kirby, Carrie (24 June 2011). \"Former White House aide backs some Net regulation / Clarke says government, industry deserve 'F' in cyber security\". The San Francisco Chronicle.\n- McCarthy, Daniel (11 June 2018). \"Privatizing Political Authority: Cybersecurity, Public-Private Partnerships, and the Reproduction of Liberal Political Order\". Politics and Governance. 6 (2): 5–12. doi:10.17645/pag.v6i2.1335.\n- \"It's Time to Treat Cybersecurity as a Human Rights Issue\". Human Rights Watch. 26 May 2020. Retrieved 26 May 2020.\n- \"FIRST Mission\". FIRST. Retrieved 6 July 2018.\n- \"FIRST Members\". FIRST. Retrieved 6 July 2018.\n- \"European council\". Archived from the original on 3 December 2014.\n- \"MAAWG\". Archived from the original on 23 September 2014.\n- \"MAAWG\". Archived from the original on 17 October 2014.\n- \"Government of Canada Launches Canada's Cyber Security Strategy\". Market Wired. 3 October 2010. Archived from the original on 2 November 2014. Retrieved 1 November 2014.\n- \"Canada's Cyber Security Strategy\". Public Safety Canada. Government of Canada. Archived from the original on 2 November 2014. Retrieved 1 November 2014.\n- \"Action Plan 2010–2015 for Canada's Cyber Security Strategy\". Public Safety Canada. Government of Canada. Archived from the original on 2 November 2014. Retrieved 3 November 2014.\n- \"Cyber Incident Management Framework For Canada\". Public Safety Canada. Government of Canada. Archived from the original on 2 November 2014. Retrieved 3 November 2014.\n- \"Action Plan 2010–2015 for Canada's Cyber Security Strategy\". Public Safety Canada. Government of Canada. Archived from the original on 2 November 2014. Retrieved 1 November 2014.\n- \"Canadian Cyber Incident Response Centre\". Public Safety Canada. Archived from the original on 8 October 2014. Retrieved 1 November 2014.\n- \"Cyber Security Bulletins\". Public Safety Canada. Archived from the original on 8 October 2014. Retrieved 1 November 2014.\n- \"Report a Cyber Security Incident\". Public Safety Canada. Government of Canada. Archived from the original on 11 November 2014. Retrieved 3 November 2014.\n- \"Government of Canada Launches Cyber Security Awareness Month With New Public Awareness Partnership\". Market Wired. Government of Canada. 27 September 2012. Archived from the original on 3 November 2014. Retrieved 3 November 2014.\n- \"Cyber Security Cooperation Program\". Public Safety Canada. Archived from the original on 2 November 2014. Retrieved 1 November 2014.\n- \"Cyber Security Cooperation Program\". Public Safety Canada. 16 December 2015. Archived from the original on 2 November 2014.\n- \"GetCyberSafe\". Get Cyber Safe. Government of Canada. Archived from the original on 11 November 2014. Retrieved 3 November 2014.\n- \"Australian federal government announces cybersecurity support for SMBs\",\"2023-2030 Australian Cyber Security Strategy\". Retrieved 22 November 2023.\n- \"Need for proper structure of PPPs to address specific cyberspace risks\". ORF. Archived from the original on 13 November 2017.\n- \"National Cyber Safety and Security Standards(NCSSS)-Home\". www.ncdrc.res.in. Archived from the original on 19 February 2018. Retrieved 19 February 2018.\n- \"South Korea seeks global support in cyber attack probe\". BBC Monitoring Asia Pacific. 7 March 2011.\n- Jun, Kwanwoo (23 September 2013). \"Seoul Puts a Price on Cyberdefense\". The Wall Street Journal. Dow Jones & Company, Inc. Archived from the original on 25 September 2013. Retrieved 24 September 2013.\n- White, House (March 2023). \"National security strategy\" (PDF). No. March 2032. white house. US gov.\n- Adil, Sajid (16 October 2023). \"Do You Know About Biggest Cybersecurity Threats In 2023?\". Cybernexguard. Adil Sajid. Retrieved 18 December 2023.\n- Adil, Sajid (September 2018). \"National Cyber Strategy of the United States of America\". University Libraries UNT Digital Library. Retrieved 18 December 2023.\n- Adil, Sajid (September 2018). \"Do You Know About Biggest Cybersecurity Threats In 2023?\". University Libraries UNT Digital Library. Retrieved 18 December 2023.\n- International Cybercrime Reporting and Cooperation Act at Congress.gov\n- \"111th Congress, 2nd Session\". Archived from the original on 20 January 2012.\n- Kelly, Mary Louise (13 May 2021). \"Biden Adviser On Cyber Threats And The New Executive Order To Combat Them\". NPR.\n- Executive Order on Improving the Nation's Cybersecurity (full text)\n- \"National Cyber Security Division\". U.S. Department of Homeland Security. Archived from the original on 11 June 2008. Retrieved 14 June 2008.\n- \"FAQ: Cyber Security R&D Center\". U.S. Department of Homeland Security S&T Directorate. Archived from the original on 6 October 2008. Retrieved 14 June 2008.\n- AFP-JiJi, \"U.S. boots up cybersecurity center\", 31 October 2009.\n- \"Federal Bureau of Investigation – Priorities\". Federal Bureau of Investigation. Archived from the original on 11 July 2016.\n- \"Internet Crime Complaint Center (IC3) – Home\". Archived from the original on 20 November 2011.\n- \"Infragard, Official Site\". Infragard. Archived from the original on 9 September 2010. Retrieved 10 September 2010.\n- \"Robert S. Mueller, III – InfraGard Interview at the 2005 InfraGard Conference\". Infragard (Official Site) – \"Media Room\". Archived from the original on 17 June 2011. Retrieved 9 December 2009.\n- \"CCIPS\". 25 March 2015. Archived from the original on 23 August 2006.\n- \"A Framework for a Vulnerability Disclosure Program for Online Systems\". Cybersecurity Unit, Computer Crime & Intellectual Property Section Criminal Division U.S. Department of Justice. July 2017. Retrieved 9 July 2018.\n- \"Mission and Vision\". www.cybercom.mil. Retrieved 20 June 2020.\n- William J. Lynn, III (12 November 2009). Remarks at the Defense Information Technology Acquisition Summit (Speech). Washington D.C. Archived from the original on 15 April 2010. Retrieved 10 July 2010.\n- Shachtman, Noah (23 September 2010). \"Military's Cyber Commander Swears: \"No Role\" in Civilian Networks\". brookings.edu. Archived from the original on 6 November 2010.\n- \"FCC Cybersecurity\". FCC. Archived from the original on 27 May 2010. Retrieved 3 December 2014.\n- \"Cybersecurity for Medical Devices and Hospital Networks: FDA Safety Communication\". Food and Drug Administration. Archived from the original on 28 May 2016. Retrieved 23 May 2016.\n- \"Automotive Cybersecurity – National Highway Traffic Safety Administration (NHTSA)\". Archived from the original on 25 May 2016. Retrieved 23 May 2016.\n- Air Traffic Control: FAA Needs a More Comprehensive Approach to Address Cybersecurity As Agency Transitions to NextGen (Report). U. S. Government Accountability Office. 14 April 2015. Archived from the original on 13 June 2016. Retrieved 23 May 2016.\n- Sternstein, Aliya (4 March 2016). \"FAA Working on New Guidelines for Hack-Proof Planes\". Nextgov. Archived from the original on 19 May 2016. Retrieved 23 May 2016.\n- Elias, Bart (18 June 2015). \"Protecting Civil Aviation from Cyberattacks\" (PDF). Archived (PDF) from the original on 17 October 2016. Retrieved 4 November 2016.\n- Anderson, David; Reimers, Karl (2019). CYBER SECURITY EMPLOYMENT POLICY AND WORKPLACE DEMAND IN THE U.S. GOVERNMENT. EDULEARN19 Proceedings. Vol. 1. IATED. pp. 7858–7866. doi:10.21125/edulearn.2019.1914. ISBN 978-84-09-12031-4. ISSN 2340-1117.\n- Verton, Dan (28 January 2004). \"DHS launches national cyber alert system\". Computerworld. IDG. Archived from the original on 31 August 2005. Retrieved 15 June 2008.\n- Details can be found in 10 CFR 73.54, Protection of digital computer and communication systems and networks.\n- Cyber Security Plan for Nuclear Power Reactors - Nuclear Energy Institute\n- Refer to NEI 08-09 for more details.\n- Clayton, Mark (7 March 2011). \"The new cyber arms race\". The Christian Science Monitor. Archived from the original on 16 April 2015. Retrieved 16 April 2015.\n- Nakashima, Ellen (13 September 2016). \"Obama to be urged to split cyberwar command from NSA\". The Washington Post. Archived from the original on 12 October 2016. Retrieved 15 June 2017.\n- Overland, Indra (1 March 2019). \"The geopolitics of renewable energy: Debunking four emerging myths\". Energy Research & Social Science. 49: 36–40. Bibcode:2019ERSS...49...36O. doi:10.1016/j.erss.2018.10.018. hdl:11250/2579292. ISSN 2214-6296.\n- Maness, Ryan C.; Valeriano, Brandon (11 June 2018). \"How We Stopped Worrying about Cyber Doom and Started Collecting Data\". Politics and Governance. 6 (2): 49–60. doi:10.17645/pag.v6i2.1368. hdl:10945/60589. ISSN 2183-2463.\n- Maness, Ryan C.; Valeriano, Brandon (25 March 2015). \"The Impact of Cyber Conflict on International Interactions\". Armed Forces & Society. 42 (2): 301–323. doi:10.1177/0095327x15572997. ISSN 0095-327X. S2CID 146145942.\n- Bullard, Brittany (2016). Style and Statistics: The Art of Retail Analytics. Wiley. doi:10.1002/9781119271260.ch8. ISBN 978-1-119-27031-7.\n- Oltsik, Jon (18 March 2016). \"Cybersecurity Skills Shortage Impact on Cloud Computing\". Network World. Archived from the original on 23 March 2016. Retrieved 23 March 2016.\n- Robinson, Terry (30 May 2018). \"Why is a Degree in Cyber Security one of the Best?\". DegreeQuery.com. Archived from the original on 10 October 2021. Retrieved 10 October 2021.\n- de Silva, Richard (11 October 2011). \"Government vs. Commerce: The Cyber Security Industry and You (Part One)\". Defence IQ. Archived from the original on 24 April 2014. Retrieved 24 April 2014.\n- \"Department of Computer Science\". Archived from the original on 3 June 2013. Retrieved 30 April 2013.\n- \"About Cyber Security architect\". cisa.gov. 1 August 2021. Retrieved 1 January 2022.\n- \"How to become a Chief Information Security Officer (CISO)?\". cybersecuritycareer.org. 1 August 2021. Retrieved 4 January 2022.\n- \"Data Protection Officers\". ico.org.uk. January 2021.\n- \"Student Cybersecurity Resources\". NICCS (US National Initiative for Cybercareers and Studies). Archived from the original on 5 November 2020.\n- \"Current Job Opportunities at DHS\". U.S. Department of Homeland Security. Archived from the original on 2 May 2013. Retrieved 5 May 2013.\n- \"Cybersecurity Training & Exercises\". U.S. Department of Homeland Security. 12 May 2010. Archived from the original on 7 January 2015. Retrieved 9 January 2015.\n- \"Cyber Security Awareness Free Training and Webcasts\". MS-ISAC (Multi-State Information Sharing & Analysis Center). Archived from the original on 6 January 2015. Retrieved 9 January 2015.\n- \"DoD Approved 8570 Baseline Certifications\". iase.disa.mil. Archived from the original on 21 October 2016. Retrieved 19 June 2017.\n- \"The UK Cyber Security Strategy: Report on Progress and Forward Plans December 2014\" (PDF). United Kingdom Cabinet Office. Archived (PDF) from the original on 18 April 2018. Retrieved 20 August 2021.\n- \"Cyber skills for a vibrant and secure UK\". GOV.UK.\n- \"Singapore Operational Technology (OT) Cybersecurity Competency Framework\". Cyber Security Agency (Press release). 8 October 2021. Archived from the original on 16 October 2021. Retrieved 23 October 2021.\n- \"Confidentiality\". Retrieved 31 October 2011.\n- \"Data Integrity\". Archived from the original on 6 November 2011. Retrieved 31 October 2011.\n- \"Endpoint Security\". 10 November 2010. Archived from the original on 16 March 2014. Retrieved 15 March 2014.\n- \"A Brief History of the Cybersecurity Profession\". ISACA. Retrieved 13 October 2023.\n- \"One step ahead in computing security\". RIT. Retrieved 13 October 2023.\n- Misa, Thomas J. (2016). \"Computer Security Discourse at RAND, SDC, and NSA (1958-1970)\". IEEE Annals of the History of Computing. 38 (4): 12–25. Bibcode:2016IAHC...38d..12M. doi:10.1109/MAHC.2016.48. S2CID 17609542.\n- Neumann, A. J.; Statland, N.; Webb, R. D. (1977). \"Post-processing audit tools and techniques\" (PDF). nist.gov. US Department of Commerce, National Bureau of Standards. pp. 11–3–11–4. Archived (PDF) from the original on 10 October 2016. Retrieved 19 June 2020.\n- Irwin, Luke (5 April 2018). \"How NIST can protect the CIA triad, including the often overlooked 'I' – integrity\". www.itgovernanceusa.com. Retrieved 16 January 2021.\n- Perrin, Chad (30 June 2008). \"The CIA Triad\". techrepublic.com. Retrieved 31 May 2012.\n- Stoneburner, G.; Hayden, C.; Feringa, A. (2004). Engineering Principles for Information Technology Security (PDF) (Report). csrc.nist.gov. doi:10.6028/NIST.SP.800-27rA. Archived (PDF) from the original on 12 October 2004.Note: this document has been superseded by later versions.\n- Yost, Jeffrey R. (April 2015). \"The Origin and Early History of the Computer Security Software Products Industry\". IEEE Annals of the History of Computing. 37 (2): 46–58. Bibcode:2015IAHC...37b..46Y. doi:10.1109/MAHC.2015.21. ISSN 1934-1547. S2CID 18929482.\n- \"A Brief History of Computer Viruses & What the Future Holds\". www.kaspersky.com. 19 April 2023. Retrieved 12 June 2024.\n- Tomlinson, Ray. \"Interview with Ray Tomlinson on Creeper/Reaper\". OSNews. Retrieved 25 September 2025.\n- \"First incident of cyber-espionage\". Guinness World Records. Retrieved 23 January 2024.\n- FBI News (2 November 2018). \"The Morris Worm - 30 Years Since First Major Attack on the Internet\". fbi.gov. Retrieved 23 January 2024.\n- Boncella, Robert J (April 2004). Bidgoli, Hossein (ed.). The Internet Encyclopedia, Volume 2 (2nd ed.). Wiley. p. 262. ISBN 978-0-471-68996-6.\n- \"1993: Mosaic Launches and the Web is Set Free\". Web Development History. 8 December 2021.\n- \"Web Design Museum - Netscape Navigator 2.0\". 10 March 2023. Retrieved 4 December 2023.\n- Nakashima, Ellen (26 January 2008). \"Bush Order Expands Network Monitoring: Intelligence Agencies to Track Intrusions\". The Washington Post. Retrieved 8 February 2021.\n- Perlroth, Nicole (7 February 2021). \"How the U.S. Lost to Hackers\". The New York Times. Archived from the original on 28 December 2021. Retrieved 9 February 2021.\n- Perlroth, Nicole; Sanger, David; Shane, Scott (6 May 2019). \"How Chinese Spies Got the N.S.A.'s Hacking Tools, and Used Them for Attacks\". The New York Times. Retrieved 18 October 2024.\n- Greenberg, Andy (7 May 2019). \"The Strange Journey of an NSA Zero-Day—Into Multiple Enemies' Hands\". WIRED. Retrieved 25 September 2025.\n- Schectman, Joel; Bing, Christopher (14 September 2021). \"Ex-U.S. intel operatives admit hacking American networks for UAE\". Reuters. Retrieved 25 September 2025.\n- Branch, Jordan (24 September 2020). \"What's in a Name? Metaphors and Cybersecurity\". International Organization. 75 (1). Cambridge University Press (CUP): 39–70. doi:10.1017/s002081832000051x. ISSN 0020-8183. S2CID 224886794.\n- Costigan, Sean; Hennessy, Michael (2016). Cybersecurity: A Generic Reference Curriculum (PDF). NATO. ISBN 978-92-845-0196-0. Archived (PDF) from the original on 10 March 2017.\n- Fuller, Christopher J (11 June 2018). \"The Roots of the United States' Cyber (In)Security\" (DOC). Diplomatic History. 43 (1). Oxford University Press (OUP): 157–185. doi:10.1093/dh/dhy038. ISSN 0145-2096.\n- Bob, Yonah Jeremy (21 August 2021). \"Ex-IDF cyber intel. official reveals secrets behind cyber offense\". The Jerusalem Post.\n- Kim, Peter (2014). The Hacker Playbook: Practical Guide To Penetration Testing. Seattle: CreateSpace Independent Publishing Platform. ISBN 978-1-4949-3263-3.\n- Lee, Newton (2015). Counterterrorism and Cybersecurity: Total Information Awareness (2nd ed.). Springer. ISBN 978-3-319-17243-9.\n- Montagnani, Maria Lillà; Cavallo, Mirta Antonella (2018). \"Cybersecurity and Liability in a Big Data World\". Market and Competition Law Review. 2 (2). Elsevier BV: 71–98. doi:10.2139/ssrn.3220475. ISSN 1556-5068. S2CID 216704215. SSRN 3220475.\n- Shariati, Marzieh; Bahmani, Faezeh; Shams, Fereidoon (2011). \"Enterprise information security, a review of architectures and frameworks from interoperability perspective\". Procedia Computer Science. 3. Elsevier BV: 537–543. doi:10.1016/j.procs.2010.12.089. ISSN 1877-0509.\n- Singer, P. W.; Friedman, Allan (2014). Cybersecurity and Cyberwar: What Everyone Needs to Know. Oxford University Press. ISBN 978-0-19-991811-9.\n- Wu, Chwan-Hwa (John); Irwin, J. David (2013). Introduction to Computer Networks and Cybersecurity. Boca Raton: CRC Press. ISBN 978-1-4665-7213-3.\n- Cybersecurity Best Practices | Cybersecurity and Infrastructure Security Agency CISA. (n.d.). Retrieved April 24, 2024, from https://www.cisa.gov/topics/cybersecurity-best-practices\n- Sztyber-Betley, A., Syfert, M., Kościelny, J. M., & Górecka, Z. (2023). Controller Cyber-Attack Detection and Isolation †: Sensors (14248220). Sensors (14248220), 23(5), 2778. doi:10.3390/s23052778",
    "conglomerate": "Appearance\nConglomerate or conglomeration may refer to:\nIn popular culture:\n- The Conglomerate (American group), a production crew and musical group founded by Busta Rhymes\n- Conglomerate (record label), a hip hop label founded by Busta Rhymes\n- The Conglomerate (Australian group), a jazz quartet\n- Conglomerate Ridge, in the Ellsworth Mountains, Antarctica\n- ConGlomeration (convention)",
    "data analysis": "Data analysis is the process of inspecting, cleansing, transforming, and modeling data with the goal of discovering useful information, informing conclusions, and supporting decision-making.[1] Data analysis has multiple facets and approaches, encompassing diverse techniques under a variety of names, and is used in different business, science, and social science domains.[2] In today's business world, data analysis plays a role in making decisions more scientific and helping businesses operate more effectively.[3]\nData mining is a particular data analysis technique that focuses on statistical modeling and knowledge discovery for predictive rather than purely descriptive purposes, while business intelligence covers data analysis that relies heavily on aggregation, focusing mainly on business information. In statistical applications, data analysis can be divided into descriptive statistics, exploratory data analysis (EDA), and confirmatory data analysis (CDA).[4] EDA focuses on discovering new features in the data while CDA focuses on confirming or falsifying existing hypotheses.[5] Predictive analytics focuses on the application of statistical models for predictive forecasting or classification, while text analytics applies statistical, linguistic, and structural techniques to extract and classify information from textual sources, a variety of unstructured data. All of the above are varieties of data analysis.[6]\nData analysis is a process for obtaining raw data, and subsequently converting it into information useful for decision-making by users.[1] Statistician John Tukey, defined data analysis in 1961, as:\n\"Procedures for analyzing data, techniques for interpreting the results of such procedures, ways of planning the gathering of data to make its analysis easier, more precise or more accurate, and all the machinery and results of (mathematical) statistics which apply to analyzing data.\"[7]\nThere are several phases, and they are iterative, in that feedback from later phases may result in additional work in earlier phases.[8]\nThe data is necessary as inputs to the analysis, which is specified based upon the requirements of those directing the analytics (or customers, who will use the finished product of the analysis).[9] The general type of entity upon which the data will be collected is referred to as an experimental unit (e.g., a person or population of people). Specific variables regarding a population (e.g., age and income) may be specified and obtained. Data may be numerical or categorical (i.e., a text label for numbers).[8]\nData may be collected from a variety of sources.[10] A list of data sources are available for study & research. The requirements may be communicated by analysts to custodians of the data; such as, Information Technology personnel within an organization.[11] Data collection or data gathering is the process of gathering and measuring information on targeted variables in an established system, which then enables one to answer relevant questions and evaluate outcomes. The data may also be collected from sensors in the environment, including traffic cameras, satellites, recording devices, etc. It may also be obtained through interviews, downloads from online sources, or reading documentation.[8]\nData integration is a precursor to data analysis: Data, when initially obtained, must be processed or organized for analysis. For instance, this may involve placing data into rows and columns in a table format (known as structured data) for further analysis, often through the use of spreadsheet(excel) or statistical software.[8]\nOnce processed and organized, the data may be incomplete, contain duplicates, or contain errors.[12] The need for data cleaning will arise from problems in the way that the data is entered and stored.[12][13] Data cleaning is the process of preventing and correcting these errors. Common tasks include record matching, identifying inaccuracy of data, overall quality of existing data, deduplication, and column segmentation.[14][15]\nSuch data problems can also be identified through a variety of analytical techniques. For example; with financial information, the totals for particular variables may be compared against separately published numbers that are believed to be reliable.[16] Unusual amounts, above or below predetermined thresholds, may also be reviewed. There are several types of data cleaning that are dependent upon the type of data in the set; this could be phone numbers, email addresses, employers, or other values.[17] Quantitative data methods for outlier detection can be used to get rid of data that appears to have a higher likelihood of being input incorrectly. Text data spell checkers can be used to lessen the amount of mistyped words. However, it is harder to tell if the words are contextually (i.e., semantically and idiomatically) correct.\nOnce the datasets are cleaned, they can then begin to be analyzed using exploratory data analysis. The process of data exploration may result in additional data cleaning or additional requests for data; thus, the initialization of the iterative phases mentioned above.[18] Descriptive statistics, such as the average, median, and standard deviation, are often used to broadly characterize the data.[19][20] Data visualization is also used, in which the analyst is able to examine the data in a graphical format in order to obtain additional insights about messages within the data.[8]\nMathematical formulas or models (also known as algorithms), may be applied to the data in order to identify relationships among the variables; for example, checking for correlation and by determining whether or not there is the presence of causality. In general terms, models may be developed to evaluate a specific variable based on other variable(s) contained within the dataset, with some residual error depending on the implemented model's accuracy (e.g., Data = Model + Error).[21]\nInferential statistics utilizes techniques that measure the relationships between particular variables.[22] For example, regression analysis may be used to model whether a change in advertising (independent variable X), provides an explanation for the variation in sales (dependent variable Y), i.e. is Y a function of X? This can be described as (Y = aX + b + error), where the model is designed such that (a) and (b) minimize the error when the model predicts Y for a given range of values of X.[23]\nA data product is a computer application that takes data inputs and generates outputs, feeding them back into the environment.[24] It may be based on a model or algorithm. For instance, an application that analyzes data about customer purchase history, and uses the results to recommend other purchases the customer might enjoy.[25][8]\nOnce data is analyzed, it may be reported in many formats to the users of the analysis to support their requirements.[27] The users may have feedback, which results in additional analysis.\nWhen determining how to communicate the results, the analyst may consider implementing a variety of data visualization techniques to help communicate the message more clearly and efficiently to the audience. Data visualization uses information displays (graphics such as, tables and charts) to help communicate key messages contained in the data. Tables are a valuable tool by enabling the ability of a user to query and focus on specific numbers; while charts (e.g., bar charts or line charts), may help explain the quantitative messages contained in the data.[28]\nStephen Few described eight types of quantitative messages that users may attempt to communicate from a set of data, including the associated graphs.[29][30]\n- Time-series: A single variable is captured over a period of time, such as the unemployment rate over a 10-year period. A line chart may be used to demonstrate the trend.\n- Ranking: Categorical subdivisions are ranked in ascending or descending order, such as a ranking of sales performance (the measure) by salespersons (the category, with each salesperson a categorical subdivision) during a single period. A bar chart may be used to show the comparison across the salespersons.[31]\n- Part-to-whole: Categorical subdivisions are measured as a ratio to the whole (i.e., a percentage out of 100%). A pie chart or bar chart can show the comparison of ratios, such as the market share represented by competitors in a market.[32]\n- Deviation: Categorical subdivisions are compared against a reference, such as a comparison of actual vs. budget expenses for several departments of a business for a given time period. A bar chart can show the comparison of the actual versus the reference amount.[33]\n- Frequency distribution: Shows the number of observations of a particular variable for a given interval, such as the number of years in which the stock market return is between intervals such as 0–10%, 11–20%, etc. A histogram, a type of bar chart, may be used for this analysis.\n- Correlation: Comparison between observations represented by two variables (X,Y) to determine if they tend to move in the same or opposite directions. For example, plotting unemployment (X) and inflation (Y) for a sample of months. A scatter plot is typically used for this message.[34]\n- Nominal comparison: Comparing categorical subdivisions in no particular order, such as the sales volume by product code. A bar chart may be used for this comparison.[35]\n- Geographic or geo-spatial: Comparison of a variable across a map or layout, such as the unemployment rate by state or the number of persons on the various floors of a building. A cartogram is typically used.[29]\nAuthor Jonathan Koomey has recommended a series of best practices for understanding quantitative data. These include:[16]\n- Check raw data for anomalies prior to performing an analysis;\n- Re-perform important calculations, such as verifying columns of data that are formula-driven;\n- Confirm main totals are the sum of subtotals;\n- Check relationships between numbers that should be related in a predictable way, such as ratios over time;\n- Normalize numbers to make comparisons easier, such as analyzing amounts per person or relative to GDP or as an index value relative to a base year;\n- Break problems into component parts by analyzing factors that led to the results, such as DuPont analysis of return on equity.\nFor the variables under examination, analysts typically obtain descriptive statistics, such as the mean (average), median, and standard deviation. They may also analyze the distribution of the key variables to see how the individual values cluster around the mean.[16]\nMcKinsey and Company named a technique for breaking down a quantitative problem into its component parts called the MECE principle. MECE means \"Mutually Exclusive and Collectively Exhaustive\".[36] Each layer can be broken down into its components; each of the sub-components must be mutually exclusive of each other and collectively add up to the layer above them. For example, profit by definition can be broken down into total revenue and total cost.[37]\nAnalysts may use robust statistical measurements to solve certain analytical problems. Hypothesis testing is used when a particular hypothesis about the true state of affairs is made by the analyst and data is gathered to determine whether that hypothesis is true or false.[38] For example, the hypothesis might be that \"Unemployment has no effect on inflation\", which relates to an economics concept called the Phillips Curve.[39] Hypothesis testing involves considering the likelihood of Type I and type II errors, which relate to whether the data supports accepting or rejecting the hypothesis.[40]\nRegression analysis may be used when the analyst is trying to determine the extent to which independent variable X affects dependent variable Y (e.g., \"To what extent do changes in the unemployment rate (X) affect the inflation rate (Y)?\").[41]\nNecessary condition analysis (NCA) may be used when the analyst is trying to determine the extent to which independent variable X allows variable Y (e.g., \"To what extent is a certain unemployment rate (X) necessary for a certain inflation rate (Y)?\").[41] Whereas (multiple) regression analysis uses additive logic where each X-variable can produce the outcome and the X's can compensate for each other (they are sufficient but not necessary),[42] necessary condition analysis (NCA) uses necessity logic, where one or more X-variables allow the outcome to exist, but may not produce it (they are necessary but not sufficient). Each single necessary condition must be present and compensation is not possible.[43]\nUsers may have particular data points of interest within a data set, as opposed to the general messaging outlined above. Such low-level user analytic activities are presented in the following table. The taxonomy can also be organized by three poles of activities: retrieving values, finding data points, and arranging data points.[44][45][46]\n| # | Task | General description |\nPro forma abstract |\nExamples |\n|---|---|---|---|---|\n| 1 | Retrieve Value | Given a set of specific cases, find attributes of those cases. | What are the values of attributes {X, Y, Z, ...} in the data cases {A, B, C, ...}? | - What is the mileage per gallon of the Ford Mondeo?\n- How long is the movie Gone with the Wind? |\n| 2 | Filter | Given some concrete conditions on attribute values, find data cases satisfying those conditions. | Which data cases satisfy conditions {A, B, C...}? | - What Kellogg's cereals have high fiber?\n- What comedies have won awards? - Which funds underperformed the SP-500? |\n| 3 | Compute Derived Value | Given a set of data cases, compute an aggregate numeric representation of those data cases. | What is the value of aggregation function F over a given set S of data cases? | - What is the average calorie content of Post cereals?\n- What is the gross income of all stores combined? - How many manufacturers of cars are there? |\n| 4 | Find Extremum | Find data cases possessing an extreme value of an attribute over its range within the data set. | What are the top/bottom N data cases with respect to attribute A? | - What is the car with the highest MPG?\n- What director/film has won the most awards? - What Marvel Studios film has the most recent release date? |\n| 5 | Sort | Given a set of data cases, rank them according to some ordinal metric. | What is the sorted order of a set S of data cases according to their value of attribute A? | - Order the cars by weight.\n- Rank the cereals by calories. |\n| 6 | Determine Range | Given a set of data cases and an attribute of interest, find the span of values within the set. | What is the range of values of attribute A in a set S of data cases? | - What is the range of film lengths?\n- What is the range of car horsepowers? - What actresses are in the data set? |\n| 7 | Characterize Distribution | Given a set of data cases and a quantitative attribute of interest, characterize the distribution of that attribute's values over the set. | What is the distribution of values of attribute A in a set S of data cases? | - What is the distribution of carbohydrates in cereals?\n- What is the age distribution of shoppers? |\n| 8 | Find Anomalies | Identify any anomalies within a given set of data cases with respect to a given relationship or expectation, e.g. statistical outliers. | Which data cases in a set S of data cases have unexpected/exceptional values? | - Are there exceptions to the relationship between horsepower and acceleration?\n- Are there any outliers in protein? |\n| 9 | Cluster | Given a set of data cases, find clusters of similar attribute values. | Which data cases in a set S of data cases are similar in value for attributes {X, Y, Z, ...}? | - Are there groups of cereals w/ similar fat/calories/sugar?\n- Is there a cluster of typical film lengths? |\n| 10 | Correlate | Given a set of data cases and two attributes, determine useful relationships between the values of those attributes. | What is the correlation between attributes X and Y over a given set S of data cases? | - Is there a correlation between carbohydrates and fat?\n- Is there a correlation between country of origin and MPG? - Do different genders have a preferred payment method? - Is there a trend of increasing film length over the years? |\n| 11 | Contextualization | Given a set of data cases, find contextual relevancy of the data to the users. | Which data cases in a set S of data cases are relevant to the current users' context? | - Are there groups of restaurants that have foods based on my current caloric intake? |\nBarriers to effective analysis may exist among the analysts performing the data analysis or among the audience. Distinguishing fact from opinion, cognitive biases, and innumeracy are all challenges to sound data analysis.[47]\nYou are entitled to your own opinion, but you are not entitled to your own facts.\nEffective analysis requires obtaining relevant facts to answer questions, support a conclusion or formal opinion, or test hypotheses.[48] Facts by definition are irrefutable, meaning that any person involved in the analysis should be able to agree upon them. The auditor of a public company must arrive at a formal opinion on whether financial statements of publicly traded corporations are \"fairly stated, in all material respects\".[49] This requires extensive analysis of factual data and evidence to support their opinion.\nThere are a variety of cognitive biases that can adversely affect analysis. For example, confirmation bias is the tendency to search for or interpret information in a way that confirms one's preconceptions.[50] In addition, individuals may discredit information that does not support their views.[51]\nAnalysts may be trained specifically to be aware of these biases and how to overcome them.[52] In his book Psychology of Intelligence Analysis, retired CIA analyst Richards Heuer wrote that analysts should clearly delineate their assumptions and chains of inference and specify the degree and source of the uncertainty involved in the conclusions.[53] He emphasized procedures to help surface and debate alternative points of view.[54]\nEffective analysts are generally adept with a variety of numerical techniques. However, audiences may not have such literacy with numbers or numeracy; they are said to be innumerate.[55] Persons communicating the data may also be attempting to mislead or misinform, deliberately using bad numerical techniques.[56]\nFor example, whether a number is rising or falling may not be the key factor. More important may be the number relative to another number, such as the size of government revenue or spending relative to the size of the economy (GDP) or the amount of cost relative to revenue in corporate financial statements.[57] This numerical technique is referred to as normalization[16] or common-sizing. There are many such techniques employed by analysts, whether adjusting for inflation (i.e., comparing real vs. nominal data) or considering population increases, demographics, etc.[58]\nAnalysts may also analyze data under different assumptions or scenarios. For example, when analysts perform financial statement analysis, they will often recast the financial statements under different assumptions to help arrive at an estimate of future cash flow, which they then discount to present value based on some interest rate, to determine the valuation of the company or its stock.[59] Similarly, the CBO analyzes the effects of various policy options on the government's revenue, outlays and deficits, creating alternative future scenarios for key measures.[60]\nAnalytics is the \"extensive use of data, statistical and quantitative analysis, explanatory and predictive models, and fact-based management to drive decisions and actions.\" It is a subset of business intelligence, which is a set of technologies and processes that uses data to understand and analyze business performance to drive decision-making.[61]\nIn education, most educators have access to a data system for the purpose of analyzing student data.[62] These data systems present data to educators in an over-the-counter data format (embedding labels, supplemental documentation, and a help system and making key package/display and content decisions) to improve the accuracy of educators' data analyses.[63]\nThis section contains rather technical explanations that may assist practitioners but are beyond the typical scope of a Wikipedia article.[64]\nThe most important distinction between the initial data analysis phase and the main analysis phase is that during initial data analysis one refrains from any analysis that is aimed at answering the original research question. The initial data analysis phase is guided by the following four questions:[65]\nThe quality of the data should be checked as early as possible. Data quality can be assessed in several ways, using different types of analysis: frequency counts, descriptive statistics (mean, standard deviation, median), normality (skewness, kurtosis, frequency histograms), normal imputation is needed.[66]\n- Analysis of extreme observations: outlying observations in the data are analyzed to see if they seem to disturb the distribution.[67]\n- Comparison and correction of differences in coding schemes: variables are compared with coding schemes of variables external to the data set, and possibly corrected if coding schemes are not comparable.[68]\n- Test for common-method variance. The choice of analyses to assess the data quality during the initial data analysis phase depends on the analyses that will be conducted in the main analysis phase.[69]\nThe quality of the measurement instruments should only be checked during the initial data analysis phase when this is not the focus or research question of the study.[70] One should check whether structure of measurement instruments corresponds to structure reported in the literature.\nThere are two ways to assess measurement quality:\n- Confirmatory factor analysis\n- Analysis of homogeneity (internal consistency), which gives an indication of the reliability of a measurement instrument.[71] During this analysis, one inspects the variances of the items and the scales, the Cronbach's α of the scales, and the change in the Cronbach's alpha when an item would be deleted from a scale[72]\nAfter assessing the quality of the data and of the measurements, one might decide to impute missing data, or to perform initial transformations of one or more variables, although this can also be done during the main analysis phase.[73]\nPossible transformations of variables are:[74]\n- Square root transformation (if the distribution differs moderately from normal)\n- Log-transformation (if the distribution differs substantially from normal)\n- Inverse transformation (if the distribution differs severely from normal)\n- Make categorical (ordinal / dichotomous) (if the distribution differs severely from normal, and no transformations help)\nOne should check the success of the randomization procedure, for instance by checking whether background and substantive variables are equally distributed within and across groups. If the study did not need or use a randomization procedure, one should check the success of the non-random sampling, for instance by checking whether all subgroups of the population of interest are represented in the sample.[75]\nOther possible data distortions that should be checked are:\n- dropout (this should be identified during the initial data analysis phase)\n- Item non-response (whether this is random or not should be assessed during the initial data analysis phase)\n- Treatment quality (using manipulation checks).[76]\nIn any report or article, the structure of the sample must be accurately described. It is especially important to exactly determine the size of the subgroup when subgroup analyses will be performed during the main analysis phase.[77]\nThe characteristics of the data sample can be assessed by looking at:\n- Basic statistics of important variables\n- Scatter plots\n- Correlations and associations\n- Cross-tabulations[78]\nDuring the final stage, the findings of the initial data analysis are documented, and necessary, preferable, and possible corrective actions are taken. Also, the original plan for the main data analyses can and should be specified in more detail or rewritten. In order to do this, several decisions about the main data analyses can and should be made:\n- In the case of non-normals: should one transform variables; make variables categorical (ordinal/dichotomous); adapt the analysis method?\n- In the case of missing data: should one neglect or impute the missing data; which imputation technique should be used?\n- In the case of outliers: should one use robust analysis techniques?\n- In case items do not fit the scale: should one adapt the measurement instrument by omitting items, or rather ensure comparability with other (uses of the) measurement instrument(s)?\n- In the case of (too) small subgroups: should one drop the hypothesis about inter-group differences, or use small sample techniques, like exact tests or bootstrapping?\n- In case the randomization procedure seems to be defective: can and should one calculate propensity scores and include them as covariates in the main analyses?[79]\nSeveral analyses can be used during the initial data analysis phase:[80]\n- Univariate statistics (single variable)\n- Bivariate associations (correlations)\n- Graphical techniques (scatter plots)\nIt is important to take the measurement levels of the variables into account for the analyses, as special statistical techniques are available for each level:[81]\n- Nominal and ordinal variables\n- Frequency counts (numbers and percentages)\n- Associations\n- circumambulations (crosstabulations)\n- hierarchical loglinear analysis (restricted to a maximum of 8 variables)\n- loglinear analysis (to identify relevant/important variables and possible confounders)\n- Exact tests or bootstrapping (in case subgroups are small)\n- Computation of new variables\n- Continuous variables\n- Distribution\n- Statistics (M, SD, variance, skewness, kurtosis)\n- Stem-and-leaf displays\n- Box plots\n- Distribution\nNonlinear analysis is often necessary when the data is recorded from a nonlinear system. Nonlinear systems can exhibit complex dynamic effects including bifurcations, chaos, harmonics and subharmonics that cannot be analyzed using simple linear methods. Nonlinear data analysis is closely related to nonlinear system identification.[82]\nIn the main analysis phase, analyses aimed at answering the research question are performed as well as any other relevant analysis needed to write the first draft of the research report.[83]\nIn the main analysis phase, either an exploratory or confirmatory approach can be adopted. Usually the approach is decided before data is collected.[84] In an exploratory analysis no clear hypothesis is stated before analysing the data, and the data is searched for models that describe the data well.[85] In a confirmatory analysis, clear hypotheses about the data are tested.[86]\nExploratory data analysis should be interpreted carefully. When testing multiple models at once there is a high chance on finding at least one of them to be significant, but this can be due to a type 1 error. It is important to always adjust the significance level when testing multiple models with, for example, a Bonferroni correction.[87] Also, one should not follow up an exploratory analysis with a confirmatory analysis in the same dataset.[88] An exploratory analysis is used to find ideas for a theory, but not to test that theory as well.[88] When a model is found exploratory in a dataset, then following up that analysis with a confirmatory analysis in the same dataset could simply mean that the results of the confirmatory analysis are due to the same type 1 error that resulted in the exploratory model in the first place.[88] The confirmatory analysis therefore will not be more informative than the original exploratory analysis.[89]\nIt is important to obtain some indication about how generalizable the results are.[90] While this is often difficult to check, one can look at the stability of the results. Are the results reliable and reproducible? There are two main ways of doing that.\n- Cross-validation. By splitting the data into multiple parts, we can check if an analysis (like a fitted model) based on one part of the data generalizes to another part of the data as well.[91] Cross-validation is generally inappropriate, though, if there are correlations within the data, e.g. with panel data.[92] Hence other methods of validation sometimes need to be used. For more on this topic, see statistical model validation.[93]\n- Sensitivity analysis. A procedure to study the behavior of a system or model when global parameters are (systematically) varied. One way to do that is via bootstrapping.[94]\nFree software for data analysis include:\n- DevInfo – A database system endorsed by the United Nations Development Group for monitoring and analyzing human development.[95]\n- ELKI – Data mining framework in Java with data mining oriented visualization functions.\n- KNIME – The Konstanz Information Miner, a user friendly and comprehensive data analytics framework.\n- Orange – A visual programming tool featuring interactive data visualization and methods for statistical data analysis, data mining, and machine learning.\n- Pandas – Python library for data analysis.\n- PAW – FORTRAN/C data analysis framework developed at CERN.\n- R – A programming language and software environment for statistical computing and graphics.[96]\n- ROOT – C++ data analysis framework developed at CERN.\n- SciPy – Python library for scientific computing.\n- Julia – A programming language well-suited for numerical analysis and computational science.\nThe typical data analysis workflow involves collecting data, running analyses, creating visualizations, and writing reports. However, this workflow presents challenges, including a separation between analysis scripts and data, as well as a gap between analysis and documentation. Often, the correct order of running scripts is only described informally or resides in the data scientist's memory. The potential for losing this information creates issues for reproducibility.\nTo address these challenges, it is essential to document analysis script content and workflow. Additionally, overall documentation is crucial, as well as providing reports that are understandable by both machines and humans, and ensuring accurate representation of the analysis workflow even as scripts evolve.[97]\nDifferent companies and organizations hold data analysis contests to encourage researchers to utilize their data or to solve a particular question using data analysis. A few examples of well-known international data analysis contests are:\n- Kaggle competitions; the Kaggle platform is owned and run by Google.[98]\n- LTPP data analysis contest[99] held by FHWA and ASCE.[100]\n- Actuarial science\n- Analytics\n- Augmented Analytics\n- Business intelligence\n- Data presentation architecture\n- Exploratory data analysis\n- List of datasets for machine-learning research\n- List of data science software\n- Machine learning\n- Multiway data analysis\n- Qualitative research\n- Structured data analysis (statistics)\n- Text mining\n- Unstructured data\n- \"Transforming Unstructured Data into Useful Information\", Big Data, Mining, and Analytics, Auerbach Publications, pp. 227–246, 2014-03-12, doi:10.1201/b16666-14, ISBN 978-0-429-09529-0, retrieved 2021-05-29\n- \"The Multiple Facets of Correlation Functions\", Data Analysis Techniques for Physical Scientists, Cambridge University Press, pp. 526–576, 2017, doi:10.1017/9781108241922.013, ISBN 978-1-108-41678-8, retrieved 2021-05-29\n- Xia, B. S., & Gong, P. (2015). Review of business intelligence through data analysis. Benchmarking, 21(2), 300-311. doi:10.1108/BIJ-08-2012-0050\n- \"Data Coding and Exploratory Analysis (EDA) Rules for Data Coding Exploratory Data Analysis (EDA) Statistical Assumptions\", SPSS for Intermediate Statistics, Routledge, pp. 42–67, 2004-08-16, doi:10.4324/9781410611420-6, ISBN 978-1-4106-1142-0, retrieved 2021-05-29\n- Samandar, Petersson; Svantesson, Sofia (2017). Skapandet av förtroende inom eWOM : En studie av profilbildens effekt ur ett könsperspektiv. Högskolan i Gävle, Företagsekonomi. OCLC 1233454128.\n- Goodnight, James (2011-01-13). \"The forecast for predictive analytics: hot and getting hotter\". Statistical Analysis and Data Mining: The ASA Data Science Journal. 4 (1): 9–10. doi:10.1002/sam.10106. ISSN 1932-1864. S2CID 38571193.\n- Tukey, John W. (March 1962). \"John Tukey-The Future of Data Analysis-July 1961\". The Annals of Mathematical Statistics. 33 (1): 1–67. doi:10.1214/aoms/1177704711. Archived from the original on 2020-01-26. Retrieved 2015-01-01.\n- Schutt, Rachel; O'Neil, Cathy (2013). Doing Data Science. O'Reilly Media. ISBN 978-1-449-35865-5.\n- \"USE OF THE DATA\", Handbook of Petroleum Product Analysis, Hoboken, NJ: John Wiley & Sons, Inc, pp. 296–303, 2015-02-06, doi:10.1002/9781118986370.ch18, ISBN 978-1-118-98637-0, retrieved 2021-05-29\n- Olusola, Johnson Adedeji; Shote, Adebola Adekunle; Ouigmane, Abdellah; Isaifan, Rima J. (7 May 2021). \"Table 1: Data type and sources of data collected for this research\". PeerJ. 9: e11387. doi:10.7717/peerj.11387/table-1.\n- MacPherson, Derek (2019-10-16), \"Information Technology Analysts' Perspectives\", Data Strategy in Colleges and Universities, Routledge, pp. 168–183, doi:10.4324/9780429437564-12, ISBN 978-0-429-43756-4, S2CID 211738958, retrieved 2021-05-29\n- Bohannon, John (2016-02-24). \"Many surveys, about one in five, may contain fraudulent data\". Science. doi:10.1126/science.aaf4104. ISSN 0036-8075.\n- Hancock, R.G.V.; Carter, Tristan (February 2010). \"How reliable are our published archaeometric analyses? Effects of analytical techniques through time on the elemental analysis of obsidians\". Journal of Archaeological Science. 37 (2): 243–250. Bibcode:2010JArSc..37..243H. doi:10.1016/j.jas.2009.10.004. ISSN 0305-4403.\n- \"Data Cleaning\". Microsoft Research. Archived from the original on 29 October 2013. Retrieved 26 October 2013.\n- Hellerstein, Joseph (27 February 2008). \"Quantitative Data Cleaning for Large Databases\" (PDF). EECS Computer Science Division: 3. Archived (PDF) from the original on 13 October 2013. Retrieved 26 October 2013.\n- \"Perceptual Edge-Jonathan Koomey-Best practices for understanding quantitative data-February 14, 2006\" (PDF). Archived (PDF) from the original on October 5, 2014. Retrieved November 12, 2014.\n- Peleg, Roni; Avdalimov, Angelika; Freud, Tamar (2011-03-23). \"Providing cell phone numbers and email addresses to Patients: the physician's perspective\". BMC Research Notes. 4 (1): 76. doi:10.1186/1756-0500-4-76. ISSN 1756-0500. PMC 3076270. PMID 21426591.\n- \"FTC requests additional data\". Pump Industry Analyst. 1999 (48): 12. December 1999. doi:10.1016/s1359-6128(99)90509-8. ISSN 1359-6128.\n- \"Exploring your Data with Data Visualization & Descriptive Statistics: Common Descriptive Statistics for Quantitative Data\". 2017. doi:10.4135/9781529732795.\n{{cite journal}}\n: Cite journal requires|journal=\n(help) - Murray, Daniel G. (2013). Tableau your data! : fast and easy visual analysis with Tableau Software. J. Wiley & Sons. ISBN 978-1-118-61204-0. OCLC 873810654.\n- Evans, Michelle V.; Dallas, Tad A.; Han, Barbara A.; Murdock, Courtney C.; Drake, John M. (28 February 2017). Brady, Oliver (ed.). \"Figure 2. Variable importance by permutation, averaged over 25 models\". eLife. 6: e22053. doi:10.7554/elife.22053.004.\n- Watson, Kevin; Halperin, Israel; Aguilera-Castells, Joan; Iacono, Antonio Dello (12 November 2020). \"Table 3: Descriptive (mean ± SD), inferential (95% CI) and qualitative statistics (ES) of all variables between self-selected and predetermined conditions\". PeerJ. 8: e10361. doi:10.7717/peerj.10361/table-3.\n- Nwabueze, JC (2008-05-21). \"Performances of estimators of linear model with auto-correlated error terms when the independent variable is normal\". Journal of the Nigerian Association of Mathematical Physics. 9 (1). doi:10.4314/jonamp.v9i1.40071. ISSN 1116-4336.\n- Conway, Steve (2012-07-04). \"A Cautionary Note on Data Inputs and Visual Outputs in Social Network Analysis\". British Journal of Management. 25 (1): 102–117. doi:10.1111/j.1467-8551.2012.00835.x. hdl:2381/36068. ISSN 1045-3172. S2CID 154347514.\n- \"Customer Purchases and Other Repeated Events\", Data Analysis Using SQL and Excel®, Indianapolis, Indiana: John Wiley & Sons, Inc., pp. 367–420, 2016-01-29, doi:10.1002/9781119183419.ch8, ISBN 978-1-119-18341-9, retrieved 2021-05-31\n- Grandjean, Martin (2014). \"La connaissance est un réseau\" (PDF). Les Cahiers du Numérique. 10 (3): 37–54. doi:10.3166/lcn.10.3.37-54. Archived (PDF) from the original on 2015-09-27. Retrieved 2015-05-05.\n- Data requirements for semiconductor die. Exchange data formats and data dictionary, BSI British Standards, doi:10.3403/02271298, retrieved 2021-05-31\n- Visualizing Data About UK Museums: Bar Charts, Line Charts and Heat Maps. 2021. doi:10.4135/9781529768749. ISBN 9781529768749. S2CID 240967380.\n- \"Stephen Few-Perceptual Edge-Selecting the Right Graph for Your Message-2004\" (PDF). Archived (PDF) from the original on 2014-10-05. Retrieved 2014-10-29.\n- \"Stephen Few-Perceptual Edge-Graph Selection Matrix\" (PDF). Archived (PDF) from the original on 2014-10-05. Retrieved 2014-10-29.\n- Swamidass, P. M. (2000). \"X-Bar Chart\". Encyclopedia of Production and Manufacturing Management. p. 841. doi:10.1007/1-4020-0612-8_1063. ISBN 978-0-7923-8630-8.\n- \"Chart C5.3. Percentage of 15-19 year-olds not in education, by labour market status (2012)\". doi:10.1787/888933119055. Retrieved 2021-06-03.\n{{cite journal}}\n: Cite journal requires|journal=\n(help) - \"Chart 7: Households: final consumption expenditure versus actual individual consumption\". doi:10.1787/665527077310. Retrieved 2021-06-03.\n{{cite journal}}\n: Cite journal requires|journal=\n(help) - Garnier, Elodie M.; Fouret, Nastasia; Descoins, Médéric (3 February 2020). \"Table 2: Graph comparison between Scatter plot, Violin + Scatter plot, Heatmap and ViSiElse graph\". PeerJ. 8: e8341. doi:10.7717/peerj.8341/table-2.\n- \"Product comparison chart: Wearables\". PsycEXTRA Dataset. 2009. doi:10.1037/e539162010-006. Retrieved 2021-06-03.\n- \"Consultants Employed by McKinsey & Company\", Organizational Behavior 5, Routledge, pp. 77–82, 2008-07-30, doi:10.4324/9781315701974-15, ISBN 978-1-315-70197-4, retrieved 2021-06-03\n- Carey, Malachy (November 1981). \"On Mutually Exclusive and Collectively Exhaustive Properties of Demand Functions\". Economica. 48 (192): 407–415. doi:10.2307/2553697. ISSN 0013-0427. JSTOR 2553697.\n- Heckman (1978). \"Simple Statistical Models for Discrete Panel Data Developed and Applied to Test the Hypothesis of True State Dependence against the Hypothesis of Spurious State Dependence\". Annales de l'inséé (30/31): 227–269. doi:10.2307/20075292. ISSN 0019-0209. JSTOR 20075292.\n- Munday, Stephen C. R. (1996), \"Unemployment, Inflation and the Phillips Curve\", Current Developments in Economics, London: Macmillan Education UK, pp. 186–218, doi:10.1007/978-1-349-24986-2_11, ISBN 978-0-333-64444-7, retrieved 2021-06-03\n- Louangrath, Paul I. (2013). \"Alpha and Beta Tests for Type I and Type II Inferential Errors Determination in Hypothesis Testing\". SSRN Electronic Journal. doi:10.2139/ssrn.2332756. ISSN 1556-5068.\n- Yanamandra, Venkataramana (September 2015). \"Exchange rate changes and inflation in India: What is the extent of exchange rate pass-through to imports?\". Economic Analysis and Policy. 47: 57–68. doi:10.1016/j.eap.2015.07.004. ISSN 0313-5926.\n- Feinmann, Jane. \"How Can Engineers and Journalists Help Each Other?\" (Video). The Institute of Engineering & Technology. doi:10.1049/iet-tv.48.859. Retrieved 2021-06-03.\n- Dul, Jan (2015). \"Necessary Condition Analysis (NCA): Logic and Methodology of 'Necessary But Not Sufficient' Causality\". SSRN Electronic Journal. doi:10.2139/ssrn.2588480. hdl:1765/77890. ISSN 1556-5068. S2CID 219380122.\n- Robert Amar, James Eagan, and John Stasko (2005) \"Low-Level Components of Analytic Activity in Information Visualization\" Archived 2015-02-13 at the Wayback Machine\n- William Newman (1994) \"A Preliminary Analysis of the Products of HCI Research, Using Pro Forma Abstracts\" Archived 2016-03-03 at the Wayback Machine\n- Mary Shaw (2002) \"What Makes Good Research in Software Engineering?\" Archived 2018-11-05 at the Wayback Machine\n- \"Connectivity tool transfers data among database and statistical products\". Computational Statistics & Data Analysis. 8 (2): 224. July 1989. doi:10.1016/0167-9473(89)90021-2. ISSN 0167-9473.\n- \"Information relevant to your job\", Obtaining Information for Effective Management, Routledge, pp. 48–54, 2007-07-11, doi:10.4324/9780080544304-16 (inactive 1 July 2025), ISBN 978-0-08-054430-4, retrieved 2021-06-03\n{{citation}}\n: CS1 maint: DOI inactive as of July 2025 (link) - Gordon, Roger (March 1990). \"Do Publicly Traded Corporations Act in the Public Interest?\". National Bureau of Economic Research Working Papers. Cambridge, MA. doi:10.3386/w3303.\n- Rivard, Jillian R (2014). Confirmation bias in witness interviewing: Can interviewers ignore their preconceptions? (Thesis). Florida International University. doi:10.25148/etd.fi14071109.\n- Papineau, David (1988), \"Does the Sociology of Science Discredit Science?\", Relativism and Realism in Science, Dordrecht: Springer Netherlands, pp. 37–57, doi:10.1007/978-94-009-2877-0_2, ISBN 978-94-010-7795-8, retrieved 2021-06-03\n- Bromme, Rainer; Hesse, Friedrich W.; Spada, Hans, eds. (2005). Barriers and Biases in Computer-Mediated Knowledge Communication. doi:10.1007/b105100. ISBN 978-0-387-24317-7.\n- Heuer, Richards (2019-06-10). Heuer, Richards J (ed.). Quantitative Approaches to Political Intelligence. doi:10.4324/9780429303647. ISBN 9780429303647. S2CID 145675822.\n- \"Introduction\" (PDF). Central Intelligence Agency. Archived (PDF) from the original on 2021-10-25. Retrieved 2021-10-25.\n- \"Figure 6.7. Differences in literacy scores across OECD countries generally mirror those in numeracy\". doi:10.1787/888934081549. Retrieved 2021-06-03.\n- Ritholz, Barry. \"Bad Math that Passes for Insight\". Bloomberg View. Archived from the original on 2014-10-29. Retrieved 2014-10-29.\n- Gusnaini, Nuriska; Andesto, Rony; Ermawati (2020-12-15). \"The Effect of Regional Government Size, Legislative Size, Number of Population, and Intergovernmental Revenue on The Financial Statements Disclosure\". European Journal of Business and Management Research. 5 (6). doi:10.24018/ejbmr.2020.5.6.651. ISSN 2507-1076. S2CID 231675715.\n- Taura, Toshiharu; Nagai, Yukari (2011). \"Comparing Nominal Groups to Real Teams\". Design Creativity 2010. London: Springer-Verlag London. pp. 165–171. ISBN 978-0-85729-223-0.\n- Gross, William H. (July 1979). \"Coupon Valuation and Interest Rate Cycles\". Financial Analysts Journal. 35 (4): 68–71. doi:10.2469/faj.v35.n4.68. ISSN 0015-198X.\n- \"25. General government total outlays\". doi:10.1787/888932348795. Retrieved 2021-06-03.\n- Davenport, Thomas; Harris, Jeanne (2007). Competing on Analytics. O'Reilly. ISBN 978-1-4221-0332-6.\n- Aarons, D. (2009). Report finds states on course to build pupil-data systems. Education Week, 29(13), 6.\n- Rankin, J. (2013, March 28). How data Systems & reports can either fight or propagate the data analysis error epidemic, and how educator leaders can help. Archived 2019-03-26 at the Wayback Machine Presentation conducted from Technology Information Center for Administrative Leadership (TICAL) School Leadership Summit.\n- Brödermann, Eckart J. (2018), \"Article 2.2.1 (Scope of the Section)\", Commercial Law, Nomos Verlagsgesellschaft mbH & Co. KG, p. 525, doi:10.5771/9783845276564-525, ISBN 978-3-8452-7656-4, retrieved 2021-06-03\n- Adèr 2008a, p. 337.\n- Kjell, Oscar N. E.; Thompson, Sam (19 December 2013). \"Descriptive statistics indicating the mean, standard deviation and frequency of missing values for each condition (N = number of participants), and for the dependent variables (DV)\". PeerJ. 1: e231. doi:10.7717/peerj.231/table-1.\n- Practice for Dealing With Outlying Observations, ASTM International, doi:10.1520/e0178-16a, retrieved 2021-06-03\n- \"Alternative Coding Schemes for Dummy Variables\", Regression with Dummy Variables, Newbury Park, CA: SAGE Publications, Inc., pp. 64–75, 1993, doi:10.4135/9781412985628.n5, ISBN 978-0-8039-5128-0, retrieved 2021-06-03\n- Adèr 2008a, pp. 338–341.\n- Newman, Isadore (1998). Qualitative-quantitative research methodology : exploring the interactive continuum. Southern Illinois University Press. ISBN 0-585-17889-5. OCLC 44962443.\n- Terwilliger, James S.; Lele, Kaustubh (June 1979). \"Some Relationships Among Internal Consistency, Reproducibility, and Homogeneity\". Journal of Educational Measurement. 16 (2): 101–108. doi:10.1111/j.1745-3984.1979.tb00091.x. ISSN 0022-0655.\n- Adèr 2008a, pp. 341–342.\n- Adèr 2008a, p. 344.\n- Tabachnick & Fidell, 2007, p. 87-88.\n- Random sampling and randomization procedures, BSI British Standards, doi:10.3403/30137438, retrieved 2021-06-03\n- Adèr 2008a, pp. 344–345.\n- Foth, Christian; Hedrick, Brandon P.; Ezcurra, Martin D. (18 January 2016). \"Figure 4: Centroid size regression analyses for the main sample\". PeerJ. 4: e1589. doi:10.7717/peerj.1589/fig-4.\n- Adèr 2008a, p. 345.\n- Adèr 2008a, pp. 345–346.\n- Adèr 2008a, pp. 346–347.\n- Adèr 2008a, pp. 349–353.\n- Billings S.A. \"Nonlinear System Identification: NARMAX Methods in the Time, Frequency, and Spatio-Temporal Domains\". Wiley, 2013\n- Adèr 2008b, p. 363.\n- \"Exploratory Data Analysis\", Python® for R Users, Hoboken, NJ, USA: John Wiley & Sons, Inc., pp. 119–138, 2017-10-13, doi:10.1002/9781119126805.ch4, hdl:11380/971504, ISBN 978-1-119-12680-5, retrieved 2021-06-03\n- \"Engaging in Exploratory Data Analysis, Visualization, and Hypothesis Testing – Exploratory Data Analysis, Geovisualization, and Data\", Spatial Analysis, CRC Press, pp. 106–139, 2015-07-28, doi:10.1201/b18808-8, ISBN 978-0-429-06936-9, S2CID 133412598, retrieved 2021-06-03\n- \"Hypotheses About Categories\", Starting Statistics: A Short, Clear Guide, London: SAGE Publications Ltd, pp. 138–151, 2010, doi:10.4135/9781446287873.n14, ISBN 978-1-84920-098-1, retrieved 2021-06-03\n- Liquet, Benoit; Riou, Jérémie (2013-06-08). \"Correction of the significance level when attempting multiple transformations of an explanatory variable in generalized linear models\". BMC Medical Research Methodology. 13 (1): 75. doi:10.1186/1471-2288-13-75. ISSN 1471-2288. PMC 3699399. PMID 23758852.\n- Mcardle, John J. (2008). \"Some ethical issues in confirmatory versus exploratory analysis\". PsycEXTRA Dataset. doi:10.1037/e503312008-001. Retrieved 2021-06-03.\n- Adèr 2008b, pp. 361–362.\n- Adèr 2008b, pp. 361–371.\n- Benson, Noah C; Winawer, Jonathan (December 2018). \"Bayesian analysis of retinotopic maps\". eLife. 7. doi:10.7554/elife.40224. PMC 6340702. PMID 30520736.doi:10.7554/elife.40224.014\n- Hsiao, Cheng (2014), \"Cross-Sectionally Dependent Panel Data\", Analysis of Panel Data, Cambridge: Cambridge University Press, pp. 327–368, doi:10.1017/cbo9781139839327.012, ISBN 978-1-139-83932-7, retrieved 2021-06-03\n- Hjorth, J.S. Urban (2017-10-19), \"Cross validation\", Computer Intensive Statistical Methods, Chapman and Hall/CRC, pp. 24–56, doi:10.1201/9781315140056-3, ISBN 978-1-315-14005-6, retrieved 2021-06-03\n- Sheikholeslami, Razi; Razavi, Saman; Haghnegahdar, Amin (2019-10-10). \"What should we do when a model crashes? Recommendations for global sensitivity analysis of Earth and environmental systems models\". Geoscientific Model Development. 12 (10): 4275–4296. Bibcode:2019GMD....12.4275S. doi:10.5194/gmd-12-4275-2019. ISSN 1991-9603. S2CID 204900339.\n- United Nations Development Programme (2018). \"Human development composite indices\". Human Development Indices and Indicators 2018. United Nations. pp. 21–41. doi:10.18356/ce6f8e92-en. S2CID 240207510.\n- Wiley, Matt; Wiley, Joshua F. (2019), \"Multivariate Data Visualization\", Advanced R Statistical Programming and Data Models, Berkeley, CA: Apress, pp. 33–59, doi:10.1007/978-1-4842-2872-2_2, ISBN 978-1-4842-2871-5, S2CID 86629516, retrieved 2021-06-03\n- Mailund, Thomas (2022). Beginning Data Science in R 4: Data Analysis, Visualization, and Modelling for the Data Scientist (2nd ed.). ISBN 978-148428155-0.\n- \"The machine learning community takes on the Higgs\". Symmetry Magazine. July 15, 2014. Archived from the original on 16 April 2021. Retrieved 14 January 2015.\n- \"Data.Gov:Long-Term Pavement Performance (LTPP)\". May 26, 2016. Archived from the original on November 1, 2017. Retrieved November 10, 2017.\n- Nehme, Jean (September 29, 2016). \"LTPP International Data Analysis Contest\". Federal Highway Administration. Archived from the original on October 21, 2017. Retrieved October 22, 2017.\n- Adèr, Herman J. (2008a). \"Chapter 14: Phases and initial steps in data analysis\". In Adèr, Herman J.; Mellenbergh, Gideon J.; Hand, David J (eds.). Advising on research methods : a consultant's companion. Huizen, Netherlands: Johannes van Kessel Pub. pp. 333–356. ISBN 9789079418015. OCLC 905799857.\n- Adèr, Herman J. (2008b). \"Chapter 15: The main analysis phase\". In Adèr, Herman J.; Mellenbergh, Gideon J.; Hand, David J (eds.). Advising on research methods : a consultant's companion. Huizen, Netherlands: Johannes van Kessel Pub. pp. 357–386. ISBN 9789079418015. OCLC 905799857.\n- Tabachnick, B.G. & Fidell, L.S. (2007). Chapter 4: Cleaning up your act. Screening data prior to analysis. In B.G. Tabachnick & L.S. Fidell (Eds.), Using Multivariate Statistics, Fifth Edition (pp. 60–116). Boston: Pearson Education, Inc. / Allyn and Bacon.\n- Adèr, H.J. & Mellenbergh, G.J. (with contributions by D.J. Hand) (2008). Advising on Research Methods: A Consultant's Companion. Huizen, the Netherlands: Johannes van Kessel Publishing. ISBN 978-90-79418-01-5\n- Chambers, John M.; Cleveland, William S.; Kleiner, Beat; Tukey, Paul A. (1983). Graphical Methods for Data Analysis, Wadsworth/Duxbury Press. ISBN 0-534-98052-X\n- Fandango, Armando (2017). Python Data Analysis, 2nd Edition. Packt Publishers. ISBN 978-1787127487\n- Juran, Joseph M.; Godfrey, A. Blanton (1999). Juran's Quality Handbook, 5th Edition. New York: McGraw Hill. ISBN 0-07-034003-X\n- Lewis-Beck, Michael S. (1995). Data Analysis: an Introduction, Sage Publications Inc, ISBN 0-8039-5772-6\n- NIST/SEMATECH (2008) Handbook of Statistical Methods\n- Pyzdek, T, (2003). Quality Engineering Handbook, ISBN 0-8247-4614-7\n- Richard Veryard (1984). Pragmatic Data Analysis. Oxford : Blackwell Scientific Publications. ISBN 0-632-01311-7\n- Tabachnick, B.G.; Fidell, L.S. (2007). Using Multivariate Statistics, 5th Edition. Boston: Pearson Education, Inc. / Allyn and Bacon, ISBN 978-0-205-45938-4\n| Part of a series on Statistics |\n| Data and information visualization |\n|---|\n| Major dimensions |\n| Important figures |\n| Information graphic types |\n| Related topics |\n| Computational physics |\n|---|",
    "data visualization": "| Part of a series on Statistics |\n| Data and information visualization |\n|---|\n| Major dimensions |\n| Important figures |\n| Information graphic types |\n| Related topics |\n| Information mapping |\n|---|\n| Topics and fields |\n| Node–link approaches |\n|\n| See also |\nData and information visualization (data viz/vis or info viz/vis) is the practice of designing and creating graphic or visual representations of[2] quantitative and qualitative data and information with the help of static, dynamic or interactive visual items. These visualizations are intended to help a target audience visually explore and discover, quickly understand, interpret and gain important insights into otherwise difficult-to-identify structures, relationships, correlations, local and global patterns, trends, variations, constancy, clusters, outliers and unusual groupings within data.[3][4][5] When intended for the public to convey a concise version of information in an engaging manner,[3] it is typically called infographics.\nData visualization is concerned with presenting sets of primarily quantitative raw data in a schematic form, using imagery. The visual formats used in data visualization include charts and graphs, geospatial maps, figures, correlation matrices, percentage gauges, etc..\nInformation visualization deals with multiple, large-scale and complicated datasets which contain quantitative data, as well as qualitative, and primarily abstract information, and its goal is to add value to raw data, improve the viewers' comprehension, reinforce their cognition and help derive insights and make decisions as they navigate and interact with the graphical display. Visual tools used include maps for location based data; hierarchical[6] organisations of data; displays that prioritise relationships such as Sankey diagrams; flowcharts, timelines.\nEmerging technologies like virtual, augmented and mixed reality have the potential to make information visualization more immersive, intuitive, interactive and easily manipulable and thus enhance the user's visual perception and cognition.[7] In data and information visualization, the goal is to graphically present and explore abstract, non-physical and non-spatial data collected from databases, information systems, file systems, documents, business data, which is different from scientific visualization, where the goal is to render realistic images based on physical and spatial scientific data to confirm or reject hypotheses.[8]\nEffective data visualization is well-sourced, appropriately contextualized, and presented in a simple, uncluttered manner. The underlying data is accurate and up-to-date to ensure insights are reliable. Graphical items are well-chosen and aesthetically appealing, with shapes, colors and other visual elements used deliberately in a meaningful and non-distracting manner. The visuals are accompanied by supporting texts. Verbal and graphical components complement each other to ensure clear, quick and memorable understanding. Effective information visualization is aware of the needs and expertise level of the target audience.[9][2] Effective visualization can be used for conveying specialized, complex, big data-driven ideas to a non-technical audience in a visually appealing, engaging and accessible manner, and domain experts and executives for making decisions, monitoring performance, generating ideas and stimulating research.[9][3]\nData scientists, analysts and data mining specialists use data visualization to check data quality, find errors, unusual gaps, missing values, clean data, explore the structures and features of data, and assess outputs of data-driven models.[3] Data and information visualization can be part of data storytelling, where they are paired with a narrative structure, to contextualize the analyzed data and communicate insights gained from analyzing it to convince the audience into making a decision or taking action.[2][10] This can be contrasted with statistical graphics, where complex data are communicated graphically among researchers and analysts to help them perform exploratory data analysis or convey results of such analyses, where visual appeal, capturing attention to a certain issue and storytelling are less important.[11]\nData and information visualization is interdisciplinary, it incorporates principles found in descriptive statistics,[12] visual communication, graphic design, cognitive science and, interactive computer graphics and human-computer interaction.[13] Since effective visualization requires design skills, statistical skills and computing skills, it is both an art and a science.[14] Visual analytics combines statistical data analysis, data and information visualization, and human analytical reasoning through interactive visual interfaces to help users reach conclusions, gain actionable insights and make informed decisions which are otherwise difficult for computers to do. Research into how people read and misread types of visualizations helps to determine what types and features of visualizations are most understandable and effective.[15][16] Unintentionally poor or intentionally misleading and deceptive visualizations can function as powerful tools which disseminate misinformation, manipulate public perception and divert public opinion.[17] Thus data visualization literacy has become an important component of data and information literacy in the information age akin to the roles played by textual, mathematical and visual literacy in the past.[18]\nThe field of data and information visualization has emerged \"from research in human–computer interaction, computer science, graphics, visual design, psychology, photography and business methods. It is increasingly applied as a critical component in scientific research, digital libraries, data mining, financial data analysis, market studies, manufacturing production control, and drug discovery\".[19]\nData and information visualization presumes that \"visual representations and interaction techniques take advantage of the human eye's broad bandwidth pathway into the mind to allow users to see, explore, and understand large amounts of information at once. Information visualization focused on the creation of approaches for conveying abstract information in intuitive ways.\"[20]\nData analysis is an indispensable part of all applied research and problem solving in industry. The most fundamental data analysis approaches are visualization (histograms, scatter plots, surface plots, tree maps, parallel coordinate plots, etc.), statistics (hypothesis test, regression, PCA, etc.), data mining (association mining, etc.), and machine learning methods (clustering, classification, decision trees, etc.). Among these approaches, information visualization, or visual data analysis, is the most reliant on the cognitive skills of human analysts, and allows the discovery of unstructured actionable insights that are limited only by human imagination and creativity. The analyst does not have to learn any sophisticated methods to be able to interpret the visualizations of the data. Information visualization is also a hypothesis generation scheme, which can be, and is typically followed by more analytical or formal analysis, such as statistical hypothesis testing.\nTo communicate information clearly and efficiently, data visualization uses statistical graphics, plots, information graphics and other tools. Numerical data may be encoded using dots, lines, or bars, to visually communicate a quantitative message.[21] Effective visualization helps users analyze and reason about data and evidence.[22] It makes complex data more accessible, understandable, and usable, but can also be reductive.[23] Users may have particular analytical tasks, such as making comparisons or understanding causality, and the design principle of the graphic (i.e., showing comparisons or showing causality) follows the task. Tables are generally used where users will look up a specific measurement, while charts of various types are used to show patterns or relationships in the data for one or more variables.\nData visualization refers to the techniques used to communicate data or information by encoding it as visual objects (e.g., points, lines, or bars) contained in graphics. The goal is to communicate information clearly and efficiently to users. It is one of the steps in data analysis or data science. According to Vitaly Friedman (2008) the \"main goal of data visualization is to communicate information clearly and effectively through graphical means. It doesn't mean that data visualization needs to look boring to be functional or extremely sophisticated to look beautiful. To convey ideas effectively, both aesthetic form and functionality need to go hand in hand, providing insights into a rather sparse and complex data set by communicating its key aspects in a more intuitive way. Yet designers often fail to achieve a balance between form and function, creating gorgeous data visualizations which fail to serve their main purpose — to communicate information\".[24]\nIndeed, Fernanda Viegas and Martin M. Wattenberg suggested that an ideal visualization should not only communicate clearly, but stimulate viewer engagement and attention.[25]\nData visualization is closely related to information graphics, information visualization, scientific visualization, exploratory data analysis and statistical graphics. In the new millennium, data visualization has become an active area of research, teaching and development. According to Post et al. (2002), it has united scientific and information visualization.[26]\nIn the commercial environment data visualization is often referred to as dashboards. Infographics are another very common form of data visualization.\nThe greatest value of a picture is when it forces us to notice what we never expected to see.\nEdward Tufte has explained that users of information displays are executing particular analytical tasks such as making comparisons. The design principle of the information graphic should support the analytical task.[28] As William Cleveland and Robert McGill show, different graphical elements accomplish this more or less effectively. For example, dot plots and bar charts outperform pie charts.[29]\nIn his 1983 book The Visual Display of Quantitative Information,[30] Edward Tufte defines 'graphical displays' and principles for effective graphical display in the following passage: \"Excellence in statistical graphics consists of complex ideas communicated with clarity, precision, and efficiency. Graphical displays should:\n- show the data\n- induce the viewer to think about the substance rather than about methodology, graphic design, the technology of graphic production, or something else\n- avoid distorting what the data has to say\n- present many numbers in a small space\n- make large data sets coherent\n- encourage the eye to compare different pieces of data\n- reveal the data at several levels of detail, from a broad overview to the fine structure\n- serve a reasonably clear purpose: description, exploration, tabulation, or decoration\n- be closely integrated with the statistical and verbal descriptions of a data set.\nGraphics reveal data. Indeed, graphics can be more precise and revealing than conventional statistical computations.\"[31]\nFor example, the Minard diagram shows the losses suffered by Napoleon's army in the 1812–1813 period. Six variables are plotted: the size of the army, its location on a two-dimensional surface (x and y), time, the direction of movement, and temperature. The line width illustrates a comparison (size of the army at points in time), while the temperature axis suggests a cause of the change in army size. This multivariate display on a two-dimensional surface tells a story that can be grasped immediately while identifying the source data to build credibility. Tufte wrote in 1983 that: \"It may well be the best statistical graphic ever drawn.\"[31]\nNot applying these principles may result in misleading graphs, distorting the message, or supporting an erroneous conclusion. According to Tufte, chartjunk refers to the extraneous interior decoration of the graphic that does not enhance the message or gratuitous three-dimensional or perspective effects. Needlessly separating the explanatory key from the image itself, requiring the eye to travel back and forth from the image to the key, is a form of \"administrative debris.\" The ratio of \"data to ink\" should be maximized, erasing non-data ink where feasible.[31]\nThe Congressional Budget Office summarized several best practices for graphical displays in a June 2014 presentation. These included: a) Knowing your audience; b) Designing graphics that can stand alone outside the report's context; and c) Designing graphics that communicate the key messages in the report.[32]\nUseful criteria for a data or information visualization include:[33]\n- It is based on (non-visual) data - that is, a data/info viz is not image processing and collage;\n- It creates an image - specifically that the image plays the primary role in communicating meaning and is not an illustration accompanying the data in text form; and\n- The result is readable.\nReadability means that it is possible for a viewer to understand the underlying data, such as by making comparisons between proportionally sized visual elements to compare their respective data values; or using a legend to decode a map, like identifying coloured regions on a climate map to read temperature at that location. For greatest efficiency and simplicity of design and user experience, this readability is enhanced through the use of bijective mapping in that design of the image elements - where the mapping of representational element to data variable is unique.[34]\nKosara (2007)[33] also identifies the need for a visualisation to be \"recognisable as a visualisation and not appear to be something else\". He also states that recognisability and readability may not always be required in all types of visualisation e.g. \"informative art\" (which would still meet all three above criteria but might not look like a visualisation) or \"artistic visualisation\" (which similarly is still based on non-visual data to create an image, but may not be readable or recognisable).\nAuthor Stephen Few described eight types of quantitative messages that users may attempt to understand or communicate from a set of data and the associated graphs used to help communicate the message:\n- Time-series: A single variable is captured over a period of time, such as the unemployment rate or temperature measures over a 10-year period. A line chart may be used to demonstrate the trend over time.\n- Ranking: Categorical subdivisions are ranked in ascending or descending order, such as a ranking of sales performance (the measure) by sales persons (the category, with each sales person a categorical subdivision) during a single period. A bar chart may be used to show the comparison across the sales persons.\n- Part-to-whole: Categorical subdivisions are measured as a ratio to the whole (i.e., a percentage out of 100%). A pie chart or bar chart can show the comparison of ratios, such as the market share represented by competitors in a market.\n- Deviation: Categorical subdivisions are compared against a reference, such as a comparison of actual vs. budget expenses for several departments of a business for a given time period. A bar chart can show comparison of the actual versus the reference amount.\n- Frequency distribution: Shows the number of observations of a particular variable for given interval, such as the number of years in which the stock market return is between intervals such as 0–10%, 11–20%, etc. A histogram, a type of bar chart, may be used for this analysis. A boxplot helps visualize key statistics about the distribution, such as median, quartiles, outliers, etc.\n- Correlation: Comparison between observations represented by two variables (X,Y) to determine if they tend to move in the same or opposite directions. For example, plotting unemployment (X) and inflation (Y) for a sample of months. A scatter plot is typically used for this message.\n- Nominal comparison: Comparing categorical subdivisions in no particular order, such as the sales volume by product code. A bar chart may be used for this comparison.\n- Geographic or geospatial: Comparison of a variable across a map or layout, such as the unemployment rate by state or the number of persons on the various floors of a building. A cartogram is a typical graphic used.[21][36]\nAnalysts reviewing a set of data may consider whether some or all of the messages and graphic types above are applicable to their task and audience. The process of trial and error to identify meaningful relationships and messages in the data is part of exploratory data analysis.\nA human can distinguish differences in line length, shape, orientation, distances, and color (hue) readily without significant processing effort; these are referred to as \"pre-attentive attributes\". For example, it may require significant time and effort (\"attentive processing\") to identify the number of times the digit \"5\" appears in a series of numbers; but if that digit is different in size, orientation, or color, instances of the digit can be noted quickly through pre-attentive processing.[37]\nCompelling graphics take advantage of pre-attentive processing and attributes and the relative strength of these attributes. For example, since humans can more easily process differences in line length than surface area, it may be more effective to use a bar chart (which takes advantage of line length to show comparison) rather than pie charts (which use surface area to show comparison).[37]\nAlmost all data visualizations are created for human consumption. Knowledge of human perception and cognition is necessary when designing intuitive visualizations.[38] Cognition refers to processes in human beings like perception, attention, learning, memory, thought, concept formation, reading, and problem solving.[39] Human visual processing is efficient in detecting changes and making comparisons between quantities, sizes, shapes and variations in lightness. When properties of symbolic data are mapped to visual properties, humans can browse through large amounts of data efficiently. It is estimated that 2/3 of the brain's neurons can be involved in visual processing. Proper visualization provides a different approach to show potential connections, relationships, etc. which are not as obvious in non-visualized quantitative data. Visualization can become a means of data exploration.\nStudies have shown individuals used on average 19% less cognitive resources, and 4.5% better able to recall details when comparing data visualization with text.[40]\nThere is no comprehensive history of data visualization. There are no accounts that span the entire development of visual thinking and visual representation of data, and which collate the contributions of disparate disciplines.[41] Michael Friendly and Daniel Denis of York University are engaged in a project that attempts to provide a comprehensive history of visualization. Data visualization is not a modern development. Since prehistory, stellar data, or information such as location of stars were visualized on the walls of caves (such as those found in Lascaux Cave in Southern France) since the Pleistocene era.[42] Physical artefacts such as Mesopotamian clay tokens (5500 BC), Inca quipus (2600 BC) and Marshall Islands stick charts (n.d.) can also be considered as visualizing quantitative information.[43][44]\nThe first documented data visualization can be tracked back to 1160 B.C. with the Turin Papyrus Map which accurately illustrates the distribution of geological resources and provides information about quarrying of those resources.[45] Such maps can be categorized as thematic cartography, which is a type of data visualization that presents and communicates specific data and information through a geographical illustration designed to show a particular theme connected with a specific geographic area. Earliest documented forms of data visualization were various thematic maps from different cultures and ideograms and hieroglyphs that provided and allowed interpretation of information illustrated. For example, Linear B tablets of Mycenae provided a visualization of information regarding Late Bronze Age era trades in the Mediterranean. The idea of coordinates was used by ancient Egyptian surveyors in laying out towns, earthly and heavenly positions were located by something akin to latitude and longitude at least by 200 BC, and the map projection of a spherical Earth into latitude and longitude by Claudius Ptolemy [c. 85–c. 165] in Alexandria would serve as reference standards until the 14th century.[45]\nThe invention of paper and parchment allowed further development of visualizations. One graph from the 10th or possibly 11th century is an illustration of planetary movements, used in an appendix of a textbook in monastery schools.[46] The graph apparently was meant to represent a plot of the inclinations of the planetary orbits as a function of the time. For this purpose, the zone of the zodiac was represented on a plane with a horizontal line divided into thirty parts as the time or longitudinal axis. The vertical axis designates the width of the zodiac. The horizontal scale appears to have been chosen for each planet individually for the periods cannot be reconciled. The accompanying text refers only to the amplitudes. The curves are apparently not related in time.\nBy the 16th century, techniques and instruments for precise observation and measurement of physical quantities, and geographic and celestial position were well-developed (for example, a \"wall quadrant\" constructed by Tycho Brahe [1546–1601], covering an entire wall in his observatory). Particularly important were the development of triangulation and other methods to determine mapping locations accurately.[41] Very early, the measure of time led scholars to develop innovative way of visualizing the data (e.g. Lorenz Codomann in 1596, Johannes Temporarius in 1596[47]).\nMathematicians René Descartes and Pierre de Fermat developed analytic geometry and two-dimensional coordinate system which heavily influenced the practical methods of displaying and calculating values. Fermat and Blaise Pascal's work on statistics and probability theory laid the groundwork for what we now conceptualize as data.[41] These developments helped William Playfair, who saw potential for graphical communication of quantitative data, to generate and develop graphical methods of statistics.[38] In 1786, Playfair published the first presentation graphics.\nIn the second half of the 20th century, Jacques Bertin used quantitative graphs to represent information \"intuitively, clearly, accurately, and efficiently\".[38] John Tukey and Edward Tufte pushed the bounds of data visualization; Tukey with his new statistical approach of exploratory data analysis and Tufte with his book \"The Visual Display of Quantitative Information\" paved the way for refining data visualization techniques for more than statisticians. With the progression of technology came the progression of data visualization; starting with hand-drawn visualizations and evolving into more technical applications – including interactive designs leading to software visualization.[48]\nThe modern study of visualization started with computer graphics, which \"has from its beginning been used to study scientific problems. However, in its early days the lack of graphics power often limited its usefulness. The recent emphasis on visualization started in 1987 with the special issue of Computer Graphics on Visualization in Scientific Computing. Since then there have been several conferences and workshops, co-sponsored by the IEEE Computer Society and ACM SIGGRAPH\".[49] They have been devoted to the general topics of data visualization, information visualization and scientific visualization, and more specific areas such as volume visualization.\nPrograms like SAS, SOFA, R, Minitab, Cornerstone and more allow for data visualization in the field of statistics. Other data visualization applications, more focused and unique to individuals, programming languages such as D3, Python (through matplotlib, seaborn) and JavaScript and Java(through JavaFX) help to make the visualization of quantitative data a possibility. Private schools have also developed programs to meet the demand for learning data visualization and associated programming libraries, including free programs like The Data Incubator or paid programs like General Assembly.[50]\nBeginning with the symposium \"Data to Discovery\" in 2013, ArtCenter College of Design, Caltech and JPL in Pasadena have run an annual program on interactive data visualization.[51] The program asks: How can interactive data visualization help scientists and engineers explore their data more effectively? How can computing, design, and design thinking help maximize research results? What methodologies are most effective for leveraging knowledge from these fields? By encoding relational information with appropriate visual and interactive characteristics to help interrogate, and ultimately gain new insight into data, the program develops new interdisciplinary approaches to complex science problems, combining design thinking and the latest methods from computing, user-centered design, interaction design and 3D graphics.\nData visualization involves specific terminology, some of which is derived from statistics. For example, author Stephen Few defines two types of data, which are used in combination to support a meaningful analysis or visualization:\n- Categorical: Represent groups of objects with a particular characteristic. Categorical variables can either be nominal or ordinal. Nominal variables for example gender have no order between them and are thus nominal. Ordinal variables are categories with an order, for sample recording the age group someone falls into.[52]\n- Quantitative: Represent measurements, such as the height of a person or the temperature of an environment. Quantitative variables can either be continuous or discrete. Continuous variables capture the idea that measurements can always be made more precisely. While discrete variables have only a finite number of possibilities, such as a count of some outcomes or an age measured in whole years.[52]\nThe distinction between quantitative and categorical variables is important because the two types require different methods of visualization.\nTwo primary types of information displays are tables and graphs.\n- A table contains quantitative data organized into rows and columns with categorical labels. It is primarily used to look up specific values. In the example above, the table might have categorical column labels representing the name (a qualitative variable) and age (a quantitative variable), with each row of data representing one person (the sampled experimental unit or category subdivision).\n- A graph is primarily used to show relationships among data and portrays values encoded as visual objects (e.g., lines, bars, or points). Numerical values are displayed within an area delineated by one or more axes. These axes provide scales (quantitative and categorical) used to label and assign values to the visual objects. Many graphs are also referred to as charts.[53]\nEppler and Lengler have developed the \"Periodic Table of Visualization Methods,\" an interactive chart displaying various data visualization methods. It includes six types of data visualization methods: data, information, concept, strategy, metaphor and compound.[54] In \"Visualization Analysis and Design\" Tamara Munzner writes \"Computer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively.\" Munzner argues that visualization \"is suitable when there is a need to augment human capabilities rather than replace people with computational decision-making methods.\"[55]\n| Name | Visual dimensions | Description / Example usages | |\n|---|---|---|---|\n| Bar chart |\n|\n| |\n|\n| ||\n|\nOrthogonal (orthogonal composite) bar chart |\n|\n| |\n| Histogram |\n|\n| |\n| Scatter plot (dot plot) |\n|\n| |\n| Scatter plot (3D) |\n|\n| |\n| Network |\n|\n| |\n| Pie chart |\n|\n| |\n| Line chart |\n|\n| |\n| Semi-log or log-log (non-linear) charts |\n|\n| |\n| Streamgraph (type of area chart) |\n|\n| |\n| Treemap |\n|\n| |\n| Gantt chart |\n|\n| |\n| Heat map |\n|\n| |\n| Stripe graphic |\n|\n| |\n| Animated spiral graphic |\n|\n| |\n| Box and Whisker Plot |\n|\n| |\n| Flowchart | |||\n| Radar chart |\n|\n| |\n| Venn diagram |\n| ||\n| Iconography of correlations |\n|\n|\n- Cartogram – Map distorting size to show another value\n- Cladogram – Method of biological systematics in evolutionary biology (phylogeny)\n- Concept map – Diagram showing relationships among conceptsping\n- Dendrogram – Diagram with a treelike structure (classification)\n- Information visualization reference model\n- Grand tour – Data visualisation technique\n- Graph drawing – Visualization of node-link graphs\n- Hyperbolic tree – Mathematical tree in the hyperbolic plane\n- Multidimensional scaling – Set of related ordination techniques used in information visualization\n- Parallel coordinates – Chart displaying multivariate data\n- Problem solving environment – Type of computer software\nInteractive data visualization enables direct actions on a graphical plot to change elements and link between multiple plots.[58]\nInteractive data visualization has been a pursuit of statisticians since the late 1960s. Examples of the developments can be found on the American Statistical Association video lending library.[59]\nCommon interactions include:\n- Brushing: works by using the mouse to control a paintbrush, directly changing the color or glyph of elements of a plot. The paintbrush is sometimes a pointer and sometimes works by drawing an outline of sorts around points; the outline is sometimes irregularly shaped, like a lasso. Brushing is most commonly used when multiple plots are visible and some linking mechanism exists between the plots. There are several different conceptual models for brushing and a number of common linking mechanisms. Brushing scatterplots can be a transient operation in which points in the active plot only retain their new characteristics. At the same time, they are enclosed or intersected by the brush, or it can be a persistent operation, so that points retain their new appearance after the brush has been moved away. Transient brushing is usually chosen for linked brushing, as we have just described.\n- Painting: Persistent brushing is useful when we want to group the points into clusters and then proceed to use other operations, such as the tour, to compare the groups. It is becoming common terminology to call the persistent operation painting,\n- Identification: which could also be called labeling or label brushing, is another plot manipulation that can be linked. Bringing the cursor near a point or edge in a scatterplot, or a bar in a barchart, causes a label to appear that identifies the plot element. It is widely available in many interactive graphics, and is sometimes called mouseover.\n- Scaling: maps the data onto the window, and changes in the area of the. mapping function help us learn different things from the same plot. Scaling is commonly used to zoom in on crowded regions of a scatterplot, and it can also be used to change the aspect ratio of a plot, to reveal different features of the data.\n- Linking: connects elements selected in one plot with elements in another plot. The simplest kind of linking, one-to-one, where both plots show different projections of the same data, and a point in one plot corresponds to exactly one point in the other. When using area plots, brushing any part of an area has the same effect as brushing it all and is equivalent to selecting all cases in the corresponding category. Even when some plot elements represent more than one case, the underlying linking rule still links one case in one plot to the same case in other plots. Linking can also be by categorical variable, such as by a subject id, so that all data values corresponding to that subject are highlighted, in all the visible plots.\nThere are different approaches on the scope of data visualization. One common focus is on information presentation, such as Friedman (2008). Friendly (2008) presumes two main parts of data visualization: statistical graphics, and thematic cartography.[60] In this line the \"Data Visualization: Modern Approaches\" (2007) article gives an overview of seven subjects of data visualization:[61]\n- Articles & resources\n- Displaying connections\n- Displaying data\n- Displaying news\n- Displaying websites\n- Mind maps\n- Tools and services\nAll these subjects are closely related to graphic design and information representation.\nFrom a computer science perspective, Frits Post in 2002 categorized the field into sub-fields:[26][62]\n- Information visualization\n- Interaction techniques and architectures\n- Modelling techniques\n- Multiresolution methods\n- Visualization algorithms and techniques\n- Volume visualization\nWithin The Harvard Business Review, Scott Berinato developed a framework to approach data visualisation.[63] To start thinking visually, users must consider two questions; 1) What you have and 2) what you're doing. The first step is identifying what data you want visualised. It is data-driven like profit over the past ten years or a conceptual idea like how a specific organisation is structured. Once this question is answered one can then focus on whether they are trying to communicate information (declarative visualisation) or trying to figure something out (exploratory visualisation). Scott Berinato combines these questions to give four types of visual communication that each have their own goals.[63]\nThese four types of visual communication are as follows;\n- idea illustration (conceptual & declarative).[63]\n- Used to teach, explain and/or simply concepts. For example, organisation charts and decision trees.\n- idea generation (conceptual & exploratory).[63]\n- Used to discover, innovate and solve problems. For example, a whiteboard after a brainstorming session.\n- visual discovery (data-driven & exploratory).[63]\n- Used to spot trends and make sense of data. This type of visual is more common with large and complex data where the dataset is somewhat unknown and the task is open-ended.\n- everyday data-visualisation (data-driven & declarative).[63]\n- The most common and simple type of visualisation used for affirming and setting context. For example, a line graph of GDP over time.\nData and information visualization insights are being applied in areas such as:[19]\n- Scientific research\n- Digital libraries\n- Data mining\n- Information graphics\n- Financial data analysis\n- Health care[64]\n- Market studies\n- Manufacturing production control\n- Crime mapping\n- eGovernance and Policy Modeling\n- Digital Humanities\n- Data Art\nNotable academic and industry laboratories in the field are:\n- Adobe Research\n- IBM Research\n- Google Research\n- Microsoft Research\n- Panopticon Software\n- Scientific Computing and Imaging Institute\n- Tableau Software\n- University of Maryland Human-Computer Interaction Lab\nConferences in this field, ranked by significance in data visualization research,[65] are:\n- IEEE Visualization: An annual international conference on scientific visualization, information visualization, and visual analytics. Conference is held in October.\n- ACM SIGGRAPH: An annual international conference on computer graphics, convened by the ACM SIGGRAPH organization. Conference dates vary.\n- Conference on Human Factors in Computing Systems (CHI): An annual international conference on human–computer interaction, hosted by ACM SIGCHI. Conference is usually held in April or May.\n- Eurographics: An annual Europe-wide computer graphics conference, held by the European Association for Computer Graphics. Conference is usually held in April or May.\nFor further examples, see: Category:Computer graphics organizations\nData presentation architecture (DPA) is a skill-set that seeks to identify, locate, manipulate, format and present data in such a way as to optimally communicate meaning and knowledge. Historically, data presentation architecture is attributed to Kelly Lautt:[a] \"Data Presentation Architecture (DPA) is a rarely applied skill set critical for the success and value of Business Intelligence. Data presentation architecture weds the science of numbers, data and statistics in discovering valuable information from data and making it usable, relevant and actionable with the arts of data visualization, communications, organizational psychology and change management in order to provide business intelligence solutions with the data scope, delivery timing, format and visualizations that will most effectively support and drive operational, tactical and strategic behaviour toward understood business (or organizational) goals. DPA is neither an IT nor a business skill set but exists as a separate field of expertise. Often confused with data visualization, data presentation architecture is a much broader skill set that includes determining what data on what schedule and in what exact format is to be presented, not just the best way to present data that has already been chosen. Data visualization skills are one element of DPA.\"\nDPA has two main objectives:\n- To use data to provide knowledge in the most efficient manner possible (minimize noise, complexity, and unnecessary data or detail given each audience's needs and roles)\n- To use data to provide knowledge in the most effective manner possible (provide relevant, timely and complete data to each audience member in a clear and understandable manner that conveys important meaning, is actionable and can affect understanding, behavior and decisions)\nWith the above objectives in mind, the actual work of data presentation architecture consists of:\n- Creating effective delivery mechanisms for each audience member depending on their role, tasks, locations and access to technology\n- Defining important meaning (relevant knowledge) that is needed by each audience member in each context\n- Determining the required periodicity of data updates (the currency of the data)\n- Determining the right timing for data presentation (when and how often the user needs to see the data)\n- Finding the right data (subject area, historical reach, breadth, level of detail, etc.)\n- Utilizing appropriate analysis, grouping, visualization, and other presentation formats\nDPA work shares commonalities with several other fields, including:\n- Business analysis in determining business goals, collecting requirements, mapping processes.\n- Business process improvement in that its goal is to improve and streamline actions and decisions in furtherance of business goals\n- Data visualization in that it uses well-established theories of visualization to add or highlight meaning or importance in data presentation.\n- Digital humanities explores more nuanced ways of visualising complex data.\n- Information architecture, but information architecture's focus is on unstructured data and therefore excludes both analysis (in the statistical/data sense) and direct transformation of the actual content (data, for DPA) into new entities and combinations.\n- HCI and interaction design, since many of the principles in how to design interactive data visualisation have been developed cross-disciplinary with HCI.\n- Visual journalism and data-driven journalism or data journalism: Visual journalism is concerned with all types of graphic facilitation of the telling of news stories, and data-driven and data journalism are not necessarily told with data visualisation. Nevertheless, the field of journalism is at the forefront in developing new data visualisations to communicate data.\n- Graphic design, conveying information through styling, typography, position, and other aesthetic concerns.\n- Analytics\n- Climate change art\n- Computational visualistics\n- Data management\n- Data physicalization\n- Data profiling\n- Data warehouse\n- imc FAMOS, graphical data analysis\n- Information management\n- List of information graphics software\n- List of countries by economic complexity, example of Treemapping\n- List of mathematical art software\n- Patent visualisation\n- Pirouette: Turning Points in Design\n- Statistical inference\n- The first formal, recorded, public usages of the term data presentation architecture were at Microsoft Office 2007 launch events in Dec, Jan and Feb of 2007–08 in Edmonton, Calgary and Vancouver, in a presentation by Kelly Lautt describing a business intelligence system designed to improve service quality in a pulp and paper company. The term was recorded in public usage on December 16, 2009 in a Microsoft Canada presentation on the value of merging Business Intelligence with corporate collaboration processes.\n- Corbett, John. \"Charles Joseph Minard: Mapping Napoleon's March, 1861\". Center for Spatially Integrated Social Science. Archived from the original on 19 June 2003.CSISS website has moved; use archive link for article)\n- Nussbaumer Knaflic, Cole (2 November 2015). Storytelling with Data: A Data Visualization Guide for Business Professionals. John Wiley & Sons. ISBN 978-1-119-00225-3.\n- Antony Unwin (31 January 2020). \"Why Is Data Visualization Important? What Is Important in Data Visualization?\". Harvard Data Science Review. 2 (1). doi:10.1162/99608f92.8ae4d525. Retrieved 27 March 2023.\n- Ananda Mitra (2018), \"Managing and Visualizing Unstructured Big Data\", Encyclopedia of Information Science and Technology (4th ed.), IGI Global\n- Bhuvanendra Putchala; Lasya Sreevidya Kanala; Devi Prasanna Donepudi; Hari Kishan Kondaveeti (2023), \"Applications of Big Data Analytics in Healthcare Informatics\", in Narasimha Rao Vajjhala; Philip Eappen (eds.), Health Informatics and Patient Safety in Times of Crisis, IGI Global, pp. 175–194\n- Heer, Jeffrey, Bostock, Michael, Ogievetsky, Vadim (2010) A tour through the visualization zoo, Communications of the ACM, Volume 53, Issue 6 Pages 59 - 67 https://doi.org/10.1145/1743546.1743567\n- Olshannikova, Ekaterina; Ometov, Aleksandr; Koucheryavy, Yevgeny; Ollson, Thomas (2015), \"Visualizing Big Data with augmented and virtual reality: challenges and research agenda.\", Journal of Big Data, 2 (22) 22, doi:10.1186/s40537-015-0031-2\n- Card, Mackinlay, and Shneiderman (1999), Readings in Information Visualization: Using Vision to Think, Morgan Kaufmann, pp. 6–7\n{{citation}}\n: CS1 maint: multiple names: authors list (link) - \"What is data visualization?\". IBM. 28 September 2021. Retrieved 27 March 2023.\n- Brent Dykes (2019), Effective Data Storytelling: How to Drive Change with Data, Narrative and Visuals, John Wiley & Sons, p. 16\n- David C. LeBlanc (2004), Statistics: Concepts and Applications for Science, Jones & Bartlett Learning, pp. 35–36\n- Grandjean, Martin (2022). \"Data Visualization for History\". Handbook of Digital Public History. pp. 291–300. doi:10.1515/9783110430295-024. ISBN 9783110430295.\n- E.H. Chi (2013), A Framework for Visualizing Information, Springer Science & Business Media, p. xxiii\n- Gershon, Nahum; Page, Ward (1 August 2001). \"What storytelling can do for information visualization\". Communications of the ACM. 44 (8): 31–37. doi:10.1145/381641.381653. S2CID 7666107.\n- Mason, Betsy (November 12, 2019). \"Why scientists need to be better at data visualization\". Knowable Magazine. doi:10.1146/knowable-110919-1.\n- O'Donoghue, Seán I.; Baldi, Benedetta Frida; Clark, Susan J.; Darling, Aaron E.; Hogan, James M.; Kaur, Sandeep; Maier-Hein, Lena; McCarthy, Davis J.; Moore, William J.; Stenau, Esther; Swedlow, Jason R.; Vuong, Jenny; Procter, James B. (2018-07-20). \"Visualization of Biomedical Data\". Annual Review of Biomedical Data Science. 1 (1): 275–304. doi:10.1146/annurev-biodatasci-080917-013424. hdl:10453/125943. S2CID 199591321. Retrieved 25 June 2021.\n- Leo Yu-Ho Lo; Ayush Gupta; Kento Shigyo; Aoyu Wu; Enrico Bertini; Huamin Qu, Misinformed by Visualization: What Do We Learn From Misinformative Visualizations?\n- Börner, K.; Bueckle, A.; Ginda, M. (2019), \"Data visualization literacy: Definitions, conceptual frameworks, exercises, and assessments\", Proceedings of the National Academy of Sciences, 116 (6): 1857–1864, Bibcode:2019PNAS..116.1857B, doi:10.1073/pnas.1807180116, PMC 6369751, PMID 30718386\n- Benjamin B. Bederson and Ben Shneiderman (2003). The Craft of Information Visualization: Readings and Reflections, Morgan Kaufmann ISBN 1-55860-915-6.\n- James J. Thomas and Kristin A. Cook (Ed.) (2005). Illuminating the Path: The R&D Agenda for Visual Analytics Archived 2008-09-29 at the Wayback Machine. National Visualization and Analytics Center. p.30\n- \"Stephen Few-Perceptual Edge-Selecting the Right Graph for Your Message-2004\" (PDF). Archived (PDF) from the original on 2014-10-05. Retrieved 2014-09-08.\n- \"10 Examples of Interactive Map Data Visualizations\". Tableau.\n- Engebretsen, Martin; Helen, Kennedy, eds. (2020-04-16). Data Visualization in Society. Amsterdam University Press. doi:10.5117/9789463722902_ch02. ISBN 978-90-485-4313-7.\n- Vitaly Friedman (2008) \"Data Visualization and Infographics\" Archived 2008-07-22 at the Wayback Machine in: Graphics, Monday Inspiration, January 14, 2008.\n- Viegas, Fernanda; Wattenberg, Martin (April 19, 2011). \"How To Make Data Look Sexy\". CNN. Archived from the original on May 6, 2011. Retrieved May 7, 2017.\n- Frits H. Post, Gregory M. Nielson and Georges-Pierre Bonneau (2002). Data Visualization: The State of the Art. Research paper TU delft, 2002. Archived 2009-10-07 at the Wayback Machine.\n- Tukey, John (1977). Exploratory Data Analysis. Addison-Wesley. ISBN 0-201-07616-0.\n- techatstate (7 August 2013). \"Tech@State: Data Visualization - Keynote by Dr Edward Tufte\". Archived from the original on 29 March 2017. Retrieved 29 November 2016 – via YouTube.\n- Cleveland, W. S.; McGill, R. (1985). \"Graphical perception and graphical methods for analyzing scientific data\". Science. 229 (4716): 828–33. Bibcode:1985Sci...229..828C. doi:10.1126/science.229.4716.828. PMID 17777913. S2CID 16342041.\n- Tufte, Edward R. (1983). The Visual Display of Quantitative Information (2nd ed.). Cheshire, Connecticut, US: Graphics Press LLC. ISBN 9780318029924.\n- Tufte, Edward (1983). The Visual Display of Quantitative Information. Cheshire, Connecticut: Graphics Press. ISBN 0-9613921-4-2. Archived from the original on 2013-01-14. Retrieved 2019-08-10.\n- \"Telling Visual Stories About Data - Congressional Budget Office\". www.cbo.gov. Archived from the original on 2014-12-04. Retrieved 2014-11-27.\n- Kosara, Robert (16 July 2007). \"Visualization Criticism - The Missing Link Between Information Visualization and Art\". 2007 11th International Conference Information Visualization (IV '07). pp. 631–636. doi:10.1109/IV.2007.130. ISBN 978-0-7695-2900-4. ISSN 1550-6037.\n- Ziemkiewicz, C.; Kosara, R. (2009). \"Embedding Information Visualization within Visual Representation\". Advances in Information and Intelligent Systems. Studies in Computational Intelligence. Vol. 251. Berlin, Heidelberg: Springer. pp. 307–326. doi:10.1007/978-3-642-04141-9_15. ISBN 978-3-642-04140-2.\n- Buchanan, Larry; Letherby, Lauren (June 22, 2022). \"Who Stops a 'Bad Guy With a Gun'?\". The New York Times. Archived from the original on June 22, 2022.\nData source: Advanced Law Enforcement Rapid Response Training Center\n- \"Stephen Few-Perceptual Edge-Graph Selection Matrix\" (PDF). Archived (PDF) from the original on 2014-10-05. Retrieved 2014-09-08.\n- \"Steven Few-Tapping the Power of Visual Perception-September 2004\" (PDF). Archived (PDF) from the original on 2014-10-05. Retrieved 2014-10-08.\n- \"Data Visualization for Human Perception\". The Interaction Design Foundation. Archived from the original on 2015-11-23. Retrieved 2015-11-23.\n- \"Visualization\" (PDF). SFU. SFU lecture. Archived from the original (PDF) on 2016-01-22. Retrieved 2015-11-22.\n- Graham, Fiona (2012-04-17). \"Can images stop data overload?\". BBC News. Retrieved 2020-07-30.\n- Friendly, Michael (2008). \"A Brief History of Data Visualization\". Handbook of Data Visualization. Springer-Verlag. pp. 15–56. doi:10.1007/978-3-540-33037-0_2. ISBN 9783540330370. S2CID 62626937.\n- Whitehouse, D. (9 August 2000). \"Ice Age star map discovered\". BBC News. Archived from the original on 6 January 2018. Retrieved 20 January 2018.\n- Dragicevic, Pierre; Jansen, Yvonne (2012). \"List of Physical Visualizations and Related Artefacts\". Archived from the original on 2018-01-13. Retrieved 2018-01-12.\n- Jansen, Yvonne; Dragicevic, Pierre; Isenberg, Petra; Alexander, Jason; Karnik, Abhijit; Kildal, Johan; Subramanian, Sriram; Hornbæk, Kasper (2015). \"Opportunities and challenges for data physicalization\". Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems: 3227–3236. Archived from the original on 2018-01-13. Retrieved 2018-01-12.\n- Friendly, Michael (2001). \"Milestones in the history of thematic cartography, statistical graphics, and data visualization\". Archived from the original on 2014-04-14.\n- Funkhouser, Howard Gray (January 1936). \"A Note on a Tenth Century Graph\". Osiris. 1: 260–262. doi:10.1086/368425. JSTOR 301609. S2CID 144492131.\n- \"Data visualization: definition, examples, tools, advice [guide 2020]\". Market research consulting. 2020-12-09. Retrieved 2020-12-09.\n- Friendly, Michael (2006). \"A Brief History of Data Visualization\" (PDF). York University. Springer-Verlag. Archived (PDF) from the original on 2016-05-08. Retrieved 2015-11-22.\n- G. Scott Owen (1999). History of Visualization Archived 2012-10-08 at the Wayback Machine. Accessed Jan 19, 2010.\n- \"NY gets new boot camp for data scientists: It's free but harder to get into than Harvard\". Venture Beat. Archived from the original on 2016-02-15. Retrieved 2016-02-21.\n- Interactive Data Visualization\n- Bulmer, Michael (2013). A Portable Introduction to Data Analysis. The University of Queensland: Publish on Demand Centre. pp. 4–5. ISBN 978-1-921723-10-0.\n- \"Steven Few-Selecting the Right Graph for Your Message-September 2004\" (PDF). Archived (PDF) from the original on 2014-10-05. Retrieved 2014-09-08.\n- Lengler, Ralph; Eppler, Martin. J. \"Periodic Table of Visualization Methods\". www.visual-literacy.org. Archived from the original on 16 March 2013. Retrieved 15 March 2013.\n- Munzner, Tamara; Maguire, Eamonn (2015). Visualization analysis & design. A.K. Peters visualization series. Boca Raton London New York: CRC Press. ISBN 978-1-4665-0891-0.\n- Kahn, Brian (June 17, 2019). \"This Striking Climate Change Visualization Is Now Customizable for Any Place on Earth\". Gizmodo. Archived from the original on June 26, 2019.Ed Hawkins, University of Reading.\n- Mooney, Chris (11 May 2016). \"This scientist just changed how we think about climate change with one GIF\". The Washington Post. Archived from the original on 6 February 2019.\nEd Hawkins took these monthly temperature data and plotted them in the form of a spiral, so that for each year, there are twelve points, one for each month, around the center of a circle – with warmer temperatures farther outward and colder temperatures nearer inward.\n- Swayne, Deborah (1999). \"Introduction to the special issue on interactive graphical data analysis: What is interaction?\". Computational Statistics. 14 (1): 1–6. doi:10.1007/PL00022700. S2CID 86788346.\n- American Statistics Association, Statistical Graphics Section. \"Video Lending Library\". Archived from the original on 2021-01-20. Retrieved 2021-02-17.\n- Michael Friendly (2008). \"Milestones in the history of thematic cartography, statistical graphics, and data visualization\" Archived 2008-09-11 at the Wayback Machine.\n- \"Data Visualization: Modern Approaches\" Archived 2008-07-22 at the Wayback Machine. in: Graphics, August 2, 2007\n- Frits H. Post, Gregory M. Nielson and Georges-Pierre Bonneau (2002). Data Visualization: The State of the Art Archived 2009-10-07 at the Wayback Machine.\n- Berinato, Scott (June 2016). \"Visualizations That Really Work\". Harvard Business Review: 92–100.\n- Faisal, Sarah; Blandford, Ann; Potts, Henry WW (2013). \"Making sense of personal health information: Challenges for information visualization\" (PDF). Health Informatics Journal. 19 (3): 198–217. doi:10.1177/1460458212465213. PMID 23981395. S2CID 3825148.\n- Kosara, Robert (11 November 2013). \"A Guide to the Quality of Different Visualization Venues\". eagereyes. Retrieved 7 April 2017.\n- Few, Stephen (2012). Show me the numbers: designing tables and graphs to enlighten (2 ed.). Analytics Press. ISBN 9780970601971.\n- Healy, Kieran (2019). Data Visualisation: A Practical Introduction. Princeton University Press. ISBN 978-0-691-18161-5.\n- Schwabish, Jonathan A. 2014. \"An Economist's Guide to Visualizing Data.\" Journal of Economic Perspectives, 28 (1): 209–34. — Specialised guide for economic data visualisation with principles applicable across domains.\n- Wilke, Claus O. (2018). Fundamentals of Data Visualisation. O'Reilly. ISBN 978-1-4920-3108-6. Archived from the original on 2019-10-19. Retrieved 2018-09-22.\n- Tufte, Edward R. (2015). The visual display of quantitative information (2 ed.). Graphics Press. ISBN 9780961392147.\n- Milestones in the History of Thematic Cartography, Statistical Graphics, and Data Visualization, An illustrated chronology of innovations by Michael Friendly and Daniel J. Denis.\n- Duke University-Christa Kelleher Presentation-Communicating through infographics-visualizing scientific & engineering information, 2015",
    "digital distribution": "| E-commerce |\n|---|\n| Digital content |\n| Retail goods and services |\n| Online shopping |\n| Mobile commerce |\n| Customer service |\n| E-procurement |\n| Purchase-to-pay |\n| Super-apps |\nDigital distribution, also referred to as content delivery, online distribution, or electronic software distribution, among others, is the delivery or distribution of information or materials through digital platforms.[1] The distribution of digital media content may be of digitized versions of analog materials, as well as other materials offered in a purely digital format, such as audio, video, e-books, video games, and other software.[2]\nThe term is generally used to describe distribution over an online delivery medium, such as the Internet, thus bypassing physical distribution methods, such as paper, optical discs, and VHS videocassettes. The term online distribution is typically applied to freestanding products, with downloadable add-ons for other products are more commonly described as downloadable content. Content distributed online may be streamed or downloaded, and often consists of books, films and television programs, music, software, and video games. Streaming involves downloading and using content at a user's request, or \"on-demand\", rather than allowing a user to store it permanently. In contrast, fully downloading content to a hard drive or other forms of storage media may allow offline access in the future.\nSpecialist networks known as content delivery networks help distribute content over the Internet by ensuring both high availability and high performance.[3] Alternative technologies for content delivery include peer-to-peer file sharing technologies. Alternatively, content delivery platforms create and syndicate content remotely, acting like hosted content management systems.\nUnrelated to the above, the term \"digital distribution\" is also used in film distribution to describe the distribution of content through physical digital media, in opposition to distribution by analog media such as photographic film and magnetic tape (see: digital cinema).\nThe rise of online distribution has provided controversy for the traditional business models and resulted in challenges as well as new opportunities for traditional retailers and publishers. Online distribution affects all of the traditional media markets, including music, press, and broadcasting. In Britain, the iPlayer, a software application for streaming television and radio, accounts for 5% of all bandwidth used in the United Kingdom.[4]\nThe move towards online distribution led to a dip in sales in the 2000s; CD sales were nearly cut in half around this time.[5] One such example of online distribution taking its toll on a retailer is the Canadian music chain Sam the Record Man; the company blamed online distribution for having to close a number of its traditional retail venues in 2007–08.[6] One main reason that sales took such a big hit was that unlicensed downloads of music were very accessible.[citation needed] With copyright infringement affecting sales, the music industry realized it needed to change its business model to keep up with the rapidly changing technology.[7] The step that was taken to move the music industry into the online space has been successful for several reasons. The development of lossy audio compression file formats such as MP3 could take 30 MB for a typical 3-minute song and bring it down to 3 MB without any serious loss of quality.[8] Lossless FLAC files can be up to six times larger than an MP3 while,[9] in comparison, the same song might require 30–40 megabytes of storage on a CD.[7] The smaller file size yields much greater Internet transfer speeds.\nThe transition into the online space has boosted sales, and profit for some artists.[10] It has also allowed for potentially lower expenses such as lower coordination costs, lower distribution costs, as well as the possibility for redistributed total profits.[7] These lower costs have aided new artists in breaking onto the scene and gaining recognition.[citation needed] In the past, some emerging artists have struggled to find a way to market themselves and compete in the various distribution channels.[citation needed] The Internet may give artists more control over their music in terms of ownership, rights, creative process, pricing, and more. In addition to providing global users with easier access to content, online stores allow users to choose the songs they wish instead of having to purchase an entire album from which there may only be one or two titles that the buyer enjoys.\nThe number of downloaded single tracks rose from 160 million in 2004 to 795 million in 2006, which accounted for a revenue boost from US$397 million to US$2 billion.[7] Downloading peaked in the US in 2012, after which it started falling due to the rise of music streaming services. In 2017, physical formats overtook downloading again for the first time in six years,[11] but despite the vinyl revival and CDs holding its own, the physical formats account for only 11% revenue as of 2023, while streaming services are dominant with 84% of the US industry.[12]\nWith the advancement of network bandwidth capabilities, online distribution became prominent in the 21st century, with prominent platforms such as Amazon Video, and Netflix's streaming service starting in 2007.[13]\nMany traditional network television shows, movies and other video content is now available online, either from the content owner directly or from third-party services. YouTube, Netflix, Hulu, Vudu, Amazon Prime Video, DirecTV, SlingTV and other Internet-based video services allow content owners to let users access their content on computers, smartphones, tablets or by using appliances such as video game consoles, set-top boxes or Smart TVs.[14]\nMany film distributors also include a Digital Copy, also called Digital HD, with Blu-ray disc, Ultra HD Blu-ray, Blu-ray 3D or a DVD.\nSome companies, such as Bookmasters Distribution, which invested US$4.5 million in upgrading its equipment and operating systems, have had to direct capital toward keeping up with the changes in technology.[citation needed] The phenomenon of books going digital has given users the ability to access their books on handheld digital book readers. One benefit of electronic book readers is that they allow users to access additional content via hypertext links. These electronic book readers also give users portability for their books since a reader can hold multiple books depending on the size of its hard drive.[15] Companies that are able to adapt and make changes to capitalize on the digital media market have seen sales surge. Vice President of Perseus Books Group stated that since shifting to electronic books (e-books), it saw sales rise by 68%[citation needed]. Independent Publishers Group experienced a sales boost of 23% in the first quarter of 2012 alone.[16]\nTor Books, a major publisher of science fiction and fantasy books, started to sell e-books DRM-free by July 2012.[17] One year later the publisher stated that they will keep this model as removing DRM was not hurting their digital distribution ebook business.[18] Smaller e-book publishers such as O'Reilly Media, Carina Press[19] and Baen Books had already forgone DRM previously.\nOnline distribution is changing the structure of the video game industry.[citation needed] Gabe Newell, creator of the digital distribution service Steam, formulated the advantages over physical retail distribution as such:\nThe worst days [for game development] were the cartridge days for the NES. It was a huge risk – you had all this money tied up in silicon in a warehouse somewhere, and so you'd be conservative in the decisions you felt you could make, very conservative in the IPs you signed, your art direction would not change, and so on. Now it's the opposite extreme: we can put something up on Steam, deliver it to people all around the world, make changes. We can take more interesting risks.[...] Retail doesn't know how to deal with those games. On Steam [a digital distributor] there's no shelf-space restriction.\nSince the 2000s, there has been an increasing number of smaller and niche titles available and commercially successful, e.g. remakes of classic games.[21][22] The new possibility of the digital distribution stimulated also the creation of game titles of very small video game producers like Independent game developer[23][24] and Modders (e.g. Garry's Mod[25]), which were before not commercially feasible.\nThe years after 2004 saw the rise of many digital distribution services on the PC, such as Amazon Services, Desura, GameStop, Games for Windows – Live, Impulse, Steam, Origin, Battle.net, Direct2Drive, GOG.com, Epic Games Store and GamersGate. The offered properties differ significantly: while most of these digital distributors do not allow reselling of bought games, Green Man Gaming allows this. Another example is gog.com which has a strict non-DRM policy[26] while most other services allow various (strict or less strict) forms of DRM.\nDigital distribution is also more eco-friendly than physical. Optical discs are made of polycarbonate plastic and aluminum. The creation of 30 of them requires the use of 300 cubic feet of natural gas, two cups of oil and 24 gallons of water.[citation needed] The protective cases for an optical disc is made from polyvinyl chloride (PVC), a known carcinogen.[27]\nA general issue is the large number of incompatible data formats in which content is delivered, possibly restricting the devices that may be used, or making data conversion necessary. Streaming services can have several drawbacks: requiring a constant Internet connection to use content; the restriction of some content to never be stored locally; the restriction of content from being transferred to physical media; and the enabling of greater censorship at the discretion of owners of content, infrastructure,[28] and consumer devices.\nDecades after the launch of the World Wide Web, in 2019 businesses were still adapting to the evolving world of distributing content digitally—even regarding the definition and understanding of basic terminology.[29]\n- App store\n- Digital ecosystem\n- Online shopping\n- Cloud gaming\n- Comparison of digital music stores\n- Content delivery network\n- Digital distribution of video games\n- Ebook\n- Electronic publishing\n- E-commerce\n- Film distribution\n- Film distributor\n- Internet pornography\n- List of mobile app distribution platforms\n- Streaming media\n- Uberisation\n- Video on demand\n- Jones, Ashley P. (2023). The Routledge companion to video game studies (Second ed.). New York: Routledge, Taylor & Francis Group. ISBN 978-1000886023.\n- Hardy, Phil (20 November 2012). Download! How The Internet Transformed The Record Business. London UK: Omnibus Press. ISBN 978-0857128034.\n- \"What Is a CDN? How Does a CDN work?\". Cloudflare. Archived from the original on 3 June 2019. Retrieved 1 June 2019.\n- Kern, Philippe. \"The Impact of Digital Distribution – A Contribution\" (PDF). Think Tank. Archived from the original (PDF) on 17 April 2012. Retrieved 26 April 2012.\n- Goldman, David (3 February 2010). \"Music's lost decade: Sales cut in half\". CNN. Archived from the original on 27 June 2020. Retrieved 3 August 2020.\n- Canadian Press (29 May 2007). \"Sam the Record Man to shut its Yonge St. doors\". Entertainment section. The Toronto Star. Archived from the original on 5 September 2008. Retrieved 18 January 2009.\n- Janssens, Jelle; Stijn Vandaele; Tom Vander Beken (2009). \"The Music Industry on (the) Line? Surviving Music Piracy in a Digital Era\" (PDF). European Journal of Crime, Criminal Law and Criminal Justice. 77 (96): 77–96. doi:10.1163/157181709X429105. hdl:1854/LU-608677. Archived (PDF) from the original on 29 July 2020. Retrieved 25 September 2019.\n- \"How Does MP3 Compression Work?\". LedgerNote. 21 July 2016. Archived from the original on 21 May 2022. Retrieved 20 June 2022.\n- Pendlebury, Ty. \"What is FLAC? The high-def MP3 explained\". CNET. Archived from the original on 20 June 2022. Retrieved 20 June 2022.\n- \"Facts & Stats — IFPI — Representing the recording industry worldwide\". Archived from the original on 21 June 2020. Retrieved 16 October 2019.\n- Friedlander, Joshua P. (March 2018). \"News and Notes on 2017 RIAA Revenue Statistics\" (PDF). Retrieved 2 August 2025.\n- Bass, Matthew (March 2024). \"YEAR-END 2023 RIAA REVENUE STATISTICS\" (PDF). Retrieved 2 August 2025.\n- Helft, Miguel (16 January 2007). \"Netflix to Deliver Movies to the PC\". The New York Times. ISSN 0362-4331. Archived from the original on 5 February 2021. Retrieved 1 June 2019.\n- \"9.4 Influence of New Technologies\". Understanding Media and Culture: An Introduction to Mass Communication. 22 March 2016. Archived from the original on 17 May 2022. Retrieved 20 June 2022 – via University of Minnesota.\n- MacInnes, Ian (2005). \"Impediments to Digital Distribution for Software and Books\". International Journal on Media Management. 7 (1–2): 75–85. doi:10.1080/14241277.2005.9669418. S2CID 54694065.\n- Rosen, Judith (16 April 2012). \"Distribution in a Digital Age\". Publishers Weekly. ProQuest 1002661729. Archived from the original on 24 December 2021. Retrieved 24 December 2021.\n- \"Tor/Forge E-book Titles to Go DRM-Free\". Tor.com. 24 April 2012. Archived from the original on 9 March 2018. Retrieved 24 April 2012.\n- Geuss, Megan (4 May 2013). \"Tor Books says cutting DRM out of its e-books hasn't hurt the business – A look at the sci-fi publisher a year after it announced it would do away with DRM\". Arstechnica. Archived from the original on 21 March 2018. Retrieved 7 July 2013.\nEarly this week, Tor Books, a subsidiary of Tom Doherty Associates and the world's leading publisher of science fiction, gave an update on how its decision to do away with Digital Rights Management (DRM) schemes has impacted the company. Long story short: it hasn't, really.\n- \"Tor/Forge Plans DRM-Free e-Books By July\". Publishers Weekly. 24 April 2012. Archived from the original on 25 April 2012. Retrieved 24 April 2012.\n- Walker, John (22 November 2007). \"RPS Exclusive: Gabe Newell Interview\". Rock, Paper, Shotgun. Archived from the original on 12 May 2014. Retrieved 28 June 2013.\nThe worst days [for game development] were the cartridge days for the NES. It was a huge risk – you had all this money tied up in silicon in a warehouse somewhere, and so you'd be conservative in the decisions you felt you could make, very conservative in the IPs you signed, your art direction would not change, and so on. Now it's the opposite extreme: we can put something up on Steam, deliver it to people all around the world, make changes. We can take more interesting risks. [...] Retail doesn't know how to deal with those games. On Steam [a digital distributor] there's no shelf-space restriction. It's great because they're a bunch of old, orphaned games.\n- \"The Secret of Monkey Island: Special Edition Tech Info\". GameSpot. Archived from the original on 16 January 2010. Retrieved 15 November 2011.\n- Onyett, Charles (2 June 2009). \"E3 2009: The Secret of Monkey Island: Special Edition Preview\". IGN. Archived from the original on 27 May 2012. Retrieved 15 November 2011.\n- Garr, Brian (17 April 2011). \"Download distribution opening new doors for independent game developers\". Statesman.com. Archived from the original on 21 April 2011.\n- Stuart, Keith (27 January 2010). \"Back to the bedroom: how indie gaming is reviving the Britsoft spirit\". The Guardian. Archived from the original on 5 April 2019. Retrieved 8 November 2012.\n- Senior, Tom (16 March 2012). \"Garry's Mod has sold 1.4 million copies, Garry releases sales history to prove it\". PCGamer. Archived from the original on 28 April 2021. Retrieved 28 June 2013.\n- Caron, Frank (9 September 2008). \"First look: GOG revives classic PC games for download age\". Ars Technica. Archived from the original on 20 December 2021. Retrieved 27 December 2012.\n[...] [Good Old Games] focuses on bringing old, time-tested games into the downloadable era with low prices and no DRM.\n- \"Why digital is greener than the boxed video games?\". Expert blog for professionals in the video game industry. CodesWholesale.com. 22 April 2016. Archived from the original on 21 August 2016. Retrieved 4 August 2016.\n- Kharif, Olga (4 September 2018). \"YouTube, Netflix Videos Found to Be Slowed by Wireless Carriers\". Bloomberg. Archived from the original on 11 September 2018. Retrieved 27 June 2019.\n- Furr, Nathan; Shipilov, Andrew (July 2019). \"Digital Doesn't Have to Be Disruptive\". Harvard Business Review. Archived from the original on 16 August 2019. Retrieved 16 August 2019.",
    "e-commerce": "| E-commerce |\n|---|\n| Digital content |\n| Retail goods and services |\n| Online shopping |\n| Mobile commerce |\n| Customer service |\n| E-procurement |\n| Purchase-to-pay |\n| Super-apps |\nE-commerce (electronic commerce) refers to commercial activities including the electronic buying or selling products and services which are conducted on online platforms or over the Internet.[1] E-commerce draws on technologies such as mobile commerce, electronic funds transfer, supply chain management, Internet marketing, online transaction processing, electronic data interchange (EDI), inventory management systems, and automated data collection systems. E-commerce is a part of the retail, the largest segment of the electronics industry and is in turn driven by the technological advances of the semiconductor industry.\nDefining e-commerce\nThe term was coined and first employed by Robert Jacobson, Principal Consultant to the California State Assembly's Utilities & Commerce Committee, in the title and text of California's Electronic Commerce Act, carried by the late Committee Chairwoman Gwen Moore (D-L.A.) and enacted in 1984.\nE-commerce typically uses the web for at least a part of a transaction's life cycle although it may also use other technologies such as e-mail. Typical e-commerce transactions include the purchase of products (such as books from Amazon) or services (such as music downloads in the form of digital distribution such as the iTunes Store).[2] There are three areas of e-commerce: online retailing, electronic markets, and online auctions. E-commerce is supported by electronic business.[3] The existence value of e-commerce is to allow consumers to shop online and pay online through the Internet, saving the time and space of customers and enterprises, greatly improving transaction efficiency, especially for busy office workers, and also saving a lot of valuable time.[4]\nE-commerce businesses may also employ some or all of the following:\n- Online shopping for retail sales direct to consumers via web sites and mobile apps, conversational commerce via live chat, chatbots, and voice assistants.[5]\n- Providing or participating in online marketplaces, which process third-party business-to-consumer (B2C) or consumer-to-consumer (C2C) sales;\n- Business-to-business (B2B) buying and selling.[6]\n- Direct-to-Consumer(D2C) sales, in which manufactures or brands sell directly to end customers without traditional retail intermediaries. This model has expanded rapidly with the growth of digital storefronts and social commerce platforms such as Shopify, TikTok Shop, and Instagram Checkout.\n- Data-driven marketing, gathering demographic and behavioral data through web analytics and social media.\n- B2B electronic data interchange.\n- Marketing to prospective and established customers by e-mail or fax (for example, with newsletters).\n- Engaging in pretail for launching new products and services.\n- Online financial exchanges for currency exchanges or trading purposes.\nThere are five essential categories of E-commerce:[7]\n- Business to Business\n- Business to Consumer\n- Business to Government\n- Consumer to Business\n- Consumer to Consumer\n- Direct to Consumer\nForms\nContemporary electronic commerce can be classified into two categories. The first category is business based on types of goods sold (involves everything from ordering \"digital\" content for immediate online consumption, to ordering conventional goods and services, to \"meta\" services to facilitate other types of electronic commerce). The second category is based on the nature of the participant (B2B, B2C, C2B and C2C).[8]\nOn the institutional level, big corporations and financial institutions use the internet to exchange financial data to facilitate domestic and international business. Data integrity and security are pressing issues for electronic commerce.\nAside from traditional e-commerce, the terms m-Commerce (mobile commerce) as well (around 2013) t-Commerce[9] have also been used.\nGovernmental regulation\nIn the United States, California's Electronic Commerce Act (1984), enacted by the Legislature, the more recent California Privacy Rights Act (2020), enacted through a popular election proposition and to control specifically how electronic commerce may be conducted in California. In the US in its entirety, electronic commerce activities are regulated more broadly by the Federal Trade Commission (FTC). These activities include the use of commercial e-mails, online advertising and consumer privacy. The CAN-SPAM Act of 2003 establishes national standards for direct marketing over e-mail. The Federal Trade Commission Act regulates all forms of advertising, including online advertising, and states that advertising must be truthful and non-deceptive.[10] Using its authority under Section 5 of the FTC Act, which prohibits unfair or deceptive practices, the FTC has brought a number of cases to enforce the promises in corporate privacy statements, including promises about the security of consumers' personal information.[11] As a result, any corporate privacy policy related to e-commerce activity may be subject to enforcement by the FTC.\nThe Ryan Haight Online Pharmacy Consumer Protection Act of 2008, which came into law in 2008, amends the Controlled Substances Act to address online pharmacies.[12]\nConflict of laws in cyberspace is a major hurdle for harmonization of legal framework for e-commerce around the world. In order to give a uniformity to e-commerce law around the world, many countries adopted the UNCITRAL Model Law on Electronic Commerce (1996).[13]\nInternationally there is the International Consumer Protection and Enforcement Network (ICPEN), which was formed in 1991 from an informal network of government customer fair trade organisations. The purpose was stated as being to find ways of co-operating on tackling consumer problems connected with cross-border transactions in both goods and services, and to help ensure exchanges of information among the participants for mutual benefit and understanding. From this came Econsumer.gov, an ICPEN initiative since April 2001. It is a portal to report complaints about online and related transactions with foreign companies.\nThere is also Asia Pacific Economic Cooperation. APEC was established in 1989 with the vision of achieving stability, security and prosperity for the region through free and open trade and investment. APEC has an Electronic Commerce Steering Group as well as working on common privacy regulations throughout the APEC region.\nIn Australia, trade is covered under Australian Treasury Guidelines for electronic commerce and the Australian Competition & Consumer Commission[14] regulates and offers advice on how to deal with businesses online,[15] and offers specific advice on what happens if things go wrong.[16]\nThe European Union undertook an extensive enquiry into e-commerce in 2015–16 which observed significant growth in the development of e-commerce, along with some developments which raised concerns, such as increased use of selective distribution systems, which allow manufacturers to control routes to market, and \"increased use of contractual restrictions to better control product distribution\". The European Commission felt that some emerging practices might be justified if they could improve the quality of product distribution, but \"others may unduly prevent consumers from benefiting from greater product choice and lower prices in e-commerce and therefore warrant Commission action\" in order to promote compliance with EU competition rules.[17]\nIn the United Kingdom, the Financial Services Authority (FSA)[18] was formerly the regulating authority for most aspects of the EU's Payment Services Directive (PSD), until its replacement in 2013 by the Prudential Regulation Authority and the Financial Conduct Authority.[19] The UK implemented the PSD through the Payment Services Regulations 2009 (PSRs), which came into effect on 1 November 2009. The PSR affects firms providing payment services and their customers. These firms include banks, non-bank credit card issuers and non-bank merchant acquirers, e-money issuers, etc. The PSRs created a new class of regulated firms known as payment institutions (PIs), who are subject to prudential requirements. Article 87 of the PSD required the European Commission to report on the implementation and impact of the PSD by 1 November 2012.[20]\nIn India, the Information Technology Act 2000 governs the basic applicability of e-commerce.\nIn China, the Telecommunications Regulations of the People's Republic of China (promulgated on 25 September 2000), stipulated the Ministry of Industry and Information Technology (MIIT) as the government department regulating all telecommunications related activities, including electronic commerce.[21] On the same day, the Administrative Measures on Internet Information Services were released, the first administrative regulations to address profit-generating activities conducted through the Internet, and lay the foundation for future regulations governing e-commerce in China.[22] On 28 August 2004, the eleventh session of the tenth NPC Standing Committee adopted an Electronic Signature Law, which regulates data message, electronic signature authentication and legal liability issues. It is considered the first law in China's e-commerce legislation. It was a milestone in the course of improving China's electronic commerce legislation, and also marks the entering of China's rapid development stage for electronic commerce legislation.[23]\nGlobal trends\nE-commerce has become an important tool for small and large businesses worldwide, not only to sell to customers, but also to engage them.[24][25]\nCross-border e-Commerce is also an essential field for e-Commerce businesses. It has responded to the trend of globalization. It shows that numerous firms have opened up new businesses, expanded new markets, and overcome trade barriers; more and more enterprises have started exploring the cross-border cooperation field. In addition, compared with traditional cross-border trade, the information on cross-border e-commerce is more concealed. In the era of globalization, cross-border e-commerce for inter-firm companies means the activities, interactions, or social relations of two or more e-commerce enterprises. However, the success of cross-border e-commerce promotes the development of small and medium-sized firms, and it has finally become a new transaction mode. It has helped the companies solve financial problems and realize the reasonable allocation of resources field. SMEs ( small and medium enterprises) can also precisely match the demand and supply in the market, having the industrial chain majorization and creating more revenues for companies.[26]\nIn 2012, e-commerce sales topped $1 trillion for the first time in history.[27]\nMobile devices are playing an increasing role in the mix of e-commerce, this is also commonly called mobile commerce, or m-commerce. In 2014, one estimate saw purchases made on mobile devices making up 25% of the market by 2017.[28]\nFor traditional businesses, one research stated that information technology and cross-border e-commerce is a good opportunity for the rapid development and growth of enterprises. Many companies have invested an enormous volume of investment in mobile applications. The DeLone and McLean Model stated that three perspectives contribute to a successful e-business: information system quality, service quality and users' satisfaction.[29] There is no limit of time and space, there are more opportunities to reach out to customers around the world, and to cut down unnecessary intermediate links, thereby reducing the cost price, and can benefit from one on one large customer data analysis, to achieve a high degree of personal customization strategic plan, in order to fully enhance the core competitiveness of the products in the company.[30]\nModern 3D graphics technologies, such as Facebook 3D Posts, are considered by some social media marketers and advertisers as a preferable way to promote consumer goods than static photos, and some brands like Sony are already paving the way for augmented reality commerce. Wayfair now lets you inspect a 3D version of its furniture in a home setting before buying.[31]\nChina\nAmong emerging economies, China's e-commerce presence continued to expand every year. With 668 million Internet users as of 2014, China's online shopping sales reached $253 billion in the first half of 2015, accounting for 10% of total Chinese consumer retail sales in that period.[32] The Chinese retailers have been able to help consumers feel more comfortable shopping online.[33] e-commerce transactions between China and other countries increased 32% to 2.3 trillion yuan ($375.8 billion) in 2012 and accounted for 9.6% of China's total international trade.[34] In 2013, Alibaba had an e-commerce market share of 80% in China.[35] In 2014, Alibaba still dominated the B2B marketplace in China with a market share of 44.82%, followed by several other companies including Made-in-China.com at 3.21%, and GlobalSources.com at 2.98%, with the total transaction value of China's B2B market exceeding 4.5 billion yuan.[36]\nChina was also the largest e-commerce market in the world by value of sales, with an estimated US$899 billion in 2016.[37] It accounted for 42.4% of worldwide retail e-commerce in that year, the most of any country.[38]: 110 Research shows that Chinese consumer motivations are different enough from Western audiences to require unique e-commerce app designs instead of simply porting Western apps into the Chinese market.[39]\nThe expansion of e-commerce in China has resulted in the development of Taobao villages, clusters of e-commerce businesses operating in rural areas.[38]: 112 Because Taobao villages have increased the incomes or rural people and entrepreneurship in rural China, Taobao villages have become a component of rural revitalization strategies.[40]: 278\nIn 2015, the State Council promoted the Internet Plus initiative, a five-year plan to integrate traditional manufacturing and service industries with big data, cloud computing, and Internet of things technology.[41]: 44 The State Council provided support for Internet Plus through policy support in area including cross-border e-commerce and rural e-commerce.[41]: 44\nIn 2019, the city of Hangzhou established a pilot program artificial intelligence-based Internet Court to adjudicate disputes related to e-commerce and internet-related intellectual property claims.[42]: 124\nEurope\nIn 2010, the United Kingdom had the highest per capita e-commerce spending in the world.[43] As of 2013, the Czech Republic was the European country where e-commerce delivers the biggest contribution to the enterprises' total revenue. Almost a quarter (24%) of the country's total turnover is generated via the online channel.[44]\nArab states\nThe rate of growth of the number of internet users in the Arab countries has been rapid – 13.1% in 2015. A significant portion of the e-commerce market in the Middle East comprises people in the 30–34 year age group. Egypt has the largest number of internet users in the region, followed by Saudi Arabia and Morocco; these constitute 3/4th of the region's share. Yet, internet penetration is low: 35% in Egypt and 65% in Saudi Arabia.[45]\nThe Gulf Cooperation Council countries have a rapidly growing market and are characterized by a population that becomes wealthier (Yuldashev). As such, retailers have launched Arabic-language websites as a means to target this population. Secondly, there are predictions of increased mobile purchases and an expanding internet audience (Yuldashev). The growth and development of the two aspects make the GCC countries become larger players in the electronic commerce market with time progress. Specifically, research shows that the e-commerce market was expected to grow to over $20 billion by 2020 among these GCC countries (Yuldashev). The e-commerce market has also gained much popularity among western countries, and in particular Europe and the U.S. These countries have been highly characterized by consumer-packaged goods (CPG) (Geisler, 34). However, trends show that there are future signs of a reverse. Similar to the GCC countries, there has been increased purchase of goods and services in online channels rather than offline channels. Activist investors are trying hard to consolidate and slash their overall cost and the governments in western countries continue to impose more regulation on CPG manufacturers (Geisler, 36). In these senses, CPG investors are being forced to adapt to e-commerce as it is effective as well as a means for them to thrive.\nThe future trends in the GCC countries will be similar to that of the western countries. Despite the forces that push business to adapt e-commerce as a means to sell goods and products, the manner in which customers make purchases is similar in countries from these two regions. For instance, there has been an increased usage of smartphones which comes in conjunction with an increase in the overall internet audience from the regions. Yuldashev writes that consumers are scaling up to more modern technology that allows for mobile marketing. However, the percentage of smartphone and internet users who make online purchases is expected to vary in the first few years. It will be independent on the willingness of the people to adopt this new trend (The Statistics Portal). For example, UAE has the greatest smartphone penetration of 73.8 per cent and has 91.9 per cent of its population has access to the internet. On the other hand, smartphone penetration in Europe has been reported to be at 64.7 per cent (The Statistics Portal). Regardless, the disparity in percentage between these regions is expected to level out in future because e-commerce technology is expected to grow to allow for more users.\nThe e-commerce business within these two regions will result in competition. Government bodies at the country level will enhance their measures and strategies to ensure sustainability and consumer protection (Krings, et al.). These increased measures will raise the environmental and social standards in the countries, factors that will determine the success of the e-commerce market in these countries. For example, an adoption of tough sanctions will make it difficult for companies to enter the e-commerce market while lenient sanctions will allow ease of companies. As such, the future trends between GCC countries and the Western countries will be independent of these sanctions (Krings, et al.). These countries need to make rational conclusions in coming up with effective sanctions.\nIndia\nIndia had an Internet user base of about 460 million as of December 2017.[46] Despite being the third largest user base in the world, the penetration of the Internet is low compared to markets like the United States, United Kingdom or France but is growing at a much faster rate, adding around six million new entrants every month.[citation needed] In India, cash on delivery is the most preferred payment method, accumulating 75% of the e-retail activities.[47][citation needed] The India retail market was expected to rise from 2.5% in 2016 to 5% in 2020.[48]\nBrazil\nIn 2013, Brazil's e-commerce was growing quickly with retail e-commerce sales expected to grow at a double-digit pace through 2014. By 2016, eMarketer expected retail e-commerce sales in Brazil to reach $17.3 billion.[49]\nLogistics\nLogistics in e-commerce mainly concerns fulfillment. Online markets and retailers have to find the best possible way to fill orders and deliver products. Small companies usually control their own logistic operation because they do not have the ability to hire an outside company. Most large companies hire a fulfillment service that takes care of a company's logistic needs.[50] The optimization of logistics processes that contains long-term investment in an efficient storage infrastructure system and adoption of inventory management strategies is crucial to prioritize customer satisfaction throughout the entire process, from order placement to final delivery.[51]\nImpacts\nImpact on markets and retailers\nE-commerce markets grew at noticeable rates. The online market was expected to grow by 56% in 2015–2020. In 2017, retail e-commerce sales worldwide amounted to 2.3 trillion US dollars and e-retail revenues were projected to grow to 4.891 trillion US dollars in 2021.[52] Traditional markets are only expected 2% growth during the same time. Brick and mortar retailers are struggling because of online retailer's ability to offer lower prices and higher efficiency. Many larger retailers are able to maintain a presence offline and online by linking physical and online offerings.[53]\nE-commerce allows customers to overcome geographical barriers and allows them to purchase products anytime and from anywhere. Online and traditional markets have different strategies for conducting business. Traditional retailers offer fewer assortment of products because of shelf space where, online retailers often hold no inventory but send customer orders directly to the manufacturer. The pricing strategies are also different for traditional and online retailers. Traditional retailers base their prices on store traffic and the cost to keep inventory. Online retailers base prices on the speed of delivery.\nThere are two ways for marketers to conduct business through e-commerce: fully online or online along with a brick and mortar store. Online marketers can offer lower prices, greater product selection, and high efficiency rates. Many customers prefer online markets if the products can be delivered quickly at relatively low price. However, online retailers cannot offer the physical experience that traditional retailers can. It can be difficult to judge the quality of a product without the physical experience, which may cause customers to experience product or seller uncertainty. Another issue regarding the online market is concerns about the security of online transactions. Many customers remain loyal to well-known retailers because of this issue.[54]\nSecurity is a primary problem for e-commerce in developed and developing countries. E-commerce security is protecting businesses' websites and customers from unauthorized access, use, alteration, or destruction. The type of threats include: malicious codes, unwanted programs (ad ware, spyware), phishing, hacking, and cyber vandalism. E-commerce websites use different tools to avert security threats. These tools include firewalls, encryption software, digital certificates, and passwords.[citation needed]\nImpact on supply chain management\nFor a long time, companies had been troubled by the gap between the benefits which supply chain technology has and the solutions to deliver those benefits. However, the emergence of e-commerce has provided a more practical and effective way of delivering the benefits of the new supply chain technologies.[55]\nE-commerce has the capability to integrate all inter-company and intra-company functions, meaning that the three flows (physical flow, financial flow and information flow) of the supply chain could be also affected by e-commerce. The affections on physical flows improved the way of product and inventory movement level for companies. For the information flows, e-commerce optimized the capacity of information processing than companies used to have, and for the financial flows, e-commerce allows companies to have more efficient payment and settlement solutions.[55]\nIn addition, e-commerce has a more sophisticated level of impact on supply chains: Firstly, the performance gap will be eliminated since companies can identify gaps between different levels of supply chains by electronic means of solutions; Secondly, as a result of e-commerce emergence, new capabilities such implementing ERP systems, like SAP ERP, Xero, or Megaventory, have helped companies to manage operations with customers and suppliers. Yet these new capabilities are still not fully exploited. Thirdly, technology companies would keep investing on new e-commerce software solutions as they are expecting investment return. Fourthly, e-commerce would help to solve many aspects of issues that companies may feel difficult to cope with, such as political barriers or cross-country changes. Finally, e-commerce provides companies a more efficient and effective way to collaborate with each other within the supply chain.[55]\nImpact on employment\nE-commerce helps create new job opportunities due to information related services, software app and digital products. It also causes job losses. The areas with the greatest predicted job-loss are retail, postal, and travel agencies. The development of e-commerce will create jobs that require highly skilled workers to manage large amounts of information, customer demands, and production processes. In contrast, people with poor technical skills cannot enjoy the wages welfare. On the other hand, because e-commerce requires sufficient stocks that could be delivered to customers in time, the warehouse becomes an important element. Warehouse needs more staff to manage, supervise and organize, thus the condition of warehouse environment will be concerned by employees.[56]\nImpact on customers\nE-commerce brings convenience for customers as they do not have to leave home and only need to browse websites online, especially for buying products which are not sold in nearby shops. It could help customers buy a wider range of products and save customers' time. Consumers also gain power through online shopping. They are able to research products and compare prices among retailers. Thanks to the practice of user-generated ratings and reviews from companies like Bazaarvoice, Trustpilot, and Yelp, customers can also see what other people think of a product, and decide before buying if they want to spend money on it.[57][58] Also, online shopping often provides sales promotion or discounts code, thus it is more price effective for customers. Moreover, e-commerce provides products' detailed information; even the in-store staff cannot offer such detailed explanation. Customers can also review and track the order history online.\nE-commerce technologies cut transaction costs by allowing both manufactures and consumers to skip through the intermediaries. This is achieved through by extending the search area best price deals and by group purchase. The success of e-commerce in urban and regional levels depend on how the local firms and consumers have adopted to e-commerce.[59]\nHowever, e-commerce lacks human interaction for customers, especially who prefer face-to-face connection. Customers are also concerned with the security of online transactions and tend to remain loyal to well-known retailers. In recent years, clothing retailers such as Tommy Hilfiger have started adding Virtual Fit platforms to their e-commerce sites to reduce the risk of customers buying the wrong sized clothes, although these vary greatly in their fit for purpose.[60] When the customer regret the purchase of a product, it involves returning goods and refunding process. This process is inconvenient as customers need to pack and post the goods. If the products are expensive, large or fragile, it refers to safety issues.[53]\nImpact on the environment\nIn 2018, E-commerce generated 1.3 million short tons (1.2 megatonnes) of container cardboard in North America, an increase from 1.1 million (1.00)) in 2017. Only 35 percent of North American cardboard manufacturing capacity was from recycled content. The recycling rate in Europe was 80 percent and Asia was 93 percent. Amazon, the largest user of boxes, had a strategy to cut back on packing material and reduced packaging material used by 19 percent by weight since 2016. Amazon is requiring retailers to manufacture their product packaging in a way that does not require additional shipping packaging. Amazon also has an 85-person team researching ways to reduce and improve their packaging and shipping materials.[61]\nAccelerated movement of packages around the world includes accelerated movement of living things, such as invasive species.[62] Weeds, pests, and diseases all sometimes travel in packages of seeds.[62] Some of these packages are part of brushing manipulation of e-commerce reviews.[62]\nImpact on traditional retail\nE-commerce has been cited as a major force for the failure of major U.S. retailers in a trend frequently referred to as a \"retail apocalypse.\"[63] The rise of e-commerce outlets like Amazon has made it harder for traditional retailers to attract customers to their stores and forced companies to change their sales strategies. Many companies have turned to sales promotions and increased digital efforts to lure shoppers while shutting down brick-and-mortar locations.[64] The trend has forced some traditional retailers to shutter its brick and mortar operations.[65]\nE-commerce during COVID-19\nIn March 2020, global retail website traffic hit 14.3 billion visits[66] signifying an unprecedented growth of e-commerce during the lockdown of 2020. Later studies show that online sales increased by 25% and online grocery shopping increased by over 100% during the crisis in the United States.[67] Meanwhile, as many as 29% of surveyed shoppers state that they will never go back to shopping in person again; in the UK, 43% of consumers state that they expect to keep on shopping the same way even after the lockdown is over.[68]\nRetail sales of e-commerce shows that COVID-19 has a significant impact on e-commerce and its sales were expected to reach $6.5 trillion by 2023.[69]\nBusiness application\nSome common applications related to electronic commerce are:\n- B2B e-commerce (business-to-business)\n- B2C e-commerce (business-to-consumer)\n- Conversational commerce: e-commerce via chat\n- Digital Wallet\n- Document automation in supply chain and logistics\n- Electronic tickets\n- Enterprise content management\n- Group buying\n- Instant messaging\n- Internet security\n- Online auction\n- Online banking\n- Online office suites\n- Online shopping and order tracking\n- Online transaction processing\n- Pretail\n- Print on demand\n- Shopping cart software\n- Social networking\n- Teleconference\n- Usenet newsgroup\n- Virtual assistant\n- Domestic and international payment systems\nTimeline\nA timeline for the development of e-commerce:\n- 1971 or 1972: The ARPANET is used to arrange a cannabis sale between students at the Stanford Artificial Intelligence Laboratory and the Massachusetts Institute of Technology, later described as \"the seminal act of e-commerce\" in John Markoff's book What the Dormouse Said.[70]\n- 1979: Michael Aldrich demonstrates the first online shopping system.[71]\n- 1981: Thomson Holidays UK is the first business-to-business (B2B) online shopping system to be installed.[72]\n- 1982: Minitel was introduced nationwide in France by France Télécom and used for online ordering.\n- 1983: California State Assembly holds first hearing on \"electronic commerce\" in Volcano, California.[73] Testifying are CPUC, MCI Mail, Prodigy, CompuServe, Volcano Telephone, and Pacific Telesis. (Not permitted to testify is Quantum Technology, later to become AOL.) California's Electronic Commerce Act was passed in 1984.\n- 1983: Karen Earle Lile (AKA Karen Bean) and Kendall Ross Bean create e-commerce service in San Francisco Bay Area. Buyers and sellers of pianos connect through a database created by Piano Finders on a Kaypro personal computer. Pianos for sale are listed on a Bulletin board system. Buyers print list of pianos for sale by a dot matrix printer. Customer service happened through a Piano Advice Hotline listed in the San Francisco Chronicle classified ads and money transferred by a bank wire transfer when a sale was completed.[74][75]\n- 1984: Gateshead SIS/Tesco is first B2C online shopping system[76] and Mrs Snowball, 72, is the first online home shopper[77]\n- 1984: In April 1984, CompuServe launches the Electronic Mall in the US and Canada. It is the first comprehensive electronic commerce service.[78]\n- 1989: In May 1989, Sequoia Data Corp. introduced Compumarket, the first internet based system for e-commerce. Sellers and buyers could post items for sale and buyers could search the database and make purchases with a credit card.\n- 1990: Tim Berners-Lee writes the first web browser, WorldWideWeb, using a NeXT computer.[79]\n- 1992: Book Stacks Unlimited in Cleveland opens a commercial sales website (www.books.com) selling books online with credit card processing.\n- 1993: Paget Press releases edition No. 3[80] of the first[81] app store, The Electronic AppWrapper[82]\n- 1994: Netscape releases the Navigator browser in October under the code name Mozilla. Netscape 1.0 is introduced in late 1994 with SSL encryption that made transactions secure.\n- 1994: Ipswitch IMail Server becomes the first software available online for sale and immediate download via a partnership between Ipswitch, Inc. and OpenMarket.\n- 1994: \"Ten Summoner's Tales\" by Sting becomes the first secure online purchase through NetMarket.[83]\n- 1995: The US National Science Foundation lifts its former strict prohibition of commercial enterprise on the Internet.[84]\n- 1995: Thursday 27 April 1995, the purchase of a book by Paul Stanfield, product manager for CompuServe UK, from W H Smith's shop within CompuServe's UK Shopping Centre is the UK's first national online shopping service secure transaction. The shopping service at launch featured W H Smith, Tesco, Virgin Megastores/Our Price, Great Universal Stores (GUS), Interflora, Dixons Retail, Past Times, PC World (retailer) and Innovations.\n- 1995: Amazon is launched by Jeff Bezos.\n- 1995: eBay is founded by computer programmer Pierre Omidyar as AuctionWeb. It is the first online auction site supporting person-to-person transactions.[85]\n- 1995: The first commercial-free 24-hour, internet-only radio stations, Radio HK and NetRadio start broadcasting.\n- 1996: The use of Excalibur BBS with replicated \"storefronts\" was an early implementation of electronic commerce started by a group of SysOps in Australia and replicated to global partner sites.\n- 1998: Electronic postal stamps can be purchased and downloaded for printing from the Web.[86]\n- 1999: Alibaba Group is established in China. Business.com sold for US$7.5 million to eCompanies, which was purchased in 1997 for US$149,000. The peer-to-peer filesharing software Napster launches. ATG Stores launches to sell decorative items for the home online.\n- 1999: Global e-commerce reaches $150 billion[56]\n- 2000: The dot-com bust.\n- 2001: eBay has the largest userbase of any e-commerce site.[85]\n- 2001: Alibaba.com achieved profitability in December 2001.\n- 2002: eBay acquires PayPal for $1.5 billion.[87] Niche retail companies Wayfair and NetShops are founded with the concept of selling products through several targeted domains, rather than a central portal.\n- 2003: Amazon posts first yearly profit.\n- 2004: DHgate.com, China's first online B2B transaction platform, is established, forcing other B2B sites to move away from the \"yellow pages\" model.[88]\n- 2007: Business.com acquired by R.H. Donnelley for $345 million.[89]\n- 2014: US e-commerce and online retail sales projected to reach $294 billion, an increase of 12 percent over 2013 and 9% of all retail sales.[90] Alibaba Group has the largest Initial public offering ever, worth $25 billion.\n- 2015: Amazon accounts for more than half of all e-commerce growth,[91] selling almost 500 Million SKU's in the US.\n- 2016: The Government of India launches the BHIM UPI digital payment interface. In the year 2020 it had 2 billion digital payment transactions.[92][93]\n- 2017: Retail e-commerce sales across the world reaches $2.304 trillion, which was a 24.8 percent increase than previous year.[94]\n- 2017: Global e-commerce transactions generate $29.267 trillion, including $25.516 trillion for business-to-business (B2B) transactions and $3.851 trillion for business-to-consumer (B2C) sales.[95]\nSee also\n- Comparison of free software e-commerce web application frameworks\n- Comparison of shopping cart software\n- Customer intelligence\n- Digital economy\n- E-commerce credit card payment system\n- Electronic bill payment\n- Electronic money\n- Non-store retailing\n- Online shopping\n- Payments as a service\n- South Dakota v. Wayfair, Inc.\n- Types of e-commerce\n- Timeline of e-commerce\nReferences\n- \"E-COMMERCE\". Cambridge Dictionary.\n- \"Retail e-commerce sales CAGR forecast in selected countries from 2016 to 2021\". Statista. October 2016. Archived from the original on 26 November 2017. Retrieved 4 May 2021.\n- Wienclaw, Ruth A. (2013). \"B2B Business Models\" (PDF). Research Starters: Business. Archived (PDF) from the original on 18 July 2013. Retrieved 4 May 2021.\n- Subramani, Mani; Walden, Eric (June 2001). \"The Impact of E-Commerce Announcements on the Market Value of Firms\". Information Systems Research. 12 (2): 135–154. doi:10.1287/isre.12.2.135.9698. ISSN 1047-7047. Archived from the original on 15 June 2022. Retrieved 30 April 2022.\n- Bussey, Ed (6 March 2018). \"How to prepare your products and brand for conversational commerce\". VentureBeat. Archived from the original on 29 September 2020. Retrieved 4 May 2021.\n- \"The Ultimate Guide to eCommerce Marketing\". Mayple. Archived from the original on 28 April 2021. Retrieved 4 May 2021.\n- Simjanović, Dušan J.; Zdravković, Nemanja; Vesić, Nenad O. (March 2022). \"On the Factors of Successful e-Commerce Platform Design during and after COVID-19 Pandemic Using Extended Fuzzy AHP Method\". Axioms. 11 (3): 105. doi:10.3390/axioms11030105. ISSN 2075-1680.\n- Khurana, Ajeet (25 November 2019). \"Did You Know That There Are 4 Types of Ecommerce?\". The Balance Small Business. Dotdash. Archived from the original on 22 January 2021. Retrieved 4 May 2021.\n- Hacon, Tom (4 March 2013). \"T-Commerce – What the tablet can do for brands and their consumers\". Governor Technology. Archived from the original on 7 June 2016. Retrieved 4 May 2021.\n- \"Advertising and Marketing on the Internet: Rules of the Road\". Federal Trade Commission. September 2000. Archived from the original on 8 March 2020. Retrieved 4 May 2021.\n- \"Privacy and Security\". Federal Trade Commission. Archived from the original on 4 May 2021. Retrieved 4 May 2021.\n- \"H.R. 6353 (110th): Ryan Haight Online Pharmacy Consumer Protection Act of 2008\". GovTrack. 2 October 2008. Archived from the original on 19 March 2021. Retrieved 4 May 2021.\n- UNCITRAL Model Law on Electronic Commerce (PDF). New York: United Nations Commission on International Trade Law. 1999. ISBN 92-1-133607-4. Archived (PDF) from the original on 25 February 2021. Retrieved 4 May 2021.\n- \"Australian Competition and Consumer Commission\". Australian Competition & Consumer Commission. Government of Australia. Archived from the original on 3 May 2021. Retrieved 4 May 2021.\n- \"Dealing with other businesses online\". Australian Competition & Consumer Commission. Government of Australia. Archived from the original on 19 January 2013. Retrieved 4 May 2021.\n- \"What to do if thing go wrong in Australia\". Australian Competition & Consumer Commission. Australian Federal Government. Archived from the original on 12 February 2013. Retrieved 4 May 2021.\n- European Commission, Sector inquiry into e-commerce Archived 6 February 2023 at the Wayback Machine, accessed 6 February 2023\n- \"Financial Services Authority\". Financial Services Authority. Archived from the original on 28 December 2012. Retrieved 4 May 2021.\n- Parker, George; Masters, Brooke (16 June 2010). \"Osborne abolishes FSA and boosts Bank\". Financial Times. Archived from the original on 8 March 2021. Retrieved 4 May 2021.\n- \"The Payment Services Regulations 2009\". legislation.gov.uk. 9 February 2009. Archived from the original on 12 March 2021. Retrieved 4 May 2021.\n- \"Telecommunications Regulations of the People's Republic of China\". China Internet Information Center. 25 September 2000. Archived from the original on 5 April 2015. Retrieved 4 May 2021.\n- \"Administrative Measures on Internet Information Services\". China Internet Information Center. 20 September 2000. Archived from the original on 16 July 2015. Retrieved 4 May 2021.\n- Swan, Erin (30 October 2015). \"The PRC Electronic Signature Law\". eFileCabinet. Archived from the original on 7 November 2017. Retrieved 4 May 2021.\n- Eisingerich, Andreas B.; Kretschmer, Tobias (March 2008). \"In E-Commerce, More is More\". Harvard Business Review. 86: 20–21. Archived from the original on 3 December 2020. Retrieved 4 May 2021.\n- Burgess, Stephen; Sellitto, Carmine; Karanasios, Stan (28 February 2009). Effective Web Presence Solutions for Small Businesses: Strategies for Successful Implementation: Strategies for Successful Implementation. IGI Global. ISBN 9781605662251. Archived from the original on 4 May 2021. Retrieved 4 May 2021.\n- Chen, Si-Hua; Xiao, Hua; Huang, Wen-de; He, Wei (2 January 2022). \"Cooperation of Cross-border E-commerce: A reputation and trust perspective\". Journal of Global Information Technology Management. 25 (1): 7–25. doi:10.1080/1097198X.2021.2022396. ISSN 1097-198X. S2CID 246867732.\n- \"Ecommerce Sales Topped $1 Trillion for First Time in 2012\". eMarketer. 5 February 2013. Archived from the original on 30 March 2021. Retrieved 4 May 2021.\n- Enright, Allison (25 April 2013). \"U.S. e-commerce sales could top $434 billion in 2017\". Digital Commerce 360. Archived from the original on 2 December 2020. Retrieved 4 May 2021.\n- DeLone, William H.; McLean, Ephraim R. (8 December 2014). \"Measuring e-Commerce Success: Applying the DeLone & McLean Information Systems Success Model\". International Journal of Electronic Commerce. 9 (1): 31–47. doi:10.1080/10864415.2004.11044317. S2CID 205751936. Archived from the original on 23 March 2021. Retrieved 4 May 2021 – via Taylor & Francis.\n- Bakos, Yannis (2001). \"The Emerging Landscape for Retail E-Commerce\". Journal of Economic Perspectives. 15 (1): 69–80. CiteSeerX 10.1.1.4.9128. doi:10.1257/jep.15.1.69. Archived from the original on 18 January 2021. Retrieved 4 May 2021.\n- Constine, Josh (20 February 2018). \"Facebook's plan to unite AR, VR and News Feed with 3D posts\". TechCrunch. Archived from the original on 4 May 2018. Retrieved 4 May 2021.\n- Millward, Steven (18 August 2015). \"China is making a huge shift to mobile\". Tech in Asia (Infographic). Archived from the original on 6 March 2016. Retrieved 4 May 2021.\n- Olsen, Robert (18 January 2010). \"China's Migration To E-Commerce\". Forbes. Archived from the original on 6 August 2017. Retrieved 4 May 2021.\n- Tong, Frank (16 September 2013). \"China's cross‑border e‑commerce tops $375 billion in 2012\". Digital Commerce 360. Vertical Web Media LLC. Archived from the original on 18 October 2017. Retrieved 4 May 2021.\n- Millward, Steven (17 September 2014). \"Here are all the must-see numbers on Alibaba ahead of record-breaking IPO\". Tech in Asia. Archived from the original on 20 September 2014. Retrieved 4 May 2021.\n- PYMNTS.com (22 October 2014). \"China B2B Passes 4.5B Yuan\". PYMNTS.com. Archived from the original on 8 March 2023. Retrieved 8 March 2023.\n- Millward, Steven (18 August 2016). \"Asia's ecommerce spending to hit record $1 trillion this year – but most of that is China\". Tech in Asia. Archived from the original on 19 August 2016. Retrieved 4 May 2021.\n- Hu, Richard (2023). Reinventing the Chinese City. New York: Columbia University Press. ISBN 978-0-231-21101-7.\n- Parker, Christopher J.; Wenyu, Lu (13 May 2019). \"What influences Chinese fashion retail? Shopping motivations, demographics and spending\". Journal of Fashion Marketing and Management. 23 (2): 158–175. doi:10.1108/jfmm-09-2017-0093. ISSN 1361-2026. S2CID 170031856. Archived from the original on 8 March 2021. Retrieved 16 April 2021.\n- Yang, Saidi; Wang, Puqing; Zhou, Deyi (2021). \"Transformation and Development of Taobao Village in China Based on \"Zhijiang Mode\"Proceedings of the 2020 3rd International Seminar on Education Research and Social Science (ISERSS 2020). Paris, France: Atlantis Press. doi:10.2991/assehr.k.210120.053. ISBN 978-94-6239-316-5.\n- Zhang, Angela Huyue (2024). High Wire: How China Regulates Big Tech and Governs Its Economy. Oxford University Press. ISBN 9780197682258.\n- Šimalčík, Matej (2023). \"Rule by Law\". In Kironska, Kristina; Turscanyi, Richard Q. (eds.). Contemporary China: a New Superpower?. Routledge. ISBN 978-1-03-239508-1.\n- Robinson, James (28 October 2010). \"UK's internet industry worth £100bn\". The Guardian (report). London. Archived from the original on 19 February 2018. Retrieved 4 May 2021.\n- \"Ecommerce contribution in Europe\". Ecommerce News (infographic). 18 June 2013. Archived from the original on 25 January 2021. Retrieved 4 May 2021.\n- \"Ecommerce in the Middle East – What are the demographics?\". Embitel. 17 June 2016. Archived from the original on 27 August 2017. Retrieved 4 May 2021.\n- Keelery, Sandhya (7 July 2020). \"Internet usage in India – statistics & facts\". Statista. Archived from the original on 30 December 2017. Retrieved 4 May 2021.\n- Pasumarthy, Phani Bhaskar (December 2016). \"AFFECT OF DEMONETIZATION ON E-COMMERCE\". ResearchGate. Archived from the original on 26 October 2020. Retrieved 4 May 2021.\n- \"Fulfilled!:India's e-commerce retail logistics growth story\" (PDF). KPMG. August 2016. Archived (PDF) from the original on 8 May 2020. Retrieved 4 May 2021.\n- \"More Buyers Join Brazil's Robust Ecommerce Market\". eMarketer. 13 March 2013. Archived from the original on 4 August 2020. Retrieved 4 May 2021.\n- Kawa, Arkadiusz (2017). \"Fulfillment Service in E-Commerce Logistics\" (PDF). LogForum. 13 (4): 429–438. doi:10.17270/J.LOG.2017.4.4. eISSN 1734-459X. ISSN 1895-2038. Archived (PDF) from the original on 4 May 2021. Retrieved 4 May 2021.\n- Gomes, Alysson Cáceres; Junior, Francisco Bezerra de Lima; Soliani, Rodrigo Duarte; Oliveira, Pollyana Rufino de Souza; Oliveira, Dion Alves de; Siqueira, Reinaldo Maia; Nora, Leonardo Augusto Rodrigues da Silva; Macêdo, Jailson Juracy Souza de (10 May 2023). \"Logistics management in e-commerce: challenges and opportunities\". Revista de Gestão e Secretariado. 14 (5): 7252–7272. doi:10.7769/gesec.v14i5.2119. ISSN 2178-9010.\n- Sabanoglu, Tugba (26 March 2021). \"Retail e-commerce sales worldwide from 2014 to 2024\". Statista. Archived from the original on 22 November 2018. Retrieved 4 May 2021.\n- \"Electronic money and electronic commerce\". BBC News. Archived from the original on 4 May 2021. Retrieved 4 May 2021.\n- Dimoka, Angelika; Hong, Yili; Pavlou, Paul A. (June 2012). \"On Product Uncertainty in Online Markets: Theory and Evidence\" (PDF). Management Information Systems Quarterly. 36 (2): 395–426. doi:10.2307/41703461. JSTOR 41703461. S2CID 8963257. Archived from the original (PDF) on 6 January 2018. Retrieved 4 May 2021.\n- Marincas, Delia Adriana (2008). \"Information system for the supply chain management\". The AMFITEATRU ECONOMIC Journal. 10 (24): 236–253. Archived from the original on 18 May 2015. Retrieved 8 May 2015.\n- Terzi, Nuray (2011). \"The impact of e-commerce on international trade and employment\". Procedia - Social and Behavioral Sciences. 24: 745–753. doi:10.1016/j.sbspro.2011.09.010. hdl:11424/223579.\n- \"Consumers trump marketers in battle for purchasing influence\". Home Textiles Today. 13 May 2022. Archived from the original on 7 November 2022. Retrieved 7 November 2022.\n- \"Ecommerce Rating and Review Tools Market – A Comprehensive Study by Key Players\". The Daily Vale. 22 May 2022. Archived from the original on 3 November 2022. Retrieved 7 November 2022.\n- Evans, Richard (1 May 2002). \"E-commerce, Competitiveness and Local and Regional Governance in Greater Manchester and Merseyside: A Preliminary Assessment\". Urban Studies. 39 (5–6). SAGE Publishing: 947–975. Bibcode:2002UrbSt..39..947E. doi:10.1080/00420980220128390. JSTOR 43084757. S2CID 154155858.\n- Januszkiewicz, Monika (October 2017). \"Online Virtual Fit Is Not Yet Fit For Purpose: An Analysis of Fashion e-Commerce Interfaces\" (PDF). Proceedings of 3DBODY.TECH 2017: 210–217. doi:10.15221/17.210. ISBN 9783033064362. Archived (PDF) from the original on 22 July 2018. Retrieved 4 May 2021.\n- DePillis, Lynda (16 July 2019). \"Amazon's incredible, vanishing cardboard box\". CNN Business. Archived from the original on 16 July 2019. Retrieved 4 May 2021.\n- Newman, Jesse; Bunge, Jacob (2020). \"U.S. Postal Service Is Urged to Stop Delivering Mysterious Seeds\". The Wall Street Journal. Archived from the original on 20 September 2022. Retrieved 17 September 2022.\n- Barrabi, Thomas; Carter, Shawn M. (14 July 2017). \"Retail Apocalypse: Pier 1 and the other retailers closing, filing for bankruptcy\". Fox Business. Archived from the original on 12 August 2019. Retrieved 4 May 2021.\n- Forte, Daniela (11 March 2019). \"Store Closures, Failures Continue to Mount as Retailers Seek to Pivot Faster\". Multichannel Merchant. Access Intelligence, LLC. Archived from the original on 13 August 2019. Retrieved 4 May 2021.\n- \"The retail apocalypse is shutting down flagship stores\". USA Today. 1 August 2019. Archived from the original on 13 August 2019. Retrieved 12 August 2019.\n- Clement, J. (12 February 2021). \"Most popular online retail websites worldwide in 2020, by average monthly traffic\". Statista. Archived from the original on 21 May 2020. Retrieved 4 May 2021.\n- Song, Zhouying (January 2022). \"The geography of online shopping in China and its key drivers\". Environment and Planning B: Urban Analytics and City Science. 49 (1): 259–274. Bibcode:2022EnPlB..49..259S. doi:10.1177/23998083211002189. ISSN 2399-8083. S2CID 233623855. Archived from the original on 10 February 2023. Retrieved 15 April 2022.\n- Kuhuk, Jane (19 May 2020). \"COVID-19 shopping behavior: what products would customers rather buy online?\". Competera (Infographic). Archived from the original on 21 May 2020. Retrieved 4 May 2021.\n- Anam, Bhatti; Akram, Hamza; Basit, Hafiz Muhammad; Khan, Ahmed Usman; Naqvi, Syeda Mahwish Raza; Bilal, Muhammad (2020). \"E-commerce trends during COVID-19 Pandemic\" (PDF). International Journal of Future Generation Communication and Networking. 13 (2): 1449–1452. ISSN 2233-7857. Archived (PDF) from the original on 30 December 2020. Retrieved 4 May 2021.\n- Power, Michael 'Mike' (19 April 2013). \"Online highs are old as the net: the first e-commerce was a drugs deal\". The Guardian. Archived from the original on 30 November 2016. Retrieved 4 May 2021.\n- Tkacz, Ewaryst; Kapczynski, Adrian (2009). Internet – Technical Development and Applications. Springer Science+Business Media. p. 255. ISBN 9783642050190. Archived from the original on 4 May 2021. Retrieved 4 May 2021.\nThe first pilot system was installing in Tesco in the UK (first demonstrated in 1979 by Michael Aldrich).\n- Palmer, Colin (December 1988). \"Using IT for competitive advantage at Thomson holidays\". Long Range Planning. 21 (6): 26–29. doi:10.1016/0024-6301(88)90155-0. Archived from the original on 4 May 2021. Retrieved 4 May 2021 – via Elsevier Science Direct.\n- \"E Commerce\". StudyMode. 31 March 2013. Archived from the original on 5 August 2020. Retrieved 4 May 2021.\n- \"Piano Entrepreneurs\". Newspaper. Contra Costa Newspapers. Contra Costa Times. 11 February 1985.\n- \"In Tune With The Times - Piano Business Thrives in Slump\". Newspaper. Contra Costa Newspapers. The Daily Review. 26 June 1986.\n- \"Online shopping: The pensioner who pioneered a home shopping revolution\". BBC News. 16 September 2013. Archived from the original on 17 July 2018. Retrieved 21 June 2018.\n- Aldrich, Michael (March 2009). \"Finding Mrs Snowball\". Michael Aldrich Archive. Archived from the original on 7 December 2020. Retrieved 4 May 2021.\n- \"The Electronic Mall\". GS Brown. 30 April 2010. Archived from the original on 26 March 2016. Retrieved 4 May 2021.\n- Berners-Lee, Tim. \"The WorldWideWeb browser\". World Wide Web Consortium. Archived from the original on 1 May 2021. Retrieved 4 May 2021.\n- Geiger, Conrad (15 September 1992). \"NeXT Nugget News Digest\". NeXT. Archived from the original on 10 March 2016. Retrieved 4 May 2021.\n- Tayler, Jesse (11 April 2016). \"Jesse Tayler talks App Store and NeXTSTEP with AppStorey\". AppStorey. Archived from the original on 21 March 2018. Retrieved 4 May 2021.\n- \"PRESS RELEASE: AppWrapper Volume1 Issue 3 Ships\". Google Groups (Press Release). 28 September 1993. Archived from the original on 4 May 2021. Retrieved 4 May 2021.\n- Lewis, Peter H. (12 August 1994). \"Attention Shoppers: Internet Is Open\". The New York Times. Archived from the original on 3 September 2017. Retrieved 4 May 2021.\n- Kelly, Kevin (August 2005). \"We Are the Web\". Wired. Archived from the original on 24 August 2013. Retrieved 4 May 2021.\n- Bunnell, David (16 May 2001). \"The eBay Business Model\". The ebay Phenomenon: Business Secrets Behind the World's Hottest Internet Company. John Wiley & Sons. pp. 71–81. ISBN 9780471436799. Archived from the original on 4 May 2021. Retrieved 5 September 2019.\n- \"First Electronic Stamps Being Put to Test\". Sunday Business. 6 April 1998. p. 16. Archived from the original on 4 May 2021. Retrieved 4 May 2021.\n- \"eBay acquires PayPal\". eBay. 8 July 2002. Archived from the original on 6 October 2014. Retrieved 4 May 2021.\n- \"Diane Wang: Rounding up the \"Ant\" Heroes\". Sino Foreign Management. Archived from the original on 23 February 2012. Retrieved 3 September 2011.\n- Allemann, Andrew (26 July 2007). \"R.H. Donnelley Acquires Business.com for $345M\". Domain Name Wire. Brainstorm Labs, LLC. Archived from the original on 8 April 2021. Retrieved 4 May 2021.\n- Kodali, Sucharita (12 May 2014). \"US eCommerce Forecast: 2013 to 2018\". Forrester Research. Archived from the original on 23 January 2021. Retrieved 4 May 2021.\n- Garcia, Tonya (22 December 2015). \"Amazon will account for more than half of 2015 e-commerce growth, says Macquarie\". MarketWatch. Archived from the original on 28 January 2021. Retrieved 4 May 2021.\n- \"UPI crosses 2 billion transactions milestone in October, up 80% from year-ago; value nears Rs 4 lakh cr\". Financialexpress. November 2020. Archived from the original on 26 September 2022. Retrieved 24 March 2022.\n- \"India: number of BHIM transactions 2022\". Statista. Archived from the original on 24 March 2022. Retrieved 24 March 2022.\n- Mcnair, Corey (29 January 2018). \"Worldwide Retail and Ecommerce Sales: eMarketer's Updated Forecast and New Mcommerce Estimates for 2016—2021\". eMarketer. Insider Intelligence Inc. Archived from the original on 27 November 2018. Retrieved 4 May 2021.\n- \"Global e-Commerce sales surged to $29 trillion\" (Press Release). United Nations Conference on Trade and Development. 29 March 2019. Archived from the original on 2 May 2021. Retrieved 4 May 2021.\nFurther reading\n- Laudon, Kenneth C.; Traver, Carol Guercio (2014). E-commerce: Business, Technology, Society (10th ed.). Pearson plc. ISBN 9781292009094. Archived from the original on 5 May 2021. Retrieved 5 May 2021.\n- Chaudhury, Abijit; Kuilboer, Jean-Pierre (2002). E-business and E-commerce Infrastructure: Technologies Supporting the E-business Initiative. McGraw Hill Education. ISBN 9780071123136. Archived from the original on 5 May 2021. Retrieved 5 May 2021.\n- Frieden, Jonathan D.; Roche, Sean Patrick (2006). \"E-Commerce: Legal Issues of the Online Retailer in Virginia\" (PDF). Richmond Journal of Law and Technology. 13 (2). Archived (PDF) from the original on 22 September 2020. Retrieved 5 May 2021.\n- Graham, Mark (2008). \"Warped Geographies of Development: The Internet and Theories of Economic Development\" (PDF). Geography Compass. 2 (3). Blackwell publishing: 771–789. Bibcode:2008GComp...2..771G. doi:10.1111/j.1749-8198.2008.00093.x. S2CID 16190907. Archived from the original (PDF) on 26 November 2016. Retrieved 5 May 2021 – via Wiley Online Library.\n- Humeau, Philippe; Jung, Matthieu (21 June 2013). In depth benchmark of 12 ecommerce solutions (PDF). Archived (PDF) from the original on 5 May 2021. Retrieved 5 May 2021.\n- Kessler, Michelle (22 December 2003), More shoppers proceed to checkout online, archived from the original on 31 December 2020, retrieved 5 May 2021\n- Lowry, Paul Benjamin; Wells, Taylor Michael; Moody, Greg; Humpherys, Sean; Kettles, Degan (3 February 2006), Online Payment Gateways Used to Facilitate E-Commerce Transactions and Improve Risk Management, vol. 17 (published January 2006), pp. 1–48, SSRN 879797, archived from the original on 5 May 2021, retrieved 5 May 2021\n- Kotler, Philip (2009). Marketing Management (4th ed.). Upper Saddle River, New Jersey: Prentice Hall. ISBN 9780136026600. OCLC 1149204899. Retrieved 5 May 2021.\n- Miller, Roger LeRoy; Cross, Frank B. (2002). The Legal and E-Commerce Environment Today: Business in Its Ethical, Regulatory, and International Setting (3rd ed.). South-Western. ISBN 9780324061888. Archived from the original on 5 May 2021. Retrieved 5 May 2021.\n- Nissanoff, Daniel (2006). FutureShop: How the New Auction Culture Will Revolutionize the Way We Buy, Sell and Get the Things We Really Want. New York City: The Penguin Press. ISBN 978-1-59420-077-9. OCLC 1149173925. Retrieved 5 May 2021.\n- Seybold, Patricia B. (2001). The Customer Revolution (1st ed.). New York City: Crown Business. ISBN 978-0-609-60772-5. OCLC 1148801120. Retrieved 5 May 2021.\nExternal links\n- E-Commerce Resources, Small Business Administration, archived from the original on 21 May 2017",
    "electric power generation": "| Part of a series on |\n| Power engineering |\n|---|\n| Electric power conversion |\n| Electric power infrastructure |\n| Electric power systems components |\nElectricity generation is the process of generating electric power from sources of primary energy. For utilities in the electric power industry, it is the stage prior to its delivery (transmission, distribution, etc.) to end users or its storage, using for example, the pumped-storage method.\nConsumable electricity is not freely available in nature, so it must be \"produced\", transforming other forms of energy to electricity. Production is carried out in power stations, also called \"power plants\". Electricity is most often generated at a power plant by electromechanical generators, primarily driven by heat engines fueled by combustion or nuclear fission, but also by other means such as the kinetic energy of flowing water and wind. Other energy sources include solar photovoltaics and geothermal power. There are exotic and speculative methods to recover energy, such as proposed fusion reactor designs which aim to directly extract energy from intense magnetic fields generated by fast-moving charged particles generated by the fusion reaction (see magnetohydrodynamics).\nPhasing out coal-fired power stations and eventually gas-fired power stations,[1] or, if practical, capturing their greenhouse gas emissions, is an important part of the energy transformation required to limit climate change. Vastly more solar power[2] and wind power[3] is forecast to be required, with electricity demand increasing strongly[4] with further electrification of transport, homes and industry.[5] However, in 2023, it was reported that the global electricity supply was approaching peak CO2 emissions thanks to the growth of solar and wind power.[6]\nThe fundamental principles of electricity generation were discovered in the 1820s and early 1830s by British scientist Michael Faraday. His method, still used today, is for electricity to be generated by the movement of a loop of wire, or Faraday disc, between the poles of a magnet. Central power stations became economically practical with the development of alternating current (AC) power transmission, using power transformers to transmit power at high voltage and with low loss.\nCommercial electricity production started with the coupling of the dynamo to the hydraulic turbine. The mechanical production of electric power began the Second Industrial Revolution and made possible several inventions using electricity, with the major contributors being Thomas Alva Edison and Nikola Tesla. Previously the only way to produce electricity was by chemical reactions or using battery cells, and the only practical use of electricity was for the telegraph.\nElectricity generation at central power stations started in 1882, when a steam engine driving a dynamo at Pearl Street Station produced a DC current that powered public lighting on Pearl Street, New York. The new technology was quickly adopted by many cities around the world, which adapted their gas-fueled street lights to electric power. Soon after electric lights would be used in public buildings, in businesses, and to power public transport, such as trams and trains.\nThe first power plants used water power or coal.[7] Today a variety of energy sources are used, such as coal, nuclear, natural gas, hydroelectric, wind, and oil, as well as solar energy, tidal power, and geothermal sources.\nIn the 1880s the popularity of electricity grew massively with the introduction of the Incandescent light bulb. Although there are 22 recognised inventors of the light bulb prior to Joseph Swan and Thomas Edison, Edison and Swan's invention became by far the most successful and popular of all. During the early years of the 19th century, massive jumps in electrical sciences were made. And by the later 19th century the advancement of electrical technology and engineering led to electricity being part of everyday life. With the introduction of many electrical inventions and their implementation into everyday life, the demand for electricity within homes grew dramatically. With this increase in demand, the potential for profit was seen by many entrepreneurs who began investing into electrical systems to eventually create the first electricity public utilities. This process in history is often described as electrification.[8]\nThe earliest distribution of electricity came from companies operating independently of one another. A consumer would purchase electricity from a producer, and the producer would distribute it through their own power grid. As technology improved so did the productivity and efficiency of its generation. Inventions such as the steam turbine had a massive impact on the efficiency of electrical generation but also the economics of generation as well. This conversion of heat energy into mechanical work was similar to that of steam engines, however at a significantly larger scale and far more productively. The improvements of these large-scale generation plants were critical to the process of centralised generation as they would become vital to the entire power system that we now use today.\nThroughout the middle of the 20th century many utilities began merging their distribution networks due to economic and efficiency benefits. Along with the invention of long-distance power transmission, the coordination of power plants began to form. This system was then secured by regional system operators to ensure stability and reliability. The electrification of homes began in Northern Europe and in the Northern America in the 1920s in large cities and urban areas. It was not until the 1930s that rural areas saw the large-scale establishment of electrification.[9]\n- Coal 10,587 (34.4%)\n- Natural gas 6,796 (22.1%)\n- Hydro 4,417 (14.4%)\n- Nuclear 2,765 (8.99%)\n- Wind 2,497 (8.12%)\n- Solar 2,130 (6.92%)\n- Other 1,569 (5.10%)\nSeveral fundamental methods exist to convert other forms of energy into electrical energy. Utility-scale generation is achieved by rotating electric generators or by photovoltaic systems. A small proportion of electric power distributed by utilities is provided by batteries. Other forms of electricity generation used in niche applications include the triboelectric effect, the piezoelectric effect, the thermoelectric effect, and betavoltaics.\nElectric generators transform kinetic energy into electricity. This is the most used form for generating electricity based on Faraday's law. It can be seen experimentally by rotating a magnet within closed loops of conducting material, e.g. copper wire. Almost all commercial electrical generation uses electromagnetic induction, in which mechanical energy forces a generator to rotate.\nElectrochemistry is the direct transformation of chemical energy into electricity, as in a battery. Electrochemical electricity generation is important in portable and mobile applications. Currently, most electrochemical power comes from batteries.[11] Primary cells, such as the common zinc–carbon batteries, act as power sources directly, but secondary cells (i.e. rechargeable batteries) are used for storage systems rather than primary generation systems. Open electrochemical systems, known as fuel cells, can be used to extract power either from natural fuels or from synthesized fuels. Osmotic power is a possibility at places where salt and fresh water merge.\nThe photovoltaic effect is the transformation of light into electrical energy, as in solar cells. Photovoltaic panels convert sunlight directly to DC electricity. Power inverters can then convert that to AC electricity if needed. The photovoltaic industry has undergone spectacular growth since the 1990s.\nThe selection of electricity production modes and their economic viability varies in accordance with demand and region. The economics vary considerably around the world, resulting in widespread residential selling prices. Hydroelectric plants, nuclear power plants, thermal power plants and renewable sources have their own pros and cons, and selection is based upon the local power requirement and the fluctuations in demand.\nAll power grids have varying loads on them. The daily minimum[12] is the base load, often supplied by plants which run continuously. Nuclear, coal, oil, gas and some hydro plants can supply base load. If well construction costs for natural gas are below $10 per MWh, generating electricity from natural gas is cheaper than generating power by burning coal.[13]\nNuclear power plants can produce a huge amount of power from a single unit. However, nuclear disasters have raised concerns over the safety of nuclear power, and the capital cost of nuclear plants is very high. Hydroelectric power plants are located in areas where the potential energy from falling water can be harnessed for moving turbines and the generation of power. It may not be an economically viable single source of production where the ability to store the flow of water is limited and the load varies too much during the annual production cycle.\nElectric generators were known in simple forms from the discovery of electromagnetic induction in the 1830s. In general, some form of prime mover such as an engine or the turbines described above, drives a rotating magnetic field past stationary coils of wire thereby turning mechanical energy into electricity.[14] The only commercial scale forms of electricity production that do not employ a generator are photovoltaic solar and fuel cells.\nAlmost all commercial electrical power on Earth is generated with a turbine, driven by wind, water, steam or burning gas. The turbine drives a generator, thus transforming its mechanical energy into electrical energy by electromagnetic induction. There are many different methods of developing mechanical energy, including heat engines, hydro, wind and tidal power. Most electric generation is driven by heat engines.\nThe combustion of fossil fuels supplies most of the energy to these engines, with a significant fraction from nuclear fission and some from renewable sources. The modern steam turbine, invented by Sir Charles Parsons in 1884, currently generates about 80% of the electric power in the world using a variety of heat sources. Turbine types include:\n- Steam\n- Water is boiled by coal burned in a thermal power plant. About 41% of all electricity is generated this way.[15]\n- Nuclear fission heat created in a nuclear reactor creates steam. Less than 15% of electricity is generated this way.\n- Renewable energy. The steam is generated by biomass, solar thermal energy, or geothermal power.\n- Natural gas: turbines are driven directly by gases produced by combustion. Combined cycle are driven by both steam and natural gas. They generate power by burning natural gas in a gas turbine and use residual heat to generate steam. At least 20% of the world's electricity is generated by natural gas.\n- Water Energy is captured by a water turbine from the movement of water - from falling water, the rise and fall of tides or ocean thermal currents (see ocean thermal energy conversion). Currently, hydroelectric plants provide approximately 16% of the world's electricity.\n- The windmill was a very early wind turbine. In 2018 around 5% of the world's electricity was produced from wind\nTurbines can also use other heat-transfer liquids than steam. Supercritical carbon dioxide based cycles can provide higher conversion efficiency due to faster heat exchange, higher energy density and simpler power cycle infrastructure. Supercritical carbon dioxide blends, that are currently in development, can further increase efficiency by optimizing its critical pressure and temperature points.\nAlthough turbines are most common in commercial power generation, smaller generators can be powered by gasoline or diesel engines. These may used for backup generation or as a prime source of power within isolated villages.\nTotal world generation in 2024 was 30,850 TWh, including coal (34%), gas (22%), hydro (14%), nuclear (9%), wind (8%), solar (7%), oil and other fossil fuels (3%), biomass (2%).[16]\nVariations between countries generating electrical power affect concerns about the environment. In France only 10% of electricity is generated from fossil fuels, the US is higher at 70% and China is at 80%.[17] The cleanliness of electricity depends on its source. Methane leaks (from natural gas to fuel gas-fired power plants)[18] and carbon dioxide emissions from fossil fuel-based electricity generation account for a significant portion of world greenhouse gas emissions.[19] In the United States, fossil fuel combustion for electric power generation is responsible for 65% of all emissions of sulfur dioxide, the main component of acid rain.[20] Electricity generation is the fourth highest combined source of NOx, carbon monoxide, and particulate matter in the US.[21]\nAccording to the International Energy Agency (IEA), low-carbon electricity generation needs to account for 85% of global electrical output by 2040 in order to ward off the worst effects of climate change.[22] Like other organizations including the Energy Impact Center (EIC)[23] and the United Nations Economic Commission for Europe (UNECE),[24] the IEA has called for the expansion of nuclear and renewable energy to meet that objective.[25] Some, like EIC founder Bret Kugelmass, believe that nuclear power is the primary method for decarbonizing electricity generation because it can also power direct air capture that removes existing carbon emissions from the atmosphere.[26] Nuclear power plants can also create district heating and desalination projects, limiting carbon emissions and the need for expanded electrical output.[27]\nA fundamental issue regarding centralised generation and the current electrical generation methods in use today is the significant negative environmental effects that many of the generation processes have. Processes such as coal and gas not only release carbon dioxide as they combust, but their extraction from the ground also impacts the environment. Open pit coal mines use large areas of land to extract coal and limit the potential for productive land use after the excavation. Natural gas extraction releases large amounts of methane into the atmosphere when extracted from the ground, which greatly increases global greenhouse gases. Although nuclear power plants do not release carbon dioxide through electricity generation, there are risks associated with nuclear waste and safety concerns associated with the use of nuclear sources.\nPer unit of electricity generated coal and gas-fired power life-cycle greenhouse gas emissions are almost always at least ten times that of other generation methods.[28]\nCentralised generation is electricity generation by large-scale centralised facilities, sent through transmission lines to consumers. These facilities are usually located far away from consumers and distribute the electricity through high voltage transmission lines to a substation, where it is then distributed to consumers; the basic concept being that multi-megawatt or gigawatt scale large stations create electricity for a large number of people. The vast majority of electricity used is created from centralised generation. Most centralised power generation comes from large power plants run by fossil fuels such as coal or natural gas, though nuclear or large hydroelectricity plants are also commonly used.[29]\nCentralised generation is fundamentally the opposite of distributed generation. Distributed generation is the small-scale generation of electricity to smaller groups of consumers. This can also include independently producing electricity by either solar or wind power. In recent years distributed generation as has seen a spark in popularity due to its propensity to use renewable energy generation methods such as rooftop solar.[30]\nCentralised energy sources are large power plants that produce huge amounts of electricity to a large number of consumers. Most power plants used in centralised generation are thermal power plants meaning that they use a fuel to heat steam to produce a pressurised gas which in turn spins a turbine and generates electricity. This is the traditional way of producing energy. This process relies on several forms of technology to produce widespread electricity, these being natural coal, gas and nuclear forms of thermal generation. More recently solar and wind have become large scale.\nA photovoltaic power station, also known as a solar park, solar farm, or solar power plant, is a large-scale grid-connected photovoltaic power system (PV system) designed for the supply of merchant power. They are different from most building-mounted and other decentralized solar power because they supply power at the utility level, rather than to a local user or users. Utility-scale solar is sometimes used to describe this type of project.\nThis approach differs from concentrated solar power, the other major large-scale solar generation technology, which uses heat to drive a variety of conventional generator systems. Both approaches have their own advantages and disadvantages, but to date, for a variety of reasons, photovoltaic technology has seen much wider use. As of 2019[update], about 97% of utility-scale solar power capacity was PV.[31][32]\nIn some countries, the nameplate capacity of photovoltaic power stations is rated in megawatt-peak (MWp), which refers to the solar array's theoretical maximum DC power output. In other countries, the manufacturer states the surface and the efficiency. However, Canada, Japan, Spain, and the United States often specify using the converted lower nominal power output in MWAC, a measure more directly comparable to other forms of power generation. Most solar parks are developed at a scale of at least 1 MWp. As of 2018, the world's largest operating photovoltaic power stations surpassed 1 gigawatt. At the end of 2019, about 9,000 solar farms were larger than 4 MWAC (utility scale), with a combined capacity of over 220 GWAC.[31]\nMost of the existing large-scale photovoltaic power stations are owned and operated by independent power producers, but the involvement of community and utility-owned projects is increasing.[33] Previously, almost all were supported at least in part by regulatory incentives such as feed-in tariffs or tax credits, but as levelized costs fell significantly in the 2010s and grid parity has been reached in most markets, external incentives are usually not needed.Hydroelectricity is electricity generated from hydropower (water power). Hydropower supplies 15% of the world's electricity, almost 4,210 TWh in 2023, which is more than all other renewable sources combined and also more than nuclear power. Hydropower can provide large amounts of low-carbon electricity on demand, making it a key element for creating secure and clean electricity supply systems. A hydroelectric power station that has a dam and reservoir is a flexible source, since the amount of electricity produced can be increased or decreased in seconds or minutes in response to varying electricity demand.\nA wind farm, also called a wind park or wind power plant,[34] is a group of wind turbines in the same location used to produce electricity. Wind farms vary in size from a small number of turbines to several hundred wind turbines covering an extensive area. Wind farms can be either onshore or offshore.\nMany of the largest operational onshore wind farms are located in China, India, and the United States. For example, the largest wind farm in the world, Gansu Wind Farm in China had a capacity of over 6,000 MW by 2012,[35] with a goal of 20,000 MW[36] by 2020.[37] As of December 2020, the 1218 MW Hornsea Wind Farm in the UK is the largest offshore wind farm in the world.[38] Individual wind turbine designs continue to increase in power, resulting in fewer turbines being needed for the same total output.\nBecause they require no fuel, wind farms have less impact on the environment than many other forms of power generation and are often referred to as a good source of green energy. Wind farms have, however, been criticised for their visual impact and impact on the landscape. Typically they need to be spread over more land than other power stations and need to be built in wild and rural areas, which can lead to \"industrialization of the countryside\", habitat loss, and a drop in tourism. Some critics claim that wind farms have adverse health effects, but most researchers consider these claims to be pseudoscience (see wind turbine syndrome). Wind farms can interfere with radar, although in most cases, according to the US Department of Energy, \"siting and other mitigations have resolved conflicts and allowed wind projects to co-exist effectively with radar\".[39]A coal-fired power station or coal power plant is a thermal power station which burns coal to generate electricity. Worldwide there are about 2,500 coal-fired power stations,[40] on average capable of generating a gigawatt each.[41][a] They generate about a third of the world's electricity,[42] but cause many illnesses and the most early deaths per unit of energy produced,[43] mainly from air pollution.[44][45] World installed capacity doubled from 2000 to 2023 and increased 2% in 2023.[46]\nA coal-fired power station is a type of fossil fuel power station. The coal is usually pulverized and then burned in a pulverized coal-fired boiler. The furnace heat converts boiler water to steam, which is then used to spin turbines that turn generators. Thus chemical energy stored in coal is converted successively into thermal energy, mechanical energy and, finally, electrical energy.\nCoal-fired power stations are the largest single contributor to climate change,[47] releasing approximately 12 billion tonnes of carbon dioxide annually,[41] about one-fifth of global greenhouse gas emissions.[48] China accounts for over half of global coal-fired electricity generation.[49] While the total number of operational coal plants began declining in 2020,[50][51] due to retirements in Europe[52] and the Americas,[53] construction continues in Asia, primarily in China.[54] The profitability of some plants is maintained by externalities, as the health and environmental costs of coal production and use are not fully reflected in electricity prices.[55][56] However, newer plants face the risk of becoming stranded assets.[57] The UN Secretary General has called for OECD nations to phase out coal-fired generation by 2030, and the rest of the world by 2040.[58]Natural gas is ignited to create pressurised gas which is used to spin turbines to generate electricity. Natural gas plants use a gas turbine where natural gas is added along with oxygen which in turn combusts and expands through the turbine to force a generator to spin.\nNatural gas power plants are more efficient than coal power generation, they however contribute to climate change, but not as highly as coal generation. Not only do they produce carbon dioxide from the ignition of natural gas, the extraction of gas when mined releases a significant amount of methane into the atmosphere.[59]\nNuclear power plants create electricity through steam turbines where the heat input is from the process of nuclear fission. Currently, nuclear power produces 11% of all electricity in the world. Most nuclear reactors use uranium as a source of fuel. In a process called nuclear fission, energy, in the form of heat, is released when nuclear atoms are split. Electricity is created through the use of a nuclear reactor where heat produced by nuclear fission is used to produce steam which in turn spins turbines and powers the generators. Although there are several types of nuclear reactors, all fundamentally use this process.[60]\nNormal emissions due to nuclear power plants are primarily waste heat and radioactive spent fuel. In a reactor accident, significant amounts of radioisotopes can be released to the environment, posing a long term hazard to life. This hazard has been a continuing concern of environmentalists. Accidents such as the Three Mile Island accident, Chernobyl disaster and the Fukushima nuclear disaster illustrate this problem.[61]\nThe table lists 45 countries with their total electricity capacities. The data is from 2022. According to the Energy Information Administration, the total global electricity capacity in 2022 was nearly 8.9 terawatt (TW), more than four times the total global electricity capacity in 1981. The global average per-capita electricity capacity was about 1,120 watts in 2022, nearly two and a half times the global average per-capita electricity capacity in 1981.\nIceland has the highest installed capacity per capita in the world, at about 8,990 watts. All developed countries have an average per-capita electricity capacity above the global average per-capita electricity capacity, with the United Kingdom having the lowest average per-capita electricity capacity of all other developed countries.\n| Country | Total capacity (GW) |\nAverage per capita capacity (watts) |\n|---|---|---|\n| World | 8,890 | 1,120 |\n| China | 2,510 | 1,740 |\n| United States | 1,330 | 3,940 |\n| European Union | 1,080 | 2,420 |\n| India | 556 | 397 |\n| Japan | 370 | 2,940 |\n| Russia | 296 | 2,030 |\n| Germany | 267 | 3,220 |\n| Brazil | 222 | 1,030 |\n| Canada | 167 | 4,460 |\n| South Korea | 160 | 3,130 |\n| France | 148 | 2,280 |\n| Italy | 133 | 2,230 |\n| Spain | 119 | 2,580 |\n| United Kingdom | 111 | 1,640 |\n| Turkey | 107 | 1,240 |\n| Mexico | 104 | 792 |\n| Australia | 95.8 | 3,680 |\n| Saudi Arabia | 85.3 | 2,380 |\n| Iran | 83.3 | 977 |\n| Vietnam | 72.2 | 721 |\n| South Africa | 66.7 | 1,100 |\n| Poland | 64 | 1,690 |\n| Thailand | 63 | 901 |\n| Ukraine | 62.2 | 1,440 |\n| Egypt | 61.1 | 582 |\n| Taiwan | 58 | 2,440 |\n| Netherlands | 53.3 | 3,010 |\n| Sweden | 52.1 | 5,100 |\n| Argentina | 51.9 | 1,130 |\n| Pakistan | 42.7 | 192 |\n| Norway | 41.7 | 7,530 |\n| United Arab Emirates | 40.7 | 4,010 |\n| Malaysia | 37.9 | 1,110 |\n| Chile | 37 | 1,930 |\n| Venezuela | 34.1 | 1,210 |\n| Kazakhstan | 29.6 | 1,600 |\n| Switzerland | 27.8 | 2,960 |\n| Austria | 26.7 | 2,890 |\n| Algeria | 25.9 | 590 |\n| Greece | 24.4 | 2,400 |\n| Israel | 23.7 | 2,520 |\n| Finland | 22.2 | 3,980 |\n| Denmark | 21.3 | 3,710 |\n| Ireland | 13.3 | 2,420 |\n| New Zealand | 11.6 | 2,320 |\n| Iceland | 3.24 | 8,990 |\n- Glossary of power generation\n- Cogeneration: the use of a heat engine or power station to generate electricity and useful heat at the same time.\n- Cost of electricity by source\n- Diesel generator\n- Engine–generator\n- Generation expansion planning\n- Steam–electric power station\n- World energy supply and consumption\n- Chestney, Nina (May 14, 2021). \"Factbox: Getting out of gas - the sold and scrapped projects\". Reuters. Archived from the original on November 27, 2021. Retrieved November 27, 2021.\n- \"Solar PV – Analysis\". IEA. Archived from the original on November 27, 2021. Retrieved November 27, 2021.\n- \"What would a world powered entirely by offshore wind look like?\". The Economist. November 4, 2021. ISSN 0013-0613. Archived from the original on November 26, 2021. Retrieved November 27, 2021.\n- \"Electricity – Global Energy Review 2021 – Analysis\". IEA. April 2021. Archived from the original on November 27, 2021. Retrieved November 27, 2021.\n- Shadbolt, Rory (November 26, 2021). \"Accelerated renewables-based electrification for the future\". SelectScience. Archived from the original on November 27, 2021. Retrieved November 27, 2021.\n- Lempriere, Molly (October 4, 2023). \"World's electricity supply close to 'peak emissions' due to growth of wind and solar\". Carbon Brief. Retrieved November 8, 2023.\n- \"Pearl Street Station - Engineering and Technology History Wiki\". ethw.org. Archived from the original on August 26, 2016. Retrieved August 14, 2016.\n- \"History of Electrification Sites\". edisontechcenter.org. Archived from the original on May 25, 2019. Retrieved June 8, 2019.\n- \"Power Grid History\". www.itc-holdings.com. Archived from the original on June 8, 2019. Retrieved June 8, 2019.\n- \"Yearly electricity data\". ember-energy.org. April 21, 2025. Retrieved April 21, 2025.\n- World's Largest Utility Battery System Installed in Alaska Archived 2008-06-27 at the Wayback Machine (press release, 2003-09-24), U.S. Department of Energy. \"13,670 nickel-cadmium battery cells to generate up to 40 megawatts of power for about 7 minutes, or 27 megawatts of power for 15 minutes.\"\n- \"Baseload power - Energy Education\". energyeducation.ca. Retrieved September 17, 2025.\n- Smith, Karl (March 22, 2013). \"Will Natural Gas Stay Cheap Enough To Replace Coal And Lower Us Carbon Emissions\". Forbes. Archived from the original on November 2, 2017. Retrieved June 20, 2015.\n- Sedlazeck, K.; Richter, C.; Strack, S.; Lindholm, S.; Pipkin, J.; Fu, F.; Humphries, B.; Montgomery, L. (May 1, 2009). \"Type testing a 2000 MW turbogenerator\". 2009 IEEE International Electric Machines and Drives Conference. pp. 465–470. doi:10.1109/IEMDC.2009.5075247. ISBN 978-1-4244-4251-5. S2CID 9118902 – via IEEE Xplore.\n- \"Coal & electricity\". World Coal Association. April 29, 2015. Archived from the original on August 23, 2016. Retrieved August 14, 2016.\n- \"Yearly electricity data\". ember-climate.org. December 6, 2023. Retrieved December 23, 2023.\n- \"Statistics and Balances\". IEA. Archived from the original on May 15, 2011. Retrieved July 12, 2011.\n- Patrick Pester (February 10, 2022). \"Massive methane leaks mapped from space\". Live Science. Archived from the original on June 29, 2022. Retrieved June 29, 2022.\n- Borenstein, Seth (June 3, 2007). \"Carbon-emissions culprit? Coal\". The Seattle Times. Archived from the original on April 24, 2011.\n- \"Sulfur Dioxide\". US Environmental Protection Agency. November 16, 2016. Archived from the original on August 14, 2015. Retrieved April 23, 2010.\n- \"AirData\". US Environmental Protection Agency. Archived from the original on September 24, 2015. Retrieved April 21, 2010.\n- Johnson, Jeff (September 23, 2019). \"Can nuclear power help save us from climate change?\". Chemical & Engineering News. Archived from the original on November 22, 2021. Retrieved November 23, 2021.\n- Takahashi, Dean (February 25, 2020). \"Last Energy raises $3 million to fight climate change with nuclear energy\". VentureBeat. Archived from the original on January 12, 2021. Retrieved November 23, 2021.\n- \"Global climate objectives fall short without nuclear power in the mix: UNECE\". United Nations Economic Commission for Europe. August 11, 2021. Archived from the original on November 22, 2021. Retrieved November 23, 2021.\n- Chestney, Nina (May 18, 2021). \"End new oil, gas and coal funding to reach net zero, says IEA\". Reuters. Archived from the original on November 17, 2021. Retrieved November 23, 2021.\n- Kugelmass, Bret (January 22, 2020). \"Want to stop climate change? Embrace the nuclear option\". USA Today. Archived from the original on November 28, 2020. Retrieved November 23, 2021.\n- Patel, Sonal (November 1, 2021). \"How an AP1000 Plant Is Changing the Nuclear Power Paradigm Through District Heating, Desalination\". Power Magazine. Archived from the original on June 3, 2022. Retrieved November 23, 2021.\n- Scarlat, Nicolae; Prussi, Matteo; Padella, Monica (January 1, 2022). \"Quantification of the carbon intensity of electricity produced and used in Europe\". Applied Energy. 305 117901. Bibcode:2022ApEn..30517901S. doi:10.1016/j.apenergy.2021.117901. ISSN 0306-2619. S2CID 244177261.\n- \"Centralized Generation of Electricity and its Impacts on the Environment\". US EPA. August 4, 2015. Archived from the original on May 19, 2019. Retrieved May 21, 2019.\n- Joshi, Siddharth; Mittal, Shivika; Holloway, Paul; Shukla, Priyadarshi Ramprasad; Ó Gallachóir, Brian; Glynn, James (October 5, 2021). \"High resolution global spatiotemporal assessment of rooftop solar photovoltaics potential for renewable electricity generation\". Nature Communications. 12 (1): 5738. Bibcode:2021NatCo..12.5738J. doi:10.1038/s41467-021-25720-2. ISSN 2041-1723. PMC 8492708. PMID 34611151.\n- Wolfe, Philip (March 17, 2020). \"Utility-scale solar sets new record\" (PDF). Wiki-Solar. Retrieved May 11, 2010.\n- \"Concentrated solar power had a global total installed capacity of 6,451 MW in 2019\". HelioCSP. February 2, 2020. Retrieved May 11, 2020.\n- \"Expanding Renewable Energy in Pakistan's Electricity Mix\". World Bank. Retrieved July 17, 2022.\n- Robert Gasch, Jochen Twele (editors). Wind Power Plants: Fundamentals, Design, Construction and Operation. Springer, 2011. p. 11.\n- Watts, Jonathan & Huang, Cecily. Winds Of Change Blow Through China As Spending On Renewable Energy Soars, The Guardian, 19 March 2012, revised on 20 March 2012. Retrieved 4 January 2012.\n- Fahey, Jonathan. In Pictures: The World's Biggest Green Energy Projects, Forbes, 9 January 2010. Retrieved 19 June 2019.\n- Kanter, Doug (April 20, 2016). \"Gansu Wind Farm – The World's Biggest Wind Farms\". Forbes. Retrieved June 3, 2024.\n- \"World's largest offshore wind farm fully up and running\". offshorewind.biz. January 30, 2020. Retrieved December 27, 2020.\n- \"WINDExchange: Wind Turbine Radar Interference\". WINDExchange. Retrieved June 19, 2019.\n- \"Coal burning capacity climbs worldwide despite pledges to reduce use\". PBS News. April 6, 2023. Retrieved November 16, 2024.\n- \"What would it cost to kill coal?\". The Economist. ISSN 0013-0613. Retrieved November 16, 2024.\nCumulative emissions from coal since 1882 amount to 800bn tonnes, the single biggest factor driving the warming that makes today's world about 1.2°C warmer than that of 1882. Most of that coal has been burned to produce electricity. Today's plants are producing about 12bn tonnes a year.\n- Birol, Fatih; Malpass, David (October 8, 2021). \"It's critical to tackle coal emissions – Analysis\". International Energy Agency. Retrieved October 9, 2021.\n- \"How safe is nuclear energy?\". The Economist. ISSN 0013-0613. Retrieved December 26, 2022.\n- Cropper, Maureen; Cui, Ryna; Guttikunda, Sarath; Hultman, Nate; Jawahar, Puja; Park, Yongjoon; Yao, Xinlu; Song, Xiao-Peng (February 2, 2021). \"The mortality impacts of current and planned coal-fired power plants in India\". Proceedings of the National Academy of Sciences. 118 (5). Bibcode:2021PNAS..11817936C. doi:10.1073/pnas.2017936118. ISSN 0027-8424. PMC 7865184. PMID 33495332.\n- \"Killed by coal: Air pollution deaths in Jakarta 'may double' by 2030\". The Jakarta Post. Retrieved April 8, 2022.\n- Boom and Bust Coal 2024 (PDF) (Report). San Francisco, California: Global Energy Monitor. April 2024. p. 7, 21. Retrieved April 11, 2024.\n2% annual increase in the global operating coal fleet, which currently stands at 2,130 GW […] Figure 16: Global coal power capacity continues steady growth despite Paris Agreement, with a 2% uptick in 2023\n- \"It's critical to tackle coal emissions – Analysis\". International Energy Agency. October 8, 2021. Retrieved October 9, 2021.\nCoal power plants produce a fifth of global greenhouse gas emissions – more than any other single source.\n- \"Country Inventory\". Climate TRACE. Retrieved November 16, 2024.\n- \"China generated over half world's coal-fired power in 2020: study\". Reuters. March 28, 2021. Retrieved September 14, 2021.\nChina generated 53% of the world's total coal-fired power in 2020, nine percentage points more that five years earlier\n- Morton, Adam (August 3, 2020). \"More coal power generation closed than opened around the world this year, research finds\". The Guardian. ISSN 0261-3077. Retrieved August 4, 2020.\n- \"The dirtiest fossil fuel is on the back foot\". The Economist. December 3, 2020. ISSN 0013-0613. Retrieved December 12, 2020.\n- Piven, Ben. \"EU power sector emissions drop as coal collapses across Europe\". Al Jazeera. Retrieved March 21, 2020.\n- Roberts, David (March 14, 2020). \"4 astonishing signs of coal's declining economic viability\". Vox. Retrieved March 21, 2020.\n- \"China pledges to stop building new coal energy plants abroad\". BBC News. September 22, 2021. Retrieved September 22, 2021.\n- Borenstein, Severin; Bushnell, James B. (November 1, 2022). \"Do Two Electricity Pricing Wrongs Make a Right? Cost Recovery, Externalities, and Efficiency\" (PDF). American Economic Journal: Economic Policy. 14 (4): 80–110. doi:10.1257/pol.20190758. Retrieved November 11, 2022.\n- Davis, Lucas (September 21, 2020). \"Time to Vote Out Coal\". Energy Institute Blog. Retrieved September 27, 2020.\n- Harrabin, Roger (March 12, 2020). \"Coal power developers 'risk wasting billions'. BBC News.\n- \"The dirtiest fossil fuel is on the back foot\". The Economist. December 3, 2020. ISSN 0013-0613.\n- \"Natural gas power plant\". Energy Education. Archived from the original on June 8, 2019. Retrieved June 8, 2019.\n- \"Nuclear power\". Energy Education. Archived from the original on June 8, 2019. Retrieved June 8, 2019.\n- \"Nuclear Power and the Environment – Energy Explained\". Energy Information Administration. Archived from the original on May 27, 2019. Retrieved June 8, 2019.",
    "electrical industry": "The electric power industry covers the generation, transmission, distribution and sale of electric power to the general public and industry. The commercial distribution of electric power started in 1882 when electricity was produced for electric lighting. In the 1880s and 1890s, growing economic and safety concerns lead to the regulation of the industry. What was once an expensive novelty limited to the most densely populated areas, reliable and economical electric power has become an essential aspect for normal operation of all elements of developed economies.\nBy the middle of the 20th century, electricity was seen as a \"natural monopoly\", only efficient if a restricted number of organizations participated in the market; in some areas, vertically integrated companies provide all stages from generation to retail, and only governmental supervision regulated the rate of return and cost structure.\nSince the 1990s, many regions have broken up the generation and distribution of electric power[citation needed]. While such markets can be abusively manipulated with consequent adverse price and reliability impact to consumers, generally competitive production of electrical energy leads to worthwhile improvements in efficiency[citation needed]. However, transmission and distribution are harder problems since returns on investment are not as easy to find.\nAlthough electricity had been known to be produced as a result of the chemical reactions that take place in an electrolytic cell since Alessandro Volta developed the voltaic pile in 1800, its production by this means was, and still is, expensive. In 1831, Michael Faraday devised a machine that generated electricity from rotary motion, but it took almost 50 years for the technology to reach a commercially viable stage. In 1878, in the United States, Thomas Edison developed and sold a commercially viable replacement for gas lighting and heating using locally generated and distributed direct current electricity.\nRobert Hammond, in December 1881, demonstrated the new electric light in the Sussex town of Brighton in the UK for a trial period. The ensuing success of this installation enabled Hammond to put this venture on both a commercial and legal footing, as a number of shop owners wanted to use the new electric light. Thus the Hammond Electricity Supply Co. was launched.\nIn early 1882, Edison opened the world's first steam-powered electricity generating station at Holborn Viaduct in London, where he had entered into an agreement with the City Corporation for a period of three months to provide street lighting. In time he had supplied a number of local consumers with electric light. The method of supply was direct current (DC). Whilst the Godalming and the 1882 Holborn Viaduct Scheme closed after a few years the Brighton Scheme continued on, and supply was in 1887 made available for 24 hours per day.\nIt was later on in the year in September 1882 that Edison opened the Pearl Street Power Station in New York City and again it was a DC supply. It was for this reason that the generation was close to or on the consumer's premises as Edison had no means of voltage conversion. The voltage chosen for any electrical system is a compromise. For a given amount of power transmitted, increasing the voltage reduces the current and therefore reduces the required wire thickness. Unfortunately it also increases the danger from direct contact and increases the required insulation thickness. Furthermore, some load types were difficult or impossible to make work with higher voltages. The overall effect was that Edison's system required power stations to be within a mile of the consumers. While this could work in city centres, it would be unable to economically supply suburbs with power.[1]\nThe mid to late 1880s saw the introduction of alternating current (AC) systems in Europe and the U.S. AC power had an advantage in that transformers, installed at power stations, could be used to raise the voltage from the generators, and transformers at local substations could reduce voltage to supply loads. Increasing the voltage reduced the current in the transmission and distribution lines and hence the size of conductors and distribution losses. This made it more economical to distribute power over long distances. Generators (such as hydroelectric sites) could be located far from the loads. AC and DC competed for a while, during a period called the war of the currents. The DC system was able to claim slightly greater safety, but this difference was not great enough to overwhelm the enormous technical and economic advantages of alternating current which eventually won out.[1]\nThe AC power system used today developed rapidly, backed by industrialists such as George Westinghouse with Mikhail Dolivo-Dobrovolsky, Galileo Ferraris, Sebastian Ziani de Ferranti, Lucien Gaulard, John Dixon Gibbs, Carl Wilhelm Siemens, William Stanley Jr., Nikola Tesla, and others contributed to this field.\nPower electronics is the application of solid-state electronics to the control and conversion of electric power. Power electronics started with the development of the mercury arc rectifier in 1902, used to convert AC into DC. From the 1920s on, research continued on applying thyratrons and grid-controlled mercury arc valves to power transmission. Grading electrodes made them suitable for high voltage direct current (HVDC) power transmission. In 1933, selenium rectifiers were invented.[2] Transistor technology dates back to 1947, with the invention of the point-contact transistor, which was followed by the bipolar junction transistor (BJT) in 1948. By the 1950s, higher power semiconductor diodes became available and started replacing vacuum tubes. In 1956, the silicon controlled rectifier (SCR) was introduced, increasing the range of power electronic applications.[3]\nA breakthrough in power electronics came with the invention of the MOSFET (metal-oxide-semiconductor field-effect transistor) in 1959. Generations of MOSFETs enabled power designers to achieve performance and density levels not possible with bipolar transistors.[4] In 1969, Hitachi introduced the first vertical power MOSFET,[5] which would later be known as the VMOS (V-groove MOSFET).[6] The power MOSFET has since become the most common power device in the world, due to its low gate drive power, fast switching speed,[7] easy advanced paralleling capability,[7][8] wide bandwidth, ruggedness, easy drive, simple biasing, ease of application, and ease of repair.[8]\nWhile HVDC is increasingly being used to transmit large quantities of electricity over long distances or to connect adjacent asynchronous power systems, the bulk of electricity generation, transmission, distribution and retailing takes place using alternating current.\nThe electric power industry is commonly split up into four processes. These are electricity generation such as a power station, electric power transmission, electricity distribution and electricity retailing. In many countries, electric power companies own the whole infrastructure from generating stations to transmission and distribution infrastructure. For this reason, electric power is viewed as a natural monopoly. The industry is generally heavily regulated, often with price controls and is frequently government-owned and operated. However, the modern trend has been growing deregulation in at least the latter two processes.[9]\nThe nature and state of market reform of the electricity market often determines whether electric companies are able to be involved in just some of these processes without having to own the entire infrastructure, or citizens choose which components of infrastructure to patronise. In countries where electricity provision is deregulated, end-users of electricity may opt for more costly green electricity.\n- Coal 10,587 (34.4%)\n- Natural gas 6,796 (22.1%)\n- Hydro 4,417 (14.4%)\n- Nuclear 2,765 (8.99%)\n- Wind 2,497 (8.12%)\n- Solar 2,130 (6.92%)\n- Other 1,569 (5.10%)\nGeneration is the conversion of some primary energy source into electric power suitable for commercial use on an electrical grid. Most commercial electric power is produced by rotating electrical machines, \"generators\", which move conductors through a magnetic field to produce electric current. The generator is rotated by some other prime mover machine; in typical grid-connected generators this is a steam turbine, a gas turbine, or a hydraulic turbine. Primary energy sources for these machine are often fossil fuels (coal, oil, natural gas), nuclear fission, geothermal steam, or falling water. Renewable sources such as wind and solar energy are increasingly of commercial importance.\nSince electrical generation must be closely matched with electrical consumption, enough generation capacity must be installed to meet peak demands. At the same time, primary energy sources must be selected to minimize the cost of produced electrical energy. Generally the lowest-incremental-cost source of electrical energy will be the next unit connected to meet rising demand. Electrical generators have automatic controls to regulate the power fed into the electrical transmission system, adjusting generator output moment by moment to balance with electrical demand. For a large grid with scores or hundreds of generators connected and thousands of loads, management of stable generator supply is a problem with significant challenges, to meet economic, environmental and reliability requirements. For example, low-incremental-cost generation sources such as nuclear power plants may be run continually to meet the average \"base load\" of the connected system, whereas more costly peaking power plants such as natural gas turbines may be run for brief times during the day to meet peak loads. Alternatively, load management strategies may encourage more even demand for electrical power and reduce costly peaks. Designated generator units for a particular electrical grid may be run at partial output only, to provide \"spinning reserve\" for sudden increases in demand or faults with other generating units.\nIn addition to electrical power production, electrical generation units may provide other ancillary services to the electrical grid, such as frequency control, reactive power, and black start of a collapsed power grid. These ancillary services may be commercially valuable when the generation, transmission, and distribution electrical companies are separate commercial entities.\nElectric power transmission is the bulk movement of electrical energy from a generating site, such as a power plant, to an electrical substation. The interconnected lines which facilitate this movement are known as a transmission network. This is distinct from the local wiring between high-voltage substations and customers, which is typically referred to as electric power distribution. The combined transmission and distribution network is known as the \"power grid\" in North America, or just \"the grid\". In the United Kingdom, India, Malaysia and New Zealand, the network is known as the National Grid.\nA wide area synchronous grid, also known as an \"interconnection\" in North America, directly connects many generators delivering AC power with the same relative frequency numerous consumers. For example, there are four major interconnections in North America (the Western Interconnection, the Eastern Interconnection, the Quebec Interconnection and the Electric Reliability Council of Texas (ERCOT) grid). In Europe one large grid connects most of continental Europe.\nHistorically, transmission and distribution lines were owned by the same company, but starting in the 1990s, many countries have liberalized the regulation of the electricity market in ways that have led to the separation of the electricity transmission business from the distribution business.[11]\nElectric power distribution is the final stage in the delivery of electric power; it carries electricity from the transmission system to individual consumers. Distribution substations connect to the transmission system and lower the transmission voltage to medium voltage ranging between 2 kV and 35 kV with the use of transformers.[12] Primary distribution lines carry this medium voltage power to distribution transformers located near the customer's premises. Distribution transformers again lower the voltage to the utilization voltage used by lighting, industrial equipment or household appliances. Often several customers are supplied from one transformer through secondary distribution lines. Commercial and residential customers are connected to the secondary distribution lines through service drops. Customers demanding a much larger amount of power may be connected directly to the primary distribution level or the subtransmission level.[13]\nElectricity retailing is the final sale of electricity from generation to the end-use consumer.\nThe organization of the electrical sector of a country or region varies depending on the economic system of the country. In some places, all electric power generation, transmission and distribution is provided by a government controlled organization. Other regions have private or investor-owned utility companies, city or municipally owned companies, cooperative companies owned by their own customers, or combinations. Generation, transmission and distribution may be offered by a single company, or different organizations may provide each of these portions of the system.\nNot everyone has access to grid electricity. About 840 million people (mostly in Africa) had no access in 2017, down from 1.2 billion in 2010.[14]\nThe business model behind the electric utility has changed over the years playing a vital role in shaping the electricity industry into what it is today; from generation, transmission, distribution, to the final local retailing. This has occurred prominently since the reform of the electricity supply industry in England and Wales in 1990.\nIn 1996 – 1999 the Federal Energy Regulatory Commission (FERC) made a series of decisions which were intended to open the U.S. wholesale power market to new players, with the hope that spurring competition would save consumers $4 to $5 billion per year and encourage technical innovation in the industry.[15] Steps were taken to give all market participants open access to existing interstate transmission lines.\n- Order No. 888 ordered vertically integrated electric utilities to functionally separate their transmission, power generation and marketing businesses to prevent self-dealing.[16]\n- Order No. 889 set up a system to provide all participants with timely access to information about available transmission capacity and prices.[17]\n- The FERC also endorsed the concept of appointing independent system operators (ISOs) to manage the electric power grid – a function that was traditionally the responsibility of vertically integrated electric utility companies.[18] The concept of an independent system operator evolved into that of regional transmission organizations (RTOs). FERC's intention was that all U.S. companies owning interstate electric transmission lines would place those facilities under the control of an RTO.[19] In its Order No. 2000 (Regional Transmission Organizations), issued in 1999, FERC specified the minimum capabilities that an RTO should possess.[20]\nThese decisions, which were intended to create a fully interconnected grid and an integrated national power market, resulted in the restructuring of the U.S. electricity industry. That process was soon dealt two setbacks: the California energy crisis of 2000, and the Enron scandal and collapse. Although industry restructuring proceeded, these events made clear that competitive markets could be manipulated and thus must be properly designed and monitored. Furthermore, the Northeast blackout of 2003 highlighted the need for a dual focus on competitive pricing and strong reliability standards.[21]\nIn some countries, wholesale electricity markets operate, with generators and retailers trading electricity in a similar manner to shares and currency. As deregulation continues further, utilities are driven to sell their assets as the energy market follows in line with the gas market in use of the futures and spot markets and other financial arrangements. Even globalization with foreign purchases are taking place. One such purchase was when the UK's National Grid, the largest private electric utility in the world, bought several electric utilities in New England for $3.2 billion.[22] Between 1995 and 1997, seven of the 12 Regional Electric Companies (RECs) in England and Wales were bought by U.S. energy companies.[23] Domestically, local electric and gas firms have merged operations as they saw the advantages of joint affiliation, especially with the reduced cost of joint-metering. Technological advances will take place in the competitive wholesale electric markets, such examples already being utilized include fuel cells used in space flight; aeroderivative gas turbines used in jet aircraft; solar engineering and photovoltaic systems; off-shore wind farms; and the communication advances spawned by the digital world, particularly with microprocessing which aids in monitoring and dispatching.[24]\nElectricity is expected to see growing demand in the future. The Information Revolution is highly reliant on electric power. Other growth areas include emerging new electricity-exclusive technologies, developments in space conditioning, industrial processes, and transportation (for example hybrid vehicles, locomotives).[24]\n- AC power\n- Distributed generation\n- Emissions & Generation Resource Integrated Database\n- Meter Point Administration Number, a unique UK supply number\n- National Grid (disambiguation)\n- North American Electric Reliability Corporation\n- Rate Case\n- Reddy Kilowatt, a U.S. electricity corporate logo\n- Samuel Insull\n- Shock and Awe: The Story of Electricity – 2. The Age of Invention\n- Thompson, M.T. \"Notes 01\" (PDF). Introduction to Power Electronics. Thompson Consulting, Inc.\n- Kharagpur. \"Power Semiconductor Devices\" (PDF). EE IIT. Archived (PDF) from the original on 20 September 2008. Retrieved 25 March 2012.\n- \"Rethink Power Density with GaN\". Electronic Design. 21 April 2017. Retrieved 23 July 2019.\n- Oxner, E. S. (1988). Fet Technology and Application. CRC Press. p. 18. ISBN 9780824780500.\n- \"Advances in Discrete Semiconductors March On\". Power Electronics Technology. Informa: 52–6. September 2005. Archived (PDF) from the original on 22 March 2006. Retrieved 31 July 2019.\n- \"Power MOSFET Basics\" (PDF). Alpha & Omega Semiconductor. Retrieved 29 July 2019.\n- Duncan, Ben (1996). High Performance Audio Power Amplifiers. Elsevier. pp. 178–81. ISBN 9780080508047.\n- \"The Bumpy Road to Energy Deregulation\". EnPowered. 2016-03-28. Archived from the original on 2017-04-07. Retrieved 2017-05-01.\n- \"Yearly electricity data\". ember-energy.org. 21 April 2025. Retrieved 21 April 2025.\n- \"A Primer on Electric Utilities, Deregulation, and Restructuring of U.S. Electricity Markets\" (PDF). United States Department of Energy. United States Department of Energy Federal Energy Management Program (FEMP). May 2002. Retrieved October 30, 2018.\n- Short, T.A. (2014). Electric Power Distribution Handbook. Boca Raton, Florida, USA: CRC Press. pp. 1–33. ISBN 978-1-4665-9865-2.\n- \"How Power Grids Work\". HowStuffWorks. Retrieved 2016-03-18.\n- Closing Sub-Saharan Africa’s Electricity Access Gap: Why Cities Must Be Part of the Solution\n- Tomain, Joseph and Cudahy, Richard (2004). Energy Law in a Nutshell. Thomson-West Group. p. 277. ISBN 9780314150585.\n{{cite book}}\n: CS1 maint: multiple names: authors list (link) - Tomain and Cudahy op cit. pp. 276–277.\n- Tomain and Cudahy op cit. p. 277.\n- Tomain, Joseph and Cudahy, Richard (2004). Energy Law in a Nutshell. Thomson – West Group. ISBN 9780314150585.\n{{cite book}}\n: CS1 maint: multiple names: authors list (link) - \"Order No. 2000\" (PDF). Federal Energy Regulatory Commission. Retrieved 7 June 2021.\n- \"U.S. Energy Law: Electricity (About Regional Transmission Organizations)\". George Washington University Law Library.\n- Tomain and Cudahy op cit. pp. 285–297.\n- SEC filing dated March 15, 2000\n- \"Electricity companies in the United Kingdom – a brief chronology,\" Electricity Association, 30 June 2003\n- Borberly, A. and Kreider, J. F. (2001). Distributed Generation: The Power Paradigm for the New Millennium. CRC Press, Boca Raton, FL. 400 pp.\n- P. Strange, \"Early Electricity Supply in Britain: Chesterfield and Godalming\", IEEE Proceedings (1979).\n- D. G. Tucker, \"Hydro-Electricity for Public Supply in Britain\", Industrial Archaeology Review, (1977).\n- B. Bowers, A History of Electric Light & Power, Peregrinus (1982).\n- T. P. Hughes, Networks of Power, Johns Hopkins Press London (1983).\n- IRENA, INNOVATION LANDSCAPE FOR A RENEWABLE-POWERED FUTURE: SOLUTIONS TO INTEGRATE VARIABLE RENEWABLES Archived 2021-01-24 at the Wayback Machine, (2019).",
    "electricity generation": "| Part of a series on |\n| Power engineering |\n|---|\n| Electric power conversion |\n| Electric power infrastructure |\n| Electric power systems components |\nElectricity generation is the process of generating electric power from sources of primary energy. For utilities in the electric power industry, it is the stage prior to its delivery (transmission, distribution, etc.) to end users or its storage, using for example, the pumped-storage method.\nConsumable electricity is not freely available in nature, so it must be \"produced\", transforming other forms of energy to electricity. Production is carried out in power stations, also called \"power plants\". Electricity is most often generated at a power plant by electromechanical generators, primarily driven by heat engines fueled by combustion or nuclear fission, but also by other means such as the kinetic energy of flowing water and wind. Other energy sources include solar photovoltaics and geothermal power. There are exotic and speculative methods to recover energy, such as proposed fusion reactor designs which aim to directly extract energy from intense magnetic fields generated by fast-moving charged particles generated by the fusion reaction (see magnetohydrodynamics).\nPhasing out coal-fired power stations and eventually gas-fired power stations,[1] or, if practical, capturing their greenhouse gas emissions, is an important part of the energy transformation required to limit climate change. Vastly more solar power[2] and wind power[3] is forecast to be required, with electricity demand increasing strongly[4] with further electrification of transport, homes and industry.[5] However, in 2023, it was reported that the global electricity supply was approaching peak CO2 emissions thanks to the growth of solar and wind power.[6]\nThe fundamental principles of electricity generation were discovered in the 1820s and early 1830s by British scientist Michael Faraday. His method, still used today, is for electricity to be generated by the movement of a loop of wire, or Faraday disc, between the poles of a magnet. Central power stations became economically practical with the development of alternating current (AC) power transmission, using power transformers to transmit power at high voltage and with low loss.\nCommercial electricity production started with the coupling of the dynamo to the hydraulic turbine. The mechanical production of electric power began the Second Industrial Revolution and made possible several inventions using electricity, with the major contributors being Thomas Alva Edison and Nikola Tesla. Previously the only way to produce electricity was by chemical reactions or using battery cells, and the only practical use of electricity was for the telegraph.\nElectricity generation at central power stations started in 1882, when a steam engine driving a dynamo at Pearl Street Station produced a DC current that powered public lighting on Pearl Street, New York. The new technology was quickly adopted by many cities around the world, which adapted their gas-fueled street lights to electric power. Soon after electric lights would be used in public buildings, in businesses, and to power public transport, such as trams and trains.\nThe first power plants used water power or coal.[7] Today a variety of energy sources are used, such as coal, nuclear, natural gas, hydroelectric, wind, and oil, as well as solar energy, tidal power, and geothermal sources.\nIn the 1880s the popularity of electricity grew massively with the introduction of the Incandescent light bulb. Although there are 22 recognised inventors of the light bulb prior to Joseph Swan and Thomas Edison, Edison and Swan's invention became by far the most successful and popular of all. During the early years of the 19th century, massive jumps in electrical sciences were made. And by the later 19th century the advancement of electrical technology and engineering led to electricity being part of everyday life. With the introduction of many electrical inventions and their implementation into everyday life, the demand for electricity within homes grew dramatically. With this increase in demand, the potential for profit was seen by many entrepreneurs who began investing into electrical systems to eventually create the first electricity public utilities. This process in history is often described as electrification.[8]\nThe earliest distribution of electricity came from companies operating independently of one another. A consumer would purchase electricity from a producer, and the producer would distribute it through their own power grid. As technology improved so did the productivity and efficiency of its generation. Inventions such as the steam turbine had a massive impact on the efficiency of electrical generation but also the economics of generation as well. This conversion of heat energy into mechanical work was similar to that of steam engines, however at a significantly larger scale and far more productively. The improvements of these large-scale generation plants were critical to the process of centralised generation as they would become vital to the entire power system that we now use today.\nThroughout the middle of the 20th century many utilities began merging their distribution networks due to economic and efficiency benefits. Along with the invention of long-distance power transmission, the coordination of power plants began to form. This system was then secured by regional system operators to ensure stability and reliability. The electrification of homes began in Northern Europe and in the Northern America in the 1920s in large cities and urban areas. It was not until the 1930s that rural areas saw the large-scale establishment of electrification.[9]\n- Coal 10,587 (34.4%)\n- Natural gas 6,796 (22.1%)\n- Hydro 4,417 (14.4%)\n- Nuclear 2,765 (8.99%)\n- Wind 2,497 (8.12%)\n- Solar 2,130 (6.92%)\n- Other 1,569 (5.10%)\nSeveral fundamental methods exist to convert other forms of energy into electrical energy. Utility-scale generation is achieved by rotating electric generators or by photovoltaic systems. A small proportion of electric power distributed by utilities is provided by batteries. Other forms of electricity generation used in niche applications include the triboelectric effect, the piezoelectric effect, the thermoelectric effect, and betavoltaics.\nElectric generators transform kinetic energy into electricity. This is the most used form for generating electricity based on Faraday's law. It can be seen experimentally by rotating a magnet within closed loops of conducting material, e.g. copper wire. Almost all commercial electrical generation uses electromagnetic induction, in which mechanical energy forces a generator to rotate.\nElectrochemistry is the direct transformation of chemical energy into electricity, as in a battery. Electrochemical electricity generation is important in portable and mobile applications. Currently, most electrochemical power comes from batteries.[11] Primary cells, such as the common zinc–carbon batteries, act as power sources directly, but secondary cells (i.e. rechargeable batteries) are used for storage systems rather than primary generation systems. Open electrochemical systems, known as fuel cells, can be used to extract power either from natural fuels or from synthesized fuels. Osmotic power is a possibility at places where salt and fresh water merge.\nThe photovoltaic effect is the transformation of light into electrical energy, as in solar cells. Photovoltaic panels convert sunlight directly to DC electricity. Power inverters can then convert that to AC electricity if needed. The photovoltaic industry has undergone spectacular growth since the 1990s.\nThe selection of electricity production modes and their economic viability varies in accordance with demand and region. The economics vary considerably around the world, resulting in widespread residential selling prices. Hydroelectric plants, nuclear power plants, thermal power plants and renewable sources have their own pros and cons, and selection is based upon the local power requirement and the fluctuations in demand.\nAll power grids have varying loads on them. The daily minimum[12] is the base load, often supplied by plants which run continuously. Nuclear, coal, oil, gas and some hydro plants can supply base load. If well construction costs for natural gas are below $10 per MWh, generating electricity from natural gas is cheaper than generating power by burning coal.[13]\nNuclear power plants can produce a huge amount of power from a single unit. However, nuclear disasters have raised concerns over the safety of nuclear power, and the capital cost of nuclear plants is very high. Hydroelectric power plants are located in areas where the potential energy from falling water can be harnessed for moving turbines and the generation of power. It may not be an economically viable single source of production where the ability to store the flow of water is limited and the load varies too much during the annual production cycle.\nElectric generators were known in simple forms from the discovery of electromagnetic induction in the 1830s. In general, some form of prime mover such as an engine or the turbines described above, drives a rotating magnetic field past stationary coils of wire thereby turning mechanical energy into electricity.[14] The only commercial scale forms of electricity production that do not employ a generator are photovoltaic solar and fuel cells.\nAlmost all commercial electrical power on Earth is generated with a turbine, driven by wind, water, steam or burning gas. The turbine drives a generator, thus transforming its mechanical energy into electrical energy by electromagnetic induction. There are many different methods of developing mechanical energy, including heat engines, hydro, wind and tidal power. Most electric generation is driven by heat engines.\nThe combustion of fossil fuels supplies most of the energy to these engines, with a significant fraction from nuclear fission and some from renewable sources. The modern steam turbine, invented by Sir Charles Parsons in 1884, currently generates about 80% of the electric power in the world using a variety of heat sources. Turbine types include:\n- Steam\n- Water is boiled by coal burned in a thermal power plant. About 41% of all electricity is generated this way.[15]\n- Nuclear fission heat created in a nuclear reactor creates steam. Less than 15% of electricity is generated this way.\n- Renewable energy. The steam is generated by biomass, solar thermal energy, or geothermal power.\n- Natural gas: turbines are driven directly by gases produced by combustion. Combined cycle are driven by both steam and natural gas. They generate power by burning natural gas in a gas turbine and use residual heat to generate steam. At least 20% of the world's electricity is generated by natural gas.\n- Water Energy is captured by a water turbine from the movement of water - from falling water, the rise and fall of tides or ocean thermal currents (see ocean thermal energy conversion). Currently, hydroelectric plants provide approximately 16% of the world's electricity.\n- The windmill was a very early wind turbine. In 2018 around 5% of the world's electricity was produced from wind\nTurbines can also use other heat-transfer liquids than steam. Supercritical carbon dioxide based cycles can provide higher conversion efficiency due to faster heat exchange, higher energy density and simpler power cycle infrastructure. Supercritical carbon dioxide blends, that are currently in development, can further increase efficiency by optimizing its critical pressure and temperature points.\nAlthough turbines are most common in commercial power generation, smaller generators can be powered by gasoline or diesel engines. These may used for backup generation or as a prime source of power within isolated villages.\nTotal world generation in 2024 was 30,850 TWh, including coal (34%), gas (22%), hydro (14%), nuclear (9%), wind (8%), solar (7%), oil and other fossil fuels (3%), biomass (2%).[16]\nVariations between countries generating electrical power affect concerns about the environment. In France only 10% of electricity is generated from fossil fuels, the US is higher at 70% and China is at 80%.[17] The cleanliness of electricity depends on its source. Methane leaks (from natural gas to fuel gas-fired power plants)[18] and carbon dioxide emissions from fossil fuel-based electricity generation account for a significant portion of world greenhouse gas emissions.[19] In the United States, fossil fuel combustion for electric power generation is responsible for 65% of all emissions of sulfur dioxide, the main component of acid rain.[20] Electricity generation is the fourth highest combined source of NOx, carbon monoxide, and particulate matter in the US.[21]\nAccording to the International Energy Agency (IEA), low-carbon electricity generation needs to account for 85% of global electrical output by 2040 in order to ward off the worst effects of climate change.[22] Like other organizations including the Energy Impact Center (EIC)[23] and the United Nations Economic Commission for Europe (UNECE),[24] the IEA has called for the expansion of nuclear and renewable energy to meet that objective.[25] Some, like EIC founder Bret Kugelmass, believe that nuclear power is the primary method for decarbonizing electricity generation because it can also power direct air capture that removes existing carbon emissions from the atmosphere.[26] Nuclear power plants can also create district heating and desalination projects, limiting carbon emissions and the need for expanded electrical output.[27]\nA fundamental issue regarding centralised generation and the current electrical generation methods in use today is the significant negative environmental effects that many of the generation processes have. Processes such as coal and gas not only release carbon dioxide as they combust, but their extraction from the ground also impacts the environment. Open pit coal mines use large areas of land to extract coal and limit the potential for productive land use after the excavation. Natural gas extraction releases large amounts of methane into the atmosphere when extracted from the ground, which greatly increases global greenhouse gases. Although nuclear power plants do not release carbon dioxide through electricity generation, there are risks associated with nuclear waste and safety concerns associated with the use of nuclear sources.\nPer unit of electricity generated coal and gas-fired power life-cycle greenhouse gas emissions are almost always at least ten times that of other generation methods.[28]\nCentralised generation is electricity generation by large-scale centralised facilities, sent through transmission lines to consumers. These facilities are usually located far away from consumers and distribute the electricity through high voltage transmission lines to a substation, where it is then distributed to consumers; the basic concept being that multi-megawatt or gigawatt scale large stations create electricity for a large number of people. The vast majority of electricity used is created from centralised generation. Most centralised power generation comes from large power plants run by fossil fuels such as coal or natural gas, though nuclear or large hydroelectricity plants are also commonly used.[29]\nCentralised generation is fundamentally the opposite of distributed generation. Distributed generation is the small-scale generation of electricity to smaller groups of consumers. This can also include independently producing electricity by either solar or wind power. In recent years distributed generation as has seen a spark in popularity due to its propensity to use renewable energy generation methods such as rooftop solar.[30]\nCentralised energy sources are large power plants that produce huge amounts of electricity to a large number of consumers. Most power plants used in centralised generation are thermal power plants meaning that they use a fuel to heat steam to produce a pressurised gas which in turn spins a turbine and generates electricity. This is the traditional way of producing energy. This process relies on several forms of technology to produce widespread electricity, these being natural coal, gas and nuclear forms of thermal generation. More recently solar and wind have become large scale.\nA photovoltaic power station, also known as a solar park, solar farm, or solar power plant, is a large-scale grid-connected photovoltaic power system (PV system) designed for the supply of merchant power. They are different from most building-mounted and other decentralized solar power because they supply power at the utility level, rather than to a local user or users. Utility-scale solar is sometimes used to describe this type of project.\nThis approach differs from concentrated solar power, the other major large-scale solar generation technology, which uses heat to drive a variety of conventional generator systems. Both approaches have their own advantages and disadvantages, but to date, for a variety of reasons, photovoltaic technology has seen much wider use. As of 2019[update], about 97% of utility-scale solar power capacity was PV.[31][32]\nIn some countries, the nameplate capacity of photovoltaic power stations is rated in megawatt-peak (MWp), which refers to the solar array's theoretical maximum DC power output. In other countries, the manufacturer states the surface and the efficiency. However, Canada, Japan, Spain, and the United States often specify using the converted lower nominal power output in MWAC, a measure more directly comparable to other forms of power generation. Most solar parks are developed at a scale of at least 1 MWp. As of 2018, the world's largest operating photovoltaic power stations surpassed 1 gigawatt. At the end of 2019, about 9,000 solar farms were larger than 4 MWAC (utility scale), with a combined capacity of over 220 GWAC.[31]\nMost of the existing large-scale photovoltaic power stations are owned and operated by independent power producers, but the involvement of community and utility-owned projects is increasing.[33] Previously, almost all were supported at least in part by regulatory incentives such as feed-in tariffs or tax credits, but as levelized costs fell significantly in the 2010s and grid parity has been reached in most markets, external incentives are usually not needed.Hydroelectricity is electricity generated from hydropower (water power). Hydropower supplies 15% of the world's electricity, almost 4,210 TWh in 2023, which is more than all other renewable sources combined and also more than nuclear power. Hydropower can provide large amounts of low-carbon electricity on demand, making it a key element for creating secure and clean electricity supply systems. A hydroelectric power station that has a dam and reservoir is a flexible source, since the amount of electricity produced can be increased or decreased in seconds or minutes in response to varying electricity demand.\nA wind farm, also called a wind park or wind power plant,[34] is a group of wind turbines in the same location used to produce electricity. Wind farms vary in size from a small number of turbines to several hundred wind turbines covering an extensive area. Wind farms can be either onshore or offshore.\nMany of the largest operational onshore wind farms are located in China, India, and the United States. For example, the largest wind farm in the world, Gansu Wind Farm in China had a capacity of over 6,000 MW by 2012,[35] with a goal of 20,000 MW[36] by 2020.[37] As of December 2020, the 1218 MW Hornsea Wind Farm in the UK is the largest offshore wind farm in the world.[38] Individual wind turbine designs continue to increase in power, resulting in fewer turbines being needed for the same total output.\nBecause they require no fuel, wind farms have less impact on the environment than many other forms of power generation and are often referred to as a good source of green energy. Wind farms have, however, been criticised for their visual impact and impact on the landscape. Typically they need to be spread over more land than other power stations and need to be built in wild and rural areas, which can lead to \"industrialization of the countryside\", habitat loss, and a drop in tourism. Some critics claim that wind farms have adverse health effects, but most researchers consider these claims to be pseudoscience (see wind turbine syndrome). Wind farms can interfere with radar, although in most cases, according to the US Department of Energy, \"siting and other mitigations have resolved conflicts and allowed wind projects to co-exist effectively with radar\".[39]A coal-fired power station or coal power plant is a thermal power station which burns coal to generate electricity. Worldwide there are about 2,500 coal-fired power stations,[40] on average capable of generating a gigawatt each.[41][a] They generate about a third of the world's electricity,[42] but cause many illnesses and the most early deaths per unit of energy produced,[43] mainly from air pollution.[44][45] World installed capacity doubled from 2000 to 2023 and increased 2% in 2023.[46]\nA coal-fired power station is a type of fossil fuel power station. The coal is usually pulverized and then burned in a pulverized coal-fired boiler. The furnace heat converts boiler water to steam, which is then used to spin turbines that turn generators. Thus chemical energy stored in coal is converted successively into thermal energy, mechanical energy and, finally, electrical energy.\nCoal-fired power stations are the largest single contributor to climate change,[47] releasing approximately 12 billion tonnes of carbon dioxide annually,[41] about one-fifth of global greenhouse gas emissions.[48] China accounts for over half of global coal-fired electricity generation.[49] While the total number of operational coal plants began declining in 2020,[50][51] due to retirements in Europe[52] and the Americas,[53] construction continues in Asia, primarily in China.[54] The profitability of some plants is maintained by externalities, as the health and environmental costs of coal production and use are not fully reflected in electricity prices.[55][56] However, newer plants face the risk of becoming stranded assets.[57] The UN Secretary General has called for OECD nations to phase out coal-fired generation by 2030, and the rest of the world by 2040.[58]Natural gas is ignited to create pressurised gas which is used to spin turbines to generate electricity. Natural gas plants use a gas turbine where natural gas is added along with oxygen which in turn combusts and expands through the turbine to force a generator to spin.\nNatural gas power plants are more efficient than coal power generation, they however contribute to climate change, but not as highly as coal generation. Not only do they produce carbon dioxide from the ignition of natural gas, the extraction of gas when mined releases a significant amount of methane into the atmosphere.[59]\nNuclear power plants create electricity through steam turbines where the heat input is from the process of nuclear fission. Currently, nuclear power produces 11% of all electricity in the world. Most nuclear reactors use uranium as a source of fuel. In a process called nuclear fission, energy, in the form of heat, is released when nuclear atoms are split. Electricity is created through the use of a nuclear reactor where heat produced by nuclear fission is used to produce steam which in turn spins turbines and powers the generators. Although there are several types of nuclear reactors, all fundamentally use this process.[60]\nNormal emissions due to nuclear power plants are primarily waste heat and radioactive spent fuel. In a reactor accident, significant amounts of radioisotopes can be released to the environment, posing a long term hazard to life. This hazard has been a continuing concern of environmentalists. Accidents such as the Three Mile Island accident, Chernobyl disaster and the Fukushima nuclear disaster illustrate this problem.[61]\nThe table lists 45 countries with their total electricity capacities. The data is from 2022. According to the Energy Information Administration, the total global electricity capacity in 2022 was nearly 8.9 terawatt (TW), more than four times the total global electricity capacity in 1981. The global average per-capita electricity capacity was about 1,120 watts in 2022, nearly two and a half times the global average per-capita electricity capacity in 1981.\nIceland has the highest installed capacity per capita in the world, at about 8,990 watts. All developed countries have an average per-capita electricity capacity above the global average per-capita electricity capacity, with the United Kingdom having the lowest average per-capita electricity capacity of all other developed countries.\n| Country | Total capacity (GW) |\nAverage per capita capacity (watts) |\n|---|---|---|\n| World | 8,890 | 1,120 |\n| China | 2,510 | 1,740 |\n| United States | 1,330 | 3,940 |\n| European Union | 1,080 | 2,420 |\n| India | 556 | 397 |\n| Japan | 370 | 2,940 |\n| Russia | 296 | 2,030 |\n| Germany | 267 | 3,220 |\n| Brazil | 222 | 1,030 |\n| Canada | 167 | 4,460 |\n| South Korea | 160 | 3,130 |\n| France | 148 | 2,280 |\n| Italy | 133 | 2,230 |\n| Spain | 119 | 2,580 |\n| United Kingdom | 111 | 1,640 |\n| Turkey | 107 | 1,240 |\n| Mexico | 104 | 792 |\n| Australia | 95.8 | 3,680 |\n| Saudi Arabia | 85.3 | 2,380 |\n| Iran | 83.3 | 977 |\n| Vietnam | 72.2 | 721 |\n| South Africa | 66.7 | 1,100 |\n| Poland | 64 | 1,690 |\n| Thailand | 63 | 901 |\n| Ukraine | 62.2 | 1,440 |\n| Egypt | 61.1 | 582 |\n| Taiwan | 58 | 2,440 |\n| Netherlands | 53.3 | 3,010 |\n| Sweden | 52.1 | 5,100 |\n| Argentina | 51.9 | 1,130 |\n| Pakistan | 42.7 | 192 |\n| Norway | 41.7 | 7,530 |\n| United Arab Emirates | 40.7 | 4,010 |\n| Malaysia | 37.9 | 1,110 |\n| Chile | 37 | 1,930 |\n| Venezuela | 34.1 | 1,210 |\n| Kazakhstan | 29.6 | 1,600 |\n| Switzerland | 27.8 | 2,960 |\n| Austria | 26.7 | 2,890 |\n| Algeria | 25.9 | 590 |\n| Greece | 24.4 | 2,400 |\n| Israel | 23.7 | 2,520 |\n| Finland | 22.2 | 3,980 |\n| Denmark | 21.3 | 3,710 |\n| Ireland | 13.3 | 2,420 |\n| New Zealand | 11.6 | 2,320 |\n| Iceland | 3.24 | 8,990 |\n- Glossary of power generation\n- Cogeneration: the use of a heat engine or power station to generate electricity and useful heat at the same time.\n- Cost of electricity by source\n- Diesel generator\n- Engine–generator\n- Generation expansion planning\n- Steam–electric power station\n- World energy supply and consumption\n- Chestney, Nina (May 14, 2021). \"Factbox: Getting out of gas - the sold and scrapped projects\". Reuters. Archived from the original on November 27, 2021. Retrieved November 27, 2021.\n- \"Solar PV – Analysis\". IEA. Archived from the original on November 27, 2021. Retrieved November 27, 2021.\n- \"What would a world powered entirely by offshore wind look like?\". The Economist. November 4, 2021. ISSN 0013-0613. Archived from the original on November 26, 2021. Retrieved November 27, 2021.\n- \"Electricity – Global Energy Review 2021 – Analysis\". IEA. April 2021. Archived from the original on November 27, 2021. Retrieved November 27, 2021.\n- Shadbolt, Rory (November 26, 2021). \"Accelerated renewables-based electrification for the future\". SelectScience. Archived from the original on November 27, 2021. Retrieved November 27, 2021.\n- Lempriere, Molly (October 4, 2023). \"World's electricity supply close to 'peak emissions' due to growth of wind and solar\". Carbon Brief. Retrieved November 8, 2023.\n- \"Pearl Street Station - Engineering and Technology History Wiki\". ethw.org. Archived from the original on August 26, 2016. Retrieved August 14, 2016.\n- \"History of Electrification Sites\". edisontechcenter.org. Archived from the original on May 25, 2019. Retrieved June 8, 2019.\n- \"Power Grid History\". www.itc-holdings.com. Archived from the original on June 8, 2019. Retrieved June 8, 2019.\n- \"Yearly electricity data\". ember-energy.org. April 21, 2025. Retrieved April 21, 2025.\n- World's Largest Utility Battery System Installed in Alaska Archived 2008-06-27 at the Wayback Machine (press release, 2003-09-24), U.S. Department of Energy. \"13,670 nickel-cadmium battery cells to generate up to 40 megawatts of power for about 7 minutes, or 27 megawatts of power for 15 minutes.\"\n- \"Baseload power - Energy Education\". energyeducation.ca. Retrieved September 17, 2025.\n- Smith, Karl (March 22, 2013). \"Will Natural Gas Stay Cheap Enough To Replace Coal And Lower Us Carbon Emissions\". Forbes. Archived from the original on November 2, 2017. Retrieved June 20, 2015.\n- Sedlazeck, K.; Richter, C.; Strack, S.; Lindholm, S.; Pipkin, J.; Fu, F.; Humphries, B.; Montgomery, L. (May 1, 2009). \"Type testing a 2000 MW turbogenerator\". 2009 IEEE International Electric Machines and Drives Conference. pp. 465–470. doi:10.1109/IEMDC.2009.5075247. ISBN 978-1-4244-4251-5. S2CID 9118902 – via IEEE Xplore.\n- \"Coal & electricity\". World Coal Association. April 29, 2015. Archived from the original on August 23, 2016. Retrieved August 14, 2016.\n- \"Yearly electricity data\". ember-climate.org. December 6, 2023. Retrieved December 23, 2023.\n- \"Statistics and Balances\". IEA. Archived from the original on May 15, 2011. Retrieved July 12, 2011.\n- Patrick Pester (February 10, 2022). \"Massive methane leaks mapped from space\". Live Science. Archived from the original on June 29, 2022. Retrieved June 29, 2022.\n- Borenstein, Seth (June 3, 2007). \"Carbon-emissions culprit? Coal\". The Seattle Times. Archived from the original on April 24, 2011.\n- \"Sulfur Dioxide\". US Environmental Protection Agency. November 16, 2016. Archived from the original on August 14, 2015. Retrieved April 23, 2010.\n- \"AirData\". US Environmental Protection Agency. Archived from the original on September 24, 2015. Retrieved April 21, 2010.\n- Johnson, Jeff (September 23, 2019). \"Can nuclear power help save us from climate change?\". Chemical & Engineering News. Archived from the original on November 22, 2021. Retrieved November 23, 2021.\n- Takahashi, Dean (February 25, 2020). \"Last Energy raises $3 million to fight climate change with nuclear energy\". VentureBeat. Archived from the original on January 12, 2021. Retrieved November 23, 2021.\n- \"Global climate objectives fall short without nuclear power in the mix: UNECE\". United Nations Economic Commission for Europe. August 11, 2021. Archived from the original on November 22, 2021. Retrieved November 23, 2021.\n- Chestney, Nina (May 18, 2021). \"End new oil, gas and coal funding to reach net zero, says IEA\". Reuters. Archived from the original on November 17, 2021. Retrieved November 23, 2021.\n- Kugelmass, Bret (January 22, 2020). \"Want to stop climate change? Embrace the nuclear option\". USA Today. Archived from the original on November 28, 2020. Retrieved November 23, 2021.\n- Patel, Sonal (November 1, 2021). \"How an AP1000 Plant Is Changing the Nuclear Power Paradigm Through District Heating, Desalination\". Power Magazine. Archived from the original on June 3, 2022. Retrieved November 23, 2021.\n- Scarlat, Nicolae; Prussi, Matteo; Padella, Monica (January 1, 2022). \"Quantification of the carbon intensity of electricity produced and used in Europe\". Applied Energy. 305 117901. Bibcode:2022ApEn..30517901S. doi:10.1016/j.apenergy.2021.117901. ISSN 0306-2619. S2CID 244177261.\n- \"Centralized Generation of Electricity and its Impacts on the Environment\". US EPA. August 4, 2015. Archived from the original on May 19, 2019. Retrieved May 21, 2019.\n- Joshi, Siddharth; Mittal, Shivika; Holloway, Paul; Shukla, Priyadarshi Ramprasad; Ó Gallachóir, Brian; Glynn, James (October 5, 2021). \"High resolution global spatiotemporal assessment of rooftop solar photovoltaics potential for renewable electricity generation\". Nature Communications. 12 (1): 5738. Bibcode:2021NatCo..12.5738J. doi:10.1038/s41467-021-25720-2. ISSN 2041-1723. PMC 8492708. PMID 34611151.\n- Wolfe, Philip (March 17, 2020). \"Utility-scale solar sets new record\" (PDF). Wiki-Solar. Retrieved May 11, 2010.\n- \"Concentrated solar power had a global total installed capacity of 6,451 MW in 2019\". HelioCSP. February 2, 2020. Retrieved May 11, 2020.\n- \"Expanding Renewable Energy in Pakistan's Electricity Mix\". World Bank. Retrieved July 17, 2022.\n- Robert Gasch, Jochen Twele (editors). Wind Power Plants: Fundamentals, Design, Construction and Operation. Springer, 2011. p. 11.\n- Watts, Jonathan & Huang, Cecily. Winds Of Change Blow Through China As Spending On Renewable Energy Soars, The Guardian, 19 March 2012, revised on 20 March 2012. Retrieved 4 January 2012.\n- Fahey, Jonathan. In Pictures: The World's Biggest Green Energy Projects, Forbes, 9 January 2010. Retrieved 19 June 2019.\n- Kanter, Doug (April 20, 2016). \"Gansu Wind Farm – The World's Biggest Wind Farms\". Forbes. Retrieved June 3, 2024.\n- \"World's largest offshore wind farm fully up and running\". offshorewind.biz. January 30, 2020. Retrieved December 27, 2020.\n- \"WINDExchange: Wind Turbine Radar Interference\". WINDExchange. Retrieved June 19, 2019.\n- \"Coal burning capacity climbs worldwide despite pledges to reduce use\". PBS News. April 6, 2023. Retrieved November 16, 2024.\n- \"What would it cost to kill coal?\". The Economist. ISSN 0013-0613. Retrieved November 16, 2024.\nCumulative emissions from coal since 1882 amount to 800bn tonnes, the single biggest factor driving the warming that makes today's world about 1.2°C warmer than that of 1882. Most of that coal has been burned to produce electricity. Today's plants are producing about 12bn tonnes a year.\n- Birol, Fatih; Malpass, David (October 8, 2021). \"It's critical to tackle coal emissions – Analysis\". International Energy Agency. Retrieved October 9, 2021.\n- \"How safe is nuclear energy?\". The Economist. ISSN 0013-0613. Retrieved December 26, 2022.\n- Cropper, Maureen; Cui, Ryna; Guttikunda, Sarath; Hultman, Nate; Jawahar, Puja; Park, Yongjoon; Yao, Xinlu; Song, Xiao-Peng (February 2, 2021). \"The mortality impacts of current and planned coal-fired power plants in India\". Proceedings of the National Academy of Sciences. 118 (5). Bibcode:2021PNAS..11817936C. doi:10.1073/pnas.2017936118. ISSN 0027-8424. PMC 7865184. PMID 33495332.\n- \"Killed by coal: Air pollution deaths in Jakarta 'may double' by 2030\". The Jakarta Post. Retrieved April 8, 2022.\n- Boom and Bust Coal 2024 (PDF) (Report). San Francisco, California: Global Energy Monitor. April 2024. p. 7, 21. Retrieved April 11, 2024.\n2% annual increase in the global operating coal fleet, which currently stands at 2,130 GW […] Figure 16: Global coal power capacity continues steady growth despite Paris Agreement, with a 2% uptick in 2023\n- \"It's critical to tackle coal emissions – Analysis\". International Energy Agency. October 8, 2021. Retrieved October 9, 2021.\nCoal power plants produce a fifth of global greenhouse gas emissions – more than any other single source.\n- \"Country Inventory\". Climate TRACE. Retrieved November 16, 2024.\n- \"China generated over half world's coal-fired power in 2020: study\". Reuters. March 28, 2021. Retrieved September 14, 2021.\nChina generated 53% of the world's total coal-fired power in 2020, nine percentage points more that five years earlier\n- Morton, Adam (August 3, 2020). \"More coal power generation closed than opened around the world this year, research finds\". The Guardian. ISSN 0261-3077. Retrieved August 4, 2020.\n- \"The dirtiest fossil fuel is on the back foot\". The Economist. December 3, 2020. ISSN 0013-0613. Retrieved December 12, 2020.\n- Piven, Ben. \"EU power sector emissions drop as coal collapses across Europe\". Al Jazeera. Retrieved March 21, 2020.\n- Roberts, David (March 14, 2020). \"4 astonishing signs of coal's declining economic viability\". Vox. Retrieved March 21, 2020.\n- \"China pledges to stop building new coal energy plants abroad\". BBC News. September 22, 2021. Retrieved September 22, 2021.\n- Borenstein, Severin; Bushnell, James B. (November 1, 2022). \"Do Two Electricity Pricing Wrongs Make a Right? Cost Recovery, Externalities, and Efficiency\" (PDF). American Economic Journal: Economic Policy. 14 (4): 80–110. doi:10.1257/pol.20190758. Retrieved November 11, 2022.\n- Davis, Lucas (September 21, 2020). \"Time to Vote Out Coal\". Energy Institute Blog. Retrieved September 27, 2020.\n- Harrabin, Roger (March 12, 2020). \"Coal power developers 'risk wasting billions'. BBC News.\n- \"The dirtiest fossil fuel is on the back foot\". The Economist. December 3, 2020. ISSN 0013-0613.\n- \"Natural gas power plant\". Energy Education. Archived from the original on June 8, 2019. Retrieved June 8, 2019.\n- \"Nuclear power\". Energy Education. Archived from the original on June 8, 2019. Retrieved June 8, 2019.\n- \"Nuclear Power and the Environment – Energy Explained\". Energy Information Administration. Archived from the original on May 27, 2019. Retrieved June 8, 2019.",
    "electronics": "Electronics is a scientific and engineering discipline that studies and applies the principles of physics to design, create, and operate devices that manipulate electrons and other electrically charged particles. It is a subfield of physics[1][2] and electrical engineering which uses active devices such as transistors, diodes, and integrated circuits to control and amplify the flow of electric current and to convert it from one form to another, such as from alternating current (AC) to direct current (DC) or from analog signals to digital signals. Electronics is often contrasted with electrical power engineering, which focuses on generation, transmission, and distribution of electric power rather than signal processing or device level control.[3]\nElectronic devices have significantly influenced the development of many aspects of modern society, such as telecommunications, entertainment, education, health care, industry, and security. The main driving force behind the advancement of electronics is the semiconductor industry, which continually produces ever-more sophisticated electronic devices and circuits in response to global demand. The semiconductor industry is one of the global economy's largest and most profitable industries, with annual revenues exceeding $481 billion in 2018. The electronics industry also encompasses other branches that rely on electronic devices and systems, such as e-commerce,[citation needed] which generated over $29 trillion in online sales in 2017. Practical electronic systems commonly combine analog and digital techniques, using analog front ends with digital processing.[4]\nKarl Ferdinand Braun's development of the crystal detector, the first semiconductor device, in 1874 and the identification of the electron in 1897 by Sir Joseph John Thomson, along with the subsequent invention of the vacuum tube which could amplify and rectify small electrical signals, inaugurated the field of electronics and the electron age.[5][6] Practical applications started with the invention of the diode by Ambrose Fleming and the triode by Lee De Forest in the early 1900s, which made the detection of small electrical voltages, such as radio signals from a radio antenna, practicable. Thermionic vacuum tubes enabled reliable amplification and detection, making long-distance telephony, broadcast radio, and early television feasible by 1920s-1930s.[7]\nVacuum tubes (thermionic valves) were the first active electronic components which controlled current flow by influencing the flow of individual electrons, and enabled the construction of equipment that used current amplification and rectification to give us radio, television, radar, long-distance telephony and much more. The early growth of electronics was rapid, and by the 1920s, commercial radio broadcasting and telecommunications were becoming widespread and electronic amplifiers were being used in such diverse applications as long-distance telephony and the music recording industry.[8]\nThe next big technological step took several decades to appear, when the first working point-contact transistor was invented by John Bardeen and Walter Houser Brattain at Bell Labs in 1947.[9] The 1947 point contact transistor showed that semiconductors could replace many tube functions with lower power and size.[10] However, vacuum tubes continued to play a leading role in the field of microwave and high power transmission as well as television receivers until the middle of the 1980s.[11] Since then, solid-state devices have all but completely taken over. Vacuum tubes are still used in some specialist applications such as high power RF amplifiers, cathode-ray tubes, specialist audio equipment, guitar amplifiers and some microwave devices.\nIn April 1955, the IBM 608 was the first IBM product to use transistor circuits without any vacuum tubes and is believed to be the first all-transistorized calculator to be manufactured for the commercial market.[12][13] The 608 contained more than 3,000 germanium transistors. Thomas J. Watson Jr. ordered all future IBM products to use transistors in their design. From that time on transistors were almost exclusively used for computer logic circuits and peripheral devices. However, early junction transistors were relatively bulky devices that were difficult to manufacture on a mass-production basis, which limited them to a number of specialised applications.[14]\nThe MOSFET was invented at Bell Labs between 1955 and 1960.[15][16][17][18][19][20] It was the first truly compact transistor that could be miniaturised and mass-produced for a wide range of uses.[14] The MOSFET became the most widely used device in VLSI, enabling compact, low power circuits.[21] Its advantages include high scalability,[22] affordability,[23] low power consumption, and high density.[24] The MOSFET's scalability and cost made it dominant in modern electronics.[25] It revolutionized the electronics industry,[26][27] becoming the most widely used electronic device in the world.[28][29] The MOSFET is the basic element in most modern electronic equipment.[30][31] As the complexity of circuits grew, problems arose.[32] One problem was the size of the circuit. A complex circuit like a computer was dependent on speed. If the components were large, the wires interconnecting them must be long. The electric signals took time to go through the circuit, thus slowing the computer.[32] The invention of the integrated circuit by Jack Kilby and Robert Noyce solved this problem by making all the components and the chip out of the same block (monolith) of semiconductor material. The circuits could be made smaller, and the manufacturing process could be automated. This led to the idea of integrating all components on a single-crystal silicon wafer, which led to small-scale integration (SSI) in the early 1960s, and then medium-scale integration (MSI) in the late 1960s, followed by VLSI. In 2008, billion-transistor processors became commercially available.[33] Integrated circuits put many components on one chip, shortening interconnects and increase speed.[25]\nAn electronic component is any component, either active or passive, in an electronic system or electronic device. Components are connected together, usually by being soldered to a printed circuit board (PCB), to create an electronic circuit with a particular function. Components may be packaged singly, or in more complex groups as integrated circuits. Passive electronic components are capacitors, inductors, resistors, whilst active components are such as semiconductor devices; transistors and thyristors, which control current flow at electron level.[34]\nElectronic circuit functions can be divided into two function groups: analog and digital. A particular device may consist of circuitry that has either or a mix of the two types. Analog circuits are becoming less common, as many of their functions are being digitized.\nAnalog circuits use a continuous range of voltage or current for signal processing, as opposed to the discrete levels used in digital circuits. Analog circuits were common throughout an electronic device in the early years in devices such as radio receivers and transmitters. Analog electronic computers were valuable for solving problems with continuous variables until digital processing advanced.\nAs semiconductor technology developed, many of the functions of analog circuits were taken over by digital circuits, and modern circuits that are entirely analog are less common; their functions being replaced by hybrid approach which, for instance, uses analog circuits at the front end of a device receiving an analog signal, and then use digital processing using microprocessor techniques thereafter.\nSometimes it may be difficult to classify some circuits that have elements of both linear and non-linear operation. An example is the voltage comparator which receives a continuous range of voltage but only outputs one of two levels as in a digital circuit. Similarly, an overdriven transistor amplifier can take on the characteristics of a controlled switch, having essentially two levels of output.\nAnalog circuits are still widely used for signal amplification, such as in the entertainment industry, and conditioning signals from analog sensors, such as in industrial measurement and control.\nDigital circuits are electric circuits based on discrete voltage levels. Digital circuits use Boolean algebra and are the basis of all digital computers and microprocessor devices. They range from simple logic gates to large integrated circuits, employing millions of such gates.\nDigital circuits use a binary system with two voltage levels labelled \"0\" and \"1\" to indicated logical status. Often logic \"0\" will be a lower voltage and referred to as \"Low\" while logic \"1\" is referred to as \"High\". However, some systems use the reverse definition (\"0\" is \"High\") or are current based. Quite often the logic designer may reverse these definitions from one circuit to the next as they see fit to facilitate their design. The definition of the levels as \"0\" or \"1\" is arbitrary.[35]\nTernary (with three states) logic has been studied, and some prototype computers made, but have not gained any significant practical acceptance.[36] Universally, Computers and Digital signal processors are constructed with digital circuits using Transistors such as MOSFETs in the electronic logic gates to generate binary states.\nHighly integrated devices:\n- Memory chip\n- Microprocessors\n- Microcontrollers\n- Application-specific integrated circuit (ASIC)\n- Digital signal processor (DSP)\n- Field-programmable gate array (FPGA)\n- Field-programmable analog array (FPAA)\n- System on chip (SOC)\nElectronic systems design deals with the multi-disciplinary design issues of complex electronic devices and systems, such as mobile phones and computers. The subject covers a broad spectrum, from the design and development of an electronic system (new product development) to assuring its proper function, service life and disposal.[37] Electronic systems design is therefore the process of defining and developing complex electronic devices to satisfy specified requirements of the user.\nDue to the complex nature of electronics theory, laboratory experimentation is an important part of the development of electronic devices. These experiments are used to test or verify the engineer's design and detect errors. Historically, electronics labs have consisted of electronics devices and equipment located in a physical space, although in more recent years the trend has been towards electronics lab simulation software, such as CircuitLogix, Multisim, and PSpice.\nToday's electronics engineers have the ability to design circuits using premanufactured building blocks such as power supplies, semiconductors (i.e. semiconductor devices, such as transistors), and integrated circuits. Electronic design automation software programs include schematic capture programs and printed circuit board design programs. Popular names in the EDA software world are NI Multisim, Cadence (ORCAD), EAGLE PCB[38] and Schematic, Mentor (PADS PCB and LOGIC Schematic), Altium (Protel), LabCentre Electronics (Proteus), gEDA, KiCad and many others.\nHeat generated by electronic circuitry must be dissipated to prevent immediate failure and improve long term reliability. Heat dissipation is mostly achieved by passive conduction/convection. Means to achieve greater dissipation include heat sinks and fans for air cooling, and other forms of computer cooling such as water cooling. These techniques use convection, conduction, and radiation of heat energy.\nElectronic noise is defined[39] as unwanted disturbances superposed on a useful signal that tend to obscure its information content. Noise is not the same as signal distortion caused by a circuit. Noise is associated with all electronic circuits. Noise may be electromagnetically or thermally generated, which can be decreased by lowering the operating temperature of the circuit. Other types of noise, such as shot noise cannot be removed as they are due to limitations in physical properties.\nMany different methods of connecting components have been used over the years. For instance, early electronics often used point to point wiring with components attached to wooden breadboards to construct circuits. Cordwood construction and wire wrap were other methods used. Most modern-day electronics now use printed circuit boards made of materials such as FR-4 and FR-2. Modern PCBs are usually FR-4 epoxy boards with through hole or surface mount parts.[40] Electrical components are generally mounted to PCBs using through-hole or surface mount.\nHealth and environmental concerns associated with electronics assembly have gained increased attention in recent years.\nThe electronics industry consists of various branches. The central driving force behind the entire electronics industry is the semiconductor industry,[41] which has annual sales of over $481 billion as of 2018.[42] The largest industry sector is e-commerce,[citation needed] which generated over $29 trillion in 2017.[43] The most widely manufactured electronic device is the metal-oxide-semiconductor field-effect transistor (MOSFET), with an estimated 13 sextillion MOSFETs having been manufactured between 1960 and 2018.[44] In the 1960s, U.S. manufacturers were unable to compete with Japanese companies such as Sony and Hitachi who could produce high-quality goods at lower prices. By the 1980s, however, U.S. manufacturers became the world leaders in semiconductor development and assembly.[45]\nHowever, during the 1990s and subsequently, the industry shifted overwhelmingly to East Asia (a process begun with the initial movement of microchip mass-production there in the 1970s), as plentiful, cheap labor, and increasing technological sophistication, became widely available there.[46][47]\nOver three decades, the United States' global share of semiconductor manufacturing capacity fell, from 37% in 1990, to 12% in 2022.[47] America's pre-eminent semiconductor manufacturer, Intel Corporation, fell far behind its subcontractor Taiwan Semiconductor Manufacturing Company (TSMC) in manufacturing technology.[46]\nBy that time, Taiwan had become the world's leading source of advanced semiconductors[47][46]—followed by South Korea, the United States, Japan, Singapore, and China.[47][46]\nImportant semiconductor industry facilities (which often are subsidiaries of a leading producer based elsewhere) also exist in Europe (notably the Netherlands), Southeast Asia, South America, and Israel.[46]\n- Index of electronics articles\n- Outline of electronics\n- Atomtronics\n- Audio engineering\n- Biodegradable electronics\n- Broadcast engineering\n- Computer engineering\n- Electronics and Computer Engineering\n- Electronics engineering\n- Electronics engineering technology\n- Fuzzy electronics\n- Go-box\n- Marine electronics\n- Photonics\n- Robotics\n- française, Académie. \"électronique | Dictionnaire de l'Académie française | 9e édition\". www.dictionnaire-academie.fr (in French). Retrieved 26 May 2024.\n- \"Definition of ELECTRONICS\". www.merriam-webster.com. 21 May 2024. Retrieved 26 May 2024.\n- IEEE. ''IEEE Dictionary of Electrical and Electronics Terms''. Wiley. ISBN 978-0-471-42806-0\n- Brown, Stephen; Vranesic, Zvonko (2008). ''Fundamentals of Digital Logic''. McGraw Hill. ISBN 978-0-07-714422-7\n- \"Urvater der Kommunikationsgesellschaft: Ferdinand Braun – Student und Professor in Marburg – kam vor 150 Jahren zur Welt\" [Forefather of the communications society: Ferdinand Braun – student and professor in Marburg – was born 150 years ago] (PDF) (in German). Philipps-Universität Marburg. 17 December 2007. Retrieved 5 September 2025.\n- \"This Month in Physics History - October 1897: The Discovery of the Electron\". American Physical Society. Archived from the original on 19 September 2018. Retrieved 19 September 2018.\n- Guarnieri, M. (2012). \"The age of vacuum tubes: Early devices and the rise of radio communications\". IEEE Industrial Electronics Magazine 6 (1): 41–43. doi:10.1109/MIE.2012.2182822.\n- Guarnieri, M. (2012). \"The age of vacuum tubes: Early devices and the rise of radio communications\". IEEE Ind. Electron. Mag. 6 (1): 41–43. Bibcode:2012IIEM....6a..41G. doi:10.1109/MIE.2012.2182822. S2CID 23351454.\n- \"1947: Invention of the Point-Contact Transistor\". Computer History Museum. Archived from the original on 30 September 2021. Retrieved 10 August 2019.\n- \"1947: Invention of the Point-Contact Transistor\". Computer History Museum. Archived 30 September 2021.\n- Sōgo Okamura (1994). History of Electron Tubes. IOS Press. p. 5. ISBN 978-9051991451. Archived from the original on 31 December 2013. Retrieved 5 December 2012.\n- Bashe, Charles J.; et al. (1986). IBM's Early Computers. MIT. p. 386. ISBN 978-0262022255.\n- Pugh, Emerson W.; Johnson, Lyle R.; Palmer, John H. (1991). IBM's 360 and early 370 systems. MIT Press. p. 34. ISBN 978-0262161237.\n- Moskowitz, Sanford L. (2016). Advanced Materials Innovation: Managing Global Technology in the 21st century. John Wiley & Sons. p. 168. ISBN 978-0470508923. Archived from the original on 5 November 2020. Retrieved 22 August 2019.\n- Huff, Howard; Riordan, Michael (1 September 2007). \"Frosch and Derick: Fifty Years Later (Foreword)\". The Electrochemical Society Interface. 16 (3): 29. doi:10.1149/2.F02073IF. ISSN 1064-8208.\n- Frosch, C. J.; Derick, L (1957). \"Surface Protection and Selective Masking during Diffusion in Silicon\". Journal of the Electrochemical Society. 104 (9): 547. doi:10.1149/1.2428650.\n- Kahng, Dawon (March 1991) [Orig. pub. 1961]. \"Silicon-Silicon Dioxide Surface Device\". In Sze, Simon Min (ed.). Semiconductor Devices: Pioneering Papers (2nd ed.). World Scientific. pp. 583–596. doi:10.1142/1087. ISBN 978-981-02-0209-5.\n- Lojek, Bo (2007). History of Semiconductor Engineering. Berlin, Heidelberg: Springer-Verlag Berlin Heidelberg. p. 321. ISBN 978-3-540-34258-8.\n- Ligenza, J.R.; Spitzer, W.G. (1960). \"The mechanisms for silicon oxidation in steam and oxygen\". Journal of Physics and Chemistry of Solids. 14: 131–136. Bibcode:1960JPCS...14..131L. doi:10.1016/0022-3697(60)90219-5.\n- Lojek, Bo (2007). History of Semiconductor Engineering. Springer Science & Business Media. p. 120. ISBN 9783540342588.\n- Grant, Duncan A.; Gowar, John (1989). Power MOSFETS: Theory and Applications. Wiley. ISBN 978-0-471-82867-9\n- Motoyoshi, M. (2009). \"Through-Silicon Via (TSV)\". Proceedings of the IEEE. 97 (1): 43–48. doi:10.1109/JPROC.2008.2007462. ISSN 0018-9219. S2CID 29105721.\n- \"Tortoise of Transistors Wins the Race – CHM Revolution\". Computer History Museum. Archived from the original on 10 March 2020. Retrieved 22 July 2019.\n- \"Transistors Keep Moore's Law Alive\". EETimes. 12 December 2018. Archived from the original on 24 September 2019. Retrieved 18 July 2019.\n- \"The History of the Integrated Circuit\". NobelPrize.org. Archived 29 June 2018.\n- Chan, Yi-Jen (1992). Studies of InAIAs/InGaAs and GaInP/GaAs heterostructure FET's for high speed applications. University of Michigan. p. 1. Archived from the original on 20 December 2019. Retrieved 10 August 2019.\nThe Si MOSFET has revolutionized the electronics industry and as a result impacts our daily lives in almost every conceivable way.\n- Grant, Duncan Andrew; Gowar, John (1989). Power MOSFETS: theory and applications. Wiley. p. 1. ISBN 978-0471828679. Archived from the original on 30 July 2020. Retrieved 10 August 2019.\nThe metal–oxide–semiconductor field-effect transistor (MOSFET) is the most commonly used active device in the very large-scale integration of digital integrated circuits (VLSI). During the 1970s these components revolutionized electronic signal processing, control systems and computers.\n- \"Who Invented the Transistor?\". Computer History Museum. 4 December 2013. Archived from the original on 13 December 2013. Retrieved 20 July 2019.\n- Golio, Mike; Golio, Janet (2018). RF and Microwave Passive and Active Technologies. CRC Press. p. 18-2. ISBN 978-1420006728. Archived from the original on 31 July 2020. Retrieved 10 August 2019.\n- Daniels, Lee A. (28 May 1992). \"Dr. Dawon Kahng, 61, Inventor in Field of Solid-State Electronics\". The New York Times. Archived from the original on 26 July 2020. Retrieved 1 April 2017.\n- Colinge, Jean-Pierre; Greer, James C. (2016). Nanowire Transistors: Physics of Devices and Materials in One Dimension. Cambridge University Press. p. 2. ISBN 978-1107052406. Archived from the original on 17 March 2020. Retrieved 17 September 2019.\n- \"The History of the Integrated Circuit\". Nobelprize.org. Archived from the original on 29 June 2018. Retrieved 21 April 2012.\n- \"Intel to deliver first computer chip with two billion transistors\". The Sydney Morning Herald. 5 February 2008. Archived from the original on 12 August 2022. Retrieved 12 August 2022.\n- Bose, Bimal K, ed. (1996). Power Electronics and Variable Frequency Drives: Technology and Applications. Wiley Online Library. doi:10.1002/9780470547113. ISBN 978-0470547113. S2CID 107126716.\n- Brown, Stephen; Vranesic, Zvonko (2008). Fundamentals of Digital Logic (e-book). McGraw Hill. ISBN 978-0077144227. Archived from the original on 4 October 2022. Retrieved 12 August 2022.\n- Knuth, Donald (1980). The Art of Computer Programming. Vol. 2: Seminumerical Algorithms (2nd ed.). Addison-Wesley. pp. 190–192. ISBN 0201038226.\n- J. Lienig; H. Bruemmer (2017). Fundamentals of Electronic Systems Design. Springer International Publishing. p. 1. doi:10.1007/978-3-319-55840-0. ISBN 978-3319558394.\n- \"PCB design made easy for every engineer\". Autodesk. 19 April 2023. Archived from the original on 19 April 2023. Retrieved 19 April 2023.\n- IEEE Dictionary of Electrical and Electronics Terms ISBN 978-0471428060\n- \"PCB design made easy for every engineer\". Autodesk. Archived 19 April 2023.\n- \"Annual Semiconductor Sales Increase 21.6 Percent, Top $400 Billion for First Time\". Semiconductor Industry Association. 5 February 2018. Archived from the original on 30 January 2021. Retrieved 11 October 2019.\n- \"Semiconductors – the Next Wave\" (PDF). Deloitte. April 2019. Archived from the original (PDF) on 11 October 2019. Retrieved 11 October 2019.\n- \"Global e-Commerce sales surged to $29 trillion\". United Nations Conference on Trade and Development. 29 March 2019. Archived from the original on 21 October 2019. Retrieved 13 October 2019.\n- \"13 Sextillion & Counting: The Long & Winding Road to the Most Frequently Manufactured Human Artifact in History\". Computer History Museum. 2 April 2018. Archived from the original on 28 July 2019. Retrieved 28 July 2019.\n- \"Consumer electronics industry in the year 1960s\". NaTechnology. Archived from the original on 27 January 2021. Retrieved 2 February 2021.\n- Shih, Willy (Harvard Business School): \"Congress Is Giving Billions To The U.S. Semiconductor Industry. Will It Ease Chip Shortages?\" Archived 3 July 2023 at the Wayback Machine transcript, August 3, 2022, Forbes, retrieved September 12, 2022\n- Lewis, James Andrew: \"Strengthening a Transnational Semiconductor Industry\", Archived 13 September 2022 at the Wayback Machine June 2, 2022, Center for Strategic and International Studies (CSIS), retrieved September 12, 2022\n- Horowitz, Paul; Hill, Winfield (1980). The Art of Electronics. Cambridge University Press. ISBN 978-0521370950.\n- Mims, Forrest M. (2003). Getting Started in Electronics. Master Publishing, Incorporated. ISBN 978-0-945053-28-6.\n- Navy 1998 Navy Electricity and Electronics Training Series (NEETS) Archived 2 November 2004 at the Wayback Machine\n- DOE 1998 Electrical Science, Fundamentals Handbook, 4 vols.",
    "energy industry": "The energy industry refers to all of the industries involved in the production and sale of energy, including fuel extraction, manufacturing, refining and distribution. Modern society consumes large amounts of fuel, and the energy industry is a crucial part of the infrastructure and maintenance of society in almost all countries.\nIn particular, the energy industry comprises:\n- the fossil fuel industries, which include petroleum industries (oil companies, petroleum refiners, fuel transport and end-user sales at gas stations), coal industries (extraction and processing), and the natural gas industries (natural gas extraction, and coal gas manufacture, as well as distribution and sales);\n- the electrical power industry, including electricity generation, electric power distribution, and sales;\n- the nuclear power industry;\n- the renewable energy industry, comprising alternative energy and sustainable energy companies, including those involved in hydroelectric power, wind power, and solar power generation, and the manufacture, distribution and sale of alternative fuels; and,\n- traditional energy industry based on the collection and distribution of firewood, the use of which, for cooking and heating, is particularly common in poorer countries.\nThe increased dependence during the 20th century on carbon-emitting energy sources, such as fossil fuels, and carbon-emitting renewables, such as biomass, means that the energy industry has frequently contributed to pollution and environmental impacts on the economy. Until recently, fossil fuels were the primary source of energy generation in most parts of the world and are a significant contributor to global warming and pollution. Many economies are investing in renewable and sustainable energy to limit global warming and reduce air pollution.\nThe use of energy has been a key in the development of human societies by helping it to control and adapt to the environment. Managing the use of energy is inevitable in any functional society. In the industrialized world the development of energy resources has become essential for agriculture, transportation, waste collection, information technology, communications that have become prerequisites of a developed society. The increasing use of energy since the Industrial Revolution has also brought with it a number of serious problems, some of which, such as global warming, present potentially grave risks to the world.[1]\nIn some industries, the word energy is used as a synonym for energy resources, which refer to substances like fuels, petroleum products, and electricity in general. This is because a significant portion of the energy contained in these resources can easily be extracted to serve a useful purpose. After a useful process has taken place, the total energy is conserved. Still, the resource itself is not conserved since a process usually transforms the energy into unusable forms (such as unnecessary or excess heat).\nEver since humanity discovered various energy resources available in nature, it has been inventing devices, known as machines, that make life more comfortable by using energy resources. Thus, although primitive man knew the utility of fire to cook food, the invention of devices like gas burners and microwave ovens led to additional ways of how energy can be used. The trend is the same in any other field of social activity, be it the construction of social infrastructure, manufacturing of fabrics for covering, porting, printing, decorating, for example, textiles, air conditioning, communication of information, or for moving people and goods (automobiles).\nProduction and consumption of energy resources is very important to the global economy. All economic activity requires energy resources, whether to manufacture goods, provide transportation, run computers and other machines.\nWidespread demand for energy may encourage competing energy utilities and the formation of retail energy markets. Note the presence of the \"Energy Marketing and Customer Service\" (EMACS) sub-sector.[2]\nThe energy sector accounts for 4.6% of outstanding leveraged loans, compared with 3.1% a decade ago, while energy bonds make up 15.7% of the $1.3 trillion junk bond market, up from 4.3% over the same period.[3]\nSince the cost of energy has become a significant factor in the performance of societies' economies, the management of energy resources has become crucial. Energy management involves using the available energy resources more effectively, that is, with minimum incremental costs. Simple management techniques can often save energy expenditures without incorporating fresh technology.[4] Energy management is most often the practice of using energy more efficiently by eliminating energy wastage or balancing justifiable energy demand with appropriate energy supply. The process couples energy awareness with energy conservation.\nThe United Nations developed the International Standard Industrial Classification, which is a list of economic and social classifications.[5] There is no distinct classification for an energy industry, because the classification system is based on activities, products, and expenditures according to purpose.[6]\nCountries in North America use the North American Industry Classification System (NAICS). The NAICS sectors No. 21 and No. 22 (mining and utilities) might roughly define the energy industry in North America. This classification is used by the U.S. Securities and Exchange Commission.\nThe Global Industry Classification Standard used by Morgan Stanley define the energy industry as comprising companies primarily working with oil, gas, coal and consumable fuels, excluding companies working with certain industrial gases.[7] Add also to expand this section: Dow Jones Industrial Average[8]\nGovernment encouragement in the form of subsidies and tax incentives for energy-conservation efforts has increasingly fostered the view of conservation as a major function of the energy industry: saving an amount of energy provides economic benefits almost identical to generating that same amount of energy. This is compounded by the fact that the economics of delivering energy tend to be priced for capacity as opposed to average usage. One of the purposes of a smart grid infrastructure is to smooth out demand so that capacity and demand curves align more closely. Some parts of the energy industry generate considerable pollution, including toxic and greenhouse gases from fuel combustion, nuclear waste from the generation of nuclear power, and oil spillages as a result of petroleum extraction. Government regulations to internalize these externalities form an increasing part of doing business, and the trading of carbon credits and pollution credits on the free market may also result in energy-saving and pollution-control measures becoming even more important to energy providers.\nConsumption of energy resources, (e.g. turning on a light) requires resources and has an effect on the environment. Many electric power plants burn coal, oil or natural gas to generate electricity for energy needs. While burning these fossil fuels produces a readily available and instantaneous supply of electricity, it also generates air pollutants including carbon dioxide (CO2), sulfur dioxide and trioxide (SOx) and nitrogen oxides (NOx). Carbon dioxide is an important greenhouse gas, known to be responsible, along with methane, nitrous oxide, and fluorinated gases, for the rapid increase in global warming since the Industrial Revolution. In the 20th century, global temperature records are significantly higher than temperature records from thousands of years ago, taken from ice cores in Arctic regions. Burning fossil fuels for electricity generation also releases trace metals such as beryllium, cadmium, chromium, copper, manganese, mercury, nickel, and silver into the environment, which also act as pollutants.\nThe large-scale use of renewable energy technologies would \"greatly mitigate or eliminate a wide range of environmental and human health impacts of energy use\".[9][10] Renewable energy technologies include biofuels, solar heating and cooling, hydroelectric power, solar power, and wind power. Energy conservation and the efficient use of energy would also help.\nIn addition it is argued that there is also the potential to develop a more efficient energy sector. This can be done by:[11]\n- Fuel switching in the power sector from coal to natural gas;\n- Power plant optimisation and other measures to improve the efficiency of existing CCGT power plants;\n- Combined heat and power (CHP), from micro-scale residential to large-scale industrial;\n- Waste heat recovery\nBest available technology (BAT) offers supply-side efficiency levels far higher than global averages. The relative benefits of gas compared to coal are influenced by the development of increasingly efficient energy production methods. According to an impact assessment carried out for the European Commission, the levels of energy efficiency of coal-fired plants built have now increased to 46–49% efficiency rates, as compared to coals plants built before the 1990s (32–40%).[12] However, at the same time gas can reach 58–59% efficiency levels with the best available technology.[12] Meanwhile, combined heat and power can offer efficiency rates of 80–90%.[12]\nSince energy now plays an essential role in industrial societies, the ownership and control of energy resources plays an increasing role in politics. At the national level, governments seek to influence the sharing (distribution) of energy resources among various sections of the society through pricing mechanisms; or even who owns resources within their borders. They may also seek to influence the use of energy by individuals and business in an attempt to tackle environmental issues.\nThe most recent international political controversy regarding energy resources is in the context of the Iraq Wars. Some political analysts maintain that the hidden reason for both 1991 and 2003 wars can be traced to strategic control of international energy resources.[13] Others counter this analysis with the numbers related to its economics. According to the latter group of analysts, U.S. has spent about $336 billion in Iraq[14] as compared with a background current value of $25 billion per year budget for the entire U.S. oil import dependence[15]\nEnergy policy is the manner in which a given entity (often governmental) has decided to address issues of energy development, including energy production, distribution and consumption. The attributes of energy policy may include legislation, international treaties, incentives to investment, guidelines for energy conservation, taxation and other public policy techniques.\nEnergy security is the intersection of national security and the availability of natural resources for energy consumption. Access to cheap energy has become essential to the functioning of modern economies. However, the uneven distribution of energy supplies among countries has led to significant vulnerabilities. Threats to energy security include the political instability of several energy producing countries, the manipulation of energy supplies, the competition over energy sources, attacks on supply infrastructure, as well as accidents, natural disasters, the funding to foreign dictators, rising terrorism, and dominant countries reliance to the foreign oil supply.[16] The limited supplies, uneven distribution, and rising costs of fossil fuels, such as oil and gas, create a need to change to more sustainable energy sources in the foreseeable future. With as much dependence that the U.S. currently has for oil and with the peaking limits of oil production; economies and societies will begin to feel the decline in the resource that we have become dependent upon. Energy security has become one of the leading issues in the world today as oil and other resources have become as vital to the world's people. But with oil production rates decreasing and oil production peak nearing, the world has come to protect what resources we have left. With new advancements in renewable resources, less pressure has been put on companies that produce the world's oil; these resources are geothermal, solar power, wind power, and hydroelectric. Although these are not all the current and possible options for the world to turn to as the oil depletes, the most critical issue is protecting these vital resources from future threats. These new resources will become more valuable as the price of exporting and importing oil will increase due to increased demand.\nProducing energy to sustain human needs is an essential social activity, and a great deal of effort goes into the activity. While most of such effort is limited towards increasing the production of electricity and oil, newer ways of producing usable energy resources from the available energy resources are being explored. One such effort is to explore means of producing hydrogen fuel from water. Though hydrogen use is environmentally friendly, its production requires energy and existing technologies to make it, are not very efficient. Research is underway to explore enzymatic decomposition of biomass.[17]\nOther forms of conventional energy resources are also being used in new ways. Coal gasification and liquefaction are recent technologies that are becoming attractive after the realization that oil reserves, at present consumption rates, may be rather short lived. See alternative fuels.\nEnergy is the subject of significant research activities globally. For example, the UK Energy Research Centre is the focal point for UK energy research while the European Union has many technology programmes as well as a platform for engaging social science and humanities within energy research.[18]\nAll societies require materials and food to be transported over distances, generally against some force of friction. Since application of force over distance requires the presence of a source of usable energy, such sources are of great worth in society.\nWhile energy resources are an essential ingredient for all modes of transportation in society, the transportation of energy resources is becoming equally important. Energy resources are frequently located far from the place where they are consumed. Therefore, their transportation is always in question. Some energy resources like liquid or gaseous fuels are transported using tankers or pipelines, while electricity transportation invariably requires a network of grid cables. The transportation of energy, whether by tanker, pipeline, or transmission line, poses challenges for scientists and engineers, policy makers, and economists to make it more risk-free and efficient.\nEconomic and political instability can lead to an energy crisis. Notable oil crises are the 1973 oil crisis and the 1979 oil crisis. The advent of peak oil, the point in time when the maximum rate of global petroleum extraction is reached, will likely precipitate another energy crisis.\nBetween 1985 and 2018 there had been around 69,932 deals in the energy sector. This cumulates to an overall value of US$9,578bn. The most active year was 2010 with about 3.761 deals. In terms of value 2007 was the strongest year (US$684bn), which was followed by a steep decline until 2009 (−55.8%).[19]\nHere is a list of the top 10 deals in history in the energy sector:\n| Date Announced | Acquiror Name | Acquiror Mid Industry | Acquiror Nation | Target Name | Target Mid Industry | Target Nation | Value of Transaction ($mil) |\n|---|---|---|---|---|---|---|---|\n| 12/01/1998 | Exxon Corp | Oil & Gas | United States | Mobil Corp | Oil & Gas | United States | 78,945.79 |\n| 10/28/2004 | Royal Dutch Petroleum Co | Oil & Gas | Netherlands | Shell Transport & Trading Co | Oil & Gas | United Kingdom | 74,558.58 |\n| 04/08/2015 | Royal Dutch Shell PLC | Petrochemicals | Netherlands | BG Group PLC | Oil & Gas | United Kingdom | 69,445.02 |\n| 02/25/2006 | Gaz de France SA | Oil & Gas | France | Suez SA | Power | France | 60,856.45 |\n| 07/05/1999 | Total Fina SA | Oil & Gas | France | Elf Aquitaine | Oil & Gas | France | 50,070.05 |\n| 08/11/1998 | British Petroleum Co PLC | Oil & Gas | United Kingdom | Amoco Corp | Oil & Gas | United States | 48,174.09 |\n| 09/01/2010 | Petrobras | Oil & Gas | Brazil | Brazil-Oil & Gas Blocks | Oil & Gas | Brazil | 42,877.03 |\n| 10/16/2000 | Chevron Corp | Petrochemicals | United States | Texaco Inc | Petrochemicals | United States | 42,872.30 |\n| 06/20/2000 | Vivendi SA | Water and Waste Management | France | Seagram Co Ltd | Motion Pictures / Audio Visual | Canada | 40,428.19 |\n| 12/14/2009 | Exxon Mobil Corp | Petrochemicals | United States | XTO Energy Inc | Oil & Gas | United States | 40,298.14 |\n- Climate lawsuit\n- Energy accounting\n- Energy quality\n- Energy system – the interpretation of the energy sector in system terms\n- Energy transformation\n- Economics of climate change\n- Hydrogen economy\n- List of books about the energy industry\n- List of countries by energy consumption per capita\n- List of energy resources\n- List of largest energy companies\n- Renewable energy\n- Stranded asset\n- World energy consumption\n- Worldwide energy supply\n- \"If the energy sector is to tackle climate change, it must also think about water – Analysis\". IEA. 23 March 2020. Archived from the original on 7 November 2021. Retrieved 7 November 2021.\n- Allen, J (1998). \"Emacs ushers in customer-, marketing-driven industry\". Electrical World. 212 (3): 41–43. ISSN 0013-4457. Archived from the original on 3 July 2017. Retrieved 13 October 2010.\nThe Energy Marketing and Customer Service (EMACS) conference/exhibition focuses exclusively on the selling of energy in competitive retail markets.\n- Alloway, Tracy (26 November 2014). \"Oil price fall starts to weigh on banks\". ft.com. Archived from the original on 29 November 2014. Retrieved 27 November 2014.\n- Energy Management :: MEPoL Archived 25 March 2008 at the Wayback Machine\n- United Nations economic and social classifications Archived 24 April 2007 at the Wayback Machine Accessed 6 April 2007.\n- United Nations Available Classifications Archived 10 April 2007 at the Wayback Machine Accessed 6 April 2007.\n- MSCI-Barra GICS Tables Archived 10 June 2007 at the Wayback Machine Accessed 6 April 2007.\n- \"Industry Classification Benchmark for Dow Jones Indexes (United States) and FTSE Indexes (United Kingdom)\" (PDF). Archived (PDF) from the original on 22 April 2007. Retrieved 7 April 2007.\n- Jacobson, Mark Z.; Delucchi, Mark A. (2010). \"Providing all Global Energy with Wind, Water, and Solar Power, Part I: Technologies, Energy Resources, Quantities and Areas of Infrastructure, and Materials\" (PDF). Energy policy.[permanent dead link]\n- Kuli Aye. \"Energie vergelijken switchen Energieleverancier top 10\". Energie vergelijken (in Dutch). Archived from the original on 29 October 2016. Retrieved 28 October 2016.\n- European Movement for Efficient Energy 2011. Energy efficient solutions for the conservation of energy. Retrieved: 11 October 2011 18:52\n- European Commission 2011. Impact Assessment Accompanying the document Directive of the European Parliament and of the Council on energy efficiency and amending and subsequently repealing Directives 2004/8/EC and 2006/32/EC Archived 17 January 2012 at the Wayback Machine. p. 106 Retrieved 11 October 2011 19:01\n- \"The Peakist » Oil and Empire – the backstory to the invasion of Iraq\". Archived from the original on 19 April 2012. Retrieved 6 June 2011.\n- The War in Iraq Costs Archived 12 October 2005 at the Wayback Machine, A running total of the U.S. taxpayer cost to date of the Iraq War. The number is based on Congressional appropriations.\n- Gibson Consulting Archived 12 September 2008 at the Wayback Machine US OIL DEMAND, 2004.\n- \"Power plays: Energy and Australia's security\". Aspi.org.au. Archived from the original on 11 August 2010. Retrieved 1 June 2010.\n- \"Virginia Tech Deans' Task Force on Energy Security and Sustainability\". Archived from the original on 8 April 2011. Retrieved 6 June 2011.\n- \"H2020 SHAPE-Energy\". Archived from the original on 27 February 2017. Retrieved 27 February 2017.\n- \"M&A by Industries – Institute for Mergers, Acquisitions and Alliances (IMAA)\". Institute for Mergers, Acquisitions and Alliances (IMAA). Archived from the original on 3 November 2020. Retrieved 27 February 2018.\n- Armstrong, Robert C., Catherine Wolfram, Robert Gross, Nathan S. Lewis, and M.V. Ramana et al. The Frontiers of Energy, Nature Energy, Vol 1, 11 January 2016.\n- Bradley, Robert (2004). Energy: The Master Resource. Kendall Hunt. p. 252. ISBN 978-0757511691.\n- Fouquet, Roger, and Peter J.G. Pearson. \"Seven Centuries of Energy Services: The Price and Use of Light in the United Kingdom (1300-2000)\". Energy Journal 27.1 (2006).\n- Gales, Ben, et al. \"North versus South: Energy transition and energy intensity in Europe over 200 years\". European Review of Economic History 11.2 (2007): 219–253.\n- Nye, David E. Consuming power: A social history of American energies (MIT Press, 1999)\n- Pratt, Joseph A. Exxon: Transforming Energy, 1973–2005 (2013) 600pp\n- Smil, Vaclav (1994). Energy in World History. Westview Press. ISBN 978-0-8133-1902-5.\n- Stern, David I. \"The role of energy in economic growth\". Annals of the New York Academy of Sciences 1219.1 (2011): 26–51.\n- Warr, Benjamin, et al. \"Energy use and economic development: A comparative analysis of useful work supply in Austria, Japan, the United Kingdom and the US during 100 years of economic growth\". Ecological Economics 69.10 (2010): 1904–1917.\n- Yergin, Daniel (2011). The Quest: Energy, Security, and the Remaking of the Modern World. Penguin. p. 816. ISBN 978-1594202834.",
    "enterprise software": "Enterprise software, also known as enterprise application software (EAS), is computer software that has been specially developed or adapted to meet the complex requirements of larger organizations. Enterprise software is an integral part of a computer-based information system, handling a number of business operations, for example to enhance business and management reporting tasks, or support production operations and back office functions. Enterprise systems must process information at a relatively high speed.\nServices provided by enterprise software are typically business-oriented tools. As companies and other organizations have similar departments and systems, enterprise software is often available as a suite of customizable programs. Function-specific enterprise software uses include database management, customer relationship management, supply chain management and business process management.[1]\nThe term enterprise software is used in industry, and business research publications, but is not common in computer science. The term was widely popularized in the early 1990s by major software vendors in conjunction with licensing deals with the show Star Trek [2][dubious – discuss] In academic literature no coherent definition can be found. The computer historian Martin Campbell-Kelly contemplated in 2003 that the growth of the corporate software industry is not well understood. Enterprise application software (EAS) is recognized among academics as enterprise software components and modules which support only a particular business function. These EAS software components and modules can interoperate, so that cross-functional or inter-organizational enterprise systems can be built up. In this context the industry may speak of middleware. Software that is primarily sold to consumers, is not called enterprise software.[3]\nAccording to Martin Fowler, \"Enterprise applications are about the display, manipulation, and storage of large amounts of often complex data and the support or automation of business processes with that data.\"[4]\nEnterprise application software is application software that performs business functions such as order processing, procurement, production scheduling, customer information management, energy management, and accounting.\n| Type | software package |\n|---|\nEnterprise systems (ES) are large-scale enterprise software packages which support a range of business processes, information flows, reporting, and data analytics in complex organizations. While ES are generally packaged enterprise application software (PEAS) systems,[5] they can also be bespoke, custom-developed systems created to support a specific organization's needs. Types of enterprise system include:\n- enterprise resources planning (ERP) systems,\n- enterprise planning systems, and\n- customer relationship management software.\nAlthough data warehousing or business intelligence systems are enterprise-wide packaged application software often sold by ES vendors, since they do not directly support execution of business processes, they are often excluded from the term.\nEnterprise systems are built on software platforms, such as SAP's NetWeaver and Oracle's Fusion, and databases.\nFrom a hardware perspective, enterprise systems are the servers, storage and associated software that large businesses use as the foundation for their IT infrastructure. These systems are designed to manage large volumes of critical data and thus are typically designed to provide high levels of transaction performance and data security.[6]\nThe \"seemingly boundless complexity\" of enterprise systems has been criticised, and arguments maintained for deploying discrete systems for specific business tasks. Cynthia Rettig, an American businesswoman, has argued that \"the concept of a single monolithic system [has] failed for many companies\".[7]\nEnterprise software can be categorized by business function. Each type of enterprise application can be considered a \"system\" due to the integration with a firm's business processes.[8] Categories of enterprise software may overlap due to this systemic interpretation. For example, IBM's business intelligence platform (Cognos), integrates with a predictive analytics platform (SPSS) and can obtain records from its database packages (Infosphere, DB2).\nCertain industry-standard product categories have emerged, and these are shown below:\n- Business intelligence (BI)\n- Business Process Management (BPM)\n- Content Management System (CMS)\n- Customer Relationship Management (CRM)\n- Database Management System (DBMS) - such as Master Data Management (MDM) and Data Warehousing (DW, DWH or EDW)\n- Enterprise Resource Planning (ERP)\n- Enterprise Asset Management (EAM)\n- Human Resource Management (HRM)\n- Knowledge Management (KM)\n- Low-code Development Platforms (LCDP)\n- Product Data Management (PDM)\n- Product Information Management (PIM)\n- Product Lifecycle Management (PLM)\n- Supply Chain Management (SCM)\n- Software Configuration Management (SCM) - such as Version Control System (VCS)\n- Networking and Information Security\n- Intrusion Detection Prevention (IDS) - and by extension Intrusion Prevention System (IPS)\n- Software Defined Networking (SDN) - including SD-WAN\n- Security Information Event Management (SIEM) - which can combine Security Information Management (SIM) and Security Event Management (SEM).\nOther types of software which do not fit into well-known standard categories, including backup software, billing management, and accounting software. Enterprise contract management software is used to bring all of an organisation's contractual commitments into a single system for holistic management and to avoid the variability and inefficiency inherent in manual contracting processes.[9]\n- Application Release Automation Software\n- Business informatics\n- Business software\n- Enterprise architecture\n- Enterprise forms automation\n- Enterprise planning system\n- Global Information Network Architecture\n- IBM Smarter Computing\n- Identity management\n- Identity management system\n- Information technology management\n- Integrated business planning\n- Management information system\n- Operational risk management\n- Retail software\n- Strategic information system\n- \"Management Information Systems Glossary of Terms\". Uganda Martyrs University. 27 March 2013. Archived from the original on 1 November 2021. Retrieved 3 November 2021.\n- Gilani, Aziz (March 8, 2020). \"How the information system industry became enterprise software\".\n- Thomas Otter (2019). Externalities and Enterprise Software: Helping and Hindering Legal Compliance. KIT Scientific Publishing. p. 16. ISBN 9783731509370.\n- Martin Fowler, \"Patterns of Enterprise Application Architecture\" (2002). Addison Wesley.\n- University of Melbourne, Enterprise Systems (ISYS90036), last updated 10 November 2023, accessed 30 November 2023\n- \"MES Relationship with Other Enterprise Systems\". statii. Archived from the original on 10 May 2016. Retrieved 10 May 2016.\n- Rettig, C., The Trouble With Enterprise Software, MIT Sloan Management Review, Fall 2007, Volume 49, No. 1, accessed 17 November 2023\n- \"What is enterprise application? A Word Definition From the Webopedia Computer Dictionary\". Webopedia.com. 7 May 2010. Archived from the original on 2013-06-20. Retrieved 2013-06-16.\n- Icertis, Inc., What is Enterprise Contract Management?, accessed 30 November 2023",
    "fast-moving consumer goods": "Fast-moving consumer goods (FMCG) are products that are sold quickly and at a relatively low cost. Examples include non-durable household goods such as packaged foods, beverages, toiletries, candies, cosmetics, over-the-counter drugs, dry goods, and other consumables.[1][2][3]\nFast-moving consumer goods have a high inventory turnover and are contrasted with specialty items, which have lower sales and higher inventory holding costs. Many retailers carry only FMCGs, particularly hypermarkets, big box stores, and warehouse club stores. Small convenience stores also stock fast-moving goods; the limited shelf space is filled with higher-turnover items.\nThey are also known as consumer packaged goods (CPG)[4] or convenience goods.\nThe following are the main characteristics of FMCGs:[1]\n- From the consumer perspective\n- Frequent purchases\n- Low engagement (little or no effort to choose the item)\n- Low prices\n- Short shelf life\n- Rapid consumption\n- From the marketer perspective\n- High volumes\n- Low contribution margins\n- Extensive distribution\n- High inventory turnover\nBetween 2009 and 2023, shelf space in the U.S. supercenters and supermarkets decreased by 5 and 3.3 percent, respectively. This reduction has intensified competition for shelf space among brands, as the number of products available has increased. Retailers often charge slotting fees to brands for product placement. While some well-established brands may avoid these fees, the average cost can range from $100 per item per store to significantly higher amounts.[5]\nWell-known CPG manufacturing companies include:[6]\n- Nestlé\n- Procter & Gamble\n- PepsiCo\n- Unilever\n- AB InBev\n- L’Oréal\n- Coca-Cola\n- Mondelez International\n- Kraft Heinz\n- Heineken\nConsumers in rural areas typically purchase goods from nearby towns and villages. A recent[when?] shift in consumer purchase behavior toward purchasing locally has prompted the need for better local promotional efforts to generate brand awareness in small towns. FMCGs play a large part in the economy, as they are inelastic products that touch every part of consumer life. Businesses that supply FMCGs to rural communities can help provide employment opportunities and reduce the cost of such products in those rural areas. For instance, FMCGs represent the fourth-largest sector in the Indian economy[7] and generate employment for more than three million people in downstream activities.[8]\n- Ramanuj Majumdar (2004). Product Management in India. PHI Learning. pp. 26–27. ISBN 978-81-203-1252-4. Archived from the original on 2023-07-01. Retrieved 2010-06-19.\n- Sean Brierley (2002). The Advertising Handbook (2nd, illustrated ed.). Routledge. p. 14. ISBN 978-0-415-24391-9.\n- Nellist, George (2022-10-06). \"By looking to nature, health products manufacturer Melaleuca is breaking barriers\". Digital Journal. Archived from the original on 2022-10-09. Retrieved 2022-10-09.\n- \"Consumer Goods Industry News, Research & Events\". Consumer Goods Technology. Retrieved 2024-10-21.\n- Williams, Jennifer (2024-08-14). \". The Wall Street Journal. Retrieved 2024-08-15.\n- Jesse; Jesse (2020-04-30). \"Top 10 Largest CPG Companies by Revenue in the World 2020 | CPG Industry Factsheet\". Bizvibe Blog. Archived from the original on 2022-10-09. Retrieved 2022-10-09.\n- \"Indian FMCG Industry Analysis\". ibef.org. Archived from the original on 2020-02-25. Retrieved 2020-02-25.\n- Singaravelu, Dr. K. (October 2013). \"Rural Consumer Behaviour on Fast Moving Consumer Goods\" (PDF). Archived (PDF) from the original on 2018-10-08. Retrieved 2018-10-07.",
    "film distribution": "Film distribution, also called film exhibition or film distribution and exhibition, is the process of making a film available for viewing to an audience. This is normally the task of a professional film distributor, who would determine the marketing and release strategy for the film, the media by which a film is to be exhibited or made available for viewing and other matters. The film may be exhibited directly to the public either through a movie theater, physical media (DVD, Blu-ray), digital download/transactional video on demand (VOD) (sale or rental), subscription VOD (e.g. Amazon Prime Video, Apple TV+, Disney+, Netflix) or television programs through broadcast syndication. For commercial projects, film distribution is usually accompanied by film promotion.\nInitially, all mass-marketed feature films were made to be shown in movie theaters. The identity of the first theater designed specifically for cinema is a matter of debate; candidates include Tally's Electric Theatre, established 1902 in Los Angeles,[1] and Pittsburgh's Nickelodeon, established 1905.[2] Thousands of such theaters were built or converted from existing facilities within a few years.[3] In the United States, these theaters came to be known as nickelodeons, because admission typically cost a nickel (five cents).\n| Rank | Country | Number of movies viewed |\n|---|---|---|\n| 1 | South Korea | 4.12 |\n| 2 | United States | 3.88 |\n| 3 | Australia | 3.75 |\n| 4 | France | 3.44 |\nDistributors license films to theaters granting the right to show the film for a theatrical rental rental fee. The movie theater pays an average of about 50-55% of its ticket sales to the movie studio, as film rental fees.[5] The actual percentage starts with a number higher than that and decreases as the duration of a film's showing continues, as an incentive to theaters to keep movies in the theater longer. However, today's barrage of highly marketed movies ensures that most movies are shown in first-run theaters for less than 8 weeks. There are a few movies every year that defy this rule, often limited-release movies that start in only a few theaters and actually grow their theater count through good word-of-mouth and reviews.[citation needed] According to a 2000 study by ABN AMRO, about 26% of Hollywood movie studios' worldwide income came from box office ticket sales; 46% came from VHS and DVD sales to consumers; and 28% came from television (broadcast, cable, and pay-per-view).[5]\nTypically, one film is the feature presentation (or feature film). Before the 1970s, there were \"double features\"; typically, a high-quality \"A picture\" rented by an independent theater for a lump sum, and a lower-quality \"B picture\" rented for a percentage of the gross receipts. Today, the bulk of the material shown before the feature film consists of previews for upcoming movies (also known as trailers) and paid advertisements.\nThe development of television has allowed films to be broadcast to larger audiences, usually after the film is no longer being shown in theaters. [citation needed] In 1971 U-Matic became the first magnetic format in which movies could be enjoyed in institutions outside the theatre. Later that year, the first videocassettes of movies became available to consumers to watch in their own homes.[6] Recording technology has since enabled consumers to rent or buy copies of films on home media such as VHS, DVD or Blu-ray. Older formats include Betamax, LaserDisc, Video CD, and other video disc formats. Internet downloads are also revenue sources for film production companies.\nPrior to the decline of the Motion Picture Patents Company (Edison Trust) in 1915, there were two main forms of film distribution: states rights and roadshow.[7]\nUnder the states rights system, films were sold on a local, territorial basis. The local salesperson would then play the film as often as they desired in an attempt to make as much profit as possible. Film copyright holders would sell rights of a movie directly to the theater or franchise salesperson,[8] typically on a foot-by-foot basis for 10 cents a foot.[7] Absent major studios or national theater franchises, this system was generally the best way to ensure national release of a film, particularly for shorter films. However, in terms of profitability, the states rights system was not the most effective way to screen feature-length films since the film's producers only made money on the initial sale of each film copy.\nThis method also made it possible to screen films of various genre which may be illegal in one state but legal in another.[8]\nWith the roadshow system, the producer would enter into an agreement with each theater, with priority given to large-seating and famous theaters. Money would be made via ticket sales. A movie's showing would be limited to drive up demand and to help create a sense of prestige.[7] Although this method helped increase film earnings for the producer, given its nature, a movie's release would only be at the regional level. Some of the first road show films were the Italian film Cabiria (1914) and the American The Birth of a Nation (1915).[9]\nThe standard release routine for a movie is regulated by a business model[10] called \"release windows\". The release windows system was first conceived in the 1970s as a strategy to keep different instances of a movie from competing with each other,[11] allowing the movie to take advantage of different markets (cinema, home video, TV, etc.) at different times.\nIn the standard process in 1979 in the United States, a movie was first released in movie theaters (theatrical window), then released to pay television for a short run before being re-released in movie theaters. It then returned to pay television before being made available for free-to-air television.[12]\nCurrently, after a movie is released in movie theaters, it is released on home video and VOD services. After an additional period, it is usually released to pay television, and then made available for free-to-air television.[13]\nA simultaneous release takes place when a movie is made available on many media (cinema, home video, VOD) at the same time or with very little difference in timing.\nSimultaneous releases offer great advantages to both consumers, who can choose the medium that most suits their needs, and production studios that only have to run one marketing campaign for all releases. The flip side, though, is that such distribution efforts are often regarded as experimental and thus do not receive substantial investment or promotion.\nSimultaneous release approaches have gained both praise, with investor Mark Cuban claiming movies should simultaneously be made available on all media allowing viewers to choose whether to see it at home or at the theater,[14] and disapproval, with director M. Night Shyamalan claiming it could potentially destroy the \"magic\" of moviegoing.[15]\nCinema owners can be affected if they have to share their opportunity window, especially at the beginning of the movie lifecycle, since, according to Disney, about 95% of all box office tickets for a film are sold within the first six weeks after initial distribution.[16]\nAmong relevant simultaneous release attempts are Bubble (2006) by Academy Award-winning director Steven Soderbergh, EMR (2005) by James Erskine & Danny McCullough, and The Road to Guantanamo (2006).\nBetween 1967 and 1974, the average theatrical window in the United States between a film's theatrical release and its showing on TV was just over five years.[17] By 1979, with the advent of pay television, films were normally made available to pay television in the United States one or two years after theatrical release.[12] With the advent of home video, the Cinema United in the United States passed a resolution in 1980 objecting to the proposed release of video cassettes at the same time as a film was released in theaters on the basis that their release would negatively impact theatrical revenues.[18] The window between theatrical release and free-to-air television in the United States at the time was normally three years.[19] By 1983 in the United States, the theatrical window before a film would be made available to other media, (at the time, firstly cable or pay TV) was around a year.[20] In France, with the rise of home video, a law was created to give a theatrical window of one year before a film was made available to home video with it then being available to pay television then free-to-air television two or three years later.[13] By 1985 in the United States, the theatrical window before a film was released on home video was normally four to six months, depending on the performance of the film at the box office.[21] Films in the US were then available for pay-per-view four months later[11] and, approximately two years after its theatrical release date, available for free-to-air television. The reduction in the theatrical window impacted subrun theaters that showed films after they had been screened by first-run theaters.[20] By 2019, the theatrical window had been reduced to an average of three months in the United States.[22] Major film studios reportedly pushed to shrink the theatrical window in an attempt to make up for the substantial losses in the DVD market suffered since the 2004 sales peak. These attempts have encountered the firm opposition of theater owners, whose profits depend solely upon attendance and therefore benefit from keeping a movie available on their screens.[10][23]\nIn early 2010, Disney announced it would be putting out the DVD and Blu-ray versions of Tim Burton's Alice in Wonderland 14 weeks after the movie's release date (instead of the then usual 17) in order to avoid competition from the 2010 World Cup.[10] In response to such statements, theater owners made threats not to show the movie on their screens,[24] but later reconsidered their position before the movie was released.[25] As of 2019, most major theater chains mandated an exclusivity window of 90 days before release on physical home video and rental availability, and 74–76 days before digital sell-through.[26]\nOn November 11, 2002, MGM, Paramount, Sony, Universal and Warner Bros. banded together to sell or rent movies online through a site called Movielink. In September 2006, Amazon.com and Apple began offering digital downloads, and Microsoft followed in November. YouTube joined in 2010, and Google Play in 2011. The recent trend has been for films to be released to Transactional Video on Demand before they come to DVD or Blu-Ray.\nAmazon Prime Video (originally Amazon Unbox) began showing movies on their subscription service from September 2006. Netflix switched over from its DVD rental service to a subscription video on demand service in early 2007. Apple TV+ and Disney+ were launched in November 2019, and show movies there.\nIn July 2010 Netflix secured a deal with Relativity Media in which the latter agreed to distribute a number of major movies to its subscription service before Pay TV.[27]\nProducers of relatively smaller-budget movies are also utilizing new release strategies. In 2009, the movie The House of the Devil premiered on VOD systems on October 1, and received a limited theatrical release one month later. In August 2010, it was announced that the movie Freakonomics would be released on video on demand on September 3, one month before its theatrical release. The British sci-fi movie Monsters has also undergone the same release timetable.[citation needed] After Netflix bought the worldwide distribution rights to Beasts of No Nation, the film was simultaneously released theatrically and online through its subscription video-on-demand (SVOD) service on October 16, 2015.[28]\nIn late 2018, five of the major Hollywood studios, including Universal and Warner Bros., identified that they were working on an agreement that would see certain movies receive a premium video-on-demand release within weeks of their theatrical premieres.[29] Nothing came out of these discussions, and after Disney bought 21st Century Fox, then Disney CEO Bob Iger stated that the theatrical window is working for the company and they had no plans to adjust it.[30]\nDuring the COVID-19 pandemic, all the major studios broke the theatrical window due to widespread theatre closings and made several films available on home media shortly after their theatrical debuts, such as Universal releasing The Invisible Man for rental 21 days after theatrical release, Sony and Columbia Pictures releasing Bloodshot for purchase 12 days after theatrical release,[31] Warner Bros. releasing The Way Back 18 days after theatrical release,[31] and Disney releasing Onward for purchase 15 days after theatrical release and streaming on Disney+ 29 days after theatrical release.[32][33] Sonic the Hedgehog, I Still Believe, and The Invisible Man also became available for in-home on-demand viewing after a theatrical run shorter than usual in the wake of widespread theatre closures.[32][31] As a result of the controversy surrounding the shrinking and even elimination of the theatrical window, in April 2020 AMC Theatres stated it would no longer screen films made by Universal Pictures after Trolls World Tour was made available for video on demand purchases simultaneous to its theatrical release.[34][35][36]\nIn November 2020, Warner Bros. announced it would release Wonder Woman 1984 simultaneously in theaters and on HBO Max, with theaters granted a higher 60% take of box office sales.[37] In December 2020, Warner Bros. announced it would release its entire 2021 theatrical slate simultaneously in theaters and on HBO Max for 30 days.[38] AMC Theatres CEO Adam Aron criticized the plan.[39]\nHowever, this would be short-lived, because in March 2021, it was announced that Warner Bros. would discontinue same-day releases in 2022, as part of an agreement the studio reached with Cineworld (who operates Regal Cinemas) and will instead use a 45-day exclusive release window for theaters.[40] Most recently,[when?] the parent company has reached an agreement for a 17-day and a 31-day theatrical window with Universal Pictures and has agreed on a deal with Walt Disney Pictures to show its movies in U.S. and U.K. theaters.[citation needed]\nSome films may be made specifically for non-theatrical formats, being released as a \"television movie\" or \"direct-to-video\" movie. The production values on these films are often considered to be of inferior quality compared to theatrical releases in similar genres; some films that are rejected by their own movie studios upon completion may be distributed through these markets.[citation needed]\nA direct-to-video release (also called \"straight-to-DVD\" or \"straight-to-Blu-ray\", depending on media used for film distribution) occurs when a movie is released on home video formats (such as VHS, DVD, etc.) without being released in theaters first, thereby not taking into consideration the \"theatrical window\".\nAs a result of strong DVD sales, straight-to-video releases achieved higher success and were noted in 2005 to have become a profitable market,[41][42] especially for independent filmmakers and distributors.[43]\nFeature films released directly to YouTube or other streaming platforms include: Zeitgeist: The Movie (2007), The Cult of Sincerity (2008), Home (2009), Life in a Day (2011) and Eyes and Ears of God: Video Surveillance of Sudan (2012).\n- Counterprogramming (film distribution)\n- Bel Air Circuit\n- Blu-ray\n- Digital distribution\n- Direct-to-video\n- DVD-Video\n- Film distributor\n- \"Tally's Electric Theatre\". Cinema Treasures. Retrieved 11 August 2010.\n- McNulty, Timothy (2005-06-19). \"You saw it here first: Pittsburgh's Nickelodeon introduced the moving picture theater to the masses in 1905\". Pittsburgh Post-Gazette. Retrieved 2007-01-25.\n- \"Pre-Nickelodeon/ Nickelodeon\". A Theater Near You: Washington Theater Memorabilia from the collection of Robert Headley. University of Maryland Special Collections. Archived from the original on 30 July 2012. Retrieved 23 August 2013.\n- \"Koreans are No. 1 moviegoers in the world\". The Korea Times. Archived from the original on 2014-05-05. Retrieved 2014-06-29.\n- \"PBS Frontline: The Monster that Ate Hollywood: Anatomy of a Monster: Now Playing ... And playing ... And playing ...\" pbs.org. Retrieved June 23, 2007.\n- \"Timeline/Fun Facts,\" Broadcasting & Cable, Nov. 21, 2011.\n- J.A. Aberdeen (2005). \"The Early Film Business - Distribution: States Rights or Road Show\". Cobblestone Entertainment. Retrieved March 9, 2015.\n- Hall, Sheldon; Neale, Stephen (2010). Epics, Spectacles, and Blockbusters: A Hollywood History. Wayne State University Press. p. 24. ISBN 9780814330081. Retrieved March 9, 2015.\n- Holston, Kim R. (2012). Movie Roadshows: A History and Filmography of Reserved-Seat Limited Showings, 1911-1973. McFarland. p. 9. ISBN 9780786460625. Retrieved March 9, 2015.\n- Ethan Smith; Lauren Cathode (12 February 2010). \"Movie Studios Push to Unlock VHS Release Dates\". Wall Street Journal.[permanent dead link]\n- \"Hollywood's death spiral\". Slate Magazine. 25 July 2005.\n- \"Pay-Cable Men Assurance To Theatres: \"Don't Worry\"Variety. February 28, 1979. p. 17.\n- Monet, Jack (May 1, 1985). \"French Exhibs Spur Seizures Of HV Titles As Vid Battle Continues\". Daily Variety. p. 8.\n- \"Mark Cuban's distribution revolution\". Slate Magazine. 24 October 2005.\n- \"Director Warns of Big Screens' Extinction\". Los Angeles Times. 28 October 2005. Archived from the original on January 27, 2013. Retrieved April 20, 2020.\n- \"DVDS of films to be sold 3 months after cinema release\". The Telegraph. 19 February 2010. Archived from the original on 2022-01-11.\n- \"Ask FCC To Ban Theatre Pix On TV Til Cable Gets 1st Crack\". Variety. October 9, 1974. p. 57.\n- Gelman, Morrie (October 8, 1980). \"Hirschfield: Stake In New Media Crucial\". Variety. p. 5.\n- Fabrikant, Geri (April 16, 1980). \"NBC Pays $5 Mil For Fox' 'Breaking Away' In Hopes Of Bolstering Its Ratings\". Daily Variety. p. 1.\n- Greenberg, James (October 25, 1983). \"Exhibs Eyeing Future\". Daily Variety. p. 182.\n- \"U.S. Suppliers Irked By Ruling On HV Window\". Daily Variety. July 16, 1985. p. 1.\n- \"Theatrical Release Window\". NATO. 2013-07-20. Retrieved 2019-09-15.\n- Lauren A.E. Schuker; Ethan Smith (22 May 2010). \"Hollywood Eyes Shortcut to TV\". Wall Street Journal.\n- Pamela McClintock (17 February 2010). \". Variety. Archived from the original on February 5, 2013. Retrieved April 20, 2020.\n- \"Disney and UK theater chain reach deal on 'Alice'. Reuters. Reuters Editorial. 19 February 2010.\n- \"Netflix Forgoes Wide Release for Martin Scorsese's 'The Irishman'. The Hollywood Reporter. 27 August 2019. Retrieved 2019-10-05.\n- \"Relativity Media To Stream Movies On Netflix Instead Of Premium Cable\". Slashfilm. 6 July 2010. Archived from the original on 11 July 2010. Retrieved 20 April 2020.\n- Hurwitz (March 3, 2015). \"Netflix to stream 'Beasts of No Nation'USA TODAY.\n- Lang, Brent (2017-02-23). \"Studios Push for $50 Early Home Movie Rentals, but Negotiations Are Complex (EXCLUSIVE)\". Variety. Retrieved 2018-11-07.\n- Lindahl, Chris (2020-02-04). \"Disney Soothes Exhibitors, Says It Loves Theaters Just As Much As Disney+\". IndieWire. Retrieved 2020-04-02.\n- \"All the movies streaming early amid coronavirus theater closures: 'Onward,' 'Sonic the Hedgehog,' 'I Still Believe'. USA Today. Retrieved 2020-03-19.\n- \"NBCUniversal will break the theatrical window to release 'The Invisible Man' and other movies on-demand\". TechCrunch. 16 March 2020. Retrieved 2020-03-17.\n- Gartenberg, Chaim (2020-03-20). \"Disney releases Onward for digital purchase two weeks after its theatrical premiere\". The Verge. Retrieved 2020-03-20.\n- AMC bans Universal films from its theaters over Trolls World Tour CNN, April 29, 2020\n- AMC, largest cinema chain in US, announces boycott of Universal theguardian.com April 29, 2020\n- Universal and AMC are quarreling: What it says about Hollywood cnbc.com April 30, 2020\n- Rubin, Rebecca (2020-11-18). \". Variety. Retrieved 2020-12-05.\n- Swisher, Kara (2020-12-04). \"Opinion | The Window on New Movie Releases Finally Shatters\". The New York Times. ISSN 0362-4331. Retrieved 2020-12-05.\n- Keane, Sean. \"AMC Theatres boss criticizes Warner Bros. for HBO Max 2021 release plans\". CNET. Retrieved 2020-12-05.\n- D'Alessandro, Anthony; Tartaglione, Nancy (March 23, 2021). \"Regal Cinemas To Reopen In April; Parent Cineworld & Warner Bros Reach Multi-Year Deal To Show WB Films In U.S. & UK\". Deadline. Retrieved March 24, 2021.\nCineworld and Warner Bros have also hatched a multi-year agreement that will see the No. 2 global exhibitor show the studio's 2021 theatrical and HBO Max day-and-date titles in the U.S. as of their theatrical release. Then, beginning in 2022, Warner Bros theatrical films will have a 45-day window of theatrical exclusivity at Cineworld's Regal chain.\n- Scott Hettrick (30 December 2005). \"Spending on DVDs up 10%\". Variety. Archived from the original on February 8, 2013. Retrieved April 20, 2020.\n- \"DVD Exclusive Online\". Archived from the original on 15 May 2006.\n- Lerman, Laurence (September 17, 2001). \"Independents' 'Bread and Butter'\". Video Business 21 (38): Section: Video Premieres",
    "filmmaking": "| Part of a series on |\n| Filmmaking |\n|---|\n| Glossary |\nFilmmaking or film production, is the process of creating a motion picture. It involves a number of distinct stages, including an initial story idea or commission, followed by screenwriting, casting, pre-production, shooting, sound recording, post-production, and screening the finished product before an audience, which may result in a film release and exhibition. The process is nonlinear, in that the filmmaker typically shoots the script out of sequence, repeats shots as needed, and puts them together through editing later. Filmmaking takes place in a variety of economic, social, and political contexts around the world, and uses a wide range of technologies and cinematic techniques. While originally films were recorded on photographic film, most modern filmmaking is now digital.[1]\nThe production of a film typically consists of five major stages. The first is development, where the initial idea for the film is explored, rights to intellectual property may be secured, the screenplay is written, and financing is obtained. This is followed by pre-production, where all the arrangements and preparations for the shoot are made, including hiring cast and crew, scouting and securing locations, and constructing sets. The third stage is production, which is when the raw footage and other elements of the film are recorded.\nAfter filming is complete, the project enters post-production. In this stage, the raw footage is edited, sound is mixed, visual effects are added, and a musical score is composed and recorded. The final stage is distribution, where the finished film is released to audiences. This involves marketing and promotion, and the film may be shown in cinemas, released on home video, or made available through streaming services. Some filmmakers operate outside of the mainstream system and engage in independent filmmaking, which has become more accessible with the advent of affordable digital technology.\nFilm production consists of five major stages:[2]\n- Development: Ideas for the film are created, rights to existing intellectual properties are purchased, etc., and the screenplay is written. Financing for the project is sought and obtained.\n- Pre-production: Arrangements and preparations are made for the shoot, such as hiring cast and film crew, selecting locations, and constructing sets.\n- Production: The raw footage and other elements of the film are recorded during the film shoot, including principal photography.\n- Post-production: The images, sound, and visual effects of the recorded film are edited and combined into a finished product.\n- Distribution: The completed film is distributed, marketed, and screened in cinemas and released on home video to be viewed at home.\nThe development stage contains both general and specific components. Each film studio has a yearly retreat where their top creative executives meet and interact on a variety of areas and topics they wish to explore through collaborations with producers and screenwriters, and then ultimately, directors, actors, and actresses. They choose trending topics from the media and real life, as well as many other sources, to determine their yearly agenda. For example, in a year when action is popular, they may wish to explore that topic in one or more movies. Sometimes, they purchase the rights to articles, bestselling novels, plays, the remaking of older films, stories with some basis in real life through a person or event, a video game, fairy tale, comic book, graphic novel. Likewise, research through surveys may inform their decisions. They may have had blockbusters from their previous year and wish to explore a sequel. They will additionally acquire a completed and independently financed and produced film. Such notable examples are Little Miss Sunshine, The English Patient, and Roma.\nStudios hold general meetings with producers and screenwriters about original story ideas. \"In my decade working as a writer, I knew of only a few that were sold and fewer that made it to the screen,\" relays writer Wayne Powers. Alan Watt, writer-director and Founder of The LA Writer's Lab confirmed that completed original screenplays, referred to as \"specs\", make big news when they sell, but these make up a very small portion of movies that are ultimately given the green light to be produced by the president of a studio.\nThe executives return from the retreat with fairly well-established instructions. They spread these concepts through the industry community, especially to producers they have deals with (traditional studios will have those producers in offices on their lots). Also, agents for screenwriters are made aware. This results in a pairing of producers with writers, where they develop a \"take\", a basic story idea that utilizes the concept given by studio executives. Often it is a competition with several pairings meeting with studio executives and \"pitching\" their \"take\". Very few writing jobs are from original ideas brought to studios by producers or writers. Perhaps one movie a year will be a \"spec\" script that was purchased.\nOnce the producer and writer have sold their approach to the desired subject matter, they begin to work. However, many writers and producers usually pass before a particular concept is realized in a way that is awarded a green light to production. Production of Unforgiven, which earned Oscars for its Director/Star Clint Eastwood, as well as its screenwriter, David Webb Peoples, required fifteen years. Powers related that The Italian Job took approximately eight years from concept to screen, which, as Powers added, \"is average.\" And most concepts turned into paid screenplays wind up gathering dust on some executive's shelf, never to see production.\nWriters have different styles and creative processes; some have stronger track records than others. Because of this, how the development process proceeds from there and how much detail a writer returns to the studio to divulge before beginning writing can vary greatly. Screenwriters are often protected by the union, the Writers Guild of America, or WGA. The WGA allows a screenwriter to contract for One Draft, One Revision, and One Polish. Bob Eisle, Writer and Member of the Guild Board, states, \"Additional writing requires an extension of contracts and payment for additional work\". They are paid 80% of their fee after the First Draft. Preliminary discussions are minimal with studio executives but might be quite detailed with the producer.\nNext, a screenwriter writes a screenplay over a period of several months, or however long it takes. Deadlines are in their contracts but there is no pressure to adhere to them. Again, every writer's process and speed vary. The screenwriter may rewrite the script several times to improve dramatization, clarity, structure, characters, dialogue, and overall style.\nScript Coverage, a freelance job held by recent university graduates, does not feed scripts into the system that are ready for production nor already produced. \"Coverage\" is a way for young screenwriters to be read and their ideas might make their way up to an executive or famous producer and result in \"meet and greets\" where relations with up-and-comers can be formed. But it has not historically yielded ideas studios pursue into production.\nThe studio is the film distributor who at an early stage attempts to choose a slate of concepts that are likely to have market appeal and find potential financial success. Hollywood distributors consider factors such as the film genre, the target audience and assumed audience, the historical success of similar films, the actors who might appear in the film, and potential directors. All these factors imply a certain appeal of the film to a possible audience. Not all films make a profit from the theatrical release alone, however, the studio mainly targets the opening weekend and the second weekend to make most domestic profits. Occasionally, a film called a \"word of mouth film\" does not market strongly but its success spreads by word of mouth. It slowly gains its audience. These are special circumstances and these films may remain in theaters for 5 months while a typical film run is closer to 5 weekends. Further earnings result from pay television purchases, foreign market purchases and DVD sales to establish worldwide distribution gross of a film.\nOnce a screenplay is \"greenlit\", directors and actors are attached and the film proceeds into the pre-production stage, although sometimes development and pre-production stages will overlap. Projects which fail to obtain a green light may have protracted difficulties in making the transition to pre-production and enter a phase referred to as development hell for extended period of time or until developmental turnaround.\nAnalogous to almost any business venture, financing of a film project deals with the study of filmmaking as the management and procurement of investments. It includes the dynamics of assets that are required to fund the filmmaking and liabilities incurred during the filmmaking over the time period from early development through the management of profits and losses after distribution under conditions of different degrees of uncertainty and risk. The practical aspects of filmmaking finance can also be defined as the science of the money management of all phases involved in filmmaking. Film finance aims to price assets based on their risk level and their expected rate of return based upon anticipated profits and protection against losses.\nIn pre-production, every step of actually creating the film is carefully designed and planned. This is the phase where one would narrow down all the options of the production. It is where all the planning takes place before the camera rolls and sets the overall vision of the project. The production company is created and a production office established. The film is pre-visualized by the director and may be storyboarded with the help of illustrators and concept artists. A production budget is drawn up to plan expenditures for the film. For major productions, insurance is procured to protect against accidents. Pre-production also includes working out the shoot location and casting process. The Producer hires a Line Manager or a Production Manager to create the schedule and budget for the film.\nThe nature of the film, and the budget, determine the size and type of crew used during filmmaking. Many Hollywood blockbusters employ a cast and crew of hundreds, while a low-budget, independent film may be made by a \"skeleton crew\" of eight or nine (or fewer). These are typical crew positions:\n- Storyboard artist: creates visual images to help the director and production designer communicate their ideas to the production team.\n- Director: is primarily responsible for the storytelling, creative decisions and acting of the film.\n- Assistant director (AD): manages the shooting schedule and logistics of the production, among other tasks. There are several types of AD, each with different responsibilities.\n- Film producer: hires the film's crew.\n- Unit production manager: manages the production budget and production schedule. They also report, on behalf of the production office, to the studio executives or financiers of the film.\n- Location manager: finds and manages film locations. Nearly all pictures feature segments that are shot in the controllable environment of a studio sound stage, while outdoor sequences call for filming on location.\n- Unit production manager: manages the production budget and production schedule. They also report, on behalf of the production office, to the studio executives or financiers of the film.\n- Production designer: the one who creates the visual conception of the film, working with the art director, who manages the art department which makes production sets.[3]\n- Costume designer: creates the clothing for the characters in the film working closely with the actors, as well as other departments.\n- Makeup and hair designer: works closely with the costume designer in order to create a certain look for a character.\n- Casting director: finds actors to fill the parts in the script. This normally requires that actors partake in an audition, either live in front of the casting director or in front of one or more cameras.\n- Choreographer: creates and coordinates the movement and dance – typically for musicals. Some films also credit a fight choreographer.\n- Director of photography (DOP): the head of the photography of the entire film, supervises all cinematographers and camera operators.\n- Production sound mixer: the head of the sound department during the production stage of filmmaking. They record and mix the audio on set – dialogue, presence and sound effects in monaural and ambience in stereo.[4][5] They work with the boom operator, Director, DA, DP, and First AD.\n- Sound designer: creates the aural conception of the film,[3] working with the supervising sound editor. On Bollywood-style Indian productions the sound designer plays the role of a director of audiography.[6]\n- Composer: creates new music for the film. (usually not until post-production)\nIn production, the film is created and shot. In this phase, it is key to keep planning ahead of the daily shoot. The primary aim is to stick to the budget and schedule, which requires constant vigilance. More crew will be recruited at this stage, such as the property master, script supervisor, assistant directors, stills photographer, picture editor, and sound editors. These are the most common roles in filmmaking; the production office will be free to create any unique blend of roles to suit the various responsibilities needed during the production of a film. Communication is key between the location, set, office, production company, distributors and all other parties involved.\nA typical day shooting begins with the crew arriving on the set/location by their call time. Actors usually have their own separate call times. Since set construction, dressing and lighting can take many hours or even days, they are often set up in advance.\nThe grip, electric and production design crews are typically a step ahead of the camera and sound departments: for efficiency's sake, while a scene is being filmed, they are already preparing the next one.\nWhile the crew prepares their equipment, the actors do their costumes and attend the hair and make-up departments. The actors rehearse the script and blocking with the director, and the camera and sound crews rehearse with them and make final tweaks. Finally, the action is shot in as many takes as the director wishes. Most American productions follow a specific procedure:\nThe assistant director (AD) calls \"picture is up!\" to inform everyone that a take is about to be recorded, and then \"quiet, everyone!\" Once everyone is ready to shoot, the AD calls \"roll sound\" (if the take involves sound), and the production sound mixer will start their equipment, record a verbal slate of the take's information, and announce \"sound speed\", or just \"speed\", when they are ready. The AD follows with \"roll camera\", answered by \"speed!\" by the camera operator once the camera is recording. The clapper loader, who is already in front of the camera with the clapperboard, calls \"marker!\" and slaps it shut. If the take involves extras or background action, the AD will cue them (\"action background!\"), and last is the director, telling the actors \"action!\". The AD may echo \"action\" louder on large sets.\nA take is over when the director calls \"Cut!\" and the camera and sound stop recording. The script supervisor will note any continuity issues, and the sound and camera teams log technical notes for the take on their respective report sheets. If the director decides additional takes are required, the whole process repeats. Once satisfied, the crew moves on to the next camera angle or \"setup\", until the whole scene is \"covered.\" When shooting is finished for the scene, the assistant director declares a \"wrap\" or \"moving on\", and the crew will \"strike\", or dismantle, the set for that scene.\nAt the end of the day, the director approves the next day's shooting schedule and a daily progress report is sent to the production office. This includes the report sheets from continuity, sound, and camera teams. Call sheets are distributed to the cast and crew to tell them when and where to turn up the next shooting day. Later on, the director, producer, other department heads, and, sometimes, the cast, may gather to watch that day or yesterday's footage, called dailies, and review their work.\nWith workdays often lasting fourteen or eighteen hours in remote locations, film production tends to create a team spirit. When the entire film is \"in the can\", or in the completion of the production phase, it is customary for the production office to arrange a wrap party, to thank all the cast and crew for their efforts.\nFor the production phase on live-action films, synchronizing work schedules of key cast and crew members is very important.[7] For many scenes, several cast members and many crew members must be physically present at the same place at the same time (and bankable stars may need to rush from one project to another). Animated films have different workflow at the production phase, in that voice actors can record their takes in the recording studio at different times and may not see one another until the film's premiere.[8] Animated films also have different crew, since most physical live-action tasks are either unnecessary or are simulated by various types of animators.\nThis stage is usually thought of as starting when principal photography ends, but they may overlap. The bulk of post-production consists of the film editor reviewing the footage with the director and assembling the film out of selected takes. The production sound (dialogue) is also edited; music tracks and songs are composed and recorded if a film is intended to have a score; sound effects are designed and recorded. Any computer-generated visual effects are digitally added by an artist. Finally, all sound elements are mixed down into \"stems\", which are synchronized to the images on the screen, and the film is fully completed (\"locked\").\nDistribution is the last stage, where the film is released in movie theaters or, occasionally, directly to consumer media (VHS, VCD, DVD, Blu-ray) or direct download from a digital media provider. The film is duplicated as required (either onto film or hard disk drives) and distributed in cinemas for exhibition (screening). Press kits, posters, and other advertising materials are published, and the film is advertised and promoted. A B-roll clip may be released to the press based on raw footage shot for a \"making of\" documentary, which may include making-of clips as well as on-set interviews separate from those of the production company or distributor. For major films, key personnel are often contractually required to participate in promotional tours in which they appear at premieres and festivals and sit for interviews with many TV, print, and online journalists. The largest productions may require more than one promotional tour, in order to rejuvenate audience demand at each release window.\nSince the advent of home video in the late 1970s, most major films have followed a pattern of having several distinct release windows. A film may first be released to a few select cinemas, or if it tests well enough, may go directly into wide release. Next, it is released, normally at different times several weeks (or months) apart, into different market segments like rental, retail, pay-per-view, in-flight entertainment, cable television, satellite television, or free-to-air broadcast television. The distribution rights for the film are also usually sold for worldwide distribution. The distributor and the production company share profits and manage losses.\nFilmmaking also takes place outside of the mainstream and is commonly called independent filmmaking. Since the introduction of DV technology, the means of production have become more democratized and economically viable. Filmmakers can conceivably shoot and edit a film, create and edit the sound and music, and mix the final cut on a home computer. However, while the means of production may be democratized, financing, traditional distribution, and marketing remain difficult to accomplish outside the traditional system. In the past, most independent filmmakers have relied on film festivals (such as Sundance Film Festival, Venice Film Festival, Cannes Film Festival, and Toronto International Film Festivals) to get their films noticed and sold for distribution and production. However, the internet has allowed for the relatively inexpensive distribution of independent films on websites such as YouTube. As a result, several companies have emerged to assist filmmakers in getting independent movies seen and sold via mainstream internet marketplaces, often adjacent to popular Hollywood titles. With internet movie distribution, independent filmmakers who choose to forego a traditional distribution deal now have the ability to reach global audiences.\n- 35 mm film\n- 3D film\n- Audiography\n- Cinematic techniques\n- Digital cinema\n- Experimental filmmaking\n- Film colorization\n- Film industry\n- Filmmaking technique in Kurosawa\n- Filmmaking technique of Luis Buñuel\n- Film poster\n- Film school\n- Film studies\n- Film title design\n- Film trailer\n- First-look deal\n- Glossary of motion picture terms\n- Housekeeping deal\n- List of film topics\n- Motion Picture Association\n- Motion picture content rating system\n- Movie production incentives in the United States\n- Movie theater\n- Outline of film\n- Television\n- Video production\n- Film portal\n- \"The New World of Digital Filmmaking\". Film Connection Film Institute. 2013-01-09. Archived from the original on 2021-10-07. Retrieved 2021-10-07.\n- Steiff, Josef (2005). The Complete Idiot's Guide to Independent Filmmaking. Alpha Books. pp. 26–28.\n- Sound-On-Film by Vincent LoBrutto (1994)\n- Sound for Digital Video by Tomlinson Holman (Focal Press) 2005 (p. 162)\n- Dialogue Editing for Motion Pictures by John Purcell (Focal Press) 2007 (p. 148)\n- Film Sound: Theory and Practice, Edited by Elisabeth Weis and John Belton, Columbia University Press (1985). p. 361\n- Wurmfeld, Eden H.; Laloggia, Nicole (2004). IFP/Los Angeles Independent Filmmaker's Manual (2nd ed.). Amsterdam: Elsevier. p. 52. ISBN 9781136051067. Archived from the original on 22 July 2023. Retrieved 28 June 2023.\n- Hayes, Derek; Webster, Chris (2013). Acting and Performance for Animation. New York and London: Focal Press. p. 176. ISBN 9781136135989. Archived from the original on 2023-04-09. Retrieved 2023-03-19.",
    "food industry": "The food industry is a complex, global network of diverse businesses that supplies most of the food consumed by the world's population. The food industry today has become highly diversified, with manufacturing ranging from small, traditional, family-run activities that are highly labour-intensive, to large, capital-intensive and highly mechanized industrial processes. Many food industries depend almost entirely on local agriculture, animal farms, produce, and/or fishing.[1]\nIt is challenging to find an inclusive way to cover all aspects of food production and sale. The UK Food Standards Agency describes it as \"the whole food industry – from farming and food production, packaging and distribution, to retail and catering\".[2] The Economic Research Service of the USDA uses the term food system to describe the same thing, stating: \"The U.S. food system is a complex network of farmers and the industries that link to them. Those links include makers of farm equipment and chemicals as well as firms that provide services to agribusinesses, such as providers of transportation and financial services. The system also includes the food marketing industries that link farms to consumers, and which include food and fiber processors, wholesalers, retailers, and foodservice establishments.\"[3] The food industry includes:\n- Agriculture: raising crops, livestock, and seafood. Agricultural economics.\n- Manufacturing: agrichemicals, agricultural construction, farm machinery and supplies, seed, etc.\n- Food processing: preparation of fresh products for market, and manufacture of prepared food products\n- Marketing: promotion of generic products (e.g., milk board), new products, advertising, marketing campaigns, packaging, public relations, etc.\n- Wholesale and food distribution: logistics, transportation, warehousing\n- Foodservice (which includes catering)\n- Grocery, farmers' markets, public markets and other retailing\n- Regulation: local, regional, national, and international rules and regulations for food production and sale, including food quality, food security, food safety, marketing/advertising, and industry lobbying activities\n- Education: academic, consultancy, vocational\n- Research and development: food science, food microbiology, food technology, food chemistry, and food engineering\n- Financial services: credit, insurance\nAreas of research such as food grading, food preservation, food rheology, food storage directly deal with the quality and maintenance of quality overlapping many of the above processes.\nOnly subsistence farmers, those who survive on what they grow, and hunter-gatherers can be considered outside the scope of the modern food industry.\nThe dominant companies in the food industry have sometimes been referred to as Big Food, a term coined by the writer Neil Hamilton.[4][5][6][7]\nMost food produced for the food industry comes from commodity crops using conventional agricultural practices. Agriculture is the process of producing food, feeding products, fiber and other desired products by the cultivation of certain plants and the raising of domesticated animals (livestock). On average, 83% of the food consumed by humans is produced using terrestrial agriculture. In addition to terrestrial agriculture, aquaculture and fishing play vital roles in global food production. Aquaculture involves the cultivation of aquatic organisms such as fish, shrimp, and mollusks in controlled environments like ponds, tanks, or cages. It contributes significantly to the world's seafood supply and provides an important source of protein for human consumption. Fishing, on the other hand, relies on harvesting wild aquatic species from oceans, rivers, and lakes, further diversifying the sources of food for human populations and supporting livelihoods in coastal communities worldwide. Together, terrestrial agriculture, aquaculture, and fishing collectively ensure a diverse and ample supply of food to meet the dietary needs of people across the globe.[8]\nScientists, inventors, and others devoted to improving farming methods and implements are also said to be engaged in agriculture. One in three people worldwide are employed in agriculture,[9] yet it only contributes 3% to global GDP.[10] In 2017, on average, agriculture contributes 4% of national GDPs.[8] Global agricultural production is responsible for between 14 and 28% of global greenhouse gas emissions, making it one of the largest contributors to global warming, in large part due to conventional agricultural practices, including nitrogen fertilizers and poor land management.[8]\nAgronomy is the science and technology of producing and using plants for food, fuel, fibre, and land reclamation. Agronomy encompasses work in the areas of plant genetics, plant physiology, meteorology, and soil science. Agronomy is the application of a combination of sciences. Agronomists today are involved with many issues including producing food, creating healthier food, managing the environmental impact of agriculture, and extracting energy from plants.[11]\nFood processing includes the methods and techniques used to transform raw ingredients into food for human consumption. Food processing takes clean, harvested or slaughtered and butchered components and uses them to produce marketable food products. There are several different ways in which food can be produced.[12]\nOne-off production: This method is used when customers make an order for something to be made to their own specifications, for example, a wedding cake. The making of one-off products could take days depending on how intricate the design is.[citation needed]\nBatch production: This method is used when the size of the market for a product is not clear, and where there is a range within a product line. A certain number of the same goods will be produced to make up a batch or run, for example a bakery may bake a limited number of cupcakes. This method involves estimating consumer demand.[citation needed]\nMass production: This method is used when there is a mass market for a large number of identical products, for example chocolate bars, ready meals and canned food. The product passes from one stage of production to another along a production line.[citation needed]\nJust-in-time (JIT) (production): This method of production is mainly used in restaurants. All components of the product are available in-house and the customer chooses what they want in the product. It is then prepared in a kitchen, or in front of the buyer as in sandwich delicatessens, pizzerias, and sushi bars.[citation needed]\nThe food industry has a large influence on consumerism. Organizations, such as The American Academy of Family Physicians (AAFP), have been criticized for accepting monetary donations from companies within the food industry, such as Coca-Cola.[13] These donations have been criticized for creating a conflict of interest and favoring an interest such as financial gains.[13]\nThere are a number of books, film, TV and web-related exposés and critiques of the food industry, including:\n- Eat This, Not That (nonfiction series published in Men's Health magazine)\n- Fast Food Nation (2001 nonfiction book)\n- Chew On This (2005 book adaptation of Fast Food Nation for younger readers)\n- Fast Food Nation (2006 documentary film)\n- Food, Inc. (2008 documentary film)\n- Panic Nation (2006 nonfiction book)\n- Super Size Me (2004 documentary film)\n- Forks over Knives (2011 documentary film)\n- The Jungle (1906 novel by Upton Sinclair that exposed health violations and unsanitary practices in the American meat packing industry during the early 20th century, based on his investigation for a socialist newspaper)\nThe Bretton Woods Institutions - The World Bank and International Monetary Fund - play a large role in how the food industry functions today.[14] These global funds were born after World War II, to help rebuild Europe and prevent another Great Depression. Overall, their main purpose was to stabilize economies.[14] The IMF provided short term loans while the World Bank was focused on larger projects that would bring electricity back to cities, roads, and other \"essential\" needs.[15] The World Banks mission and purpose, however, transformed as its President Robert McNamara issued a system of loans known as Structural Adjustment. In accepting loans from the World Bank, countries - especially the Global South - became economically, politically, and socially tied to the West.[16] Many countries struggled to pay back their loans, beginning the process of global debt, privatization, and the downfall of local economies.[17] As a result of Western intervention, many small scale farmers have been displaced, as US corporations have bought out land in other countries and continued to monopolize on food.[18] Today, several multinational corporations have pushed agricultural technologies on developing countries including improved seeds, chemical fertilizers, and pesticides, crop production.[19]\nIn 2020 scientists reported that reducing emissions from the global food system is essential to achieving the Paris Agreement's climate goals.[20][21] In 2020, an evidence review for the European Union's Scientific Advice Mechanism found that, without significant change, emissions would increase by 30–40% by 2050 due to population growth and changing consumption patterns, and concluded that \"the combined environmental cost of food production is estimated to amount to some $12 trillion per year, increasing to $16 trillion by 2050\".[22] The IPCC's and the EU's reports concluded that adapting the food system to reduce greenhouse gas emissions impacts and food security concerns, while shifting towards a sustainable diet, is feasible.[8]\nSince World War II, agriculture in the United States and the entire national food system in its entirety has been characterized by models that focus on monetary profitability at the expense of social and environmental integrity.[23] Regulations exist to protect consumers and somewhat balance this economic orientation with public interests for food quality, food security, food safety, animal well-being, environmental protection and health.[24]\nIn 2020, researchers published projections and models of potential impacts of policy-dependent mechanisms of modulation, or lack thereof, of how, where, and what food is produced. They analyzed policy-effects for specific regions or nations such as reduction of meat production and consumption, reductions in food waste and loss, increases in crop yields and international land-use planning. Their conclusions include that raising agricultural yields is highly beneficial for biodiversity-conservation in sub-Saharan Africa while measures leading to shifts of diets are highly beneficial in North America and that global coordination and rapid action are necessary.[25][26][27]\nA vast global cargo network connects the numerous parts of the industry. These include suppliers, manufacturers, warehousers, retailers and the end consumers.) Wholesale markets for fresh food products have tended to decline in importance in urbanizing countries, including Latin America and some Asian countries as a result of the growth of supermarkets, which procure directly from farmers or through preferred suppliers, rather than going through markets.\nThe constant and uninterrupted flow of product from distribution centers to store locations is a critical link in food industry operations. Distribution centers run more efficiently, throughput can be increased, costs can be lowered, and manpower better utilized if the proper steps are taken when setting up a material handling system in a warehouse.[28]\nWith worldwide urbanization,[29] food buying is increasingly removed from food production. During the 20th century, the supermarket became the defining retail element of the food industry. There, tens of thousands of products are gathered in one location, in continuous, year-round supply.\nFood preparation is another area where the change in recent decades has been dramatic. Today, two food industry sectors are in apparent competition for the retail food dollar. The grocery industry sells fresh and largely raw products for consumers to use as ingredients in home cooking. The food service industry, by contrast, offers prepared food, either as finished products or as partially prepared components for final \"assembly\". Restaurants, cafes, bakeries and mobile food trucks provide opportunities for consumers to purchase food.\nIn the 21st century online grocery stores emerged and digital technologies for community-supported agriculture have enabled farmers to directly sell produce.[30] Some online grocery stores have voluntarily set social goals or values beyond meeting consumer demand and the accumulation of profit.[31]\nModern food production is defined by sophisticated technologies. These include many areas. Agricultural machinery, originally led by the tractor, has practically eliminated human labor in many areas of production. Biotechnology is driving much change, in areas as diverse as agrochemicals, plant breeding and food processing. Many other types of technology are also involved, to the point where it is hard to find an area that does not have a direct impact on the food industry. As in other fields, computer technology is also a central force. Other than that, there few more modern technologies that can help to improve the industry as well which are, robotics and automation, blockchain, nanotech, 3D printing, artificial intelligence, smart farming and others. These new technologies can improve the industry in the following ways:\n- Robotics and automation: Robotics and automation are being used to automate processes such as packaging, sorting, and quality control, which reduces labor costs and increases efficiency. These technologies also reduce the likelihood of contamination by reducing human contact with food.[32]\n- Blockchain: Blockchain technology is being used to improve food safety by providing transparency in the supply chain. This technology allows for real-time tracking of food products, from farm to table, which helps to identify any potential safety hazards and enables quick response to any issues.[33]\n- Nanotechnology: Nanotechnology is being used to develop new packaging materials that can extend the shelf life of food and reduce food waste. These materials can also be designed to be biodegradable, reducing the environmental impact of packaging.[34]\n- 3D printing: 3D printing is being used to create custom food products and to make food production more efficient.[35] With 3D printing, it is possible to create complex shapes and designs that would be difficult to achieve with traditional manufacturing techniques.\n- Artificial intelligence: (AI) is being used to analyze large amounts of data in the food industry, which can help to identify trends and patterns. This technology can be used to optimize processes and to improve the quality and safety of food products.[citation needed]\n- Smart farming: Smart farming involves the use of sensors and data analytics to optimize crop yields and reduce waste. This technology can help farmers to make more informed decisions about when to plant, water, and harvest crops, which can improve the efficiency and sustainability of agriculture.[36]\nAs consumers grow increasingly removed from food production, the role of product creation, advertising, and publicity become the primary vehicles for information about food. With processed food as the dominant category, marketers have almost infinite possibilities in product creation. Of the food advertised to children on television, 73% is fast or convenience foods.[37]\nOne of the main challenges in food industry marketing is the high level of competition in the market. Companies must differentiate themselves from their competitors by offering unique products or using innovative marketing techniques. For example, many food companies are now using social media platforms to promote their products and engage with customers.\nAnother important aspect of food industry marketing is understanding consumer behavior and preferences. This includes factors such as age, gender, income, and cultural background. Companies must also be aware of changing consumer trends and adapt their marketing strategies accordingly.\nThis section needs to be updated.(June 2021) |\nUntil the last 100 years, agriculture was labor-intensive. Farming was a common occupation and millions of people were involved in food production. Farmers, largely trained from generation to generation, carried on the family business. That situation has changed dramatically today. In America in 1870, 70–80% of the US population was employed in agriculture.[38] As of 2021[update], less than 2% of the population is directly employed in agriculture,[39][40][41] and about 83% of the population lives in cities.[42]\n- Agroindustry\n- Agricultural expansion\n- Dietary supplement\n- Factory farming\n- Food fortification, also called Nutrification\n- Geography of food\n- Local food\n- Ultra-processed food\n- Parmeggiani, Lougi, ed. (1983). \"???\". Encyclopædia of Occupational Health and Safety (3rd ed.). Geneva: International Labour Office. ISBN 92-2-103289-2.\n- \"Industry\". Food Standards Agency (UK). Archived from the original on 2012-06-05. Retrieved 2010-12-09.\n- \"Food market structures: Overview\". Economic Research Service (USDA). Archived from the original on July 28, 2012.\n- Sue Booth; John Coveney (19 February 2015). Food Democracy: From consumer to food citizen. Springer. pp. 3–. ISBN 978-981-287-423-8.\n- Gray, Allison; Hinch, Ronald (1 October 2019). A Handbook of Food Crime: Immoral and Illegal Practices in the Food Industry and What to Do About Them. Policy Press. pp. 371–. ISBN 978-1-4473-5628-8.\n- Booth, Sue; Coveney, John (2015), Booth, Sue; Coveney, John (eds.), \"Food Democracy: From consumer to food citizen, SpringerBriefs in Public Health, Singapore: Springer, pp. 3–11, doi:10.1007/978-981-287-423-8_2, ISBN 978-981-287-423-8\n- Stuckler, David; Nestle, Marion (19 June 2012). \"Big Food, Food Systems, and Global Health\". PLOS Medicine. 9 (6) e1001242. doi:10.1371/journal.pmed.1001242. ISSN 1549-1676. PMC 3378592. PMID 22723746.\n- Mbow, C.; Rosenzweig, C.; Barioni, L. G.; Benton, T.; et al. (2019). \"Chapter 5: Food Security\" (PDF). IPCC SRCCL 2019.\n- \"Labour\" (PDF). FAO.org. The Food and Agriculture Organization of the United Nations. Retrieved 15 May 2015.\n- \"Macroeconomy\" (PDF). FAO.org. The Food and Agriculture Organization of the United Nations. Retrieved 15 May 2015.\n- \"I'm An Agronomist!\". Imanagronomist.net. Archived from the original on 16 November 2017. Retrieved 2 May 2013.\n- Fellows, P. J. (2009). Food Processing Technology: Principles and Practice. Woodhead Publishing. pp. 3–5. ISBN 978-1-84569-216-2.\n- Brody, Howard (1 August 2016). \"Professional medical organizations and commercial conflicts of interest: ethical issues\". Annals of Family Medicine. 8 (4): 354–358. doi:10.1370/afm.1140. ISSN 1544-1717. PMC 2906531. PMID 20644191.\n- Hickel, Jason (2017). The divide: a brief guide to global inequality and its solutions. London. ISBN 978-1-78515-112-5. OCLC 984907212.\n{{cite book}}\n: CS1 maint: location missing publisher (link) - Goldman, Michael (2008-10-01). Imperial Nature. Yale University Press. doi:10.12987/9780300132090. ISBN 978-0-300-13209-0. S2CID 264519062.\n- Steinmetz-Jenkins, Daniel (2022-06-15). \"The Rotten Roots of the IMF and the World Bank\". ISSN 0027-8378. Retrieved 2022-12-08.\n- Escobar, Arturo (2012). Encountering Development: The Making and Unmaking of the Third World. Princeton, N.J. p. 3. ISBN 978-1-4008-3992-6. OCLC 757736395.\n{{cite book}}\n: CS1 maint: location missing publisher (link) - Clapp, Jennifer (2018). Speculative harvests: financialization, food, and agriculture. S. Ryan Isakson. Black Point, Nova Scotia. ISBN 978-1-77363-023-6. OCLC 1013824989.\n{{cite book}}\n: CS1 maint: location missing publisher (link) - Aktar, Wasim; Sengupta, Dwaipayan; Chowdhury, Ashim (2009-03-01). \"Impact of pesticides use in agriculture: their benefits and hazards\". Interdisciplinary Toxicology. 2 (1): 1–12. doi:10.2478/v10102-009-0001-7. ISSN 1337-9569. PMC 2984095. PMID 21217838.\n- \"Reducing global food system emissions key to meeting climate goals\". phys.org. Retrieved 8 December 2020.\n- Clark, Michael A.; Domingo, Nina G. G.; Colgan, Kimberly; Thakrar, Sumil K.; Tilman, David; Lynch, John; Azevedo, Inês L.; Hill, Jason D. (6 November 2020). \"Global food system emissions could preclude achieving the 1.5° and 2°C climate change targets\". Science. 370 (6517): 705–708. Bibcode:2020Sci...370..705C. doi:10.1126/science.aba7357. ISSN 0036-8075. PMID 33154139. S2CID 226254942. Retrieved 8 December 2020.\n- SAPEA (2020). A sustainable food system for the European Union (PDF). Berlin: SAPEA - Science Advice for Policy by European Academies. p. 39. doi:10.26356/sustainablefood. ISBN 978-3-9820301-7-3. Archived from the original (PDF) on 2020-04-18. Retrieved 2020-12-28.\n- Schattman, Rachel. Sustainable Food Sourcing and Distribution in the Vermont-Regional Food System (PDF) (Report). Archived from the original (PDF) on 2 February 2017. Retrieved 22 January 2017.\n- Szajkowska, Anna (March 2012). Regulating Food Law: Risk Analysis and the Precautionary Principle as General Principles of EU Food Law. Wageningen Academic Pub. ISBN 978-90-8686-194-1. Retrieved 22 January 2017.\n- \"Global food industry on course to drive rapid habitat loss – research\". The Guardian. 21 December 2020. Retrieved 17 January 2021.\n- \"Current food production systems could mean far-reaching habitat loss\". phys.org. Retrieved 17 January 2021.\n- Williams, David R.; Clark, Michael; Buchanan, Graeme M.; Ficetola, G. Francesco; Rondinini, Carlo; Tilman, David (21 December 2020). \"Proactive conservation to prevent habitat losses to agricultural expansion\". Nature Sustainability. 4 (4): 314–322. Bibcode:2020NatSu...4..314W. doi:10.1038/s41893-020-00656-5. hdl:2434/857211. ISSN 2398-9629. S2CID 229346085. Archived from the original on 25 January 2021. Retrieved 17 January 2021.\n- \"Boosting efficiency at the DC\". Grocery Headquarters. Archived from the original on 27 March 2010. Retrieved 26 March 2012.\n- \"World Urbanization Prospects: The 2003 Revision\". Department of Economic and Social Affairs, Population Division (United Nations).\n- Foote, Natasha (2 April 2020). \"Innovation spurred by COVID-19 crisis highlights 'potential of small-scale farmers'.\n- \"Amid Pandemic, Local Company Delivering Meat And Fresh, Organic Sustainable Foods\". 22 May 2020. Retrieved 26 May 2020.\n- Robotnik (2022-01-31). \"Application of robotics in agriculture\". Robotnik. Retrieved 2023-05-05.\n- Tian, Feng (2016). \"An agri-food supply chain traceability system for China based on RFID & blockchain technology\". 2016 13th International Conference on Service Systems and Service Management (ICSSSM). pp. 1–6. doi:10.1109/ICSSSM.2016.7538424. ISBN 978-1-5090-2842-9.\n- \"Nanotechnology in Agriculture and Food Systems\". National Institute of Food and Agriculture. 24 May 2022. Retrieved 2023-05-05.\n- \"Can 3D Printing Revolutionise The Agriculture Industry? - Manufactur3D\". manufactur3dmag.com. 2021-08-18. Retrieved 2023-05-05.\n- Sciforce (2023-01-25). \"Smart Farming: The Future of Agriculture\". IoT For All. Retrieved 2023-05-05.\n- Kunkel, Dale (2009). \"The Impact of Industry Self-Regulation on the Nutritional Quality of Foods Advertised to Children on Television\" (PDF). Children Now. Archived from the original (PDF) on 2018-09-19. Retrieved 2018-09-19.\n- Neat Facts About United States Agriculture Archived 14 March 2014 at the Wayback Machine, Retrieved 19 November 2013\n- \"Employment by major industry sector\". Bls.gov. 19 December 2013. Archived from the original on 11 May 2018. Retrieved 1 April 2014.\n- \"Extension\". Csrees.usda.gov. 28 March 2014. Archived from the original on 28 March 2014. Retrieved 1 April 2014.\n- \"Agriculture and Food Sectors and the Economy\". Retrieved 18 May 2023.\n- \"U.S Cities Factsheet\". Retrieved 18 May 2023.\n- IPCC (2019). Shukla, P. R.; Skea, J.; Calvo Buendia, E.; Masson-Delmotte, V.; et al. (eds.). IPCC Special Report on Climate Change, Desertification, Land Degradation, Sustainable Land Management, Food Security, and Greenhouse gas fluxes in Terrestrial Ecosystems (PDF). In press.\n- Nelson, Scott Reynolds. Oceans of Grain: How American Wheat Remade the World (2022) excerpt\n- Nestle, M. (2013). Food Politics: How the Food Industry Influences Nutrition and Health. California Studies in Food and Culture. University of California Press. ISBN 978-0-520-95506-6.\n- Vasconcellos, J.A. (2003). Quality Assurance for the Food Industry: A Practical Approach. CRC Press. ISBN 978-0-203-49810-1.\n- Kress-Rogers, E.; Brimelow, C.J.B. (2001). Instrumentation and Sensors for the Food Industry. Woodhead Publishing Series in Food Science, Technology and Nutrition. Woodhead. ISBN 978-1-85573-560-6.\n- Traill, B.; Pitts, E. (1998). Competitiveness in the Food Industry. Springer. ISBN 978-0-7514-0431-9.\n- Food Fight: The Inside Story of the Food Industry",
    "health care": "Health care, or healthcare, is the improvement or maintenance of health via the prevention, diagnosis, treatment, amelioration or cure of disease, illness, injury, and other physical and mental impairments in people. Health care is delivered by health professionals and allied health fields. Medicine, dentistry, pharmacy, midwifery, nursing, optometry, audiology, psychology, occupational therapy, physical therapy, athletic training, and other health professions all constitute health care. The term includes work done in providing primary care, secondary care, tertiary care, and public health.\nAccess to health care may vary across countries, communities, and individuals, influenced by social and economic conditions and health policies. Providing health care services means \"the timely use of personal health services to achieve the best possible health outcomes\".[3] Factors to consider in terms of health care access include financial limitations (such as insurance coverage), geographical and logistical barriers (such as additional transportation costs and the ability to take paid time off work to use such services), sociocultural expectations, and personal limitations (lack of ability to communicate with health care providers, poor health literacy, low income).[4] Limitations to health care services affect negatively the use of medical services, the efficacy of treatments, and overall outcome (well-being, mortality rates).\nHealth systems are the organizations established to meet the health needs of targeted populations. According to the World Health Organization (WHO), a well-functioning health care system requires a financing mechanism, a well-trained and adequately paid workforce, reliable information on which to base decisions and policies, and well-maintained health facilities to deliver quality medicines and technologies.\nAn efficient health care system can contribute to a significant part of a country's economy, development, and industrialization. Health care is an important determinant in promoting the general physical and mental health and well-being of people around the world.[5] An example of this was the worldwide eradication of smallpox in 1980, declared by the WHO, as the first disease in human history to be eliminated by deliberate health care interventions.[6]\nThe delivery of modern health care depends on groups of trained professionals and paraprofessionals coming together as interdisciplinary teams.[7] This includes professionals in medicine, psychology, physiotherapy, nursing, dentistry, midwifery and allied health, along with many others such as public health practitioners, community health workers and assistive personnel. These professionals systematically provide personal and population-based preventive, curative and rehabilitative care services.[citation needed]\nWhile the definitions of the various types of health care vary based on the different cultural, political, organizational, and disciplinary perspectives, there is general consensus that primary care constitutes the first element of a continuous health care process and may also include the provision of secondary and tertiary levels of care.[8] Health care can be defined as either public or private.[citation needed]\nPrimary care refers to the work of health professionals who act as a first point of consultation for all patients within the health care system. The primary care model supports first-contact, accessible, continuous, comprehensive and coordinated person-focused care.[10] Such a professional would usually be a primary care physician, such as a general practitioner or family physician. Another professional would be a licensed independent practitioner such as a physiotherapist, or a non-physician primary care provider such as a physician assistant or nurse practitioner. Depending on the locality and health system organization, the patient may see another health care professional first, such as a pharmacist or nurse. Depending on the nature of the health condition, patients may be referred for secondary or tertiary care.[citation needed]\nPrimary care is often used as the term for the health care services that play a role in the local community. It can be provided in different settings, such as Urgent care centers that provide same-day appointments or services on a walk-in basis.[citation needed]\nPrimary care involves the widest scope of health care, including all ages of patients, patients of all socioeconomic and geographic origins, patients seeking to maintain optimal health, and patients with all types of acute and chronic physical, mental and social health issues, including multiple chronic diseases. Consequently, a primary care practitioner must possess a wide breadth of knowledge in many areas. Continuity is a key characteristic of primary care, as patients usually prefer to consult the same practitioner for routine check-ups and preventive care, health education, and every time they require an initial consultation about a new health problem. The International Classification of Primary Care (ICPC) is a standardized tool for understanding and analyzing information on interventions in primary care based on the reason for the patient's visit.[11]\nCommon chronic illnesses usually treated in primary care may include, for example, hypertension, diabetes, asthma, COPD, depression and anxiety, back pain, arthritis or thyroid dysfunction. Primary care also includes many basic maternal and child health care services, such as family planning services and vaccinations. In the United States, the 2013 National Health Interview Survey found that skin disorders (42.7%), osteoarthritis and joint disorders (33.6%), back problems (23.9%), disorders of lipid metabolism (22.4%), and upper respiratory tract disease (22.1%, excluding asthma) were the most common reasons for accessing a physician.[12]\nIn the United States, primary care physicians have begun to deliver primary care outside of the managed care (insurance-billing) system through direct primary care which is a subset of the more familiar concierge medicine. Physicians in this model bill patients directly for services, either on a pre-paid monthly, quarterly, or annual basis, or bill for each service in the office. Examples of direct primary care practices include Foundation Health in Colorado and Qliance in Washington.[citation needed]\nIn the context of global population aging, with increasing numbers of older adults at greater risk of chronic non-communicable diseases, rapidly increasing demand for primary care services is expected in both developed and developing countries.[13][14] The World Health Organization attributes the provision of essential primary care as an integral component of an inclusive primary health care strategy.[8]\nSecondary care includes acute care: necessary treatment for a short period of time for a brief but serious illness, injury, or other health condition. This care is often found in a hospital emergency department. Secondary care also includes skilled attendance during childbirth, intensive care, and medical imaging services.[16]\nThe term \"secondary care\" is sometimes used synonymously with \"hospital care\". However, many secondary care providers, such as psychiatrists, clinical psychologists, occupational therapists, most dental specialties or physiotherapists, do not necessarily work in hospitals. Some primary care services are delivered within hospitals. Depending on the organization and policies of the national health system, patients may be required to see a primary care provider for a referral before they can access secondary care.[17][18]\nIn countries that operate under a mixed market health care system, some physicians limit their practice to secondary care by requiring patients to see a primary care provider first. This restriction may be imposed under the terms of the payment agreements in private or group health insurance plans. In other cases, medical specialists may see patients without a referral, and patients may decide whether self-referral is preferred.[citation needed]\nIn other countries patient self-referral to a medical specialist for secondary care is rare as prior referral from another physician (either a primary care physician or another specialist) is considered necessary, regardless of whether the funding is from private insurance schemes or national health insurance.[citation needed]\nAllied health professionals, such as physical therapists, respiratory therapists, occupational therapists, speech therapists, and dietitians, also generally work in secondary care, accessed through either patient self-referral or through physician referral.[citation needed]\nTertiary care is specialized consultative health care, usually for inpatients and on referral from a primary or secondary health professional, in a facility that has personnel and facilities for advanced medical investigation and treatment, such as a tertiary referral hospital.[19]\nExamples of tertiary care services are cancer management, neurosurgery, cardiac surgery, plastic surgery, treatment for severe burns, advanced neonatology services, palliative, and other complex medical and surgical interventions.[20]\nThe term quaternary care is sometimes used as an extension of tertiary care in reference to advanced levels of medicine which are highly specialized and not widely accessed. Experimental medicine and some types of uncommon diagnostic or surgical procedures are considered quaternary care. These services are usually only offered in a limited number of regional or national health care centers.[20][21]\nMany types of health care interventions are delivered outside of health facilities. They include many interventions of public health interest, such as food safety surveillance, distribution of condoms and needle-exchange programs for the prevention of transmissible diseases.[citation needed]\nThey also include the services of professionals in residential and community settings in support of self-care, home care, long-term care, assisted living, treatment for substance use disorders among other types of health and social care services.[citation needed]\nCommunity rehabilitation services can assist with mobility and independence after the loss of limbs or loss of function. This can include prostheses, orthotics, or wheelchairs.[citation needed]\nMany countries are dealing with aging populations, so one of the priorities of the health care system is to help seniors live full, independent lives in the comfort of their own homes. There is an entire section of health care geared to providing seniors with help in day-to-day activities at home such as transportation to and from doctor's appointments along with many other activities that are essential for their health and well-being. Although they provide home care for older adults in cooperation, family members and care workers may harbor diverging attitudes and values towards their joint efforts. This state of affairs presents a challenge for the design of ICT (information and communication technology) for home care.[22]\nBecause statistics show that over 80 million Americans have taken time off of their primary employment to care for a loved one,[23] many countries have begun offering programs such as the Consumer Directed Personal Assistant Program to allow family members to take care of their loved ones without giving up their entire income.[citation needed]\nWith obesity in children rapidly becoming a major concern, health services often set up programs in schools aimed at educating children about nutritional eating habits, making physical education a requirement and teaching young adolescents to have a positive self-image.[24]\nHealth care ratings are ratings or evaluations of health care used to evaluate the process of care and health care structures and/or outcomes of health care services. This information is translated into report cards that are generated by quality organizations, nonprofit, consumer groups and media. This evaluation of quality is based on measures of:[citation needed]\n- health plan quality\n- hospital quality\n- of patient experience\n- physician quality\n- quality for other health professionals\nA health system, also sometimes referred to as health care system or healthcare system, is the organization of people, institutions, and resources that deliver health care services to populations in need.[citation needed] Health care extends beyond the delivery of services to patients, encompassing many related sectors, and is set within a bigger picture of financing and governance structures.\nThe healthcare industry incorporates several sectors that are dedicated to providing health care services and products. As a basic framework for defining the sector, the United Nations' International Standard Industrial Classification categorizes health care as generally consisting of hospital activities, medical and dental practice activities, and \"other human health activities.\" The last class involves activities of, or under the supervision of, nurses, midwives, physiotherapists, scientific or diagnostic laboratories, pathology clinics, residential health facilities, patient advocates[25] or other allied health professions.\nIn addition, according to industry and market classifications, such as the Global Industry Classification Standard and the Industry Classification Benchmark, health care includes many categories of medical equipment, instruments and services including biotechnology, diagnostic laboratories and substances, drug manufacturing and delivery.[citation needed]\nFor example, pharmaceuticals and other medical devices are the leading high technology exports of Europe and the United States.[26][27] The United States dominates the biopharmaceutical field, accounting for three-quarters of the world's biotechnology revenues.[26][28]\nThe quantity and quality of many health care interventions are improved through the results of science, such as advanced through the medical model of health which focuses on the eradication of illness through diagnosis and effective treatment. Many important advances have been made through health research, biomedical research and pharmaceutical research, which form the basis for evidence-based medicine and evidence-based practice in health care delivery. Health care research frequently engages directly with patients, and as such issues for whom to engage and how to engage with them become important to consider when seeking to actively include them in studies. While single best practice does not exist, the results of a systematic review on patient engagement suggest that research methods for patient selection need to account for both patient availability and willingness to engage.[29]\nHealth services research can lead to greater efficiency and equitable delivery of health care interventions, as advanced through the social model of health and disability, which emphasizes the societal changes that can be made to make populations healthier.[30] Results from health services research often form the basis of evidence-based policy in health care systems. Health services research is also aided by initiatives in the field of artificial intelligence for the development of systems of health assessment that are clinically useful, timely, sensitive to change, culturally sensitive, low-burden, low-cost, built into standard procedures, and involve the patient.[31]\nAccess to health care may vary across countries, communities, and individuals, influenced by social and economic conditions as well as health policies. Providing health care services means \"the timely use of personal health services to achieve the best possible health outcomes\".[3] Factors to consider in terms of health care access include financial limitations (such as insurance coverage), geographical and logistical barriers (such as additional transportation costs and the ability to take paid time off work to use such services), sociocultural expectations, and personal limitations (lack of ability to communicate with health care providers, poor health literacy, low income).[4] Lower cost-effectiveness thresholds can make make health care more affordable by avoiding the least cost-effective procedures.[32]\nThere are generally five primary methods of funding health care systems:[33]\n- General taxation to the state, county or municipality\n- Social health insurance\n- Voluntary or private health insurance\n- Out-of-pocket payments\n- Donations to health charities\nIn most countries, there is a mix of all five models, but this varies across countries and over time within countries. Aside from financing mechanisms, an important question should always be how much to spend on health care. For the purposes of comparison, this is often expressed as the percentage of GDP spent on health care. In OECD countries for every extra $1000 spent on health care, life expectancy falls by 0.4 years.[35] A similar correlation is seen from the analysis carried out each year by Bloomberg.[36] Clearly this kind of analysis is flawed in that life expectancy is only one measure of a health system's performance, but equally, the notion that more funding is better is not supported.[citation needed]\nIn the United States, the healthcare industry accounts for 18% of gross domestic product in 2020 and is one of the largest and most complex parts of the U.S. economy.[37] In 2011, the health care industry consumed an average of 9.3 percent of the GDP or US$ 3,322 (PPP-adjusted) per capita across the 34 members of OECD countries. The US (17.7%, or US$ PPP 8,508), the Netherlands (11.9%, 5,099), France (11.6%, 4,118), Germany (11.3%, 4,495), Canada (11.2%, 5669), and Switzerland (11%, 5,634) were the top spenders, however life expectancy in total population at birth was highest in Switzerland (82.8 years), Japan and Italy (82.7), Spain and Iceland (82.4), France (82.2) and Australia (82.0), while OECD's average exceeds 80 years for the first time ever in 2011: 80.1 years, a gain of 10 years since 1970. The US (78.7 years) ranges only on place 26 among the 34 OECD member countries, but has the highest costs by far. All OECD countries have achieved universal (or almost universal) health coverage, except the US and Mexico.[38][39] (see also international comparisons.)\nIn the United States, where around 18% of GDP is spent on health care,[36] the Commonwealth Fund analysis of spend and quality shows a clear correlation between worse quality and higher spending.[40]\nExpand the OECD charts below to see the breakdown:\n- \"Government/compulsory\": Government spending and compulsory health insurance.\n- \"Voluntary\": Voluntary health insurance and private funds such as households' out-of-pocket payments, NGOs and private corporations.\n- They are represented by columns starting at zero. They are not stacked. The 2 are combined to get the total.\n- At the source you can run your cursor over the columns to get the year and the total for that country.[41]\n- Click the table tab at the source to get 3 lists (one after another) of amounts by country: \"Total\", \"Government/compulsory\", and \"Voluntary\".[41]\nThe management and administration of health care is vital to the delivery of health care services. In particular, the practice of health professionals and the operation of health care institutions is typically regulated by national or state/provincial authorities through appropriate regulatory bodies for purposes of quality assurance.[42] Most countries have credentialing staff in regulatory boards or health departments who document the certification or licensing of health workers and their work history.[43]\nHealth information technology (HIT) is \"the application of information processing involving both computer hardware and software that deals with the storage, retrieval, sharing, and use of health care information, data, and knowledge for communication and decision making.\"[44]\nHealth information technology components:\n- Electronic health record (EHR) – An EHR contains a patient's comprehensive medical history, and may include records from multiple providers.[45]\n- Electronic Medical Record (EMR) – An EMR contains the standard medical and clinical data gathered in one's provider's office.[45]\n- Health information exchange (HIE) – Health Information Exchange allows health care professionals and patients to appropriately access and securely share a patient's vital medical information electronically.[46]\n- Medical practice management software (MPM) – is designed to streamline the day-to-day tasks of operating a medical facility. Also known as practice management software or practice management system (PMS).[citation needed]\n- Personal health record (PHR) – A PHR is a patient's medical history that is maintained privately, for personal use.[47]\n- Category:Health care by country\n- Global health\n- Healthcare system / Health professionals\n- Tobacco control laws\n- \"Hospital beds per 1,000 people\". Our World in Data. Archived from the original on 12 April 2020. Retrieved 7 March 2020.\n- \"Governor Hochul, Mayor Adams Announce Plan for SPARC Kips Bay, First-of-Its-Kind Job and Education Hub for Health and Life Sciences Innovation\". State of New York. 13 October 2022. Archived from the original on 1 November 2022. Retrieved 13 October 2022.\n- Institute of Medicine (US) Committee on Monitoring Access to Personal Health Care Services, Millman M (1993). Access to Health Care in America. The National Academies Press, US National Academies of Science, Engineering and Medicine. doi:10.17226/2009. ISBN 978-0-309-04742-5. PMID 25144064. Archived from the original on 11 February 2021. Retrieved 14 June 2019.\n- \"Healthcare Access in Rural Communities Introduction\". Rural Health Information Hub. 2019. Archived from the original on 11 February 2021. Retrieved 14 June 2019.\n- \"Health Topics: Health Systems\". www.who.int. World Health Organization. Archived from the original on 18 July 2019. Retrieved 24 November 2013.\n- World Health Organization. Anniversary of smallpox eradication. Geneva, 18 June 2010.\n- United States Department of Labor. Employment and Training Administration: Health care Archived 2012-01-29 at the Wayback Machine. Retrieved June 24, 2011.\n- Thomas-MacLean R et al. No Cookie-Cutter Response: Conceptualizing Primary Health Care. Archived 2019-04-12 at the Wayback Machine Retrieved 26 August 2014.\n- \"June 2014\". Magazine. Archived from the original on 22 December 2020. Retrieved 9 March 2019.\n- \"Primary care\". World Health Organization. Retrieved 21 June 2024.\n- World Health Organization. International Classification of Primary Care, Second edition (ICPC-2). Archived 2020-12-22 at the Wayback Machine Geneva. Accessed 24 June 2011.\n- St Sauver JL, Warner DO, Yawn BP, et al. (January 2013). \"Why patients visit their doctors: assessing the most prevalent conditions in a defined American population\". Mayo Clin. Proc. 88 (1): 56–67. doi:10.1016/j.mayocp.2012.08.020. PMC 3564521. PMID 23274019.\n- World Health Organization. Aging and life course: Our aging world. Archived 2019-06-11 at the Wayback Machine Geneva. Accessed 24 June 2011.\n- Simmons J. Primary Care Needs New Innovations to Meet Growing Demands. Archived 2011-07-11 at the Wayback Machine HealthLeaders Media, May 27, 2009.\n- \"100 of the largest hospitals and health systems in America\" Archived 2 June 2022 at the Wayback Machine, Becker's Hospital Review\n- \"Health Care System\". the Free Medical Dictionary. Archived from the original on 5 February 2021. Retrieved 21 December 2020.\n- \"Secondary Care\". MS Trust. Archived from the original on 5 February 2021. Retrieved 22 December 2020.\n- \"Difference between primary, secondary and tertiary health care\". EInsure. 24 January 2017. Archived from the original on 6 May 2021. Retrieved 21 December 2020.\n- Johns Hopkins Medicine. Patient Care: Tertiary Care Definition. Archived 2017-07-11 at the Wayback Machine Accessed 27 June 2011.\n- Emory University. School of Medicine. Archived 2011-04-23 at the Wayback Machine Accessed 27 June 2011.\n- Alberta Physician Link. Levels of Care. Archived 2014-06-14 at the Wayback Machine Retrieved 26 August 2014.\n- Christensen L, Grönvall E (2011). \"ECSCW 2011: Proceedings of the 12th European Conference on Computer Supported Cooperative Work, 24–28 September 2011, Aarhus Denmark\". In S. Bødker, N. O. Bouvin, W. Letters, V. Wulf, L. Ciolfi (eds.). ECSCW 2011: Proceedings of the 12th European Conference on Computer Supported Cooperative Work, 24–28 September 2011, Aarhus Denmark. London: Springer. pp. 61–80. doi:10.1007/978-0-85729-913-0_4. ISBN 978-0-85729-912-3.\n- Porter E (29 August 2017). \"Home Health Care: Shouldn't It Be Work Worth Doing?\". The New York Times. ISSN 0362-4331. Archived from the original on 22 December 2020. Retrieved 29 November 2017.\n- Sanyaolu A, Okorie C, Qi X, Locke J, Rehman S (January 2019). \"Childhood and Adolescent Obesity in the United States: A Public Health Concern\". Global Pediatric Health. 6: 2333794X1989130. doi:10.1177/2333794X19891305. ISSN 2333-794X. PMC 6887808. PMID 31832491.\n- Dorothy Kamaker (21 September 2015). \"Patient advocacy services ensure optimum health outcomes\". Archived from the original on 20 December 2017. Retrieved 26 September 2015.\n- \"The Pharmaceutical Industry in Figures\" (pdf). European Federation of Pharmaceutical Industries and Associations. 2007. Archived from the original on 22 December 2020. Retrieved 15 February 2010.\n- 2008 Annual Report. Pharmaceutical Research and Manufacturers of America. 2008.\n- \"Europe's competitiveness\". European Federation of Pharmaceutical Industries and Associations. Archived from the original on 23 August 2009. Retrieved 15 February 2010.\n- Domecq JP, Prutsky G, Elraiyah T, Wang Z, Nabhan M, Shippee N, Brito JP, Boehmer K, Hasan R, Firwana B, Erwin P (26 February 2014). \"Patient engagement in research: a systematic review\". BMC Health Services Research. 14 (1): 89. doi:10.1186/1472-6963-14-89. ISSN 1472-6963. PMC 3938901. PMID 24568690.\n- Bond J., Bond S. (1994). Sociology and Health Care. Churchill Livingstone. ISBN 978-0-443-04059-7.\n- Erik Cambria, Tim Benson, Chris Eckl, Amir Hussain (2012). \"Sentic PROMs: Application of Sentic Computing to the Development of a Novel Unified Framework for Measuring Health-Care Quality\". Expert Systems with Applications, Elsevier. Vol. 39. pp. 10533–10543. doi:10.1016/j.eswa.2012.02.120.\n- Vanness DJ, Lomas J, Ahn H (2021). \"A Health Opportunity Cost Threshold for Cost-Effectiveness Analysis in the United States\" (PDF). Annals of Internal Medicine. 174 (1): 25–32. doi:10.7326/M20-1392. ISSN 0003-4819. PMID 33136426. Retrieved 8 June 2025.\n- World Health Organization. \"Regional Overview of Social Health Insurance in South-East Asia.' Archived 2012-09-03 at the Wayback Machine Retrieved December 02, 2014.\n- Link between health spending and life expectancy: US is an outlier Archived 11 March 2022 at the Wayback Machine. May 26, 2017. By Max Roser at Our World in Data. Click the sources tab under the chart for info on the countries, healthcare expenditures, and data sources. See the later version of the chart here Archived 5 March 2022 at the Wayback Machine.\n- \"Improve operational efficiency in healthcare with RPA\". NuAIg. 2 March 2021. Archived from the original on 27 May 2021. Retrieved 27 May 2021.\n- \"These Are the Economies With the Most (and Least) Efficient Health Care\". BloombergQuint. 19 September 2018. Archived from the original on 22 December 2020. Retrieved 14 January 2019.\n- \"Healthcare Sector: Industries Defined and Key Statistics\". 21 October 2021. pp. 5, 39, 46, 48. (link). Retrieved 30 November 2013.\n- \"Health at a Glance 2013 – OECD Indicators\" (PDF). OECD. 21 November 2013. pp. 5, 39, 46, 48. (link). Archived (PDF) from the original on 12 April 2019. Retrieved 24 November 2013.\n- \"OECD.StatExtracts, Health, Health Status, Life expectancy, Total population at birth, 2011\" (online statistics). stats.oecd.org/. OECD's iLibrary. 2013. Archived from the original on 2 April 2019. Retrieved 24 November 2013.\n- Commonwealth Fund (2018). \"Health Care Quality-Spending Interactive | Commonwealth Fund\". commonwealthfund.org. doi:10.26099/bf4n-8j57. Archived from the original on 22 December 2020. Retrieved 14 January 2019.\n- OECD Data. Health resources - Health spending Archived 12 April 2020 at the Wayback Machine. doi:10.1787/8643de7e-en. 2 bar charts: For both: From bottom menus: Countries menu > choose OECD. Check box for \"latest data available\". Perspectives menu > Check box to \"compare variables\". Then check the boxes for government/compulsory, voluntary, and total. Click top tab for chart (bar chart). For GDP chart choose \"% of GDP\" from bottom menu. For per capita chart choose \"US dollars/per capita\". Click fullscreen button above chart. Click \"print screen\" key. Click top tab for table, to see data.\n- \"Quality and accreditation in health care services\" (PDF). Geneva: World Health Organization. Archived from the original (PDF) on 22 December 2020.\n- Tulenko et al., \"Framework and measurement issues for monitoring entry into the health workforce.\" Handbook on monitoring and evaluation of human resources for health. Geneva, World Health Organization, 2012.\n- \"Health information technology — HIT\". HealthIT.gov. Archived from the original on 22 December 2020. Retrieved 5 August 2014.\n- \"Definition and Benefits of Electronic Medical Records (EMR) | Providers & Professionals | HealthIT.gov\". www.healthit.gov. Archived from the original on 9 September 2017. Retrieved 27 November 2017.\n- \"Official Information about Health Information Exchange (HIE) | Providers & Professionals | HealthIT.gov\". www.healthit.gov. Archived from the original on 22 December 2020. Retrieved 27 November 2017.\n- \"What is a personal health record? | FAQs | Providers & Professionals | HealthIT.gov\". www.healthit.gov. Archived from the original on 22 December 2020. Retrieved 27 November 2017.\n- Media related to Healthcare at Wikimedia Commons\n- Travel health travel guide from Wikivoyage",
    "health care industry": "The healthcare industry (also called the medical industry or health economy) is an aggregation and integration of sectors within the economic system that provides goods and services to treat patients with curative, preventive, rehabilitative, and palliative care. It encompasses the creation and commercialization of products and services conducive to the preservation and restoration of well-being. The contemporary healthcare sector comprises three fundamental facets, namely services, products, and finance. It can be further subdivided into numerous sectors and categories and relies on interdisciplinary teams of highly skilled professionals and paraprofessionals to address the healthcare requirements of both individuals and communities.[1][2]\nThe healthcare industry is one of the world's largest and fastest-growing industries.[3] Consuming over 10 percent of gross domestic product (GDP) of most developed nations, health care can form an enormous part of a country's economy. U.S. healthcare spending grew 2.7 percent in 2021, reaching $4.3 trillion or $12,914 per person. As a share of the nation's Gross Domestic Product, health spending accounted for 18.3 percent.[4] The per capita expenditure on health and pharmaceuticals in OECD countries has steadily grown from a couple of hundred in the 1970s to an average of US$4'000 per year in current purchasing power parities.[5]\nFor the purpose of finance and management, the healthcare industry is typically divided into several areas. As a basic framework for defining the sector, the United Nations International Standard Industrial Classification (ISIC) categorizes the healthcare industry as generally consisting of:\n- Hospital activities;\n- Medical and dental practice activities;\n- \"Other human health activities\".\nThis third class involves activities of or under the supervision of, nurses, midwives, physiotherapists, scientific or diagnostic laboratories, pathology clinics, residential health facilities, or other allied health professions, e.g. in the field of optometry, hydrotherapy, medical massage, yoga therapy, music therapy, occupational therapy, speech therapy, chiropody, homoeopathy, chiropractic, acupuncture, etc.\nThe Global Industry Classification Standard and the Industry Classification Benchmark further distinguish the industry into two main groups:\n- healthcare equipment and services; and\n- pharmaceuticals, biotechnology and related life sciences.\nThe healthcare equipment and services group consists of companies and entities that provide medical equipment, medical supplies, and healthcare services, such as hospitals, home healthcare providers, and nursing homes. The latter listed industry group includes companies that produce biotechnology, pharmaceuticals, and miscellaneous scientific services.\nOther approaches to defining the scope of the healthcare industry tend to adopt a broader definition, also including other key actions related to health, such as education and training of health professionals, regulation and management of health services delivery, provision of traditional and complementary medicines, and administration of health insurance., chiropractic, acupuncture, etc.[6]\nA healthcare provider is an institution (such as a hospital or clinic) or person (such as a physician, nurse, allied health professional or community health worker) that provides preventive, curative, promotional, rehabilitative or palliative care services in a systematic way to individuals, families or communities.\nThe World Health Organization estimates there are 9.2 million physicians, 19.4 million nurses and midwives, 1.9 million dentists and other dentistry personnel, 2.6 million pharmacists and other pharmaceutical personnel, and over 1.3 million community health workers worldwide,[7] making the health care industry one of the largest segments of the workforce.\nThe medical industry is also supported by many professions that do not directly provide health care itself, but are part of the management and support of the health care system. The incomes of managers and administrators, underwriters, and medical malpractice attorneys, marketers, investors, and shareholders of for-profit services, all are attributable to health care costs.[8] Many healthcare providers outsource non-clinical and revenue cycle functions such as medical billing, claims processing, and denial management to business process outsourcing (BPO) companies. In 2025, several firms were recognized by Clutch as among the top medical billing providers for their compliance with HIPAA standards and strong client satisfaction ratings.[9]\nIn 2017, healthcare costs paid to hospitals, physicians, nursing homes, diagnostic laboratories, pharmacies, medical device manufacturers, and other components of the healthcare system, consumed 17.9 percent of the gross domestic product (GDP) of the United States, the largest of any country in the world. It is expected that the health share of the Gross domestic product (GDP) will continue its upward trend, reaching 19.9 percent of GDP by 2025.[10] In 2001, for the OECD countries the average was 8.4 percent[11] with the United States (13.9%), Switzerland (10.9%), and Germany (10.7%) being the top three. US health care expenditures totaled US$2.2 trillion in 2006.[3] According to Health Affairs, US$7,498 be spent on every woman, man and child in the United States in 2007, 20 percent of all spending. Costs are projected to increase to $12,782 by 2016.[12]\nThe government does not ensure all-inclusive health care to every one of its residents. However, certain freely supported healthcare programs help to accommodate a portion of people who are elderly, disabled, or poor. Elected law guarantees community to crisis benefits paying little respect to the capacity to pay. Those without health protection scope are relied upon to pay secretly for therapeutic administrations. Health protection is costly and hospital expenses are overwhelmingly the most well-known explanation behind individual liquidation in the United States.\nExpand the OECD charts below to see the breakdown:\n- \"Government/compulsory\": Government spending and compulsory health insurance.\n- \"Voluntary\": Voluntary health insurance and private funds such as households' out-of-pocket payments, NGOs and private corporations.\n- They are represented by columns starting at zero. They are not stacked. The 2 are combined to get the total.\n- At the source you can run your cursor over the columns to get the year and the total for that country.[13]\n- Click the table tab at the source to get 3 lists (one after another) of amounts by country: \"Total\", \"Government/compulsory\", and \"Voluntary\".[13]\nThe delivery of healthcare services—from primary care to secondary and tertiary levels of care—is the most visible part of any healthcare system, both to users and the general public.[15] There are many ways of providing healthcare in the modern world. The place of delivery may be in the home, the community, the workplace, or in health facilities. The most common way is face-to-face delivery, where care provider and patient see each other in person. This is what occurs in general medicine in most countries. However, with modern telecommunications technology, in absentia health care or Tele-Health is becoming more common. This could be when practitioner and patient communicate over the phone, video conferencing, the internet, email, text messages, or any other form of non-face-to-face communication. Practices like these are especial applicable to rural regions in developed nations. These services are typically implemented on a clinic-by-clinic basis.[16]\nImproving access, coverage and quality of health services depends on the ways services are organized and managed, and on the incentives influencing providers and users. In market-based health care systems, for example in the United States, such services are usually paid for by the patient or through the patient's health insurance company. Other mechanisms include government-financed systems (such as the National Health Service in the United Kingdom). In many poorer countries, development aid, as well as funding through charities or volunteers, help support the delivery and financing of health care services among large segments of the population.[17]\nThe structure of healthcare charges can also vary dramatically among countries. For instance, Chinese hospital charges tend toward 50% for drugs, another major percentage for equipment, and a small percentage for healthcare professional fees.[18] China has implemented a long-term transformation of its healthcare industry, beginning in the 1980s. Over the first twenty-five years of this transformation, government contributions to healthcare expenditures have dropped from 36% to 15%, with the burden of managing this decrease falling largely on patients. Also over this period, a small proportion of state-owned hospitals have been privatized. As an incentive to privatization, foreign investment in hospitals—up to 70% ownership has been encouraged.[18]\nHealthcare systems dictate the means by which people and institutions pay for and receive health services. Models vary based on the country with the responsibility of payment ranging from the public (social insurance) and private health insurers to the consumer-driven by patients themselves. These systems finance and organize the services delivered by providers. A two-tier system of public and private is common.\nThe American Academy of Family Physicians defines four commonly utilized systems of payment:\nNamed after British economist and social reformer William Beveridge, the Beveridge model sees healthcare financed and provided by a central government.[19] The system was initially proposed in his 1942 report, Social Insurance and Allied Services—known as the Beveridge Report. The system is the guiding basis of the modern British healthcare model enacted post-World War II. It has been utilized in numerous countries, including The United Kingdom, Cuba, and New Zealand.[20]\nThe system sees all healthcare services— which are provided and financed solely by the government. This single payer system is financed through national taxation.[21] Typically, the government owns and runs the clinics and hospitals, meaning that doctors are employees of the government. However, depending on the specific system, public providers can be accompanied by private doctors who collect fees from the government.[20] The underlying principle of this system is that healthcare is a fundamental human right. Thus, the government provides universal coverage to all citizens.[22] Generally, the Beveridge model yields a low cost per capita compared to other systems.[23]\nThe Bismarck system was first employed in 1883 by Prussian Chancellor Otto von Bismarck.[24] In this system, insurance is mandated by the government and is typically sold on a non-profit basis. In many cases, employers and employees finance insurers through payroll deduction. In a pure Bismarck system, access to insurance is seen as a right solely predicated on labor status. The system attempts to cover all working citizens, meaning patients cannot be excluded from insurance due to pre-existing conditions. While care is privatized, it is closely regulated by the state through fixed procedure pricing. This means that most insurance claims are reimbursed without challenge, creating a low administrative burden.[24] Archetypal implementation of the Bismarck system can be seen in Germany's nationalized healthcare. Similar systems can be found in France, Belgium, and Japan.[25]\nThe national insurance model shares and mixes elements from both the Bismarck and Beveridge models. The emergence of the National Health Insurance model is cited as a response to the challenges presented by the traditional Bismarck and Beveridge systems.[26] For instance, it is difficult for Bismarck Systems to contend with aging populations, as these demographics are less economically active.[27] Ultimately, this model has more flexibility than a traditional Bismarck or Beveridge model, as it can pull effective practices from both systems as needed.\nThis model maintains private providers, but payment comes directly from the government.[citation needed] Insurance plans control costs by paying for limited services. In some instances, citizens can opt out of public insurance for private insurance plans. However, large public insurance programs provide the government with bargaining power, allowing them to drive down prices for certain services and medication. In Canada, for instance, drug prices have been extensively lowered by the Patented Medicine Prices Review Board.[28] Examples of this model can be found in Canada, Taiwan, and South Korea.[29]\nIn areas with low levels of government stability or poverty, there is often no mechanism for ensuring that health costs are covered by a party other than the individual. In this case, patients must pay for services on their own.[20] Payment methods can vary—ranging from physical currency, to trade for goods and services.[20] Those that cannot afford treatment typically remain sick or die.[20]\nIn countries where insurance is not mandated, there can be underinsurance—especially among disadvantaged and impoverished communities that can not afford private plans.[30] The UK National Health System creates excellent patient outcomes and mandates universal coverage but also has large lag times for treatment. Critics argue that reforms brought about by the Health and Social Care Act 2012 only proved to fragment the system, leading to high regulatory burden and long treatment delays.[31] In his review of NHS leadership in 2015, Sir Stuart Rose concluded that \"the NHS is drowning in bureaucracy.\"[32]\n- HEALTH PROFESSIONS [1]\n- \"Health Care Initiatives, Employment & Training Administration (ETA) - U.S. Department of Labor\". Doleta.gov. Archived from the original on 2012-01-29. Retrieved 2015-02-17.\n- \"Snapshots: Comparing Projected Growth in Health Care Expenditures and the Economy | The Henry J. Kaiser Family Foundation\". Kff.org. 2006-04-17. Archived from the original on 2013-04-02. Retrieved 2015-02-17.\n- \"Historical | CMS\". www.cms.gov. Retrieved 2023-02-06.\n- \"THE PHARMACEUTICAL INDUSTRY AND GLOBAL HEALTH - FACTS AND FIGURES 2021\" (PDF). INTERNATIONAL FEDERATION OF PHARMACEUTICAL MANUFACTURERS & ASSOCIATIONS. Archived from the original (PDF) on 2022-02-01. Retrieved 2022-02-28.\n- United Nations. International Standard Industrial Classification of All Economic Activities, Rev.3. New York.\n- World Health Organization. World Health Statistics 2011 – Table 6: Health workforce, infrastructure and essential medicines. Geneva, 2011. Accessed 21 July 2011.\n- Evans RG (1997). \"Going for the gold: the redistributive agenda behind market-based health care reform\" (PDF). J Health Polit Policy Law. 22 (2): 427–65. CiteSeerX 10.1.1.573.7172. doi:10.1215/03616878-22-2-427. PMID 9159711.\n- Briones, Julliana. \"Select Voicecom, 5 Source Partners in Clutch's top medical billing firms 2025\".\n- Keehan, Sean P.; Stone, Devin A.; Poisal, John A.; Cuckler, Gigi A.; Sisko, Andrea M.; Smith, Sheila D.; Madison, Andrew J.; Wolfe, Christian J.; Lizonitz, Joseph M. (March 2017). \"National Health Expenditure Projections, 2016–25: Price Increases, Aging Push Sector To 20 Percent Of Economy\". Health Affairs. 36 (3): 553–563. doi:10.1377/hlthaff.2016.1627. ISSN 0278-2715. PMID 28202501. S2CID 4927588.\n- [2] Archived March 20, 2007, at the Wayback Machine\n- \"Average 2016 health-care bill: $12,782\" by Ricardo Alonso-Zalvidar Los Angeles Times February 21, 2007\n- OECD Data. Health resources - Health spending. doi:10.1787/8643de7e-en. 2 bar charts: For both: From bottom menus: Countries menu > choose OECD. Check box for \"latest data available\". Perspectives menu > Check box to \"compare variables\". Then check the boxes for government/compulsory, voluntary, and total. Click top tab for chart (bar chart). For GDP chart choose \"% of GDP\" from bottom menu. For per capita chart choose \"US dollars/per capita\". Click fullscreen button above chart. Click \"print screen\" key. Click top tab for table, to see data.\n- Link between health spending and life expectancy: US is an outlier. May 26, 2017. By Max Roser at Our World in Data. Click the sources tab under the chart for info on the countries, healthcare expenditures, and data sources. See the later version of the chart here.\n- \"WHO | Health systems service delivery\". Who.int. Archived from the original on March 27, 2006. Retrieved 2015-02-17.\n- \"Telehealth Use in Rural Healthcare Introduction - Rural Health Information Hub\". www.ruralhealthinfo.org. Retrieved 2018-10-29.\n- [3] Archived July 26, 2011, at the Wayback Machine\n-\nRobert Yuan (2007-06-15). \"China Cultivates Its Healthcare Industry\". Genetic Engineering & Biotechnology News. Mary Ann Liebert, Inc. pp. 49–51. Retrieved 2008-07-07.\n(subtitle) The Risks and Opportunities in a Society Undergoing Explosive Change\n- \"The National Archives | Exhibitions | Citizenship | Brave new world\". www.nationalarchives.gov.uk. Retrieved 2018-10-27.\n- \"Health Care Reform: Learning From Other Major Health Care Systems | Princeton Public Health Review\". pphr.princeton.edu. Archived from the original on 2021-03-10. Retrieved 2018-10-27.\n- Beveridge, William (1942). Social Insurance and Allied Services. Macmillan.\n- Bevan, Gwyn; Helderman, Jan-Kees; Wilsford, David (July 2010). \"Changing choices in health care: implications for equity, efficiency and cost\". Health Economics, Policy and Law. 5 (3): 251–267. doi:10.1017/S1744133110000022. hdl:2066/87091. ISSN 1744-134X. PMID 20478104.\n- Organization, World Health (2000). The World Health Report 2000: Health Systems: Improving Performance. World Health Organization. ISBN 978-92-4-156198-3.\nBritain.\n- Busse, Reinhard; Blümel, Miriam; Knieps, Franz; Bärnighausen, Till (2017-08-26). \"Statutory health insurance in Germany: a health system shaped by 135 years of solidarity, self-governance, and competition\". Lancet. 390 (10097): 882–897. doi:10.1016/S0140-6736(17)31280-1. ISSN 1474-547X. PMID 28684025.\n- \"Five Countries - Health Care Systems -- The Four Basic Models | Sick Around The World | FRONTLINE\". www.pbs.org. Retrieved 2018-10-27.\n- van der Zee, Jouke; Kroneman, Madelon (2007-02-01). \"Bismarck or Beveridge: A beauty contest between dinosaurs\". BMC Health Services Research. 7: 94. doi:10.1186/1472-6963-7-94. PMC 1934356. PMID 17594476.\n- Joël, Marie-Eve; Dufour-Kippelen, Sandrine (August 2002). \"Financing systems of care for older persons in Europe\". Aging Clinical and Experimental Research. 14 (4): 293–299. doi:10.1007/bf03324453. ISSN 1594-0667. PMID 12462375. S2CID 43533840.\n- Office, U.S. Government Accountability (1993-02-22). \"Prescription Drug Prices: Analysis of Canada's Patented Medicine Prices Review Board\" (HRD-93-51).\n{{cite journal}}\n: Cite journal requires|journal=\n(help) - Reid, T R (2009). The healing of America: a global quest for better, cheaper, and fairer health care. Penguin Press. ISBN 978-1-59420-234-6.\n- \"The Coverage Gap: Uninsured Poor Adults in States that Do Not Expand Medicaid\". The Henry J. Kaiser Family Foundation. 2018-06-12. Retrieved 2018-11-07.\n- \"Implementation of the Health and Social Care Act\". BMJ. 346 f2173. 2013-04-05. doi:10.1136/bmj.f2173. ISSN 1756-1833.\n- \"Better leadership for tomorrow: NHS leadership review\". GOV.UK. Retrieved 2018-11-07.\n- Mahar, Maggie, Money-Driven Medicine: The Real Reason Health Care Costs So Much, Harper/Collins, 2006. ISBN 978-0-06-076533-0\n- Meidinger, Roy (2015). Truth About Healthcare Industry. City: BookBaby. ISBN 978-1-4835-5003-9. OCLC 958576690.\nThe Truth About The Healthcare Industry, is it is an Oligopoly, an Industry, with very high costs and low quality of service. The book looks at the last 30 years and explains how this industry has stolen $21 trillion, through false billings, accounting fraud, kickbacks and restrained trade by using economic duress. As this industry expanded, it damaged other industries, especially the manufacturing industry, which closed 75,000 companies and caused the loss of 7 million manufacturing jobs. The book shows that the government has known for some time, has covered up the illegal practices, especially the IRS.\n- Media related to Healthcare industry at Wikimedia Commons",
    "hospitality industry": "The hospitality industry is a broad category of fields within the service industry that includes lodging, food and beverage services, event planning, theme parks, travel agency, tourism, hotels, restaurants, nightclubs, and bars.\nAccording to the Cambridge Business English Dictionary the \"hospitality industry\" consists of hotels and food service,[1] equivalent to NAICS code 72, \"Accommodation and Food Service\".\nIn 2020, the United States Department of Labor Standard Industrial Classification (SIC) defines the hospitality industry more broadly, including:[2]\n- 701 Hotels and Motels, including auto courts, bed and breakfast inns, cabins and cottages, casino hotels, hostels, hotels (except residential ones), inns furnishing food and lodging, motels, recreational hotels, resort hotels, seasonal hotels, ski lodges and resorts, tourist cabins and tourist courts\n- 704 Organization Hotels and Lodging Houses, On a Membership Basis\n- 58 Eating and Drinking Places (cf. U.S. \"food service industry\", U.K. \"catering industry\")\n- 5812 Eating Places, including restaurants (among which carry-out restaurants, drive-in restaurants and fast food restaurants), automats, beaneries, box lunch stands, buffets, cafés, cafeterias, caterers, coffee shops, commissary restaurants a.k.a. canteens, concession stands, dhaba prepared food (e.g., in airports and sports arenas), contract feeding, dairy bars, diners, dining rooms, dinner theaters, food bars, frozen custard stands, grills, hamburger stands, hot dog stands, ice cream stands, industrial feeding, institutional food service such as that aboard airplanes, railroads, and ships), lunch bars, lunch counters, luncheonettes, lunchrooms, oyster bars, pizza parlors and pizzerias, refreshment stands, sandwich bars or shops, snack shops, soda fountains, soft drink stands, submarine sandwich shops, and tearooms. Sources other than the SIC also mention other formats of eating places such as cyber cafés, ramen shops a.k.a. noodle bars, and sushi bars.[3]\n- 5813 Drinking Places (alcoholic beverages) including bars, beer gardens/parlors/taverns, sale of beer, wine, and liquors for on-premise consumption, bottle clubs, cabarets, cocktail lounges, discotheques, drinking places, nightclubs, saloons, taprooms, taverns, and wine bars\n- 472 Arrangement of Passenger Transportation\n- 4724 Travel Agencies\n- 4725 Tour Operators\n- 4729 Arrangement of Passenger Transportation, Not Elsewhere Classified, such as ticket offices not operated by transportation companies, and services that arrange carpools\nIn the United States, hotels are the most popular vacation accommodation. In 2022, the hotel and motel industry in the United States was a $224.9 billion market, measured by revenue.[4]\nHoreca (also HoReCa, HORECA) is the Dutch, Indonesian, German, Italian, Romanian, Portuguese and French term for the food service and hotel industries. The term is a syllabic abbreviation of the words hotel/restaurant/café.[5][6] The term is mostly used in the Benelux countries, Indonesia, and Switzerland.\n\"Horeca\" is often not a one-to-one equivalent to the term \"hospitality industry\" used in English, which is often used more broadly. According to the Cambridge Business English Dictionary the \"hospitality industry\" consists of hotels and food service,[7] equivalent to NAICS code 72, \"Accommodation and Food Service\". However, the United States Department of Labor Standard Industry Classification (SIC) defines the hospitality industry more broadly, as noted above.\nThe Dutch Uniforme Voorwaarden Horeca (UVH) is translated into English as Uniform Conditions for the Hotel and Catering Industry. This code covers hotels, bars, restaurants and related businesses in the Netherlands. Koninklijke Horeca Nederland is the Dutch trade association for the hotel and catering industry.[8]\nThis sector is one of the fastest growing in Europe. In 2004, more than 7.8 million people were employed[9] and the sector generated more than $338 billion in turnover.[10] Jobs tend to be temporary, with irregular hours, low pay, and few career prospects. There is a high proportion of young people working in the sector. Some distribution companies use this term to define the food & beverage service trade channel or the hospitality trade.\nThe hotel industry in India is poised for continued strong growth, with CareEdge Ratings forecasting a 9-11% year-over-year increase in revenue for hotels in FY25. This comes after an estimated 12-14% growth in RevPAR (revenue per available room) in FY24, driven by robust demand outpacing supply.[11] Average room rates across India are projected to rise from around ₹7,200-7,400 in FY24 to ₹7,700-7,900 in FY25, with RevPAR climbing to an average of ₹4,800-5,000 by end-FY24. The recovery is fueled by healthy domestic leisure and business travel demand, complemented by increasing foreign tourist arrivals. While new supply is expected at a 4-5% CAGR over 4-5 years adding over 50,000 branded rooms, this delayed catch-up will allow demand-supply dynamics to gradually align. The CareEdge report notes a better balance emerging across segments like upscale, upper midscale and midscale/economy, reducing the earlier concentration in luxury/upper upscale. With high occupancies of 68-70% forecast for FY25, the strong RevPAR growth should aid in improving the credit profile of industry players.\nIn 2015 the United Kingdom hospitality industry employed around 2.9m people – around 9% of the UK workforce.[12] By employment, it is the UK's fourth-largest industry. The most jobs in the industry are found in London (around 500,000) and South East England (around 400,000); 18% of workers in the UK industry are in London. There are around 1.5m restaurant workers, and around 0.5m work in hotels. The Food Safety Act 1990 introduced the training that staff have to follow. Around 25% of the hospitality workforce comes from the EU, making up around 25% of chefs and around 75% of waiting staff.[13][14] In 2019, 1 in 50 applicants to Pret a Manger was British.\nThe hotel industry in Vietnam is an important economic sector, contributing significantly to the country's GDP.[15][16][17] According to statistics from the Vietnam National Administration of Tourism, in 2022, Vietnam had a total of 32,313 accommodation establishments[18][19] with 611,352 rooms, including 1,576 hotels with three stars or higher with 334,487 rooms.[20][21][22] Despite this, the Vietnamese hotel industry is still considered to have great potential for development in the future.[23][24] According to the forecast of the World Tourism Organization (UNWTO), Vietnam will be one of the top tourist destinations in the world in the coming years.[25][26][27] This will create opportunities for the development of the Vietnamese hotel industry.[28][29][30] According to statistics from the Vietnam National Administration of Tourism, the Vietnamese hotel industry has had an average growth rate of 15% per year in the period 2010–2022.[31][32]\n- American Hotel & Lodging Educational Institute\n- Customer service\n- Destination marketing organization\n- Gastronomy\n- Hospitality\n- Hotel manager\n- Leisure industry\n- \"Hospitality industry\". Cambridge Business English Dictionary. Retrieved 19 March 2020.\n- \"Global Hospitality Leadership: Industry & Company Information\". Georgetown University Library. Retrieved 19 March 2020.\n- Andrews (2007). Introduction To Tourism And Hospitality Industry. McGraw-Hill Education (India). ISBN 9780070660212. Retrieved 19 March 2020.\n- \"Hotels & Motels in the US - Market Size 2005–2029\". IBISWorld. Retrieved 6 August 2023.\n- \"Abbreviations and Acronyms\". Eurostat. Retrieved 28 February 2017.\n- \"Wat valt onder horeca? (\"What is included in 'horeca'?\")\". CBS (Central Bureau for Statistics of The Netherlands) (in Dutch). Retrieved 19 March 2020.\n- \"Hospitality industry\". Cambridge Business English Dictionary. Retrieved 19 March 2020.\n- Uniform Conditions for the Hotel and Catering Industry – Koninklijk Horeca Nederland\n- Eurostat, 2005\n- Hospitality industry course\n- V, Manju (28 March 2024). \"Hotels to see 9-11% Revenue Growth in FY25: CareEdge Ratings\". The Times of India. Retrieved 17 June 2024.\n- \"International Marketing Mix of ITC Hotels in UK | PDF | Economies | Marketing\". Scribd. Retrieved 2024-01-26.\n- \"BHA report\". Archived from the original on 2017-09-11. Retrieved 2024-01-26.\n- \"Employer Immigration Services | Employ Overseas Workers\". www.wmimmigration.com. Retrieved 2022-01-19.\n- dulich.vn. \"Ứng dụng công nghệ trong marketing truyền thông tích hợp cho các khách sạn ở VN\". Tạp chí Du lịch (in Vietnamese). Retrieved 2024-01-26.\n- hanoimoi.vn (2016-01-27). \"Du lịch Việt Nam: Lớn mạnh nhờ thay đổi tư duy\". hanoimoi.vn (in Vietnamese). Retrieved 2024-01-26.\n- \"Du lịch đóng góp 6,6% GDP quốc gia\". Bộ Tài chính (in Vietnamese). 2016-01-27. Retrieved 2024-01-26.\n- \"Cả nước có thêm 20 cơ sở lưu trú 4-5 sao với 7.275 buồng\". baodautu (in Vietnamese). Retrieved 2024-01-26.\n- Việt/nhadautu.vn, Theo Đăng (2022-09-08). \"Ngành Du lịch tăng trưởng mạnh nhờ chuyển đổi số\". Tạp chí Tài chính (in Vietnamese). Retrieved 2024-01-26.\n- Mai -, Ban (2023-02-14). \"Khách quốc tế sẽ làm \"nóng\" ngành khách sạn\". Nhịp sống kinh tế Việt Nam & Thế giới (in Vietnamese). Retrieved 2024-01-26.\n- VTV, BAO DIEN TU (2023-03-24). \"Khách sạn vừa và nhỏ tại TP Hồ Chí Minh muốn được 'trỗi dậy' nhờ chuyển đổi số\". BAO DIEN TU VTV (in Vietnamese). Retrieved 2024-01-26.\n- Mai -, Ban (2023-08-15). \"Khách sạn \"trông chờ\" nguồn khách nội địa\". Nhịp sống kinh tế Việt Nam & Thế giới (in Vietnamese). Retrieved 2024-01-26.\n- \"Trải nghiệm xanh: Lộ trình đến tương lai của ngành khách sạn Việt Nam | Du lịch\". diendandoanhnghiep.vn (in Vietnamese). Retrieved 2024-01-26.\n- \"Bất động sản du lịch, nghỉ dưỡng có nhiều tiềm năng phát triển\". mof.gov.vn. Retrieved 2024-01-26.\n- \"Tổ chức Du lịch thế giới công bố những dấu ấn của du lịch toàn cầu\". vietnamtourism.gov.vn. Retrieved 2024-01-26.\n- \"Tổ chức Du lịch thế giới (UNWTO): Du lịch nội địa và gần nhà là xu hướng nổi bật trong năm 2021\". vietnamtourism.gov.vn. Retrieved 2024-01-26.\n- baochinhphu.vn (2023-03-03). \"Việt Nam là điểm đến ưa thích của du khách quốc tế\". baochinhphu.vn (in Vietnamese). Retrieved 2024-01-26.\n- \"Triển vọng ngành du lịch - khách sạn sẽ khả quan hơn trong năm 2024\". Báo Đấu thầu (in Vietnamese). 2023-12-15. Retrieved 2024-01-26.\n- VnExpress. \"Best Hotel Group In Vietnam\". vnexpress.net (in Vietnamese). Retrieved 2024-01-26.\n- Sơn -, Tuấn (2023-10-05). \"Định hình tương lai bền vững của ngành du lịch và khách sạn\". Nhịp sống kinh tế Việt Nam & Thế giới (in Vietnamese). Retrieved 2024-01-26.\n- \"Việt Nam dẫn đầu châu Á về tăng trưởng khách sạn\". vietnamtourism.gov.vn. Retrieved 2024-01-26.\n- \"Việt Nam nằm trong tốp 10 quốc gia có tốc độ tăng trưởng du lịch nhanh nhất thế giới\". vietnamtourism.gov.vn. Retrieved 2024-01-26.",
    "human resource management": "| Business administration |\n|---|\nHuman resource management (HRM) is the strategic and coherent approach to the effective and efficient management of people in a company or organization such that they help their business gain a competitive advantage. It is designed to maximize employee performance in service of an employer's strategic objectives.[1][2][3][4]\nHuman resource management is primarily concerned with the management of people within organizations, focusing on policies and systems.[5] HR departments are responsible for overseeing employee-benefits design, employee recruitment, training and development, performance appraisal, and reward management, such as managing pay and employee benefits systems.[6] HR also concerns itself with organizational change and industrial relations, or the balancing of organizational practices with requirements arising from collective bargaining and governmental laws.[7]\nThe overall purpose of human resources (HR) is to ensure that the organization can achieve success through people.[8] HR professionals manage the human capital of an organization and focus on implementing policies and processes. They can specialize in finding, recruiting, selecting, training, and developing employees, as well as maintaining employee relations or benefits. Training and development professionals ensure that employees are trained and have continuous development. This is done through training programs, performance evaluations, and reward programs. Employee relations deals with the concerns of employees when policies are broken, such as in cases involving harassment or discrimination. Managing employee benefits includes developing compensation structures, parental leave, discounts, and other benefits. On the other side of the field are HR generalists or business partners. These HR professionals could work in all areas or be labour relations representatives working with unionized employees.\nHR is a product of the human relations movement of the early 20th century when researchers began documenting ways of creating business value through the strategic management of the workforce.[9] It was initially dominated by transactional work, such as payroll and benefits administration, but due to globalization, company consolidation, technological advances, and further research, HR as of 2015[update] focuses on strategic initiatives like mergers and acquisitions, talent management, succession planning, industrial and labor relations, and diversity and inclusion. In the current[update] global work environment, most companies focus on lowering employee turnover and on retaining the talent and knowledge held by their workforce.[10]\nThe human resources field began to take shape in 19th century Europe. It is built on a simple idea by Robert Owen (1771–1858) and Charles Babbage (1791–1871) during the Industrial Revolution. These men concluded that people were crucial to the success of an organization. They expressed the thought that well-being of employees led to perfect work; without healthy workers, the organization would not survive.[11][need quotation to verify]\nThe term \"human resource\" was first coined by labor economist John R. Commons in 1893.[12][13] HR emerged as a specific field in the early 20th century, influenced by Frederick Winslow Taylor (1856–1915). Taylor explored what he termed \"scientific management\" (sometimes referred to as \"Taylorism\"), striving to improve economic efficiency in manufacturing jobs. He eventually focused on one of the principal inputs into the manufacturing process—labor—sparking inquiry into workforce productivity.[14]\nMeanwhile, in London C S Myers inspired by unexpected problems among soldiers who alarmed generals and politicians. During the First World War, he co-founded the National Institute of Industrial Psychology (NIIP) in 1921.[15] He set seeds for the human relations movement, this movement, on both sides of the Atlantic, built on the research of Elton Mayo (1880–1949) and others to document through the Hawthorne studies (1924–1932) and other studies how stimuli, unrelated to financial compensation and working conditions, could yield more productive workers.[16] Work by Abraham Maslow (1908–1970), Kurt Lewin (1890–1947), Max Weber (1864–1920), Frederick Herzberg (1923–2000), and David McClelland (1917–1998) formed the basis for studies in industrial and organizational psychology, organizational behavior and organizational theory.[citation needed]\nBy the time there was enough theoretical evidence to make a business case for strategic workforce management, changes in the business landscape—à la Andrew Carnegie (1835–1919) and John Rockefeller (1839–1937)—and in public policy—à la Sidney (1859–1947) and Beatrice Webb (1858–1943), Franklin D. Roosevelt and the New Deal of 1933 to 1939—had transformed employer-employee relationships, and the HRM discipline became formalized as \"industrial and labor relations\". In 1913 one of the oldest known professional HR associations—the Chartered Institute of Personnel and Development (CIPD)—started in England as the Welfare Workers' Association; it changed its name a decade later to the Institute of Industrial Welfare Workers, and again the next decade to Institute of Labour Management before settling upon its current name in 2000.[17] From 1918 the early Soviet state institutions began to implement a distinct ideological HRM focus[18] alongside technical management—first in the Red Army (through political commissars alongside military officers), later (from 1933) in work sites more generally (through partorg posts alongside conventional managers).[19]\nIn 1920, James R. Angell delivered an address to a conference on personnel research in Washington detailing the need for personnel research. This preceded and led to the organization of the Personnel Research Federation. In 1922 the first volume of The Journal of Personnel Research was published, a joint initiative between the National Research Council and the Engineering Foundation.[20] Likewise in the United States, the world's first institution of higher education dedicated to workplace studies—the School of Industrial and Labor Relations—formed at Cornell University in 1945.[21] In 1948 what would later become the largest professional HR association—the Society for Human Resource Management (SHRM)—formed as the American Society for Personnel Administration (ASPA).[22]\nIn the Soviet Union, Stalin's use of patronage exercised through the \"HR Department\" equivalent in the Bolshevik Party, its Orgburo, demonstrated the effectiveness and influence of human-resource policies and practices,[23][24] and Stalin himself acknowledged the importance of the human resource,[25] exemplified in his mass deployment of it, as in the five-year plans and in the Gulag system.\nDuring the latter half of the 20th century, private-sector union membership in the U.S. declined significantly,[26][27][28][29] while workforce-management specialists continued to expand their influence within organizations.[30] In the U.S., the phrase \"industrial and labor relations\" came into use to refer specifically to issues concerning collective representation, and companies began referring to the proto-HR profession as \"personnel administration.\"[31][32] Many current HR practices originated with the needs of companies in the 1950s to develop and retain talent.[33]\nIn the late 20th century, advances in transportation and communications greatly facilitated workforce mobility and collaboration. Corporations began viewing employees as assets. \"Human resource management\" consequently became the dominant term for the function,[34] with the ASPA even changing its name to the Society for Human Resource Management (SHRM) in 1998.[22]\n\"Human capital management\" (HCM) is sometimes used synonymously with \"HR\", although \"human capital\" typically refers to a narrower view of human resources; i.e. the knowledge the individuals embody and can contribute to an organization.[35] Other terms sometimes used to describe the HRM field include \"organizational management\", \"manpower management\", \"talent management\", \"personnel management\", \"workforce management\", and simply \"people management\".\nSeveral popular media productions have depicted human resource management in operation. The U.S. television series The Office, HR representative Toby Flenderson is sometimes portrayed as a nag because he constantly reminds coworkers of company policies and government regulations.[36] Long-running American comic strip Dilbert frequently portrays sadistic HR policies through the character Catbert, the \"evil director of human resources\".[37] An HR manager is the title character in the 2010 Israeli film The Human Resources Manager, while an HR intern is the protagonist in 1999 French film Ressources humaines. The main character in the BBC sitcom dinnerladies, Philippa, is an HR manager. The protagonist of the Mexican telenovela Mañana es para siempre is a director of human resources. Up In the Air is centered on corporate \"downsizer\" Ryan Bingham (George Clooney) and his travels. As the film progresses, HR is portrayed as a data-driven function that deals with people as human resource metrics, which can lead to absurd outcomes for real people.\nDave Ulrich lists the function of human resources as:[38]\n- Aligning human resource strategy and human resource metrics with business strategy\n- Re-engineering organization processes\n- Listening and responding to employees, and managing transformation and change.\nAt the macro level, HR is in charge of overseeing organizational leadership and culture. HR also ensures compliance with employment and labor laws and often oversees employee health, safety, and security. Labor laws may vary from one jurisdiction to the next. In a workplace administered by the federal government, HR managers may need to be familiar with certain crucial federal laws, in order to protect both their company and its employees. In the United States of America, important federal laws and regulations include:\n- Fair Labor Standards Act of 1938: It establishes a minimum wage and protects the right of certain workers to earn overtime.\n- Equal Employment Opportunity Act of 1972: It strengthens the Equal Employment Opportunity Commission's authority to prevent and address workplace discrimination and prohibits employers from making hiring, firing, or employment decisions based on race, color, religion, sex, national origin, or age.\n- Family and Medical Leave Act of 1993: It allows eligible employees to take up to twelve weeks of unpaid leave for family and medical reasons while ensuring they can return to their job afterward.\n- Immigration Reform and Control Act: It requires employers to verify the identity and employment eligibility of all employees, prohibits the hiring of unauthorized workers, and establishes penalties for employers who hire unauthorized aliens while protecting employees from discrimination based on nationality or citizenship, except for the \"right to prefer equally qualified citizens\".[39]\nAn important responsibility of HR is to ensure that a company complies with all laws and regulations, thus protecting the company from legal liability.[40] In circumstances where employees exercise their legal authorization to negotiate a collective bargaining agreement, HR will typically also serve as the company's primary liaison with employee representatives (usually a labor union). Consequently, the HR industry lobbies governmental agencies (e.g., in the United States, the United States Department of Labor and the National Labor Relations Board) to advance its priorities.\n- Staffing: The process of the recruitment and selection of employees through the use of interviews, applications and networking. Staffing involves two main factors. The first is to attract talented recruits who meet the organization's requirements, and doing so by using tools such as mass media; the second is to manage hiring resources. Managers can use hiring resources to exercise different strategies.\n- Training and Development: It involves a continuous process of training and developing competent and adapted employees. Here, motivation is seen as key to keeping employees highly productive. This includes employee benefits, performance appraisals, and rewards. Employee benefits, appraisals, and rewards are all encouragements to bring forward the best employees.\n- Maintenance: Involves keeping the employees' commitment and loyalty to the organization. Managing for employee retention involves strategic actions to keep employees motivated and focused so they remain employed and fully productive for the benefit of the organization.[41] Some businesses globalize and form more diverse teams. HR departments have the role of making sure that these teams can function and that people can communicate across cultures and across borders. The discipline may also engage in mobility management, especially for expatriates; and it is frequently involved in the merger and acquisition process. HR is generally viewed as a support function to the business, helping to minimize costs and reduce risk.[42]\nOther Activities:\n- Talent Acquisition: focuses on the long-term strategic planning required to identify, attract, and hire the top talent necessary to meet the organization's needs.\n- Talent Recruitment: involves identifying, attracting, and hiring suitable candidates to fulfill specific job openings and meet business needs.[43]\n- Talent Management: helps organizations identify key positions vital for long-term success, develop a pool of high-potential employees to fill these roles, and establish a framework for managing performance, developing leaders, retaining talent, and fostering organizational commitment.[44]\n- Compensation and Benefits: design competitive compensation and benefits packages to attract and retain talent.\n- Employee Relations: manage employee relations issues, such as conflict resolution, employee grievances, and workplace investigations.\n- Training and Development: develop and implement training programs and professional development opportunities for their employees.[45]\n- Performance Management: a systematic process focused on enhancing organizational effectiveness according to the organization's tactical and strategic goals, using performance management systems and designing human resource metrics. Performance is considered a function of ability, motivation, and environment; hence, this approach provides employees with clear feedback on their performance outcomes and support areas for improvement, ensuring that active learning and cultural engagement take place in alignment with organizational objectives.[46]\n- Legal Compliance: ensure that organizations are compliant with labor laws and regulations, including employment standards, workplace safety, and anti-discrimination policies.\nIn startup companies, trained professionals may perform HR duties. In larger companies, an entire functional group is typically dedicated to the discipline, with staff specializing in various HR tasks and functional leadership engaging in strategic decision-making across the business. To train practitioners for the profession, institutions of higher education, professional associations, and companies have established programs of study dedicated explicitly to the duties of the function. Academic and practitioner organizations may produce field-specific publications. HR is also a field of research study that is popular within the fields of management and industrial/organizational psychology. One of the important goal of HRM is establishing with the notion of unitarism (seeing a company as a cohesive whole, in which both employers and employees should work together for its common good) and securing a long-term partnership of employees and employers with common interests.[47]\nCode of ethics provides a framework for ethical behavior and professional conduct in HRM. It ensures integrity, fairness, and responsibility. Its function is to guide HR professionals and departments in upholding the rights, safety, and interests of all stakeholders. They are generally categorized into the following:[48][49]\n- Duties to the Public: HR professionals must act ethically, lawfully, and with integrity. They should address illegal acts, uphold public trust, maintain competence, and engage in continuous professional development.\n- Duties to the Profession: HR professionals must uphold the reputation of the profession by avoiding misconduct, adhering to ethical codes, promoting a positive image, and cooperating with investigations or disciplinary processes.\n- Duties to Clients and Employers: HR professionals must prioritize the best interests of employers and clients, ensure impartiality, disclose conflicts of interest, maintain accurate records, and safeguard confidentiality.\n- Duties to Individuals: HR professionals must advance dignity, equity, and safety for all. They should respect privacy, avoid discrimination or harassment, report imminent risks of harm, and foster an inclusive workplace.\n- Overarching Duties: HR professionals must foster trust, respect, and fairness in all relationships. They must act impartially, comply with laws, promote diversity, and resolve disputes ethically and professionally.\nTechnology has a significant impact on HR practices. Utilizing technology makes information more accessible within organizations, eliminates time doing administrative tasks, allows businesses to function globally, and cuts costs.[50] The adoption of modern business practices and information technology has transformed HR practices in the following ways:\nRecruiting has mostly been influenced by information technology.[51] In the past, recruiters relied on printing in publications and word of mouth to fill open positions. Human Resource professionals were not able to post a job in more than one location and did not have access to millions of people, causing the lead time of new hires to be drawn out and tiresome. With the use of e-recruiting tools, HR professionals can post jobs and track applicants for thousands of jobs in various locations all in one place. Interview feedback, background checks and drug tests, and onboarding can all be viewed online. This helps HR professionals keep track of all of their open jobs and applicants in a way that is faster and easier than before. E-recruiting also helps eliminate limitations of geographic location.[51]\nHR professionals generally handle large amounts of paperwork on a daily basis, ranging from department transfer requests to confidential employee tax forms. Forms must be on file for a considerable period of time. The use of human resources information systems (HRIS) has made it possible for companies to store and retrieve files in an electronic format for people within the organization to access when needed, thereby eliminating the need for physical files and freeing up space within the office. HRIS also allows for information to be accessed in a timelier manner; files can be accessible within seconds.[52] Having all of the information in one place also allows for professionals to analyze data quickly and across multiple locations because the information is in a centralized location. Human resource analytics can improve human resource management.[53]\nTechnology allows HR professionals to train new staff members in a more efficient manner. This gives employees the ability to access onboarding and training programs from virtually anywhere. This eliminates the need of organizing costly face-to-face training and onboarding sessions. It allows management's to provide necessary training for job success and monitor progress of their employees through virtual classrooms and computerized testing, predict the risk of employee turnover through data analysis, help HR to formulate relevant talent retention and incentive strategies, improve the personal development of the company,[54] and maintain metrics that aid in performance management.[50]\nVirtual management also allows HR departments to quickly complete necessary paperwork for large numbers of new employees and maintain contact with them throughout their entire professional cycle within the organization. Through virtual management, employees gain greater control over their learning and development, feel more engaged with the organizational culture, and can participate in training at a time and place of their choosing, helping them manage their work–life balance and reducing layoffs and turnover.\nAn Employer of Record (EOR) is an arrangement in which a third-party organization serves as the official employer for a company's workforce, handling various HR functions such as payroll, tax compliance, and employee benefits, while the client company retains day-to-day management of the workers. This arrangement eliminates the need for an organization to directly engage in HRM matters, allowing it to focus on other priorities.\nHRM consultancies are private organizations that offer tailored solutions through specialized expertise for a fee. They design customized human resource strategies and processes to address each company's unique needs. Their services include developing recruitment plans, compensation frameworks, training programs, and performance management systems, all aligned with specific HR practices and the organization's goals and culture. By acting as consultants, they provide targeted solutions that help businesses optimize their workforce and achieve organizational objectives in complex and evolving market conditions.\nThere are half a million HR practitioners in the United States and millions more worldwide.[55] The Chief HR Officer or HR Director is the highest ranking HR executive in most companies. He or she typically reports directly to the chief executive officer and works with the Board of Directors on CEO succession.[56][57]\nWithin companies, HR positions generally fall into one of two categories: generalist and specialist. Generalists support employees directly with their questions, grievances, and work on a range of projects within the organization. They \"may handle all aspects of human resources work, and thus require an extensive range of knowledge. The responsibilities of human resources generalists can vary widely, depending on their employer's needs.\" Specialists, conversely, work in a specific HR function. Some practitioners will spend an entire career as either a generalist or a specialist while others will obtain experiences from each and choose a path later. Human resource consulting is a related career path where individuals may work as advisers to companies and complete tasks outsourced from companies.[58]\nSome individuals with PhDs in HR and related fields, such as industrial and organizational psychology and management, are professors who teach HR principles at colleges and universities. They are most often found in Colleges of Business in departments of HR or Management. Many professors conduct research on topics that fall within the HR domain, such as financial compensation, recruitment, and training.\nThere are a number of professional associations, some of which offer training and certification. The Society for Human Resource Management, which is based in the United States, is the largest professional association dedicated to HR,[55] with over 285,000 members in 165 countries.[59] It offers a suite of Professional in Human Resources (PHR) certifications through its HR Certification Institute. An international provider of specialized certifications is Academy to Innovate HR (AIHR). The Chartered Institute of Personnel and Development, based in England, is the oldest professional HR association, with its predecessor institution being founded in 1918.\nSeveral associations also serve specific niches within HR. The Institute of Recruiters (IOR) is a recruitment professional association, offering members education, support and training.[60] WorldatWork focuses on \"total rewards\" (i.e., compensation, benefits, work life, performance, recognition, and career development), offering several certifications and training programs dealing with remuneration and work–life balance. Other niche associations include the American Society for Training & Development and Recognition Professionals International.\nA largely academic organization that is relevant to HR is the Academy of Management that has an HR division. This division is concerned with finding ways to improve the effectiveness of HR.[61] The academy publishes several journals devoted in part to research on HR, including Academy of Management Journal[62] and Academy of Management Review,[63] and it hosts an annual meeting.\nSome universities offer programs of study for human resources and related fields. The School of Industrial and Labor Relations at Cornell University was the world's first school for college-level study in HR.[64] It currently offers education at the undergraduate, graduate, and professional levels, and it operates a joint degree program with the Samuel Curtis Johnson Graduate School of Management. In the United States of America, the Human Resources University trains federal employees.\nMany colleges and universities house departments and institutes related to the field, either within a business school or in another college. Most business schools offer courses in HR, often in their departments of management. In general, schools of human resources management offer education and research in the HRM field from diplomas to doctorate-level opportunities. The master's-level courses include MBA (HR), MM (HR), MHRM, MIR, etc. (See Master of Science in Human Resource Development for curriculum.) Various universities all over the world have taken up the responsibility of training human-resource managers and equipping them with interpersonal and intrapersonal skills so as to relate better at their places of work. As Human resource management field is continuously evolving due to technology advances of the Fourth Industrial Revolution, it is essential for universities and colleges to offer courses which are future oriented.[65]\nOngoing research investigates the relationship between human research management and performance and includes organization studies, industrial and organizational psychology, organizational theory and management science.[66]\nAcademic and practitioner publications dealing exclusively with HR:\n- Cornell HR Review[67]\n- HR Magazine (SHRM)[68]\n- Human Resource Management[69]\n- Human Resource Management Review[70]\n- International Journal of Human Resource Management[71]\n- Perspectives on Work (LERA)[72]\nRelated journals:\n- Academy of Management Journal[62]\n- Academy of Management Review[63]\n- Administrative Science Quarterly[73]\n- International Journal of Selection and Assessment[74]\n- Journal of Applied Psychology[75]\n- Journal of Management[76]\n- Journal of Occupational and Organizational Psychology[77]\n- Journal of Personnel Psychology[78]\n- Organization Science[79]\n- Personnel Psychology[80]\nA systematic review found a lack of clarity in conceptualization and measurement of human resource systems.[81] The effect size of human resource management was found to decrease when correcting for past performance of employees.[66]\nHuman resource management has been criticized of in some cases discrimination and algorithmic bias.[82] Women were found over-represented in human resource management.[83]\n- Johnson, P. (2009). HRM in changing organizational contexts. In D. G.Collings & G. Wood (Eds.), Human resource management: A critical approach (pp. 19-37). London: Routledge.\n- Kawamoto, Dawn (2024-05-09). \"How HR can strengthen talent management to improve employee performance\". HR Executive. Retrieved 2025-07-23.\n- \"Why Is Human Resource Management Important?\". MVNU. Retrieved 2025-07-23.\n- \"The Performance Review Process: An Important Guide for HR\". www.hrmorning.com. Retrieved 2025-07-23.\n- Collings, D. G., & Wood, G. (2009). Human resource management: A critical approach. In D. G. Colligs & G. Wood (Eds.), Human resource management: A critical approach (pp. 1-16). London: Routledge.\n- Paauwe, J., & Boon, C. (2009). Strategic HRM: A critical review. In D. G. Collings, G. Wood (Eds.) & M.A. Reid, Human resource management: A critical approach (pp. 38-54). London: Routledge.\n- \"Human Resource Management | Introduction to Business\".\n- Armstrong, Michael (2009). Armstrong's handbook of human resource management practice. Armstrong, Michael, 1928- (Eleventh ed.). London: Kogan Page. ISBN 9780749457389. OCLC 435643771.\n- Obedgiu, Vincent (2017-01-01). \"Human resource management, historical perspectives, evolution and professional development\". Journal of Management Development. 36 (8): 986–990. doi:10.1108/JMD-12-2016-0267. ISSN 0262-1711.\n- \"Employee retention: 10 strategies for retaining top talent\". CIO. Retrieved 2024-05-29.\n- Griffin, Ricky. Principles of Management.\n- Schiavo, ByAmanda. \"HR 101: The history and evolution of the HR department\". HR Brew. Retrieved 2025-07-23.\n- \"John R. Commons: pioneer of labor economics\" (PDF). Bureau of Labor Statistics.\n- Merkle, Judith A. (1980-01-01). Management and Ideology. University of California Press. p. 1. ISBN 978-0-520-03737-3.\n- Mark O'Sullivan, 2014, What Works at Work, The Starbank Press, Bath, page 3.\n- Mayo, Elton (1945). \"Hawthorne and the Western Electric Company\" (PDF). Harvard Business School. Archived from the original (PDF) on 6 January 2012. Retrieved 28 December 2011.\n- \"History of HR and the CIPD\". Chartered Institute of Personnel and Development. Archived from the original on 2016-07-15. Retrieved 2016-07-19.\n- Itani, Sami (22 September 2017). The Ideological Evolution of Human Resource Management: A Critical Look into HRM Research and Practices. Critical Management Studies Book Set (2016-2019). Bingley, Yorkshire: Emerald Group Publishing (published 2017). ISBN 9781787433908. Retrieved 3 April 2021.\n-\nArdichvili, Alexandre; Zavyalova, Elena K. (8 May 2015). \"HRD in the Former Soviet Union (1917-1990)\". Human Resource Development in the Russian Federation. Routledge Studies in Human Resource Development. New York: Routledge (published 2015). p. 43. ISBN 9781317815846. Retrieved 3 April 2021.\n[...] features of personnel management that were typical for the socialist Soviet Union [...]: Ideologization of all definitions, regulations, concepts, and explanations; linking the fundamental principles of personnel management with the classical works of the Marxist-Leninist theory as well as the obligatory references to the Communist Party documents of various levels [...]; and administrative and even criminal liability for non-working, enshrined as a separate item in the constitution of the USSR.\n- \"Archived copy\" (PDF). Archived from the original (PDF) on 2021-01-19. Retrieved 2020-10-05.\n{{cite web}}\n: CS1 maint: archived copy as title (link) - \"About Cornell ILR\". Cornell University School of Industrial and Labor Relations. Retrieved 2010-01-29.\n- \"About SHRM\". Society for Human Resource Management. Archived from the original on 16 January 2009. Retrieved 22 December 2011.\n-\nHale, Henry E. (2014). Patronal Politics. Problems of International Politics. Cambridge University Press. p. 49. ISBN 9781107073517. Retrieved 2015-08-24.\nNot seen as having the right stuff for high-profile posts such as the one held by Trotsky, Stalin thus occupied a series of relatively low-level positions in the Communist leadership after the revolution. One of these, which he acquired in 1919, was the de facto head of the Communist Party's Organizational Bureau (Orgburo), seen then as a technical body in much the same way a human resources department is seen in a modern institution. [...] Stalin's genius was to recognize that [...] this was precisely the position to occupy. Using his position to influence who was appointed to lower-level party posts, each relatively unimportant in its own right, Stalin systematically advanced people he believed would support him in the future, thereby constructing a large network of political clients within the party and the state which it dominated. [...] This patronalistic mechanism constituted what Robert V. Daniels later called the great 'circular flow of power' that essentially decided Communist Party leadership disputes and solved succession crises from Stalin straight through to Gorbachev. The power to influence lower-level appointments was concentrated, though still largely seen as a technical matter, with the creation of the post of general secretary in 1922, a post-Stalin was in a perfect position to occupy, and he did.\n-\nPipko, Simona (2002). Baltic Winds: Testimony of a Soviet Attorney. Xlibris Corporation. p. 451. ISBN 9781401070960. Retrieved 2015-08-24.\nThe Secretariat personified the Stalinist system. [...] It runs the day-to-day affairs of the State as well as the Party. Can you imagine that huge body of bureaucratic anachronism, which was also responsible for the selection and promotion of 'cadres'? The model invented by Stalin to consolidate his power existed up to contemporary time. [...] Stalin had both the time and the ability to shape human resources to his own ends, teaching secrecy, brutality and duplicity.\n-\nQuoted in: Stalin, Joseph (1936). Против фашистского мракобесия и демагогии [Against Fascist Obscurantism and Demagoguery]. Directmedia (published 2013). p. 81. ISBN 9785446087181. Retrieved 2015-08-24.\nНадо, наконец, понять, что из всех ценных капиталов, имеющихся в мире, самым ценным и самым решающим капиталом являются люди, кадры. [Finally, one must understand that of all the valuable forms of capital existing in the world, the most precious and the most decisive capital is people, cadres.]\n{{cite book}}\n: ISBN / Date incompatibility (help) - Bui, Quoctrung (2015-02-23). \"50 Years Of Shrinking Union Membership, In One Map\". NPR. Retrieved 2025-07-23.\n- \"UNION MEMBERS—2024\" (PDF). Bureau of Labor Statistics.\n- \"The decline of the American labor union – GIS Reports\". 2023-04-28. Retrieved 2025-07-23.\n-\nCompare:\nBelous, Richard S. (1986). Union Membership Trends: The Implications for Economic Policy and Labor Legislation. Congressional Research Service, Library of Congress. p. 27. Retrieved 3 April 2021.\nGiven the 'continued union membership decline' case vs. the 'rebound in union membership' case, which one is currently the 'general wisdom' within the community of labor-management analysts?\n- Jensen, Sara (2025-04-23). \"How HR can innovate with alternative workforce models\". HR Executive. Retrieved 2025-07-23.\n- \"Personnel Management vs. Human Resource Management\". Maryville University Online. Retrieved 2025-07-23.\n- Compare Graphed frequencies of HR jargon in American English.\n-\nCappelli, Peter (July 2015). \"Why We Love to Hate HR ... and What HR Can Do About It\". Harvard Business Review (July–August 2015). Retrieved 25 July 2015.\n[...] after World War II, U.S. industry suffered a talent shortage unlike anything since. [...] In that [...] void, modern HR was born, ushering in practices such as coaching, developmental assignments, job rotation, 360-degree feedback, assessment centers, high-potential tracks, and succession plans. They sound routine now, but they were revolutionary then. And they arose from an urgent need to develop and retain talent in the 1950s.\n- Schiavo, ByAmanda. \"HR 101: The history and evolution of the HR department\". HR Brew. Retrieved 2025-07-23.\n-\nArmstrong, Michael (2006). \"Human capital management\". A Handbook of Human Resource Management Practice. Gale virtual reference library. Kogan Page Publishers. p. 29. ISBN 9780749446314. Retrieved 2016-07-19.\nHuman capital management (HCM) has been described as 'a paradigm shift' from the traditional approach to human resource management (Kearns, 2005b) [...].\n- O'Brien, Michael (October 8, 2009). \"HR's Take on The Office\". Human Resource Executive Online. Retrieved 28 December 2011.[dead link]\n- \"Catbert shows tougher side to human resources\". Personnel Today. 30 August 2007. Archived from the original on 17 December 2009. Retrieved 28 December 2011.\n- Ulrich, Dave (1996). Human Resource Champions. The next agenda for adding value and delivering results. Boston, Mass.: Harvard Business School Press. ISBN 978-0-87584-719-1. OCLC 34704904.\n- Sen. Simpson, Alan K. [R-WY (1986-11-06). \"S.1200 - 99th Congress (1985-1986): Immigration Reform and Control Act of 1986\". www.congress.gov. Retrieved 2025-08-15.\n- Davis, Robert; Carnovalis, Michael (2018-05-13). \"The HR Function's Compliance Role\". Corporate Compliance Insights.\n- \"Managing for Employee Retention\". SHRM. 2019-02-26. Archived from the original on 2021-08-16. Retrieved 2020-10-12.\n- Towers, David. \"Human Resource Management essays\". Archived from the original on 2010-06-20. Retrieved 2007-10-17.\n- Storey, John (2014). New Perspectives on Human Resource Management (Routledge Revivals). doi:10.4324/9781315740560. ISBN 9781315740560.\n- Collings, David G.; Mellahi, Kamel (2009). \"Strategic talent management: A review and research agenda\". Human Resource Management Review. 19 (4): 304–313. doi:10.1016/j.hrmr.2009.04.001. hdl:10379/683.\n- Ulrich, Dave; Younger, Jon; Brockbank, Wayne (September 2008). \"The twenty-first-century HR organization\". Human Resource Management. 47 (4): 829–850. doi:10.1002/hrm.20247. hdl:2027.42/61309.\n- Armstrong, Michael (2022-01-03). Armstrong's Handbook of Performance Management: An Evidence-Based Guide to Performance Leadership. Kogan Page Publishers. pp. 7+. ISBN 978-1-3986-0303-5.\n- Sonia Bendix (2000 ): The Basics of Labour Relations, p. 20.\n- \"Code of Ethics and Rules of Professional Conduct: National Standards\". CPHR/CRHA Canada. n.d.PDF\n- \"Code of Conduct and Ethics\". CIPD. n.d.PDF\n- 1. Lepak, David P., and Scott A. Snell. \"Virtual HR: Strategic Human Resource Management in the 21st Century.\" Human Resources Management Review 8.3 (1998): 214-34. Web. 22 February 2016. The current and increased significance of information technology in Human Resources processes.\n- 1. Ensher, E. A., Nielson, T. R., & Grant-Vallone, E. (2002). Tales from the Hiring Line: Effects of the Internet and Technology on HR Processes. Organizational Dynamics, 31(3), 224-244.\n- 1. Johnson, R. D., & Guetal, H. G. (2012). Transforming HR Through Technology. Retrieved from https://www.shrm.org/about/foundation/products/documents/hr tech epg- final.pdf\n- Angrave, David; Charlwood, Andy; Kirkpatrick, Ian; Lawrence, Mark; Stuart, Mark (2016). \"HR and analytics: why HR is set to fail the big data challenge\". Human Resource Management Journal. 26 (1): 1–11. doi:10.1111/1748-8583.12090. ISSN 0954-5395.\n- Danach, Kassem; El Dirani, Ali; Fayyad-Kazan, Hasan (2024-05-23). \"Navigating HR 4.0: Harnessing AI for Ethical and Inclusive HR Transformation\". Proceedings. 101 (1): 18. doi:10.3390/proceedings2024101018.\n- Jonathan E. DeGraff (21 February 2010). \"The Changing Environment of Professional HR Associations\". Cornell HR Review. Archived from the original on 11 February 2012. Retrieved 21 December 2011.\n- Wright, Patrick. \"The 2011 CHRO Challenge: Building Organizational, Functional, and Personal Talent\" (PDF). Cornell Center for Advanced Human Resource Studies (CAHRS). Retrieved 3 September 2011.\n- Conaty, Bill, and Ram Charan (2011). The Talent Masters: Why Smart Leaders Put People Before Numbers. Crown Publishing Group. ISBN 978-0-307-46026-4.\n- \"Workforce-as-a-Service (WaaS)-Future of Hiring\". OnBenchMark.\n- SHRM Website: About SHRM Archived 2009-01-16 at the Wayback Machine\n- \"About IOR\". Institute of Recruiters (IOR). Archived from the original on 17 April 2019. Retrieved 22 December 2011.\n- \"Human Resources Division\". aom.org. Archived from the original on 20 February 2014. Retrieved 19 January 2018.\n- \"Academy of Management Journal\". amj.aom.org. Archived from the original on 23 November 2022. Retrieved 19 January 2018.\n- \"Academy of Management Review\". amr.aom.org. Archived from the original on 23 November 2022. Retrieved 19 January 2018.\n- \"About Cornell ILR\". Cornell University School of Industrial and Labor Relations. Retrieved 23 August 2009.\n- \"HR Courses\". My Courses. Retrieved 30 October 2019.\n- Guest, David E. (2011). \"Human resource management and performance: still searching for some answers: Human Resource Management and Performance\". Human Resource Management Journal. 21 (1): 3–13. doi:10.1111/j.1748-8583.2010.00164.x.\n- \"Cornell HR Review — The Cornell HR Review is a student-run HR publication that provides timely articles, essays, and executive commentary\". cornellhrreview.org. Retrieved 19 January 2018.\n- \"HR Magazine: December 2017 / January 2018\". SHRM. 30 November 2017. Archived from the original on 29 November 2020. Retrieved 19 January 2018.\n- \"Human Resource Management\". Human Resource Management. doi:10.1002/(issn)1099-050x.\n- Human Resource Management Review. Retrieved 19 January 2018.\n- \"The International Journal of Human Resource Management\". Taylor & Francis.\n- \"Perspectives on Work | LERA\". Archived from the original on 2014-03-12. Retrieved 2014-03-12.\n- Cornell, Johnson at. \"Johnson at Cornell - Administrative Science Quarterly\". johnson.cornell.edu. Retrieved 19 January 2018.\n- \"International Journal of Selection and Assessment\". International Journal of Selection and Assessment. doi:10.1111/(issn)1468-2389.\n- \"Journal of Applied Psychology\". apa.org. Retrieved 19 January 2018.\n- \"Journal of Management\".\n- \"Journal of Occupational and Organizational Psychology\". Journal of Occupational and Organizational Psychology. doi:10.1111/(issn)2044-8325.\n- \"Journal of Personnel Psychology\". hogrefe.com. Archived from the original on 26 December 2010. Retrieved 19 January 2018.\n- \"Organization Science - INFORMS\". pubsonline.informs.org. Retrieved 19 January 2018.\n- \"Personnel Psychology\". Personnel Psychology. 2015. doi:10.1111/(issn)1744-6570.\n- Boon, Corine; Den Hartog, Deanne N.; Lepak, David P. (2019). \"A Systematic Review of Human Resource Management Systems and Their Measurement\". Journal of Management. 45 (6): 2498–2537. doi:10.1177/0149206318818718. ISSN 0149-2063. Retrieved 17 July 2025.\n- Köchling, Alina; Wehner, Marius Claus (2020). \"Discriminated by an algorithm: a systematic review of discrimination and fairness by algorithmic decision-making in the context of HR recruitment and HR development\" (PDF). Business Research. 13 (3): 795–848. doi:10.1007/s40685-020-00134-w. ISSN 2198-3402. Retrieved 17 July 2025.\n- Ainsworth, Susan; Pekarek, Andreas (2022). \"Gender in Human Resources: Hiding in plain sight\". Human Resource Management Journal. 32 (4): 890–905. doi:10.1111/1748-8583.12437. ISSN 0954-5395.\n- Johnason, P. (2009). HRM in changing organizational contexts. In D. G. Collings & G. Wood (Eds.), Human resource management: A critical approach (pp. 19–37). London: Routledge.\n- McGaughey, E. (2020). \"A Human is not a Resource\". King's Law Journal. 31 (2): 1. doi:10.1080/09615768.2020.1789441. SSRN 3099470.\n- Media related to Human resources management at Wikimedia Commons\n- Quotations related to Human resource management at Wikiquote",
    "information technology": "| Information science |\n|---|\n| General aspects |\n| Related fields and subfields |\nInformation technology (IT) is the study or use of computers, telecommunication systems and other devices to create, process, store, retrieve and transmit information.[1] While the term is commonly used to refer to computers and computer networks, it also encompasses other information distribution technologies such as television and telephones. Information technology is an application of computer science and computer engineering.\nAn information technology system (IT system) is generally an information system, a communications system, or, more specifically speaking, a computer system — including all hardware, software, and peripheral equipment — operated by a limited group of IT users, and an IT project usually refers to the commissioning and implementation of an IT system.[2] IT systems play a vital role in facilitating efficient data management, enhancing communication networks, and supporting organizational processes across various industries. Successful IT projects require meticulous planning and ongoing maintenance to ensure optimal functionality and alignment with organizational objectives.[3]\nAlthough humans have been storing, retrieving, manipulating, analysing and communicating information since the earliest writing systems were developed,[4] the term information technology in its modern sense first appeared in a 1958 article published in the Harvard Business Review; authors Harold J. Leavitt and Thomas L. Whisler commented that \"the new technology does not yet have a single established name. We shall call it information technology (IT).\"[5] Their definition consists of three categories: techniques for processing, the application of statistical and mathematical methods to decision-making, and the simulation of higher-order thinking through computer programs.[5]\nBased on the storage and processing technologies employed, it is possible to distinguish four distinct phases of IT development: pre-mechanical (3000 BC – 1450 AD), mechanical (1450 – 1840), electromechanical (1840 – 1940), and electronic (1940 to present).[4]\nIdeas of computer science were first mentioned before the 1950s under the Massachusetts Institute of Technology (MIT) and Harvard University, where they had discussed and began thinking of computer circuits and numerical calculations. As time went on, the field of information technology and computer science became more complex and was able to handle the processing of more data. Scholarly articles began to be published from different organizations.[6]\nDuring the mid-1900s, Alan Turing, J. Presper Eckert, and John Mauchly were some of the pioneers of early computer technology. While their main efforts focused on designing the first digital computer, Turing also began to raise questions about artificial intelligence.[7]\nDevices have been used to aid computation for thousands of years, probably initially in the form of a tally stick.[8] The Antikythera mechanism, dating from about the beginning of the first century BC, is generally considered the earliest known mechanical analog computer, and the earliest known geared mechanism.[9] Comparable geared devices did not emerge in Europe until the 16th century, and it was not until 1645 that the first mechanical calculator capable of performing the four basic arithmetical operations was developed.[10]\nElectronic computers, using either relays or thermionic valves, began to appear in the early 1940s. The electromechanical Zuse Z3, completed in 1941, was the world's first programmable computer, and by modern standards one of the first machines that could be considered a complete computing machine. During the Second World War, Colossus developed the first electronic digital computer to decrypt German messages. Although it was programmable, it was not general-purpose, being designed to perform only a single task. It could not also store its program in memory; programming was carried out using plugs and switches to alter the internal wiring.[11] The first recognizably modern electronic digital stored-program computer was the Manchester Baby, which ran its first program on 21 June 1948.[12]\nThe development of transistors in the late 1940s at Bell Laboratories allowed a new generation of computers to be designed with greatly reduced power consumption. The first commercially available stored-program computer, the Ferranti Mark I, contained 4050 valves and had a power consumption of 25 kilowatts. By comparison, the first transistorized computer developed at the University of Manchester and operational by November 1953, consumed only 150 watts in its final version.[13]\nSeveral other breakthroughs in semiconductor technology include the integrated circuit (IC) invented by Jack Kilby at Texas Instruments and Robert Noyce at Fairchild Semiconductor in 1959, silicon dioxide surface passivation by Carl Frosch and Lincoln Derick in 1955,[14] the first planar silicon dioxide transistors by Frosch and Derick in 1957,[15] the MOSFET demonstration by a Bell Labs team,[16][17][18][19] the planar process by Jean Hoerni in 1959,[20][21][22] and the microprocessor invented by Ted Hoff, Federico Faggin, Masatoshi Shima, and Stanley Mazor at Intel in 1971. These important inventions led to the development of the personal computer (PC) in the 1970s, and the emergence of information and communications technology (ICT).[23]\nBy 1984, according to the National Westminster Bank Quarterly Review, the term information technology had been redefined as \"the convergence of telecommunications and computing technology (...generally known in Britain as information technology).\" We then begin to see the appearance of the term in 1990, contained within documents for the International Organization for Standardization (ISO).[24]\nInnovations in technology have already revolutionized the world by the twenty-first century as people have gained access to different online services. This has changed the workforce drastically, as thirty percent of U.S. workers were already in careers in this profession. 136.9 million people were personally connected to the Internet, which was equivalent to 51 million households.[25] Along with the Internet, new types of technology were also being introduced across the globe, which have improved efficiency and made things easier across the globe.\nAs technology revolutionized society, millions of processes could be completed in seconds. Innovations in communication were crucial as people increasingly relied on computers to communicate via telephone lines and cable networks. The introduction of the email was considered revolutionary as \"companies in one part of the world could communicate by e-mail with suppliers and buyers in another part of the world...\".[26]\nComputers and technology have also revolutionized the marketing industry, resulting in more buyers of their products. In 2002, Americans exceeded $28 billion in goods just over the Internet alone, while e-commerce a decade later resulted in $289 billion in sales.[26] And as computers are rapidly becoming more sophisticated by the day, they are becoming more widely used as people are becoming more reliant on them during the twenty-first century.\nElectronic data processing or business information processing can refer to the use of automated methods to process commercial data. Typically, this uses relatively simple, repetitive activities to process large volumes of similar information. For example: stock updates applied to an inventory, banking transactions applied to account and customer master files, booking and ticketing transactions to an airline's reservation system, and billing for utility services. The modifier \"electronic\" or \"automatic\" was used with \"data processing\" (DP), especially c. 1960, to distinguish human clerical data processing from that done by computer.[27][28]\nEarly electronic computers such as Colossus made use of punched tape, a long strip of paper on which data was represented by a series of holes, a technology now obsolete.[29] Electronic data storage, which is used in modern computers, dates from World War II, when a form of delay-line memory was developed to remove the clutter from radar signals, the first practical application of which was the mercury delay line.[30] The first random-access digital storage device was the Williams tube, which was based on a standard cathode ray tube.[31] However, the information stored in it and the delay-line memory was volatile in the fact that it had to be continuously refreshed, and thus was lost once power was removed. The earliest form of non-volatile computer storage was the magnetic drum, invented in 1932[32] and used in the Ferranti Mark 1, the world's first commercially available general-purpose electronic computer.[33]\nIBM introduced the first hard disk drive in 1956, as a component of their 305 RAMAC computer system.[34]: 6 Most digital data today is still stored magnetically on hard disks, or optically on media such as CD-ROMs.[35]: 4–5 Until 2002, most information was stored on analog devices, but that year digital storage capacity exceeded analog for the first time. As of 2007[update], almost 94% of the data stored worldwide was held digitally:[36] 52% on hard disks, 28% on optical devices, and 11% on digital magnetic tape. It has been estimated that the worldwide capacity to store information on electronic devices grew from less than 3 exabytes in 1986 to 295 exabytes in 2007,[37] doubling roughly every 3 years.[38]\nDatabase Management Systems (DMS) emerged in the 1960s to address the problem of storing and retrieving large amounts of data accurately and quickly. An early such system was IBM's Information Management System (IMS),[39] which is still widely deployed more than 50 years later.[40] IMS stores data hierarchically,[39] but in the 1970s Ted Codd proposed an alternative relational storage model based on set theory and predicate logic and the familiar concepts of tables, rows, and columns. In 1981, the first commercially available relational database management system (RDBMS) was released by Oracle.[41]\nAll DMS consist of components; they allow the data they store to be accessed simultaneously by many users while maintaining its integrity.[42] All databases have a common one point in that the structure of the data they contain is defined and stored separately from the data itself, in a database schema.[39]\nIn the late 2000s (decade), the extensible markup language (XML) became a popular format for data representation. Although XML data can be stored in normal file systems, it is commonly held in relational databases to take advantage of their \"robust implementation verified by years of both theoretical and practical effort.\"[43] As an evolution of the Standard Generalized Markup Language (SGML), XML's text-based structure offers the advantage of being both machine- and human-readable.[44]\nData transmission has three aspects: transmission, propagation, and reception.[45] It can be broadly categorized as broadcasting, in which information is transmitted unidirectionally downstream, or telecommunications, with bidirectional upstream and downstream channels.[37]\nXML has been increasingly employed as a means of data interchange since the early 2000s,[46] particularly for machine-oriented interactions such as those involved in web-oriented protocols such as SOAP,[44] describing \"data-in-transit rather than... data-at-rest\".[46]\nHilbert and Lopez identify the exponential pace of technological change (a kind of Moore's law): machines' application-specific capacity to compute information per capita roughly doubled every 14 months between 1986 and 2007; the per capita capacity of the world's general-purpose computers doubled every 18 months during the same two decades; the global telecommunication capacity per capita doubled every 34 months; the world's storage capacity per capita required roughly 40 months to double (every 3 years); and per capita broadcast information has doubled every 12.3 years.[37]\nMassive amounts of data are stored worldwide every day, but unless it can be analyzed and presented effectively it essentially resides in what have been called data tombs: \"data archives that are seldom visited\".[47] To address that issue, the field of data mining — \"the process of discovering interesting patterns and knowledge from large amounts of data\"[48] — emerged in the late 1980s.[49]\nThe technology and services IT provides for sending and receiving electronic messages (called \"letters\" or \"electronic letters\") over a distributed (including global) computer network. In terms of the composition of elements and the principle of operation, electronic mail practically repeats the system of regular (paper) mail, borrowing both terms (mail, letter, envelope, attachment, box, delivery, and others) and characteristic features — ease of use, message transmission delays, sufficient reliability, and at the same time no guarantee of delivery. The advantages of e-mail are: easily perceived and remembered by a person addresses of the form user_name@domain_name (for example, somebody@example.com); the ability to transfer both plain text and formatted, as well as arbitrary files; independence of servers (in the general case, they address each other directly); sufficiently high reliability of message delivery; ease of use by humans and programs.\nThe disadvantages of e-mail include: the presence of such a phenomenon as spam (massive advertising and viral mailings); the theoretical impossibility of guaranteed delivery of a particular letter; possible delays in message delivery (up to several days); limits on the size of one message and on the total size of messages in the mailbox (personal for users).\nA search system is a software and hardware complex with a web interface that provides the ability to look for information on the Internet. A search engine usually means a site that hosts the interface (front-end) of the system. The software part of a search engine is a search engine (search engine) — a set of programs that provides the functionality of a search engine and is usually a trade secret of the search engine developer company. Most search engines look for information on World Wide Web sites, but some systems can look for files on FTP servers, items in online stores, and information on Usenet newsgroups. Improving search is one of the priorities of the modern Internet (see the Deep Web article about the main problems in the work of search engines).\nCompanies in the information technology field are often discussed as a group as the \"tech sector\" or the \"tech industry.\"[50][51][52] These titles can be misleading at times and should not be mistaken for \"tech companies,\" which are generally large scale, for-profit corporations that sell consumer technology and software. From a business perspective, information technology departments are a \"cost center\" the majority of the time. A cost center is a department or staff that incurs expenses, or \"costs,\" within a company rather than generating profits or revenue streams. Modern businesses rely heavily on technology for their day-to-day operations, so the expenses delegated to cover technology that facilitates business in a more efficient manner are usually seen as \"just the cost of doing business.\" IT departments are allocated funds by senior leadership and must attempt to achieve the desired deliverables while staying within that budget. Government and the private sector might have different funding mechanisms, but the principles are more or less the same. This is an often overlooked reason for the rapid interest in automation and artificial intelligence, but the constant pressure to do more with less is opening the door for automation to take control of at least some minor operations in large companies.\nMany companies now have IT departments for managing the computers, networks, and other technical areas of their businesses. Companies have also sought to integrate IT with business outcomes and decision-making through a BizOps or business operations department.[53]\nIn a business context, the Information Technology Association of America has defined information technology as \"the study, design, development, application, implementation, support, or management of computer-based information systems\".[54][page needed] The responsibilities of those working in the field include network administration, software development and installation, and the planning and management of an organization's technology life cycle, by which hardware and software are maintained, upgraded, and replaced.\nInformation services is a term somewhat loosely applied to a variety of IT-related services offered by commercial companies,[55][56][57] as well as data brokers.\nThe field of information ethics was established by mathematician Norbert Wiener in the 1940s.[59]: 9 Some of the ethical issues associated with the use of information technology include:[60]: 20–21\n- Breaches of copyright by those downloading files stored without the permission of the copyright holders\n- Employers monitoring their employees' emails and other Internet usage\n- Unsolicited emails\n- Hackers accessing online databases\n- Websites installing cookies or spyware to monitor a user's online activities, which may be used by data brokers\nResearch suggests that IT projects in business and public administration can easily become significant in scale. Research conducted by McKinsey in collaboration with the University of Oxford suggested that half of all large-scale IT projects (those with initial cost estimates of $15 million or more) often failed to maintain costs within their initial budgets or to complete on time.[61]\n- Information and communications technology (ICT)\n- IT infrastructure\n- Outline of information technology\n- Knowledge society\n- \"Information Technology – Oxford Reference\". Oxford Reference. Oxford University Press.\n- Forbes Technology Council, 16 Key Steps To Successful IT Project Management, published 10 September 2020, accessed 23 June 2023\n- Hindarto, Djarot (30 August 2023). \"The Management of Projects is Improved Through Enterprise Architecture on Project Management Application Systems\". International Journal Software Engineering and Computer Science. 3 (2): 151–161. doi:10.35870/ijsecs.v3i2.1512. ISSN 2776-3242.\n- Butler, Jeremy G., A History of Information Technology and Systems, University of Arizona, archived from the original on 5 August 2012, retrieved 2 August 2012\n- Leavitt, Harold J.; Whisler, Thomas L. (1958), \"Management in the 1980s\", Harvard Business Review, 11\n- Slotten, Hugh Richard (1 January 2014). The Oxford Encyclopedia of the History of American Science, Medicine, and Technology. Oxford University Press. doi:10.1093/acref/9780199766666.001.0001. ISBN 978-0-19-976666-6.\n- Henderson, H. (2017). computer science. In H. Henderson, Facts on File science library: Encyclopedia of computer science and technology. (3rd ed.). [Online]. New York: Facts On File.\n- Schmandt-Besserat, Denise (1981), \"Decipherment of the earliest tablets\", Science, 211 (4479): 283–285, Bibcode:1981Sci...211..283S, doi:10.1126/science.211.4479.283, ISSN 0036-8075, PMID 17748027\n- Wright (2012), p. 279.\n- Chaudhuri (2004), p. 3.\n- Lavington (1980), p. 11.\n- Enticknap, Nicholas (Summer 1998), \"Computing's Golden Jubilee\", Resurrection (20), ISSN 0958-7403, archived from the original on 9 January 2012, retrieved 19 April 2008\n- Cooke-Yarborough, E. H. (June 1998), \"Some early transistor applications in the UK\", Engineering Science & Education Journal, 7 (3): 100–106, doi:10.1049/esej:19980301 (inactive 12 July 2025), ISSN 0963-7346\n{{citation}}\n: CS1 maint: DOI inactive as of July 2025 (link). - US2802760A, Lincoln, Derick & Frosch, Carl J., \"Oxidation of semiconductive surfaces for controlled diffusion\", issued 13 August 1957\n- Frosch, C. J.; Derick, L (1957). \"Surface Protection and Selective Masking during Diffusion in Silicon\". Journal of the Electrochemical Society. 104 (9): 547. doi:10.1149/1.2428650.\n- KAHNG, D. (1961). \"Silicon-Silicon Dioxide Surface Device\". Technical Memorandum of Bell Laboratories: 583–596. doi:10.1142/9789814503464_0076. ISBN 978-981-02-0209-5.\n{{cite journal}}\n: ISBN / Date incompatibility (help) - Lojek, Bo (2007). History of Semiconductor Engineering. Berlin, Heidelberg: Springer-Verlag Berlin Heidelberg. p. 321. ISBN 978-3-540-34258-8.\n- Ligenza, J.R.; Spitzer, W.G. (1960). \"The mechanisms for silicon oxidation in steam and oxygen\". Journal of Physics and Chemistry of Solids. 14: 131–136. Bibcode:1960JPCS...14..131L. doi:10.1016/0022-3697(60)90219-5.\n- Lojek, Bo (2007). History of Semiconductor Engineering. Springer Science & Business Media. p. 120. ISBN 9783540342588.\n- Lojek, Bo (2007). History of Semiconductor Engineering. Springer Science & Business Media. pp. 120 & 321–323. ISBN 9783540342588.\n- Bassett, Ross Knox (2007). To the Digital Age: Research Labs, Start-up Companies, and the Rise of MOS Technology. Johns Hopkins University Press. p. 46. ISBN 9780801886393.\n- US 3025589 Hoerni, J. A.: \"Method of Manufacturing Semiconductor Devices\" filed May 1, 1959\n- \"Advanced information on the Nobel Prize in Physics 2000\" (PDF). Nobel Prize. June 2018. Archived (PDF) from the original on 17 August 2019. Retrieved 17 December 2019.\n- Information technology. (2003). In E.D. Reilly, A. Ralston & D. Hemmendinger (Eds.), Encyclopedia of computer science. (4th ed.).\n- Stewart, C.M. (2018). Computers. In S. Bronner (Ed.), Encyclopedia of American Studies. [Online]. Johns Hopkins University Press.\n- Northrup, C.C. (2013). Computers. In C. Clark Northrup (Ed.), Encyclopedia of world trade: from ancient times to the present. [Online]. London: Routledge.\n- Illingworth, Valerie (11 December 1997). Dictionary of Computing. Oxford Paperback Reference (4th ed.). Oxford University Press. p. 126. ISBN 9780192800466.\n- Anthony Ralston. Encyclopedia of Computer Science 4ed. Nature group. p. 502.\n- Alavudeen & Venkateshwaran (2010), p. 178.\n- Lavington (1998), p. 1.\n- \"Early computers at Manchester University\", Resurrection, 1 (4), Summer 1992, ISSN 0958-7403, archived from the original on 28 August 2017, retrieved 19 April 2008\n- Universität Klagenfurt (ed.), \"Magnetic drum\", Virtual Exhibitions in Informatics, archived from the original on 21 June 2006, retrieved 21 August 2011\n- The Manchester Mark 1, University of Manchester, archived from the original on 21 November 2008, retrieved 24 January 2009\n- Khurshudov, Andrei (2001), The Essential Guide to Computer Data Storage: From Floppy to DVD, Prentice Hall, ISBN 978-0-130-92739-2\n- Wang, Shan X.; Taratorin, Aleksandr Markovich (1999), Magnetic Information Storage Technology, Academic Press, ISBN 978-0-12-734570-3\n- Wu, Suzanne, \"How Much Information Is There in the World?\", USC News, University of Southern California, retrieved 10 September 2013\n- Hilbert, Martin; López, Priscila (1 April 2011), \"The World's Technological Capacity to Store, Communicate, and Compute Information\", Science, 332 (6025): 60–65, Bibcode:2011Sci...332...60H, doi:10.1126/science.1200970, PMID 21310967, S2CID 206531385\n- \"Americas events – Video animation on The World's Technological Capacity to Store, Communicate, and Compute Information from 1986 to 2010\". The Economist. Archived from the original on 18 January 2012.\n- Ward & Dafoulas (2006), p. 2.\n- Olofson, Carl W. (October 2009), A Platform for Enterprise Data Services (PDF), IDC, archived from the original (PDF) on 25 December 2013, retrieved 7 August 2012\n- Ward & Dafoulas (2006), p. 3.\n- Silberschatz, Abraham (2010). Database System Concepts. McGraw-Hill Higher Education. ISBN 978-0-07-741800-7.\n- Pardede (2009), p. 2.\n- Pardede (2009), p. 4.\n- Weik (2000), p. 361.\n- Pardede (2009), p. xiii.\n- Han, Kamber & Pei (2011), p. 5.\n- Han, Kamber & Pei (2011), p. 8.\n- Han, Kamber & Pei (2011), p. xxiii.\n- \"Technology Sector Snapshot\". The New York Times. Archived from the original on 13 January 2017. Retrieved 12 January 2017.\n- \"Our programmes, campaigns and partnerships\". TechUK. Retrieved 12 January 2017.\n- \"Cyberstates 2016\". CompTIA. Archived from the original on 6 November 2018. Retrieved 12 January 2017.\n- \"Manifesto Hatched to Close Gap Between Business and IT\". TechNewsWorld. 22 October 2020. Retrieved 22 March 2021.\n- Proctor, K. Scott (2011), Optimizing and Assessing Information Technology: Improving Business Project Execution, John Wiley & Sons, ISBN 978-1-118-10263-3\n- \"Top Information Services companies\". VentureRadar. Retrieved 8 March 2021.\n- \"Follow Information Services on Index.co\". Index.co. Retrieved 8 March 2021.[permanent dead link]\n- Publishing, Value Line. \"Industry Overview: Information Services\". Value Line. Archived from the original on 20 June 2021. Retrieved 8 March 2021.\n- Lauren Csorny (9 April 2013). \"U.S. Careers in the growing field of information technology services\". U.S. Bureau of Labor Statistics.\n- Bynum, Terrell Ward (2008), \"Norbert Wiener and the Rise of Information Ethics\", in van den Hoven, Jeroen; Weckert, John (eds.), Information Technology and Moral Philosophy, Cambridge University Press, ISBN 978-0-521-85549-5\n- Reynolds, George (2009), Ethics in Information Technology, Cengage Learning, ISBN 978-0-538-74622-9\n- Bloch, M., Blumberg, S. and Laartz, J., Delivering large-scale IT projects on time, on budget, and on value, published 1 October 2012, accessed 23 June 2023\n- Alavudeen, A.; Venkateshwaran, N. (2010), Computer Integrated Manufacturing, PHI Learning, ISBN 978-81-203-3345-1\n- Chaudhuri, P. Pal (2004), Computer Organization and Design, PHI Learning, ISBN 978-81-203-1254-8\n- Han, Jiawei; Kamber, Micheline; Pei, Jian (2011), Data Mining: Concepts and Techniques (3rd ed.), Morgan Kaufmann, ISBN 978-0-12-381479-1\n- Lavington, Simon (1980), Early British Computers, Manchester University Press, ISBN 978-0-7190-0810-8\n- Lavington, Simon (1998), A History of Manchester Computers (2nd ed.), The British Computer Society, ISBN 978-1-902505-01-5\n- Pardede, Eric (2009), Open and Novel Issues in XML Database Applications, Information Science Reference, ISBN 978-1-60566-308-1\n- Ralston, Anthony; Hemmendinger, David; Reilly, Edwin D., eds. (2000), Encyclopedia of Computer Science (4th ed.), Nature Publishing Group, ISBN 978-1-56159-248-7\n- van der Aalst, Wil M. P. (2011), Process Mining: Discovery, Conformance and Enhancement of Business Processes, Springer, ISBN 978-3-642-19344-6\n- Ward, Patricia; Dafoulas, George S. (2006), Database Management Systems, Cengage Learning EMEA, ISBN 978-1-84480-452-8\n- Weik, Martin (2000), Computer Science and Communications Dictionary, vol. 2, Springer, ISBN 978-0-7923-8425-0\n- Wright, Michael T. (2012), \"The Front Dial of the Antikythera Mechanism\", in Koetsier, Teun; Ceccarelli, Marco (eds.), Explorations in the History of Machines and Mechanisms: Proceedings of HMM2012, Springer, pp. 279–292, ISBN 978-94-007-4131-7\n- Allen, T.; Morton, M. S. Morton, eds. (1994), Information Technology and the Corporation of the 1990s, Oxford University Press\n- Gitta, Cosmas and South, David (2011). Southern Innovator Magazine Issue 1: Mobile Phones and Information Technology: United Nations Office for South-South Cooperation. ISSN 2222-9280.\n- Gleick, James (2011).The Information: A History, a Theory, a Flood. New York: Pantheon Books.\n- Price, Wilson T. (1981), Introduction to Computer Data Processing, Holt-Saunders International Editions, ISBN 978-4-8337-0012-2\n- Shelly, Gary, Cashman, Thomas, Vermaat, Misty, and Walker, Tim. (1999). Discovering Computers 2000: Concepts for a Connected World. Cambridge, Massachusetts: Course Technology.\n- Webster, Frank, and Robins, Kevin. (1986). Information Technology — A Luddite Analysis. Norwood, NJ: Ablex.\n- Learning materials related to Information technology at Wikiversity\n- Media related to Information technology at Wikimedia Commons\n- Quotations related to Information technology at Wikiquote",
    "information technology consulting": "In management, information technology consulting (also called IT consulting, computer consultancy, business and technology services, computing consultancy, technology consulting, and IT advisory) is a field of activity which focuses on advising organizations on how best to use information technology (IT) in achieving their business objectives and goals, but it can also refer more generally to IT outsourcing, especially in the context of larger companies.\nOnce a business owner defines the needs to take a business to the next level, a decision maker will define the scope, cost and the time frame of the project.[1] The role of the IT consultancy company is to support and nurture the company from the very beginning of the project until the end, and deliver the project not only in the scope, time and cost but also with complete customer satisfaction.[1]",
    "internet security": "Internet security is a branch of computer security focused on the Internet. It includes browser security, web application security, and network security as it applies to other applications or operating systems as a whole. Its objective is to establish rules and measures to improve Internet safety and Internet privacy, including to protect against cyberattacks and cybercrime. The Internet is an inherently insecure channel for information exchange, with risk of intrusion and Internet fraud, including phishing,[1] viruses, trojans, ransomware and worms.\nMany countermeasures are used to combat Internet security threats and web threats, including encryption and ground-up engineering.[2]\nMalicious software comes in many forms, such as viruses, Trojan horses, spyware, and worms.\n- Malware, a portmanteau of malicious software, is any software used to disrupt computer operation, gather sensitive information, or gain access to private computer systems. Malware is defined by its malicious intent, acting against the requirements of the computer user, and does not include software that unintentionally causes harm due to some deficiency. The term badware applies to both malware and unintentionally harmful software.\n- A botnet is a network of computers that have been taken over by a robot or bot that performs large-scale malicious acts for its creator.\n- Computer viruses are programs that can replicate their structures or effects by infecting other files or structures on a computer. The typical purpose of a virus is to take over a computer to steal data.\n- Computer worms are programs that can replicate themselves throughout a computer network.\n- Ransomware is a type of malware that restricts access to the computer system that it infects, and demands a ransom in order for the restriction to be removed.\n- Scareware is a program of usually limited or no benefit, containing malicious payloads, that is sold via unethical marketing practices. The selling approach uses social engineering to cause shock, anxiety, or the perception of a threat, generally directed at an unsuspecting user.\n- Spyware refers to programs that surreptitiously monitor activity on a computer system and report that information to others without the user's consent.\n- One particular kind of spyware is key logging malware. Often referred to as keylogging or keyboard capturing, is the action of recording (logging) the keys struck on a keyboard.\n- A Trojan horse, commonly known as a Trojan, is a general term for malware that pretends to be harmless, so that a user will be convinced to download it onto the computer.\nA denial-of-service attack (DoS) or distributed denial-of-service attack (DDoS) is an attempt to make a computer resource unavailable to its intended users. It works by making so many service requests at once that the system is overwhelmed and becomes unable to process any of them. DoS may target cloud computing systems.[3] According to business participants in an international security survey, 25% of respondents experienced a DoS attack in 2007 and another 16.8% in 2010.[citation needed] DoS attacks often use bots (or a botnet) to carry out the attack.\nPhishing targets online users in an attempt to extract sensitive information such as passwords and financial information.[4] Phishing occurs when the attacker pretends to be a trustworthy entity, either via email or a web page. Victims are directed to web pages that appear to be legitimate, but instead route information to the attackers. Tactics such as email spoofing attempt to make emails appear to be from legitimate senders, or long complex URLs hide the actual website.[5][6] Insurance group RSA claimed that phishing accounted for worldwide losses of $10.8 billion in 2016.[7] Attackers may use AI to create more convincing phishing attacks, such as deepfakes with audio or video that seem to be real messages from a trusted person but are actually fake.[8]\nA man-in-the-middle (MITM) attack is a type of cyber attack. Cybercriminals can intercept data sent between people to steal, eavesdrop or modify data for certain malicious purposes, such as extorting money and identity theft. Public WiFi is often insecure because monitoring or intercepting Web traffic is unknown.[9]\nApplications used to access Internet resources may contain security vulnerabilities such as memory safety bugs or flawed authentication checks. Such bugs can give network attackers full control over the computer.[10][11]\n| Internet security protocols |\n|---|\n| Key management |\n| Application layer |\n| Domain Name System |\n| Internet Layer |\nTCP/IP protocols may be secured with cryptographic methods and security protocols. These protocols include Secure Sockets Layer (SSL), succeeded by Transport Layer Security (TLS) for web traffic, Pretty Good Privacy (PGP) for email, and IPsec for network layer security.[12]\nThreat modeling tools help people to proactively analyze the cyber security posture of a system or system of systems and in that way prevent security threats.\nMulti-factor authentication (MFA) is an access control method in which a user is granted access only after successfully presenting separate pieces of evidence to an authentication mechanism – two or more from the following categories: knowledge (something they know), possession (something they have), and inference (something they are).[13][14] Internet resources, such as websites and email, may be secured using this technique.\nSome online sites offer customers the ability to use a six-digit code which randomly changes every 30–60 seconds on a physical security token. The token has built-in computations and manipulates numbers based on the current time. This means that every thirty seconds only a certain array of numbers validate access. The website is made aware of that device's serial number and knows the computation and correct time to verify the number. After 30–60 seconds the device presents a new random six-digit number to log into the website.[15]\nEmail messages are composed, delivered, and stored in a multiple step process, which starts with the message's composition. When a message is sent, it is transformed into a standard format according to RFC 2822.[16] Using a network connection, the mail client sends the sender's identity, the recipient list and the message content to the server. Once the server receives this information, it forwards the message to the recipients.\nPretty Good Privacy provides confidentiality by encrypting messages to be transmitted or data files to be stored using an encryption algorithm such as Triple DES or CAST-128. Email messages can be protected by using cryptography in various ways, such as the following:\n- Digitally signing the message to ensure its integrity and confirm the sender's identity.\n- Encrypting the message body of an email message to ensure its confidentiality.\n- Encrypting the communications between mail servers to protect the confidentiality of both message body and message header.\nThe first two methods, message signing and message body encryption, are often used together; however, encrypting the transmissions between mail servers is typically used only when two organizations want to protect emails regularly sent between them. For example, the organizations could establish a virtual private network (VPN) to encrypt communications between their mail servers.[17] Unlike methods that only encrypt a message body, a VPN can encrypt all communication over the connection, including email header information such as senders, recipients, and subjects. However, a VPN does not provide a message signing mechanism, nor can it provide protection for email messages along the entire route from sender to recipient.\nA Message authentication code (MAC) is a cryptography method that uses a secret key to digitally sign a message. This method outputs a MAC value that can be decrypted by the receiver, using the same secret key used by the sender. The Message Authentication Code protects both a message's data integrity as well as its authenticity.[18]\nA computer firewall controls access to a single computer. A network firewall controls access to an entire network. A firewall is a security device — computer hardware or software — that filters traffic and blocks outsiders. It generally consists of gateways and filters. Firewalls can also screen network traffic and block traffic deemed unauthorized.\nFirewalls restrict incoming and outgoing network packets. Only authorized traffic is allowed to pass through it. Firewalls create checkpoints between networks and computers. Firewalls can block traffic based on IP source and TCP port number. They can also serve as the platform for IPsec. Using tunnel mode, firewalls can implement VPNs. Firewalls can also limit network exposure by hiding the internal network from the public Internet.\nA packet filter processes network traffic on a packet-by-packet basis. Its main job is to filter traffic from a remote IP host, so a router is needed to connect the internal network to the Internet. The router is known as a screening router, which screens packets leaving and entering the network.\nIn a stateful firewall the circuit-level gateway is a proxy server that operates at the network level of an Open Systems Interconnect (OSI) model and statically defines what traffic will be allowed. Circuit proxies forward network packets (formatted data) containing a given port number, if the port is permitted by the algorithm. The main advantage of a proxy server is its ability to provide Network Address Translation (NAT), which can hide the user's IP address from the Internet, effectively protecting internal information from the outside.\nAn application-level firewall is a third-generation firewall where a proxy server operates at the very top of the OSI model, the IP suite application level. A network packet is forwarded only if a connection is established using a known protocol. Application-level gateways are notable for analyzing entire messages rather than individual packets.\nWeb browser market share predicts the share of hacker attacks. For example, Internet Explorer 6, which used to lead the market,[19] was heavily attacked.[20]\nAs cyberthreats become more complex, user education is essential for improving internet security. Important areas of attention consist of:\n- Users should have the ability to spot phishing emails by looking for odd sender addresses, cliched salutations, and language that seems urgent. Both simulated phishing exercises and real-world examples can be incorporated into training programs.\n- Enabling two-factor authentication (2FA) and stressing the usage of strong, one-of-a-kind passwords are essential for protecting personal information. Additionally, users need to understand the dangers of oversharing on social media and how crucial it is to change their privacy settings.\n- It's critical to educate people on how to spot secure websites (search for HTTPS), steer clear of dubious downloads, and use caution when clicking links. Also, users need to be aware of the dangers of utilizing open WiFi networks without a VPN.\nAntivirus software can protect a programmable device by detecting and eliminating malware.[21] A variety of techniques are used, such as signature-based, heuristics, rootkit, and real-time.\nA password manager is a software application that creates, stores and provides passwords to applications. Password managers encrypt passwords. The user only needs to remember a single master password to access the store.[22]\nSecurity suites were first offered for sale in 2003 (McAfee) and contain firewalls, anti-virus, anti-spyware and other components.[23] They also offer theft protection, portable storage device safety check, private Internet browsing, cloud anti-spam, a file shredder or make security-related decisions (answering popup windows) and several were free of charge.[24]\n- Rhee, M. Y. (2003). Internet Security: Cryptographic Principles, Algorithms and Protocols. Chichester: Wiley. ISBN 0-470-85285-2.\n- \"101 Data Protection Tips: How to Keep Your Passwords, Financial & Personal Information Safe in 2020\". Digital Guardian. 2019-12-16. Retrieved 2020-10-23.\n- Yan, Q.; Yu, F. R.; Gong, Q.; Li, J. (2016). \"Software-Defined Networking (SDN) and Distributed Denial of Service (DDoS) Attacks in Cloud Computing Environments: A Survey, Some Research Issues, and Challenges\". IEEE Communications Surveys and Tutorials. 18 (1): 602–622. doi:10.1109/COMST.2015.2487361. S2CID 20786481.\n- Izak, Belarua. \"Welke virusscanners zijn het beste voor macOS High Sierra\". Virusscanner MAC (in Dutch). Archived from the original on 5 January 2018. Retrieved 4 January 2018.\n- Ramzan, Zulfikar (2010). \"Phishing attacks and countermeasures\". In Stamp, Mark; Stavroulakis, Peter (eds.). Handbook of Information and Communication Security. Springer. ISBN 978-3-642-04117-4.\n- van der Merwe, Alta; Loock, Marianne; Dabrowski, Marek (2005). Characteristics and responsibilities involved in a Phishing attack. Trinity College Dublin. pp. 249–254. ISBN 978-1-59593-169-6. Retrieved 4 January 2018.\n- Long, Mathew (February 22, 2017). \"Fraud Insights Through Integration\". RSA. Archived from the original on October 20, 2018. Retrieved October 20, 2018.\n- \"Deepfake Phishing\". Information Technology - University of Florida. Retrieved 2025-09-21.\n- Bonné, Bram; Rovelo, Gustavo; Quax, Peter; Lamotte, Wim (2017-07-01). \"Insecure Network, Unknown Connection: Understanding Wi-Fi Privacy Assumptions of Mobile Device Users\". Information. 8 (3): 76. doi:10.3390/info8030076. hdl:1942/23947. ISSN 2078-2489.\n- \"Improving Web Application Security: Threats and Countermeasures\". msdn.microsoft.com. 14 July 2010. Retrieved 2016-04-05.\n- \"Justice Department charges Russian spies and criminal hackers in Yahoo intrusion\". Washington Post. Retrieved 15 March 2017.\n- \"Securing the Network Layer Against Malicious Attacks\". TDK Technologies. October 27, 2020.\n- \"Two-factor authentication: What you need to know (FAQ) – CNET\". CNET. Retrieved 2015-10-31.\n- \"How to extract data from an iCloud account with two-factor authentication activated\". iphonebackupextractor.com. Retrieved 2016-06-08.\n- Margaret Rouse (September 2005). \"What is a security token?\". SearchSecurity.com. Retrieved 2014-02-14.\n- Resnick, Peter W. (2001). Resnick, P (ed.). \"Internet Message Format\". tools.ietf.org. doi:10.17487/RFC2822. Retrieved 2021-05-01.\n- \"Virtual Private Network\". NASA. Archived from the original on 2013-06-03. Retrieved 2014-02-14.\n- \"What Is a Message Authentication Code?\". Wisegeek.com. Retrieved 2013-04-20.\n- \"Browser Statistics\". W3Schools.com. Retrieved 2011-08-10.\n- Bradly, Tony. \"It's Time to Finally Drop Internet Explorer 6\". PCWorld.com. Retrieved 2010-11-09.\n- Larkin, Eric (2008-08-26). \"Build Your Own Free Security Suite\". PCWorld. Archived from the original on 2010-11-06. Retrieved 2010-11-09.\n- \"USE A FREE PASSWORD MANAGER\" (PDF). scsccbkk.org. Archived from the original (PDF) on 2016-01-25. Retrieved 2016-06-17.\n- Rebbapragada, Narasu. \"All-in-one Security\". PC World.com. Archived from the original on October 27, 2010. Retrieved 2010-11-09.\n- \"Free products for PC security\". 2015-10-08.\n- National Institute of Standards and Technology (NIST.gov) - Information Technology portal with links to computer- and cyber security\n- National Institute of Standards and Technology (NIST.gov) -Computer Security Resource Center -Guidelines on Electronic Mail Security, version 2\n- PwdHash Stanford University - Firefox & IE browser extensions that transparently convert a user's password into a domain-specific password.\n- Cybertelecom.org Security Archived 2021-04-10 at the Wayback Machine - surveying federal Internet security work.\n- DSL Reports.com- Broadband Reports, FAQs and forums on Internet security, est 1999",
    "logistics": "Logistics is the part of supply chain management that deals with the efficient forward and reverse flow of goods, services, and related information from the point of origin to the point of consumption according to the needs of customers,[2][3] and a logistician is a professional working in the field of logistics management. Logistics management is a component that holds the supply chain together.[3] The resources managed in logistics may include tangible goods such as materials, equipment, and supplies, as well as food and other edible items. Military logistics is concerned with maintaining army supply lines with food, armaments, ammunition, and spare parts, apart from the transportation of troops themselves. Meanwhile, civil logistics deals with acquiring, moving, and storing raw materials, semi-finished goods, and finished goods. For organisations that provide garbage collection, mail deliveries, public utilities, and after-sales services, logistical problems must be addressed.[2]\nLogistics deals with the movement of materials or products from one facility to another; it does not include material flow within production or assembly plants, such as production planning or single-machine scheduling.[2]\nLogistics accounts for a significant amount of the operational costs of an organisation or country. Logistical costs of organizations in the United States incurred about 11% of the United States national gross domestic product (GDP) as of 1997. In the European Union, logistics costs were 8.8% to 11.5% of GDP as of 1993.[2]\nDedicated simulation software can model, analyze, visualize, and optimize logistic complexities. Minimizing resource use is a common motivation in all logistics fields.\nThe term logistics is attested in English from 1846. It is from the French logistique, which was either coined or popularized by a Swiss military officer and writer, Antoine-Henri Jomini, who defined it in his Summary of the Art of War (Précis de l'Art de la Guerre). The term appears in the 1830 edition, then titled Analytic Table (Tableau Analytique),[4] and Jomini explains that it is derived from French: logis, lit. 'lodgings' (cognate to English lodge), in the terms French: maréchal des logis, lit. 'marshall of lodgings' and French: major-général des logis, lit. 'major-general of lodging':\nAutrefois les officiers de l’état-major se nommaient: maréchal des logis, major-général des logis; de là est venu le terme de logistique, qu’on emploie pour désigner ce qui se rapporte aux marches d’une armée.\nFormerly the officers of the general staff were named marshal of lodgings, major-general of lodgings; from there came the term logistics [logistique], which we employ to designate those who are in charge of the functioning of an army.\nThe term and its etymology were criticized in 1832 by Georges de Chambray :[5]\nLogistique: Ce mot me paraît être tout-à-fait nouveau, car je ne l'avais encore vu nulle part dans la littérature militaire. … il paraît le faire dériver du mot logis, étymologie singulière …\nLogistic: This word appears to me to be completely new, as I have not yet seen it anywhere in military literature. … he appears to derive it from the word lodgings [logis], a peculiar etymology …\nChambray also notes that the term logistique was present in the Dictionnaire de l'Académie française as a synonym for algebra. The French word: logistique is a homonym of the existing mathematical term, from Ancient Greek: λογῐστῐκός, romanized: logistikós, a traditional division of Greek mathematics; the mathematical term is presumably the origin of the term logistic in logistic growth and related terms. Some sources give this instead as the source of logistics,[6] either ignorant of Jomini's statement that it was derived from logis, or dubious and instead believing it was in fact of Greek origin, or influenced by the existing term of Greek origin.\nJomini originally defined logistics as[4]\n... l'art de bien ordonner les marches d'une armée, de bien combiner l'ordre des troupes dans les colonnes, les tems [temps] de leur départ, leur itinéraire, les moyens de communications nécessaires pour assurer leur arrivée à point nommé ...\n... the art of well-ordering the functionings of an army, of well combining the order of troops in columns, the times of their departure, their itinerary, the means of communication necessary to assure their arrival at the right time ...\nThe Oxford English Dictionary defines logistics as \"the branch of military science relating to procuring, maintaining and transporting material, personnel and facilities\". However, the New Oxford American Dictionary defines logistics as \"the detailed coordination of a complex operation involving many people, facilities, or supplies\", and the Oxford Dictionary on-line defines it as \"the detailed organization and implementation of a complex operation\".[7] As such, logistics is commonly seen as a branch of engineering that creates \"people systems\" rather than \"machine systems\".\nAccording to the Council of Supply Chain Management Professionals (previously the Council of Logistics Management),[8] logistics is the process of planning, implementing and controlling procedures for the efficient and effective transportation and storage of goods including services and related information from the point of origin to the point of consumption for the purpose of conforming to customer requirements and includes inbound, outbound, internal and external movements.[9]\nAcademics and practitioners traditionally refer to the terms operations or production management when referring to physical transformations taking place in a single business location (factory, restaurant or even bank clerking) and reserve the term logistics for activities related to distribution, that is, moving products on the territory. Managing a distribution center is seen, therefore, as pertaining to the realm of logistics since, while in theory, the products made by a factory are ready for consumption they still need to be moved along the distribution network according to some logic, and the distribution center aggregates and processes orders coming from different areas of the territory. That being said, from a modeling perspective, there are similarities between operations management and logistics, and companies sometimes use hybrid professionals, with for example a \"Director of Operations\" or a \"Logistics Officer\" working on similar problems. Furthermore, the term \"supply chain management\" originally referred to, among other issues, having an integrated vision of both production and logistics from point of origin to point of production.[10]\nLogistical activities can be divided into three main areas: order processing, inventory management, and freight transportation. Modern freight transportation relies heavily on fleet management to improve efficiency and safety. Traditionally, order processing was a time-consuming activity, but with new technologies such as bar code scanning and computers, the availability of stocks can be checked in real time. The purpose of having an inventory is to reduce the overall logistical cost while improving service to customers. Having a stockpile of finished goods beforehand can reduce the frequency of transportation and cope with the randomness of customer demands. However, maintaining an inventory requires capital investment and maintaining a warehouse. Freight transportation is a central part of logistics and allows access to broad markets. Transportation policies and warehouse management are closely intertwined.[2]\nThe rise of e-commerce has led to the development of \"e-logistics\". Compared to traditional logistics, e-logistics handles parcels valued at less than a hundred US dollars to customers scattered at various destinations worldwide. In e-logistics, customers' demands come in waves when compared to traditional logistics, where the demand is consistent.[2]\nInbound logistics is one of the primary logistics processes concentrating on purchasing and arranging the inbound movement of materials, parts, or unfinished inventory from suppliers to manufacturing or assembly plants, warehouses, or retail stores.\nOutbound logistics is the process related to the storage and movement of the final product. The related information flows from the end of the production line to the end user.\nGiven the services performed by logisticians, the main fields of logistics can be broken down as follows:\n- Procurement logistics, which consists of market research, requirements planning, make-or-buy decisions, supplier management, ordering, and order control. The targets in procurement logistics might be contradictory: maximizing efficiency by concentrating on core competencies, outsourcing while maintaining the company's autonomy, or minimizing procurement costs while maximizing security within the supply process.\n- Advance logistics involves the activities required to set up or establish a supply base in advance of other resources arriving. The term is used, for example, in military logistics for the assembly of resources ahead of troop arrival or the delivery of infrastructure components.[11]\n- Global logistics is technically the process of managing the \"flow\" of goods through a supply chain from its place of production to other parts of the world. This often requires an intermodal transport system via ocean, air, rail, and truck. The effectiveness of global logistics is measured in the Logistics Performance Index.\n- Distribution logistics has, as its main task, the delivery of the finished products to the customer. It consists of order processing, warehousing, and transportation. Modern distribution often includes the use of a vehicle tracking system to monitor shipments by collecting real-time vehicle location data. Distribution logistics is necessary because production time, place, and quantity differ with the time, place, and quantity of consumption.[12]\n- Disposal logistics has the function of reducing logistics cost(s) and enhancing service(s) related to the disposal of waste produced during a business's operation.\n- Reverse logistics denotes all operations related to the reuse of products and materials. The reverse logistics process includes the management and the sale of surpluses, as well as products being returned to vendors from buyers. It is \"the process of planning, implementing, and controlling the efficient, cost-effective flow of raw materials, in-process inventory, finished goods, and related information from the point of consumption to the point of origin to recapture value or proper disposal\".[13] More precisely, reverse logistics is the process of moving goods from their typical final destination for the purpose of capturing value, or proper disposal. The opposite of reverse logistics is forward logistics.\n- Green logistics describes all attempts to measure and minimize the ecological impact of logistics activities, including all activities of the forward and reverse flows. This can be supported by fleet digitalization initiatives aimed at optimizing routes and reducing fuel consumption.\n- RAM logistics (see also Logistic engineering) combines both business logistics and military logistics since it concerns highly complicated technological systems for which reliability, availability and maintainability are essential, e.g., weapon system and military supercomputers.\n- Asset control logistics: companies in the retail channels, both organized retailers and suppliers, often deploy assets required for the display, preservation, and promotion of their products. This can involve using a tracking system to monitor the location and status of these assets.\n- Humanitarian logistics or emergency logistics: these terms are used by the logistics, supply chain, and manufacturing industries to denote specific time-critical modes of transport used to move goods rapidly in the event of an emergency.[14] The reason for enlisting emergency logistics services could be a production delay or anticipated production delay, or an urgent need for specialized equipment to prevent events such as aircraft being grounded (also known as \"aircraft on ground\"—AOG), ships being delayed, or telecommunications failure. Humanitarian logistics involves governments, the military, aid agencies, donors, non-governmental organizations, and emergency logistics services are typically sourced from a specialist provider.[14][15][16]\nIn addition, the term production logistics describes logistic processes within a value-adding system (e.g., a factory or a mine). Production logistics aims to ensure that each machine and workstation receives the right product in the correct quantity and quality at the right time. The concern is with production, testing, transportation, storage, and supply. Production logistics can operate in existing as well as new plants. Since manufacturing in an existing plant is a constantly changing process, machines are exchanged and new ones added, which allows for improving the production logistics system accordingly.[17] Production logistics provides the means to achieve customer response and capital efficiency. Track and trace solutions, which provide visibility of products through the production line, are an important part of modern production logistics, especially in the automotive and medical industries.\nThe term construction logistics has also been employed by civilizations for thousands of years.[citation needed] Now, construction logistics is an important part of the sector. In recent years, it has emerged as a distinct field of study within supply chain management and logistics. Modern construction logistics uses automatic vehicle location (AVL) to manage the movement of heavy equipment and materials.\nThe Seven R's is a popular concept used to enforce best practices in logistics management which consists of the following:[18]\n- Right product (including the right information about it)\n- (At) right quantity\n- Right time\n- Right condition\n- Right place\n- (to) the right customer\n- (with the) right (financial) resources\nIn military science, maintaining one's supply lines while disrupting those of the enemy is a crucial element of military strategy, since an armed force without resources and transportation is defenseless. The historical leaders Hannibal, Alexander the Great, and the Duke of Wellington are considered[by whom?] to have been logistical geniuses: Alexander's expedition benefited considerably from his meticulous attention to the provisioning of his army,[20] Hannibal is credited to have \"taught logistics\" to the Romans during the Punic Wars[21] and the success of the Anglo-Portuguese army in the Peninsula War was due to the effectiveness of Wellington's supply system, despite the numerical disadvantage.[22] The defeat of the British in the American War of Independence and the defeat of the Axis in the African theater of World War II are attributed by some scholars to logistical failures.[23]\nMilitaries have a significant need for logistics solutions and so have developed advanced implementations. Integrated logistics support (ILS) is a discipline used in military industries to ensure an easily supportable system with a robust customer service (logistic) concept at the lowest cost and in line with (often high) reliability, availability, maintainability, and other requirements, as defined for the project.\nIn military logistics, Logistics Officers manage how and when to move resources to the places they are needed.\nSupply chain management in military logistics often deals with a number of variables in predicting cost, deterioration, consumption, and future demand. The United States Armed Forces' categorical supply classification was developed in such a way that categories of supply with similar consumption variables are grouped together for planning purposes. For instance, peacetime consumption of ammunition and fuel will be considerably lower than wartime consumption of these items, whereas other classes of supply such as subsistence and clothing have a relatively consistent consumption rate regardless of war or peace.\nSome classes of supply have a linear demand relationship: as more troops are added, more supply items are needed; or as more equipment is used, more fuel and ammunition are consumed. Other classes of supply must consider a third variable besides usage and quantity: time. As equipment ages, more and more repair parts are needed over time, even when usage and quantity stay consistent. By recording and analyzing these trends over time and applying them to future scenarios, the US Armed Forces can accurately supply troops with the items necessary at the precise moment they are needed.[24] History has shown that good logistical planning creates a lean and efficient fighting force. The lack thereof can lead to a clunky, slow, and ill-equipped force with too much or too little supply.\n| Business logistics |\n|---|\n| Distribution methods |\n| Management systems |\n| Industry classification |\nOne definition of business logistics speaks of \"having the right item in the right quantity at the right time at the right place for the right price in the right condition to the right customer\".[25] Business logistics incorporates all industry sectors and aims to manage the fruition of project life cycles, supply chains, and resultant efficiencies.\nThe term business logistics has evolved since the 1960s[26] due to the increasing complexity of supplying businesses with materials and shipping out products in an increasingly globalized supply chain, leading to a call for professionals called supply chain logisticians.\nIn business, logistics may have either an internal focus (inbound logistics) or an external focus (outbound logistics), covering the flow and storage of materials from point of origin to point of consumption, a key factor in supply-chain management. The main functions of a qualified logistician include inventory management, purchasing, transportation, warehousing, consultation, and the organizing and planning of these activities. Logisticians combine professional knowledge of each of these functions to coordinate resources in an organization.\nThere are two fundamentally different forms of logistics: one optimizes a steady flow of material through a network of transport links and storage nodes, while the other coordinates a sequence of resources to carry out some project, such as restructuring a warehouse.\nA journey planner or route optimization software is often used to solve the complex logistical problem of determining the most efficient delivery paths for a fleet of vehicles. These systems, which are a key component of an intelligent transportation system, analyze factors like traffic, delivery windows, and vehicle capacity to create optimized routes that reduce fuel consumption and improve on-time performance.[27]\nA distribution network would require several intermediaries to bring consumer or industrial goods from manufacturers to a user. Intermediaries would markup the costs of the products during distribution, but benefit users by providing lower transportation costs than the manufacturers. The number of intermediaries required for the distribution network depends upon the types of goods being distributed. For example, consumer goods such as cosmetics and handicrafts may not require any intermediaries as they can be sold door-to-door or can be obtained from local flea markets. For industrial goods such as raw materials and equipment, intermediaries are not needed because manufacturers can sell a large number of goods to a user. Generally, there are three types of intermediaries, namely: agent/broker, wholesaler, and retailer.[2]\nThe nodes of a distribution network include:\n- Factories where products are manufactured or assembled\n- A depot or deposit, a standard type of warehouse for storing merchandise (high level of inventory)\n- Distribution centers for order processing and order fulfillment (lower level of inventory) and also for receiving returning items from clients. Typically, distribution centers are way stations for products to be disbursed further down the supply chain. They usually do not ship inventory directly to customers, whereas fulfillment centers do.[citation needed]\n- Transit points for cross-docking activities, which consist of reassembling cargo units based on deliveries scheduled (only moving merchandise)\n- Traditional \"mom-and-pop\" retail stores, modern supermarkets, hypermarkets, discount stores or also voluntary chains, consumers' co-operatives, groups of consumers with collective buying power. Note that subsidiaries will be mostly owned by another company and franchisers, although using other company brands, actually own the point of sale.\nA logistic family is a set of products that share a common characteristic: weight and volumetric characteristics, physical storing needs (temperature, radiation, etc.), handling needs, order frequency, package size, etc. The following metrics may be used by the company to organize its products in different families:[28]\n- Physical metrics used to evaluate inventory systems include stocking capacity, selectivity, superficial use, volumetric use, transport capacity, transport capacity use.\n- Monetary metrics used include space holding costs, such as building, shelving, and services, and handling costs, such as people, handling machinery, energy, and maintenance.\nOther metrics may present themselves in both physical or monetary form, such as the standard inventory turnover.\nUnit loads are combinations of individual items which are moved by handling systems, usually employing a pallet of normed dimensions.[29]\nHandling systems include: trans-pallet handlers, counterweight handler, retractable mast handler, bilateral handlers, trilateral handlers, AGV and other handlers.\nStorage systems include: pile stocking, cell racks (either static or movable), cantilever racks and gravity racks.[30]\nOrder processing is a sequential process involving: processing withdrawal list, picking (selective removal of items from loading units), sorting (assembling items based on the destination), package formation (weighting, labeling, and packing), order consolidation (gathering packages into loading units for transportation, control and bill of lading).[31]\nPicking can be both manual or automated. Manual picking can be both man-to-goods, i.e. operator using a cart or conveyor belt, or goods-to-man, i.e. the operator benefiting from the presence of a mini-load ASRS, vertical or horizontal carousel or from an Automatic Vertical Storage System (AVSS). Automatic picking is done either with dispensers or depalletizing robots.\nSorting can be done manually through carts or conveyor belts, or automatically through sorters.\nConsolidating small shipments into large shipments can help to save transportation costs. There are three methods to do this: facility consolidation, multi-stop consolidation, and temporal consolidation. Facility consolidation uses the economics of scale by transporting small shipments over short distances and large shipments over long distances. Multi-stop consolidation makes multiple stops to consolidate small shipments in the case of less-than-truckload shipping. Temporal consolidation adjusts the shipping schedules forwards or backward so as to make a single large shipment rather than several small shipments over time.[2]\nCargo can be consolidated into pallets or containers. There are five basic modes of transport, namely, ship, rail, truck, air, and pipeline operated by different carrier. These shipping methods can be combined in various ways such as intermodal transport (no handling), multimodal transport, and combined transport (minimal road transport). A shipper chooses a carrier by taking into account the total cost of shipment and transit time. Air is the most expensive type of transport, followed by truck, rail, pipeline, and ship.[2]\nCargo can be organized in different shipment categories. Unit loads are usually assembled into higher standardized units such as: ISO containers, swap bodies or semi-trailers. Especially for very long distances, product transportation will likely benefit from using different transportation means: When moving cargo, typical constraints are maximum weight and volume.\nOperators involved in transportation include: all train, road vehicles, boats, airplanes companies, couriers, freight forwarders and multi-modal transport operators.\nMerchandise being transported internationally is usually subject to the Incoterms standards issued by the International Chamber of Commerce.\nIn the logistics business, a logistical system is designed at a minimum cost based on the expected customer service level. As the service improves, the number of sales also increased. As service is further improved, more sales are captured from competing providers. Further increase in customer service levels after these only increases sales marginally.[2]\nSimilarly to production systems, logistic systems need to be properly configured and managed. Actually a number of methodologies have been directly borrowed from operations management such as using economic order quantity models for managing inventory in the nodes of the network.[32] Distribution resource planning (DRP) is similar to MRP, except that it does not concern activities inside the nodes of the network but planning distribution when moving goods through the links of the network.\nTraditionally in logistics, configuration may be at the level of the warehouse (node) or at level of the distribution system (network).\nRegarding a single warehouse, besides the issue of designing and building the warehouse, configuration means solving a number of interrelated technical-economic problems: dimensioning rack cells, choosing a palletizing method (manual or through robots), rack dimensioning and design, number of racks, number and typology of retrieval systems (e.g. stacker cranes). Some important constraints have to be satisfied: fork and load beams resistance to bending and proper placement of sprinklers. Although picking is more of a tactical planning decision than a configuration problem, it is important to take it into account when deciding the layout of the racks inside the warehouse and buying tools such as handlers and motorized carts since once those decisions are taken they will work as constraints when managing the warehouse, the same reasoning for sorting when designing the conveyor system or installing automatic dispensers.\nConfiguration at the level of the distribution system concerns primarily the problem of location of the nodes in geographic space and distribution of capacity among the nodes. The first may be referred to as facility location (with the special case of site selection) while the latter to as capacity allocation. The problem of outsourcing typically arises at this level: the nodes of a supply chain are very rarely owned by a single enterprise. Distribution networks can be characterized by numbers of levels, namely the number of intermediary nodes between supplier and consumer:\n- Direct store delivery, i.e. zero levels\n- One level network: central warehouse\n- Two level network: central and peripheral warehouses\nThis distinction is more useful for modeling purposes, but it relates also to a tactical decision regarding safety stocks: considering a two-level network, if safety inventory is kept only in peripheral warehouses then it is called a dependent system (from suppliers), if safety inventory is distributed among central and peripheral warehouses it is called an independent system (from suppliers).[28] Transportation from producer to the second level is called primary transportation, from the second level to a consumer is called secondary transportation.\nAlthough configuring a distribution network from zero is possible, logisticians usually have to deal with restructuring existing networks due to presence of an array of factors: changing demand, product or process innovation, opportunities for outsourcing, change of government policy toward trade barriers, innovation in transportation means (both vehicles or thoroughfares), the introduction of regulations (notably those regarding pollution) and availability of ICT supporting systems, such as ERP or e-commerce.\nOnce a logistic system is configured, management, meaning tactical decisions, takes place, once again, at the level of the warehouse and of the distribution network. Decisions have to be made under a set of constraints: internal, such as using the available infrastructure, or external, such as complying with the given product shelf lifes and expiration dates.\nAt the warehouse level, the logistician must decide how to distribute merchandise over the racks. Three basic situations are traditionally considered: shared storage, dedicated storage (rack space reserved for specific merchandise) and class-based storage (class meaning merchandise organized in different areas according to their access index).\nPicking efficiency varies greatly depending on the situation.[31] For a man to goods situation, a distinction is carried out between high-level picking (vertical component significant) and low-level picking (vertical component insignificant). A number of tactical decisions regarding picking must be made:\n- Routing path: standard alternatives include transversal routing, return routing, midpoint routing, and largest gap return routing\n- Replenishment method: standard alternatives include equal space supply for each product class and equal time supply for each product class.\n- Picking logic: order picking vs batch picking\nAt the level of the distribution network, tactical decisions involve mainly inventory control and delivery path optimization. Note that the logistician may be required to manage the reverse flow along with the forward flow.\nWarehouse management systems (WMS) can differ significantly from warehouse control systems (WCS), although there is some overlap in functionality. A WMS plans a weekly activity forecast based on such factors as statistics and trends, whereas a WCS acts like a floor supervisor, working in real-time to get the job done by the most effective means. For example, a WMS can tell the system that it is going to need five of stock-keeping unit (SKU) A and five of SKU B hours in advance, but by the time it acts, other considerations may have come into play or there could be a logjam on a conveyor. A WCS can prevent that problem by working in real-time and adapting to the situation by making a last-minute decision based on current activity and operational status. Working synergistically, WMS and WCS can resolve these issues and maximize efficiency for companies that rely on the effective operation of their warehouse or distribution center.[33]\nLogistics outsourcing involves a relationship between a company and an LSP (logistic service provider), who, when compared with basic logistics services, has more customized offerings, encompasses a broad number of service activities, and is characterized by a long-term orientation; thus the relationship has a strategic nature.[34]\nOutsourcing does not have to be complete externalization to an LSP, but can also be partial:\n- A single contract for supplying a specific service on occasion\n- Creation of a spin-off\n- Creation of a joint venture\nThird-party logistics (3PL) involves using external organizations to execute logistics activities that have traditionally been performed within an organization itself.[35] According to this definition, third-party logistics includes any form of outsourcing of logistics activities previously performed in house. For example, if a company with its own warehousing facilities decides to employ external transportation, this would be an example of third-party logistics. Logistics is an emerging business area in many countries. External 3PL providers have evolved from merely providing logistics capabilities to becoming real orchestrators of supply chains that create and sustain a competitive advantage, thus bringing about new levels of logistics outsourcing.[36]\nThe concept of a fourth-party logistics (4PL) provider was first defined by Andersen Consulting (now Accenture) as an integrator that assembles the resources, planning capabilities, and technology of its own organization and other organizations to design, build, and run comprehensive supply chain solutions. Whereas a third-party logistics (3PL) service provider targets a single function, a 4PL targets management of the entire process. Some[who?] have described a 4PL as a general contractor that manages other 3PLs, truckers, forwarders, custom house agents, and others, essentially taking responsibility of a complete process for the customer.\nHorizontal business alliances often occur between logistics service providers, i.e., the cooperation between two or more logistics companies that are potentially competing.[37] In a horizontal alliance, these partners can benefit twofold. On one hand, they can \"access tangible resources which are directly exploitable\". In this example extending common transportation networks, their warehouse infrastructure and the ability to provide more complex service packages can be achieved by combining resources. On the other hand, partners can \"access intangible resources, which are not directly exploitable\". This typically includes know-how and information and, in turn, innovation.[37]\nLogistics automation is the application of computer software or automated machinery to improve the efficiency of logistics operations. This typically refers to operations within a warehouse or distribution center with broader tasks undertaken by supply chain engineering systems and enterprise resource planning systems.\nIndustrial machinery can typically identify products through either barcode or RFID technologies. Information in traditional bar codes is stored as a sequence of black and white bars varying in width, which when read by laser is translated into a digital sequence, which according to fixed rules can be converted into a decimal number or other data. Sometimes information in a bar code can be transmitted through radio frequency, more typically radio transmission is used in RFID tags. An RFID tag is a card containing a memory chip and an antenna that transmits signals to a reader. RFID may be found on merchandise, animals, vehicles, and people as well.\nA logistician is a professional logistics practitioner. Professional logisticians are often certified by professional associations. One can either work in a pure logistics company, such as a shipping line, airport, or freight forwarder, or within the logistics department of a company. However, as mentioned above, logistics is a broad field, encompassing procurement, production, distribution, and disposal activities. Hence, career perspectives are broad as well. A new trend[as of?] in the industry is the 4PL, or fourth-party logistics, firms, consulting companies offering logistics services.[citation needed]\nSome universities and academic institutions train students as logisticians, offering undergraduate and postgraduate programs. A university with a primary focus on logistics is Kühne Logistics University in Hamburg, Germany. It is non-profit and supported by Kühne-Foundation of the logistics entrepreneur Klaus Michael Kühne.[citation needed]\nThe Chartered Institute of Logistics and Transport (CILT), established in the United Kingdom in 1919, received a Royal Charter in 1926. The Chartered Institute is one of the professional bodies or institutions for the logistics and transport sectors that offer professional qualifications or degrees in logistics management. CILT programs can be studied at centers around the UK, some of which also offer distance learning options.[38] The institute also have overseas branches, namely the Chartered Institute of Logistics & Transport Australia (CILTA) in Australia,[39] and the Chartered Institute of Logistics and Transport in Hong Kong (CILTHK) in Hong Kong.[40] In the UK, logistics management programs are conducted by many universities and professional bodies such as CILT. These programs are generally offered at the postgraduate level.\nThe Global Institute of Logistics,[41] established in New York in 2003, is a think tank for the profession and is primarily concerned with intercontinental maritime logistics. It is particularly concerned with container logistics and the role of the seaport authority in the maritime logistics chain.\nThe International Association of Public Health Logisticians (IAPHL)[42] is a professional network that promotes the professional development of supply chain managers and others working in the field of public health logistics and commodity security, with particular focus on developing countries. The association supports logisticians worldwide by providing a community of practice, where members can network, exchange ideas, and improve their professional skills.\nThere are many museums in the world which cover various aspects of practical logistics. These include museums of transportation, customs, packing, and industry-based logistics. In particular, the following museums are fully dedicated to logistics:\n- General logistics\n- Logistics Museum (Saint Petersburg, Russia)[43]\n- Museum of Logistics (Tokyo, Japan)[44]\n- Beijing Wuzi University Logistics Museum (Beijing, China)\n- Military logistics\n- Royal Logistic Corps Museum (Hampshire, England, United Kingdom)\n- The Canadian Forces Logistics Museum (Montreal, Quebec, Canada)[45]\n- Logistics Museum (Hanoi, Vietnam)\n- Automated identification and data capture – Methods of automatically identifying objects by computer system\n- Document automation – Design of systems for electronic documents\n- Field inventory management – Function of understanding stock mix of a company and the different demands on that stock\n- Freight claim – Legal demand against a shipment carrier\n- Freight forwarder – Handles logistics for freight\n- Incoterms – Standardized contract terms regarding transportation and delivery\n- Containerization – Intermodal freight transport system\n- Integrated Service Provider – Type of logistics services firm\n- Inventory management software – Software for tracking stock levels and flow\n- Performance-based logistics – Defense acquisition strategy for cost-effective weapon system support\n- Physical inventory – Physical verification of stored items\n- Sales territory – Geographic area or customer group managed by a sales representative\n- Storage management system – Data storage technique\n- Blockchain – Distributed data store for digital transactions\n- Dutch flower bucket\n- Self-driving truck – Type of autonomous vehicle\n- Automated storage and retrieval system – Robotic warehouse for physical objects\n- Automated guided vehicle – Type of portable robot\n- Jon Hurdle (13 May 2021). \"Report details surge in warehouse construction…\". NJ Spotlight News. Retrieved 3 January 2023.\nIn South Jersey, the area has become the \"epicenter\" of warehouse construction in the greater Philadelphia region..'Activity in the Southern New Jersey industrial market continues to amaze,' the report said.\n- Ghiani, Gianpaolo; Laporte, Gilbert; Musmanno, Roberto (2004). Introduction to Logistics Systems Planning and Control. John Wiley & Sons. p. 1, 5, 10–15. ISBN 9780470849170. Retrieved 8 January 2023.\n- Kozlenkova, Irina V.; Hult, G. Tomas M.; Lund, Donald J.; Mena, Jeannette A.; Kekec, Pinar (December 2015). \"The Role of Marketing Channels in Supply Chain Management\". Journal of Retailing. 91 (4): 586–609. doi:10.1016/j.jretai.2015.03.003.\nLogistics refers to \"that part of supply chain management that plans, implements, and controls the efficient, effective forward and reverse flow and storage of goods, services, and related information between the point of origin and the point of consumption in order to meet customers' requirements\"\n- Baron de Jomini (1830). Tableau Analytique des principales combinaisons De La Guerre, Et De Leurs Rapports Avec La Politique Des États: Pour Servir D'Introduction Au Traité Des Grandes Opérations Militaires. p. 74.\n- Chambray [in French] (1832). \"Observation sur Le Tableau Analytique des principales combinaisons De La Guerre, Et De Leurs Rapports Avec La Politique Des États: Pour Servir D'Introduction Au Traité Des Grandes Opérations Militaires par le général Jomini\". Le Spectateur militaire: Recueil de science, d'art et d'histoire militaires (in French). 13: 19.\n- Tepic, J.; Tanackov, I.; Stojić, Gordan (2011). \"Ancient logistics – historical timeline and etymology\" (PDF). Technical Gazette. 18 (3). S2CID 42097070. Archived from the original (PDF) on 9 March 2019.\n- Oxford Dictionaries. Retrieved 21 February 2012.\n- Material Handling & Logistics News http://mhlnews.com/global-supply-chain/council-logistics-management-become-council-supply-chain-management-professional\n- \"CSCMP glossary\" (PDF). Archived from the original (PDF) on 22 May 2016. Retrieved 10 September 2013.\n- V. Misra, M.I. Kahn, U.K. Singh, Supply Chain Management Systems: Architecture, Design and Vision, North American Business Press 2010 http://www.na-businesspress.com/jsis/misraweb.pdf\n- See the articles on the USS O'Brien (DD-725) and USS Victoria (AO-46) during World War II\n- Hofmann, Sebastian. \"Distribution logistics - definition, basics, examples\". Retrieved 3 March 2022.\n- Agrawal, Saurabh; Singh, Rajesh K.; Murtaza, Qasim (1 April 2015). \"A literature review and perspectives in reverse logistics\". Resources, Conservation and Recycling. 97: 76–92. Bibcode:2015RCR....97...76A. doi:10.1016/j.resconrec.2015.02.009. ISSN 0921-3449.\n- Cozzolino Alessandra, Humanitarian Logistics and Supply Chain Management, In Humanitarian Logistics, Springer Berlin Heidelberg 2012\n- \"Pooling Logistics Resources\". Fleet Forum. 19 January 2020. Retrieved 23 September 2025.\n- L. Torre, I.S. Dolinskaya, K.R. Smilowitz, Disaster relief routing: Integrating research and practice Socio-Economic Planning Sciences vol46, March 2012\n- Nyhuis P., Wiendahi Hans-Peter, Fundamentals of Production Logistics, Springer Berlin Heidelberg 2009\n- on YouTube\n- J.P. Roth, The logistics of Roman army at war (264 B.C. -A.D. 235) https://www.academia.edu/2450333/Logistics_of_the_Roman_Army_at_War\n- Donald W. Engels, Alexander the Great and the Logistics of the Macedonian Army, University of California 1980\n- Ayrault Dodge Theodore, Hannibal: A History of the Art of War Among the Carthaginians and Romans Down to the Battle of Pydna, 168 BC. Da Capo Press. 1995\n- Troy T. Kirby, The Duke of Wellington and the Supply System During the Peninsula War, CreateSpace Independent Publishing Platform 2014\n- Roger Morriss, \"Colonization, Conquest, and the Supply of Food and Transport: The Reorganization of Logistics Management, 1780–1795,\" War in History, (July 2007), 14#3 pp 310–324,\n- Cloutier, Peter J.; Frank, Brian K. (July–August 2009). \"The Joint Logistics Analysis Tool\". Army Logistician. 41 (4). Archived from the original on 9 May 2015.\n- Mallik, Susan (2010). \"Customer Service in Supply Chain Management\". In Hossein Bidgoil (ed.). The Handbook of Technology Management: Supply Chain Management, Marketing and Advertising, and Global Management, vol 2 (1 ed.). Hoboken, New Jersey: John Wiley & Sons. p. 104. ISBN 978-0-470-24948-2.\n- McGinnis M. A., Military Logistics: Insights for Business Logistics, International Journal of Physical Distribution & Logistics Management Vol 22, 1992\n- Ben Ahmed, S.; Al-Marridi, H. A.; Al-Merri, Z.; El-Saadany, M. (2021). \"Optimization of Vehicle Transportation Route Based on IoT\". Journal of Advanced Transportation. 2021: 1–14. doi:10.1155/2021/1312058.\n- Ruggeri, R.; Perego, A. (2001). Esercitazioni e temi d'esame di Logistica Industriale (in Italian). CUSL. ISBN 8881320150.\n- ISO 6780:2003 – Flat pallets for intercontinental materials handling – Principal dimensions and tolerances.\n- Lambert D., Stock J., Ellram L., Fundamentals of Logistics, McGraw-Hill 1998\n- D.F. Bozutti, M.A. Bueno-Da-Costa, R. Ruggeri, Logística: Visão Global e Picking, EdUFSCar 2010\n- Waters D., Logistics: An Introduction to Supply Chain Management, Palgrave Macmillan 2003\n- John T. Phelan, Jr. P.E. Supply & Demand Chain Executive. Enom, Inc.\n- Wallenburg, Carl Marcus; Cahill, David L.; Michael Knemeyer, A.; Goldsby, Thomas J. (2011). \"Commitment and Trust as Drivers of Loyalty in Logistics Outsourcing Relationships: Cultural Differences Between the United States and Germany\". Journal of Business Logistics. 32: 83–98. doi:10.1111/j.2158-1592.2011.01008.x.\n- Baziotopoulos (2008). An Investigation of Logistics Outsourcing Practices in the Greek Manufacturing Sector (PhD thesis).\n- Zacharia, Zach G.; Sanders, Nada R.; Nix, Nancy W. (1 April 2011). \"The Emerging Role of the Third-Party Logistics Provider (3PL) as an Orchestrator\". Journal of Business Logistics. 32 (1): 40–54. doi:10.1111/j.2158-1592.2011.01004.x.\n- Raue, Jan Simon; Wieland, Andreas (2015). \"The interplay of different types of governance in horizontal cooperations\". The International Journal of Logistics Management. 26 (2): 401–423. doi:10.1108/IJLM-08-2012-0083. hdl:10398/4de0953a-3920-409a-b63a-60342c976528. S2CID 166497725.\n- \"Chartered Institute of Logistics and Transport (CILT) – Professional Logistics Programs\". EduMaritime. Archived from the original on 3 August 2020. Retrieved 20 June 2019.\n- \"Chartered Institute of Logistics & Transport Australia (CILTA) – Certification & Training\". EduMaritime.\n- \"Chartered Institute of Logistics and Transport in Hong Kong (CILTHK) – PQE Programs\". EduMaritime.\n- \"GIL HOME\". Global Institute of Logistics. Retrieved 20 June 2019.\n- \"International Association of Public Health Logisiticians\". IAPHL. Retrieved 20 June 2019.\n- \"Logistics Museum\". logistics-museum.ru. Archived from the original on 20 June 2019. Retrieved 20 June 2019.\n- \"Museum of Logistics | 物流博物館\". www.lmuse.or.jp. Retrieved 20 June 2019.\n- \"Canadian Forces Logistics Museum\". Montreal Museums. Archived from the original on 20 June 2019. Retrieved 20 June 2019.\n- Engels, Donald W. (1980). Alexander the Great and the Logistics of the Macedonian Army, University of California Press (194 pages). online\n- Hess, Earl J. Civil War Logistics: A Study of Military Transportation (2017) online review\n- Huston, James A. (1966). The Sinews of War: Army Logistics, 1775–1953, United States Army (789 pages). online\n- Handfield, R.B., Straube, F., Pfohl, H.C. & Wieland, A., Trends and Strategies in Logistics and Supply Chain Management: Embracing Global Logistics Complexity to Drive Market Advantage, BVL 2013\n- Ronald H. Ballou, Samir K. Srivastava, Business Logistics: Supply Chain Management, Pearson Education, 2007\n- Donald Bowersox, David Closs, M. Bixby Cooper, Supply Chain Logistics Management, McGraw-Hill 2012\n- M. Christopher: Logistics & Supply Chain Management: creating value-adding networks, Prentice Hall 2010. online\n- J. V. Jones: Integrated Logistics Support Handbook, McGraw-Hill Logistics Series 2006\n- B. S. Blanchard: Logistics Engineering and Management, Pearson Prentice Hall 2004\n- R.G. Poluha: The Quintessence of Supply Chain Management: What You Really Need to Know to Manage Your Processes in Procurement, Manufacturing, Warehousing, and Logistics (Quintessence Series). First Edition. Springer Heidelberg New York Dordrecht London 2016. ISBN 978-3-662-48513-2\n- Preclík Vratislav: Průmyslová logistika (Industrial logistics), 359 p., ISBN 80-01-03449-6, First issue Nakladatelství ČVUT v Praze, 2006, pp. 7–50, 63–73, 75–85, 123–347, Prague 2006.",
    "media industry": "Mass media refers to the forms of media that reach large audiences via mass communication. It includes broadcast media, digital media, print media, social media, streaming media, advertising, and events.[1][2][3]\nMass media encompasses news, advocacy, entertainment, and public service announcements, and intersects with the study of marketing, propaganda, public relations, political communication, journalism, art, drama, computing, and technology. The influence of mass media on individuals and groups has also been analysed from the standpoint of anthropology, economics, history, law, philosophy, psychology, and sociology.\nMass media is often controlled by media conglomerates, which may include mass media organisations, companies, and networks, and may be subject to media capture.[4][5]\nIn the late 20th century, mass media could be classified into eight mass media industries: books, the Internet, magazines, movies, newspapers, radio, recordings, and television. The explosion of digital communication technology in the late 20th and early 21st centuries challenged this classification. By the early 2000s, a classification called the \"seven mass media\" came into use, comprising:[6]\n- Print (books, pamphlets, newspapers, magazines, posters, etc.) - late 15th century\n- Recordings (gramophone records, magnetic tapes, cassettes, cartridges, CDs, and DVDs) - late 19th century\n- Cinema - c. 1900\n- Radio - c. 1910\n- Television - c. 1950\n- The Internet - c. 1990\n- Mobile phones - c. 2000\nThe sixth and seventh media, Internet and mobile phones, are often referred to collectively as digital media, and the fourth and fifth, radio and TV, as broadcast media.[1][2][3] Some argue that video games have developed into a distinct mass form of media.[7]\nFive characteristics of mass communication have been identified by sociologist John Thompson of Cambridge University:[8]\n- \"Comprises both technical and institutional methods of production and distribution\".[clarification needed]\n- Involves the \"commodification of symbolic forms\"[clarification needed]\n- \"Separate contexts between the production and reception of information\"[clarification needed]\n- Its \"reach to those 'far removed' in time and space, in comparison to the producers\"[clarification needed]\n- \"Information distribution\" – a \"one-to-many\" form of communication, whereby products are mass-produced and disseminated to large audiences\nIn common usage, the term \"mass\" denotes not that a given number of individuals receives the products, but rather that the products are available in principle to a plurality of recipients.[8] The term \"mass media\" is sometimes used as a synonym for \"mainstream media\". However, mass media may include alternative media outlets that employ mass communication technology, even if their audience is smaller than mainstream media. In contrast, mainstream media are distinguished from alternative media by their content and point of view.[citation needed]\nThe first dated printed book known is the \"Diamond Sutra\", printed in China in 868 AD, although it is clear that books were printed earlier. Movable clay type was invented in 1041 in China. However, due to the slow spread of literacy to the masses in China, and the relatively high cost of paper there, the earliest printed mass medium was probably European popular prints from about 1400. Although these were produced in huge numbers, very few early examples survive, and even most known to be printed before about 1600 have not survived. The term \"mass media\" was coined with the creation of print media, which is notable for being the first example of mass media, as we use the term today. This form of media started in Europe in the Middle Ages.\nJohannes Gutenberg's invention of the printing press allowed the mass production of books to sweep the nation. He printed the first book, a Latin Bible, on a printing press with movable type in 1453. The invention of the printing press gave rise to some of the first forms of mass communication by enabling the publication of books and newspapers on a scale much larger than was previously possible.[9][10][11] The invention also transformed the way the world received printed materials, although books remained too expensive really to be called a mass medium for at least a century after that. Newspapers developed from about 1612, with the first example in English in 1620;[12] but they took until the 19th century to reach a mass audience directly. The first high-circulation newspapers arose in London in the early 1800s, such as The Times, and were made possible by the invention of high-speed rotary steam printing presses, and railroads which allowed large-scale distribution over wide geographical areas. The increase in circulation, however, led to a decline in feedback and interactivity from the readership, making newspapers a more one-way medium.[13][14][15][16]\nThe phrase \"the media\" began to be used in the 1920s.[17] The notion of \"mass media\" was generally restricted to print media up until the post-Second World War, when radio, television and video were introduced. The audio-visual facilities became very popular, because they provided both information and entertainment, because the colour and sound engaged the viewers/listeners and because it was easier for the general public to passively watch TV or listen to the radio than to actively read.\nDuring the 20th century, the growth of mass media was driven by technology, including that which allowed much duplication of material. Physical duplication technologies such as printing, record pressing and film duplication allowed the duplication of books, newspapers and movies at low prices to huge audiences. Radio and television allowed the electronic duplication of information for the first time. Mass media had the economics of linear replication: a single work could make money. Proportional to the number of copies sold, and as volumes went up, unit costs went down, increasing profit margins further. Vast fortunes were made in mass media. In a democratic society, the media can serve the electorate about issues regarding government and corporate entities. Some consider the concentration of media ownership to be a threat to democracy.[18]\nIn recent times, the Internet has become the latest and most popular mass medium. Information has become readily available through websites, and easily accessible through search engines. Modern-day mass media includes the internet, mobile phones, blogs, podcasts and RSS feeds.[19]\nBetween 1985 and 2018, about 76,720 deals have been announced in the media industry. This sums up to an overall value of around US$5,634 billion.[20] There have been three major waves of M&A in the mass media sector (2000, 2007 and 2015), while the most active year in terms of numbers was 2007 with around 3,808 deals. The United States is the most prominent country in media M&A with 41 of the top 50 deals having an acquirer from the United States.\nThe largest deal in history was the acquisition of Time Warner by AOL Inc. for US$164,746.86 million.\nIn 1997, J. R. Finnegan Jr. and K. Viswanath identified three main effects or functions of mass media.\nFirst, The Knowledge Gap: the mass media influences knowledge gaps due to factors including \"the extent to which the content is appealing, the degree to which information channels are accessible and desirable, and the amount of social conflict and diversity there is in a community\".\nSecond, Agenda Setting: people are influenced in how they think about issues due to the selective nature of what media groups choose for public consumption. J. J. Davis states that \"when risks are highlighted in the media, particularly in great detail, the extent of agenda setting is likely to be based on the degree to which a public sense of outrage and threat is provoked\". When wanting to set an agenda, framing can be invaluably useful to a mass media organisation. Framing involves \"taking a leadership role in the organisation of public discourse about an issue\". The media is influenced by the desire for balance in coverage, and the resulting pressures can come from groups with particular political action and advocacy positions. Finnegan and Viswanath say, \"groups, institutions and advocates compete to identify problems, to move them onto the public agenda, and to define the issues symbolically\" (1997, p. 324).\nThird, Cultivation of Perceptions: the extent to which media exposure shapes audience perceptions over time is known as cultivation. Television is a common experience, especially in places like the United States, to the point where it can be described as a \"homogenising agent\" (S. W. Littlejohn). However, instead of being merely a result of the TV, the effect is often based on socioeconomic factors. Having a prolonged exposure to TV or movie violence might affect a viewer to the extent where they actively think community violence is a problem, or alternatively find it justifiable. The resulting belief is likely to be different depending on where people live, however.[1]\nSince the 1950s, when cinema, radio and TV began to be the primary or only source of information for most of the population, these media became the central instruments of mass control.[21][22] When a country reaches a high level of industrialisation, the country itself \"belongs to the person who controls communications\".[23]\nMass media play a significant role in shaping public perceptions on a variety of important issues, both through the information that is dispensed through them, and through the interpretations they place upon this information.[21] They also play a large role in shaping modern culture, by selecting and portraying a particular set of beliefs, values and traditions (an entire way of life), as reality. That is, by portraying a certain interpretation of reality, they shape reality to be more in line with that interpretation.[22] Mass media also play a crucial role in the spread of civil unrest activities such as anti-government demonstrations, riots and general strikes.[24] That is, the use of radio and television receivers has made the unrest influence among cities not only by the geographic location of cities, but also by proximity within the mass media distribution networks.[24]\nMedia artist Joey Skaggs has demonstrated the ease with which mass media can be manipulated using fabricated press releases, staged events, and fictitious experts. His long-running series of media hoaxes reveal how news outlets can be drawn to sensational narratives, often publishing stories with minimal fact-checking. Skaggs' work has been cited as a critique of journalistic practices and a case study in the vulnerabilities of modern media systems.[25]\nLimited-effects theory theorizes that because people usually choose what media to interact with based on what they already believe, media exerts a negligible influence. Class-dominant theory argues that the media reflects and projects the view of a minority elite, which controls it. Culturalist theory combines the other two theories and claims people interact with media to create their own meanings out of the images and messages they receive. In 2012, an article asserted that 90 percent of US mass media—including radio, video news, sports entertainment, and other—were owned by six major companies (GE, News-Corp, Disney, Viacom, Time Warner and CBS).[26]\nMass media sources, through framing and agenda-setting, can affect the impact of a story, as particular facts and information can be highlighted (media influence). This can correlate with how individuals perceive certain groups of people, as the media coverage a person receives can be limited and may not reflect the whole story or situation. Stories are often covered to reflect a particular perspective, sometimes to target a specific demographic.[27] Mass media, as well as propaganda, can reinforce or introduce stereotypes to the general public.[28]\nOne example is how mass media has played a large role in the way white Americans perceive African Americans. Historical media focus on African Americans in the contexts of crime, drug use, gang violence and other forms of anti-social behavior has resulted in a distorted and harmful public perception of African Americans.[29] In his article \"Mass Media and Racism\", Stephen Balkaran states: \"The media has played a key role in perpetuating the effects of this historical oppression and in contributing to African Americans' continuing status as second-class citizens.\" This has resulted in uncertainty among some white Americans as to what the genuine nature of African Americans is.[29]\nLack of local or specific topic focus is a common criticism of mass media. A mass news media outlet often chooses to cover national and international news due to it having to cater for and be relevant for a wide demographic. As such, it can skip over many interesting or important local stories because they simply do not interest the large majority of their viewers.\nThe term \"mass\" suggests that the recipients of media products constitute a vast sea of passive, undifferentiated individuals. This is an image associated with some earlier critiques of \"mass culture\" and mass society, which generally assumed that the development of mass communication has had a largely negative impact on modern social life, creating a kind of bland and homogeneous culture which entertains individuals without challenging them.[8] However, interactive digital media have also been seen to challenge the read-only paradigm of earlier broadcast media.[8]\nSince the 1950s, in the countries that have reached a high level of industrialisation, the mass media of cinema, radio and TV have a key role in political power.[23] Media bias on a particular topic can be assessed in comparison to the median voter.[30]\nContemporary research demonstrates an increasing level of concentration of media ownership, with many media industries already highly concentrated and dominated by a small number of firms.[31]\nWhen the study of mass media began the media was compiled of only mass media which is a very different media system than the social media empire of the 21st-century experiences.[32] With this in mind, there are critiques that mass media no longer exists, or at least that it does not exist in the same form as it once did. This original form of mass media put filters on what the general public would be exposed to in regards to \"news\" something that is harder to do in a society of social media.[33]\nTheorist Lance Bennett explains that excluding a few major events in recent history, it is uncommon for a group big enough to be labeled a mass, to be watching the same news via the same medium of mass production.[34] Bennett's critique of 21st-century mass media argues that today it is more common for a group of people to be receiving different news stories, from completely different sources, and thus, mass media has been re-invented. As discussed above, filters would have been applied to original mass medias when the journalists decided what would or would not be printed.\nSocial media is a large contributor to the change from mass media to a new paradigm because through social media what is mass communication and what is interpersonal communication is confused.[35] Due to the widespread use of social media and the rapid development of information technology, the media landscape has undergone significant changes. As a result, the Hallin and Mancini media model, based on traditional indicators, no longer fully aligns with today’s media ecosystem. While television continues to target a more mature audience and uphold professional journalism standards, digital journalism and social media tend to adapt those standards to align more closely with audience preferences.[36]\nBroadcast media includes radio and radio and television programs. Television includes cable television, which may require a cable converter box, and generally includes subscription-based channels and pay-per-view services. Digital radio and digital television may also transmit multiplexed programming, with several channels compressed into one ensemble. Broadcast regulations,[1] programming, and terminology have emerged as independent fields of inquiry. When broadcasting is done via the Internet, the term webcasting is often used. In 2004, a new phenomenon occurred when a number of technologies combined to produce podcasting.\nThe term 'film' encompasses motion pictures as individual projects, as well as the field in general. The name comes from the photographic film (also called film stock), historically the primary medium for recording and displaying motion pictures. Many other terms for film exist, such as motion pictures (or just pictures and \"picture\"), the silver screen, photoplays, the cinema, picture shows, flicks and, most commonly, movies.[37]\nFilms are produced by recording people and objects with cameras, or by creating them using animation techniques or special effects. Films comprise a series of individual frames, but when these images are shown in rapid succession, an illusion of motion is created. Flickering between frames is not seen because of an effect known as persistence of vision, whereby the eye retains a visual image for a fraction of a second after the source has been removed. Also of relevance is what causes the perception of motion: a psychological effect identified as beta movement.\nA video game is a computer-controlled game in which a video display, such as a monitor or television set, is the primary feedback device. There must also be some sort of input device, usually in the form of button/joystick combinations, a keyboard and mouse combination, a controller, or a player's motion.\nSound recording and reproduction is the electrical or mechanical re-creation or amplification of sound, often as music. This involves the use of audio equipment such as microphones, recording devices and loudspeakers. From early beginnings, with the invention of the phonograph using purely mechanical techniques, the field has advanced with the invention of electrical recording, the mass production of the 78 record, the magnetic wire recorder followed by the tape recorder, and the vinyl LP record. The invention of the compact cassette in the 1960s, followed by Sony's Walkman, gave a major boost to the mass distribution of music recordings, and the invention of digital recording and the compact disc in 1983 brought massive improvements in ruggedness and quality.\nThe Internet is a more interactive medium of mass media, and can be briefly described as \"a network of networks\". Specifically, it is the worldwide, publicly accessible network of interconnected computer networks that transmit data by packet switching using the standard Internet Protocol (IP). It consists of millions of smaller domestic, academic, business and governmental networks, which together carry various information and services, such as email, online chat, file transfer, and the interlinked web pages and other documents of the World Wide Web.\nThe Internet is the system of interconnected computer networks, linked by copper wires, fibre-optic cables, and wireless connections, while the Web is the contents of the internet linked by hyperlinks and URLs. The World Wide Web is accessible through the Internet, along with many other services including e-mail, file sharing and others described below.\nToward the end of the 20th century, the advent of the World Wide Web marked the first era in which most individuals could have a means of exposure on a scale comparable to that of mass media. Forms of internet media include blogs, microblogs, RSS feeds, and podcasts.\nMobile phones were introduced in Japan in 1979 but became a mass media only in 1998 when the first downloadable ringing tones were introduced in Finland. Soon most forms of media content were introduced on mobile phones, tablets and other portable device. Similar to the internet, mobile is also an interactive media.\nA magazine is a periodical publication containing a variety of articles, generally financed by advertising or purchase by readers. Magazines are typically published weekly, biweekly, monthly, bimonthly or quarterly, with a date on the cover that is in advance of the date it is actually published. They are often printed in colour on coated paper, and are bound with a soft cover.\nA newspaper is a publication containing news, information, and advertising, usually printed on low-cost paper called newsprint. It may be general or special interest, and is usually published serially, most often daily or weekly. The dominant function of newspapers is to inform the public of significant events.[38] Newspapers originated after the invention and spread of the printing press by Johann Gutenberg around 1450, with the first newspaper being the German-language Relation aller Fürnemmen und gedenckwürdigen Historien, first published in 1605. The increasing prevalence of internet-based news media has, while challenging newspapers as an alternative source of information and opinion, has also provided a new platform for mass media organisations to reach new audiences.[39] As such, in the twenty-first century, newspaper circulation has fallen in almost all regions.[40]\nOutdoor media is a form of mass media which comprises billboards, signs, placards, flying billboards, blimps, skywriting, and augmented reality advertising. Many commercial advertisers use this form of mass media when advertising in sports stadiums.\nJournalism is the discipline of collecting, analyzing, verifying and presenting information regarding current events, trends, issues and people.\nPublic relations is management of communication between an organisation and its key publics to build, manage and sustain its positive image.\nPublishing is the industry concerned with the production of literature or information – the activity of making information available for public view. In some cases, authors may be their own publishers. Traditionally, the term refers to the distribution of printed works such as books and newspapers. With the advent of digital information systems and the Internet, the scope of publishing has expanded to include websites, blogs and the like.\nA software publisher is a publishing company in the software industry between the developer and the distributor. In some companies, two or all three of these roles may be combined (and indeed, may reside in a single person, especially in the case of shareware).\nAn internet celebrity is anyone who gained fame on the Internet.\n- Commercial broadcasting – Practice of airing radio and television advertisements for profit\n- Digital rights management – Technology to control access to copyrighted works and prevent unauthorized copying\n- History of newspaper publishing\n- Internet censorship – Legal control of the internet\n- Journalism – Production of reports on current events\n- Media conglomerate – Large company involved in mass media industry\n- Media echo chamber\n- Media economics – Embodies economic theoretical and practical economic questions specific to media of all types\n- Media regulation\n- Media-system dependency\n- Mediatization (media) – Process whereby the mass media influence other sectors of society\n- State media – Media under editorial control of a government\n- \"Mass Media\". eNotes.com. Archived from the original on 7 April 2020. Retrieved 25 June 2019.\n- Riesman et al. (1950) ch. 2 p. 50\n- Manohar, Uttara. \"Different Types of Mass Media\". Buzzle.com. Archived from the original on 14 November 2011. Retrieved 26 November 2011.\n- \"Mass media\". Oxford English Dictionary,\n- Potter, W. James (2008). Arguing for a general framework for mass media scholarship. Sage. p. 32. ISBN 978-1-4129-6471-5.\n- Sashwat Yogi \"Role Of Media In Social Awareness (A Review Study).\" Humanities & Social Sciences Reviews 1.1 (2013): 71–73, online.\n- \"All the world's a game\". The Economist. 10 December 2011. Archived from the original on 27 June 2013. Retrieved 28 June 2013.\n- Thompson, John (1995). The Media and Modernity. Stanford University Press. pp. 26–28, 74. ISBN 978-0-8047-2679-5.\n- Splichal, Slavko (2006). \"In Pursuit of Socialized Press\". In Berry, David; Theobald John (eds.). Radical mass media criticism: a cultural genealogy. Black Rose Books. p. 41. ISBN 978-1-55164-246-8.\n- Ramey, Carl R. (2007). Mass media unleashed: how Washington policymakers shortchanged the American public. Rowman & Littlefield. pp. 1–2. ISBN 978-0-7425-5570-9.\n- Galician, Mary-Lou (2004). Sex, love & romance in the mass media: analysis & criticism of unrealistic portrayals & their influence. Psychology Press. p. 69. ISBN 978-0-8058-4832-8.\n- \"Concise History of the British Newspaper Since 1620\". British Library. Archived from the original on 3 October 2008.\n- Newhagen, J.E. (1999). \". In Kent, Allen (ed.). Encyclopedia of library and information science, Volume 65. CRC Press. p. 210. ISBN 978-0-8247-2065-0.\n- Nerone, John (2006). \"Approaches to Media History\". In Valdivia, Angharad N. (ed.). A companion to media studies. Wiley-Blackwell. p. 102. ISBN 978-1-4051-4174-1.\n- Pace, Geoffrey L. (1997). \"The Origins of Mass Media in the United States\". In Wells, Allen; Hakenen, Ernest A. (eds.). Mass media & society. Greenwood Publishing Group. p. 10. ISBN 978-1-56750-288-6.\n- Corey Ross, Mass Communications, Society, and Politics from the Empire to the Third Reich (Oxford University Press 2010) on Germany\n- Briggs, Asa & Burke, Peter (2010). Social History of the Media: From Gutenberg to the Internet. Polity Press. p. 1. ISBN 978-0-7456-4495-0.\n- Elliot D. Cohen, ed. (2005). News Incorporated: Corporate Media Ownership And Its Threat To Democracy. Prometheus Books. ISBN 1-59102-232-0.[page needed]\n- Bhattacharyya, Ajanta. \"History of Mass Media\". Buzzle.com. Archived from the original on 5 October 2011. Retrieved 26 November 2011.\n- \"M&A by Industries\". N&A Statistics. Institute for Mergers, Acquisitions and Alliances (IMAA). Archived from the original on 3 November 2020. Retrieved 25 June 2019.\n- Lorimer and Scannell (1994) pp. 26–27\n- Vipond (2000) p. 88\n- Eco (2014), p. 135: \"Not long ago, if you wanted to seize political power in a country, you had merely to control the army and the police. Today it is only in the most backward countries that fascist generals, in carrying out a coup d'etat, still use tanks. If a country has reached a high level of industrialization the whole scene changes. The day after the fall of Khrushchev, the editors of Pravda, Izvestiia, the heads of the radio and television were replaced; the army wasn't called out. Today a country belongs to the person who controls communications.\"\n- Braha, Dan (31 October 2012). \"Global Civil Unrest: Contagion, Self-Organization, and Prediction\". PLOS ONE. 7 (10) e48596. Bibcode:2012PLoSO...748596B. doi:10.1371/journal.pone.0048596. PMC 3485346. PMID 23119067.\n- Harold, Christine (1 September 2004). \"Pranking rhetoric: \"culture jamming\" as media activism\". Critical Studies in Media Communication. 21 (3): 189–211. doi:10.1080/0739318042000212693. ISSN 1529-5036.\n- \"6 Corporations Control 90% Of The Media in America\". Morris Creative Group. 15 June 2012. Archived from the original on 6 December 2019. Retrieved 21 November 2019.\n- Powers, Shawn; el-Nawawy, Mohammed (December 2009). \"Al-Jazeera English and global news networks: clash of civilizations or cross-cultural dialogue?\". Media, War & Conflict. 2 (3): 263–284. doi:10.1177/1750635209345185. S2CID 144850273.\n- Dines, Gail (2003). Gender, Race, and Class in Media: A Text-Reader. SAGE. ISBN 978-0-7619-2261-2.\n- Balkaran, Stephen (October 1999). \"Mass Media and Racism\". The Yale Political Quarterly. Archived from the original on 24 November 2011. Retrieved 28 November 2011.\n- Puglisi, Riccardo; Snyder, James M. (2015). \"THE BALANCED US PRESS: The Balanced US Press\". Journal of the European Economic Association. 13 (2): 240–264. doi:10.1111/jeea.12101. Retrieved 21 July 2025.\n- Downing, John, ed. (2004). The Sage Handbook of Media Studies. Sage. p. 296. ISBN 978-0-7619-2169-1.\n- Turner, Graeme (November 2016). \"2015 Henry Mayer Lecture: critical media studies and the re-invention of the media\". Media International Australia. 161 (1): 101–108. doi:10.1177/1329878x16659549. S2CID 151648889.\n- Environmental Development Plan (EDP): Photovoltaics. Department of Energy. 1977. ProQuest 87571696.\n- Bennett, Lance (2011). \"The Political Economy of News\" (PDF). News: The Politics of Illusion (9 ed.). Pearson. p. 237. ISBN 978-0-205-08241-4. Archived (PDF) from the original on 3 August 2020. Retrieved 17 January 2019.\nWith the exception of the Super Bowl and national crises such as 9/11 or the invasion of Iraq, it makes little sense to talk about a mass media audience any longer, at least one defined by large numbers of people gathering around televisions and watching the same information fed from a few sources. In just one decade, between 1993 and 2004, the percentage of people who regularly watched network TV news dropped 34 percent.\n- Turner, Graeme (2015). Re-Inventing the Media. Routledge. ISBN 978-1-317-38147-1.\n- Saliu, Hasan (2023). Revisiting Hallin and Mancini's media model. Balkan Social Science Review. pp. 235–255.\n- David Bordwell, Kristin Thompson, and Jeff Smith, Film art: An introduction (McGraw-Hill, 1993.\n- Pavlik, John; McIntosh, Shawn (2017). Converging Media: A New Introduction to Mass Communication. New York: Oxford University Press. p. 75. ISBN 978-0-19-027151-0.\n- World Trends in Freedom of Expression and Media Development Global Report 201/2018. UNESCO. 2018. p. 202. ISBN 978-92-3-100242-7. Archived from the original on 13 December 2021. Retrieved 28 May 2018.\n- Campbell, Cecilia. 2017. \"World Press Trends 2017\". Frankfurt: WAN-IFRA.\n- Eco, Umberto (2014) [1967]. Travels in Hyperreality: Essays. Translated by Waever, William. San Diego: HMH. ISBN 978-0-547-54596-7.\n- Lorimer, Rowland & Scannell, Patty (1994). Mass communications: a comparative introduction. Manchester University Press. pp. 26–27. ISBN 978-0-7190-3946-1.\n- Riesman, David and Gitlin, Todd and Glazer, Nathan (1950) The Lonely Crowd, preview at google books\n- Vipond, Mary (2000). The mass media in Canada. James Lorimer & Company. p. 88. ISBN 978-1-55028-714-1.\n- This article incorporates text from a free content work. Licensed under CC BY SA 3.0 IGO (license statement/permission). Text taken from World Trends in Freedom of Expression and Media Development Global Report 2017/2018, 202, UNESCO.\n- Blanchard, Margaret A. (1998). History of the mass media in the United States: an encyclopedia. Fitzroy Dearborn. ISBN 978-1-57958-012-4.\n- Bösch, Frank. Mass Media and Historical Change: Germany in International Perspective, 1400 to the Present (Berghahn, 2015). 212 pp. online review\n- Cull, Nicholas John, David Culbert and David Welch, eds. Mass Persuasion: A Historical Encyclopedia, 1500 to the Present (2003) 479 pp; worldwide coverage\n- Dauber, Cori Elizabeth. \"The shots seen 'round the world: The impact of the images of Mogadishu on American military operations.\" Rhetoric & Public Affairs 4.4 (2001): 653–687\n- Folkerts, Jean and Dwight Teeter, eds. Voices of a Nation: A History of Mass Media in the United States (5th Edition, 2008)\n- Fourie, Pieter J. Media Studies: Media History, Media and Society (2008)\n- Graber, Doris A., and Johanna Dunaway. Mass media and American politics (CQ Press, 2017)\n- Martin, James B. (2002). Mass Media: a bibliography with indexes. Nova. ISBN 978-1-59033-262-7.\n- Paneth, Donald, ed. The Encyclopedia of American journalism (1983) online\n- Ross, Corey. Mass Communications, Society, and Politics from the Empire to the Third Reich (Oxford University press 2010) 448 pp, on Germany\n- Vaughn, Stephen L., ed. Encyclopedia of American Journalism (2007) online\n- Wilke, Jürgen (2011). Media Genres. Institute of European History.\n- Hoggart, Richard (1917). The Uses of Literacy. Penguin Books.",
    "online marketplace": "An online marketplace (or online e-commerce marketplace) is a type of e-commerce website where product or service information is provided by multiple third parties. Online marketplaces are the primary type of multichannel ecommerce and can be a way to streamline the production process.\nIn an online marketplace, consumer transactions are processed by the marketplace operator and then delivered and fulfilled by the participating retailers or wholesalers. These types of websites allow users to register and sell single items to many items for a \"post-selling\" fee.\nBecause marketplaces aggregate products from a wide array of providers, the selection is wider, and availability is higher than in vendor-specific online retail stores. Some online marketplaces have a wide variety of general interest products that cater to almost all the needs of the consumers, others are consumer specific and cater to a particular segment. Online marketplaces became abundant in 2014.\nBusiness-to-business (B2B) online marketplaces are platforms that allow companies to buy and sell products or services to other businesses. These marketplaces typically focus on a specific product or service category and are used by businesses to find suppliers, negotiate prices, and manage logistics.\nSome examples of B2B online marketplaces include VerticalNet, Commerce One, and Covisint, which were some of the earliest B2B marketplaces to emerge in the early days of e-commerce. More contemporary B2B marketplaces include EC21, Elance, and eBay Business, which focus on specific product or service categories and facilitate complex transactions such as requests for quotations (RFQs), requests for information (RFIs), and requests for proposals (RFPs).[1]\nOnline marketplaces are information technology companies that act as intermediaries by connecting buyers and sellers. Examples of prevalent online marketplaces for retailing consumer goods and services are Amazon, Taobao and eBay. On the website of the online marketplace sellers can publish their product offering with a price and information about the product's features and qualities. Marketplace sellers often utilize a marketplace integrator or channel integration software[2] to efficiently list and sell products across multiple online marketplaces. Potential customers can search and browse goods, compare price and quality, and then purchase the goods directly from the seller. The inventory is held by the sellers, not the company running the online marketplace. Online marketplaces are characterized by a low setup cost for sellers, because they do not have to run a retail store.[3] While in the past Amazon Marketplace has served as a role model for online marketplaces, the expansion of the Alibaba Group into related business such as logistics, e-commerce payment systems and mobile commerce is now trailed by other marketplace operators such as Flipkart.[4]\nFor consumers, online marketplaces reduce the search cost, but insufficient information on the quality of goods and an overloaded goods offering can make it more difficult for consumers to make purchasing decisions. Consumers' ability to make a purchasing decision is also hampered by the fact that an online marketplace only allows them to examine the quality of a product based on its description, a picture and customer reviews.[5] Another characteristic of online marketplaces is that the same product can be offered by several merchants. In this case, consumers can often make the selection of a merchant with the support of reviews of that merchant, for example. Despite many conceivable factors influencing merchant selection, such as convenience, seller ratings, delivery options and a wider selection of goods,[6][7] customers choose primarily on the basis of the lowest price for a particular product.[8]\nPeer-to-peer (P2P) online marketplaces enable direct transactions between individuals, often facilitated by an intermediary platform that provides services such as payment processing, dispute resolution, and user verification.[9] Unlike traditional e-commerce platforms that primarily follow a business-to-consumer (B2C) model, P2P marketplaces allow users to act as both buyers and sellers, fostering decentralized commerce [10]\nThere are marketplaces for the online outsourcing of professional services like IT services,[11] search engine optimization, marketing, and skilled crafts & trades work.[12] Microlabor online marketplaces such as Upwork and Amazon Mechanical Turk allow freelancers to perform tasks which only require a computer and internet access.[13] According to Amazon, its Mechanical Turk marketplace focuses on \"human intelligence tasks\" that are difficult to automate computationally. This includes content labelling and content moderation.[14]\nMicrolabor online marketplaces allow workers globally, without a formal employment status, to perform digital piece work, such as classifying an image according to content moderation guidelines. Gig workers are paid for each task performed, for example US$0.01 for each moderated image. Gig workers accumulate payment on the microlabor platform.[15]\nIn 2004 Yochai Benkler noted that online platforms, alongside free software and wireless networks, allowed households to share idle or underused resources.[16] As the sharing economy inspires itself largely from the open source philosophy,[17] open source projects dedicated to launching a peer to peer marketplace include Cocorico[18] and Sharetribe.[19] In 2010 CouchSurfing was constituted as for-profit corporation and by 2014 online marketplaces that consider themselves part of the sharing economy, such as Uber and Airbnb, organized in the trade association Peers.org.[20]\nA 2014 study of oDesk, an early global online marketplace for freelance contractors, found that the service outsourcing of microwork increased opportunities for freelancers regardless of their geographic location, but the financial gains for most contractors were limited as experience and skills did not translate into higher payment.[21]\nA general criticism is that the laws and regulations surrounding online marketplaces are quite underdeveloped. As of consequence, there is a discrepancy between the responsibility, accountability and liability of the marketplace and third parties. In recent years online marketplaces and platforms have faced much criticism for their lack of consumer protections.[22]\nIn 1997 Yannis Bakos studied online marketplaces and came to regard them as a special type of electronic marketplaces. He argued that they reduce economic inefficiencies, by lowering the cost of acquiring information about the sellers' products.[23]\nThe operators of online marketplaces are able to adapt their business model because of the data they hold on the platform users. Online marketplace operators have a unique ability to obtain and use in their economic decision making personal data and transaction data, but also social data and location data. Therefore academics have described online marketplaces as new economic actor, or even as a new type of market economy. In 2010 Christian Fuchs argued that online marketplaces operated informational capitalism. The inherent feedback loop allows the operators of online marketplaces to grow their effectiveness as economic intermediaries. In 2016 Nick Srnicek argued that online marketplaces give rise to platform capitalism.[24]\nIn 2016 and 2018 respectively, Frank Pasquale and Shoshana Zuboff cautioned, that the data collection of online marketplace operators result in surveillance capitalism.[25]\n- Dave Chaffey; Fiona Ellis-Chadwick; Richard Mayer; Kevin Johnston (2009). Internet Marketing: Strategy, Implementation and Practice. Pearson Education. p. 111. ISBN 978-0-273-71740-9.\n- \"Channel Integration Software Reviews 2023 Gartner Peer Insights\". Gartner. Retrieved 2023-02-15.[permanent dead link]\n- Matthew L. Nelson; Michael J. Shaw; Troy J. Strader, eds. (2009). Value Creation in E-Business Management: 15th Americas Conference on Information Systems, AMCIS 2009, SIGeBIZ track, San Francisco, CA, USA, August 6-9, 2009, Selected Papers. Springer Science & Business Media. pp. 156–157. ISBN 978-3-642-03132-8.\n- Oswald Mascarenhas (2018). Corporate Ethics for Turbulent Markets: The Market Context of Executive Decisions. Emerald Group Publishing. p. 123. ISBN 978-1-78756-189-2.\n- Matthew L. Nelson; Michael J. Shaw; Troy J. Strader, eds. (2009). Value Creation in E-Business Management: 15th Americas Conference on Information Systems, AMCIS 2009, SIGeBIZ track, San Francisco, CA, USA, August 6-9, 2009, Selected Papers. Springer Science & Business Media. pp. 156–157. ISBN 978-3-642-03132-8.\n- Adler, Manuel; Wohllebe, Atilla (December 2020). \"Consumers Choosing Retailers On Online Marketplaces: How Can Retailers Differentiate Apart From The Price? An Exploratory Investigation\". International Journal of Applied Research in Business and Management. 1 (1): 27–36. ISSN 2700-8983. Archived from the original on 2023-01-26. Retrieved 2023-02-15.\n- Conley, Paul (2022-01-13). \"Frequent online shoppers make half their web purchases on marketplaces\". Digital Commerce 360. Archived from the original on 2023-03-08. Retrieved 2023-02-15.\n- Manuel Rolf Adler; Atilla Wohllebe (2020). \"Consumers Choosing Retailers On Online Marketplaces: How Can Retailers Differentiate Apart From The Price? An Exploratory Investigation\". International Journal of Applied Research in Business and Management. 1 (1): 27–36. doi:10.51137/ijarbm.2020.1.1.3.\n- Einav, L., Farronato, C., & Levin, J. (2016). \"Peer-to-Peer Markets.\" Annual Review of Economics, 8(1), 615-635. [DOI: 10.1146/annurev-economics-080315-015334]\n- Sundararajan, A. (2016). The Sharing Economy: The End of Employment and the Rise of Crowd-Based Capitalism. MIT Press.\n- \"Leveraging offshore IT outsourcing by SMEs through online marketplaces Archived 2023-06-29 at the Wayback Machine\". U.L. Radkevitch, E. Van Heck, O. Koppius, University Rotterdam, Journal of Information Technology Case and Application, Vol. 8, No. 3, Date posted: August 23, 2006; Last revised: November 24, 2013\n- Head and Hands in the Cloud: Cooperative Models for Global Trade to be Murray, Kevin, RMIT University, Melbourne, Australia, 2013\n- Sarah T. Roberts (2019). Behind the Screen: Content Moderation in the Shadows of Social Media. Yale University Press. p. 46. ISBN 978-0-300-23588-3.\n- Sarah T. Roberts (2019). Behind the Screen: Content Moderation in the Shadows of Social Media. Yale University Press. p. 47. ISBN 978-0-300-23588-3.\n- Sarah T. Roberts (2019). Behind the Screen: Content Moderation in the Shadows of Social Media. Yale University Press. p. 47. ISBN 978-0-300-23588-3.\n- Arun Sundararajan (2016). The Sharing Economy: The End of Employment and the Rise of Crowd-Based Capitalism. MIT Press. p. 31. ISBN 978-0-262-03457-9.\n- \"The Sharing Economy: Why People Participate in Collaborative Consumption\". ResearchGate. Retrieved 2019-05-31.\n- ☑ Cocorico is an open source marketplace solution for peer-to-peer marketplaces.: Cocolabs-SAS/cocorico, Cocolabs SAS, 2019-05-31, archived from the original on 2021-11-25, retrieved 2019-05-31\n- Sharetribe Go is an open source marketplace platform, also available with SaaS model, Sharetribe, 2019-05-31, archived from the original on 2021-11-25, retrieved 2019-05-31\n- Cristiano Codagnone; Athina Karatzogianni; Jacob Matthews (2018). Platform Economics: Rhetoric and Reality in the \"Sharing Economy\". Emerald Group Publishing. pp. 51–52. ISBN 978-1-78743-810-1.\n- Beerepoot, Niels; Lambrefts, Bart (31 March 2014). \"Competition in online job marketplaces: towards a global labour market for outsourcing services?\". Global Networks. 15 (2): 236–255. doi:10.1111/glob.12051.\n- Nicholls, Rob. \"Who bears the cost when your Uber or Airbnb turns bad?\". Archived from the original on 2021-11-25. Retrieved 2016-08-02.\n- Bakos, Yannis J. (12 December 1997). \"Reducing Buyer Search Costs: Implications for Electronic Marketplaces\" (PDF). NYU.edu. Archived (PDF) from the original on 27 November 2022. Retrieved 27 February 2023.\n- Nick, Srnicek (2016). Platform Capitalism.\n- Sarah Barns (2019). Platform Urbanism: Negotiating Platform Ecosystems in Connected Cities. Springer Nature. p. 115. ISBN 978-981-329-725-8.",
    "petroleum industry": "The petroleum industry, also known as the oil industry, includes the global processes of exploration, extraction, refining, transportation (often by oil tankers and pipelines), and marketing of petroleum products. The largest volume products of the industry are fuel oil and gasoline (petrol). Petroleum is also the raw material for many chemical products, including pharmaceuticals, solvents, fertilizers, pesticides, synthetic fragrances, and plastics. The industry is usually divided into three major components: upstream, midstream, and downstream. Upstream regards exploration and extraction of crude oil, midstream encompasses transportation and storage of it, and downstream concerns refining crude oil into various end products.\nPetroleum is vital to many industries, and is necessary for the maintenance of industrial civilization in its current configuration, making it a critical concern for many nations. Oil accounts for a large percentage of the world's energy consumption, ranging from a low of 32% for Europe and Asia, to a high of 53% for the Middle East.\nOther geographic regions' consumption patterns are as follows: South and Central America (44%), Africa (41%), and North America (40%). The world consumes 36 billion barrels (5.8 km3) of oil per year,[1] with developed nations being the largest consumers. The United States consumed 18% of the oil produced in 2015.[2] The production, distribution, refining, and retailing of petroleum taken as a whole represents the world's largest industry in terms of dollar value.\nPetroleum is a naturally occurring liquid found in rock formations. It consists of a complex mixture of hydrocarbons of various molecular weights, plus other organic compounds. It is generally accepted that oil is formed mostly from the carbon rich remains of ancient plankton after exposure to heat and pressure in Earth's crust over hundreds of millions of years. Over time, the decayed residue was covered by layers of mud and silt, sinking further down into Earth's crust and preserved there between hot and pressured layers, gradually transforming into oil reservoirs.[3]\nPetroleum in an unrefined state has been utilized by humans for over 5000 years. Oil in general has been used since early human history to keep fires ablaze and in warfare.\nIts importance to the world economy however, evolved slowly, with whale oil being used for lighting in the 19th century and wood and coal used for heating and cooking well into the 20th century. Even though the Industrial Revolution generated an increasing need for energy, this was initially met mainly by coal, and from other sources including whale oil. However, when it was discovered that kerosene could be extracted from crude oil and used as a lighting and heating fuel, the demand for petroleum increased greatly, and by the early twentieth century had become the most valuable commodity traded on world markets.[4]\nImperial Russia produced 3,500 tons of oil in 1825 and doubled its output by mid-century.[8] After oil drilling began in the region of present-day Azerbaijan in 1846, in Baku, the Russian Empire built two large pipelines: the 833 km long pipeline to transport oil from the Caspian to the Black Sea port of Batum (Baku-Batum pipeline), completed in 1906, and the 162 km long pipeline to carry oil from Chechnya to the Caspian. The first drilled oil wells in Baku were built in 1871–1872 by Ivan Mirzoev, an Armenian businessman who is referred to as one of the 'founding fathers' of Baku's oil industry.[9][10]\nAt the turn of the 20th century, Imperial Russia's output of oil, almost entirely from the Apsheron Peninsula, accounted for half of the world's production and dominated international markets.[11] Nearly 200 small refineries operated in the suburbs of Baku by 1884.[12] As a side effect of these early developments, the Apsheron Peninsula emerged as the world's \"oldest legacy of oil pollution and environmental negligence\".[13] In 1846 Baku (Bibi-Heybat settlement) featured the first ever well drilled with percussion tools to a depth of 21 meters for oil exploration. In 1878 Ludvig Nobel and his Branobel company \"revolutionized oil transport\" by commissioning the first oil tanker and launching it on the Caspian Sea.[11]\nSamuel Kier established America's first oil refinery in Pittsburgh on Seventh avenue near Grant Street in 1853. Ignacy Łukasiewicz built one of the first modern oil-refineries near Jasło (then in the Austrian dependent Kingdom of Galicia and Lodomeria in Central European Galicia), present-day Poland, in 1854–56.[14] Galician refineries were initially small, as demand for refined fuel was limited. The refined products were used in artificial asphalt, machine oil and lubricants, in addition to Łukasiewicz's kerosene lamp. As kerosene lamps gained popularity, the refining industry grew in the area.\nThe first commercial oil-well in Canada became operational in 1858 at Oil Springs, Ontario (then Canada West).[15] Businessman James Miller Williams dug several wells between 1855 and 1858 before discovering a rich reserve of oil four metres below ground.[16][17] Williams extracted 1.5 million litres of crude oil by 1860, refining much of it into kerosene-lamp oil.[15] Some historians challenge Canada's claim to North America's first oil field, arguing that Pennsylvania's famous Drake Well was the continent's first. But there is evidence to support Williams, not least of which is that the Drake well did not come into production until August 28, 1859. The controversial point might be that Williams found oil above bedrock while Edwin Drake's well located oil within a bedrock reservoir. The discovery at Oil Springs touched off an oil boom which brought hundreds of speculators and workers to the area. Canada's first gusher (flowing well) erupted on January 16, 1862, when local oil-man John Shaw struck oil at 158 feet (48 m).[18] For a week the oil gushed unchecked at levels reported as high as 3,000 barrels per day.\nThe first modern oil-drilling in the United States began in West Virginia and Pennsylvania in the 1850s. Edwin Drake's 1859 well near Titusville, Pennsylvania, typically considered[by whom?] the first true[citation needed] modern[citation needed] oil well, touched off a major boom.[19][20][21][need quotation to verify] In the first quarter of the 20th century, the United States overtook Russia as the world's largest oil producer. By the 1920s, oil fields had been established in many countries including Canada, Poland, Sweden, Ukraine, the United States, Peru and Venezuela.[21]\nThe first successful oil tanker, the Zoroaster, was built in 1878 in Sweden, designed by Ludvig Nobel. It operated from Baku to Astrakhan.[22] A number of new tanker designs developed in the 1880s.[23]\nIn the early 1930s the Texas Company developed the first mobile steel barges for drilling in the brackish coastal areas of the Gulf of Mexico. In 1937 Pure Oil Company (now part of Chevron Corporation) and its partner Superior Oil Company (now part of ExxonMobil Corporation) used a fixed platform to develop a field in 14 feet (4.3 m) of water, one mile (1.6 km) offshore of Calcasieu Parish, Louisiana. In early 1947 Superior Oil erected a drilling/production oil-platform in 20 ft (6.1 m) of water some 18 miles[vague] off Vermilion Parish, Louisiana. Kerr-McGee Oil Industries, as operator for partners Phillips Petroleum (ConocoPhillips) and Stanolind Oil & Gas (BP), completed its historic Ship Shoal Block 32 well in November 1947, months before Superior actually drilled a discovery from their Vermilion platform farther offshore. In any case, that made Kerr-McGee's Gulf of Mexico well, Kermac No. 16, the first oil discovery drilled out of sight of land.[24][page needed][25] Forty-four Gulf of Mexico exploratory wells discovered 11 oil and natural gas fields by the end of 1949.[26]\nDuring World War II (1939–1945) control of oil supply from Romania, Baku, the Middle East and the Dutch East Indies played a huge role in the events of the war and the ultimate victory of the Allies. The Anglo-Soviet invasion of Iran (1941) secured Allied control of oil-production in the Middle East. The expansion of Imperial Japan to the south aimed largely at accessing the oil-fields of the Dutch East Indies. Germany, cut off from sea-borne oil supplies by Allied blockade, failed in Operation Edelweiss to secure the Caucasus oil-fields for the Axis military in 1942, while Romania deprived the Wehrmacht of access to Ploesti oilfields – the largest in Europe – from August 1944. Cutting off the East Indies oil-supply (especially via submarine campaigns) considerably weakened Japan in the latter part of the war. After World War II ended in 1945, the countries of the Middle East took the lead in oil production from the United States. Important developments since World War II include deep-water drilling, the introduction of the drillship, and the growth of a global shipping network for petroleum – relying upon oil tankers and pipelines. In 1949 the first offshore oil-drilling at Oil Rocks (Neft Dashlari) in the Caspian Sea off Azerbaijan eventually resulted in a city built on pylons. In the 1960s and 1970s, multi-governmental organizations of oil–producing nations – OPEC and OAPEC – played a major role in setting petroleum prices and policy. Oil spills and their cleanup have become an issue of increasing political, environmental, and economic importance. New fields of hydrocarbon production developed in places such as Siberia, Sakhalin, Venezuela and North and West Africa.[citation needed]\nWith the advent of hydraulic fracturing and other horizontal drilling techniques, shale play has seen an enormous uptick in production. Areas of shale such as the Permian Basin and Eagle-Ford have become huge hotbeds of production for the largest oil corporations in the United States.[27]\nThe American Petroleum Institute divides the petroleum industry into five sectors:[28]\n- upstream (exploration, development and production of crude oil or natural gas)\n- downstream (oil tankers, refiners, retailers and consumers)\n- pipeline\n- marine\n- service and supply\nOil companies used to be classified by sales as \"supermajors\" (BP, Chevron, ExxonMobil, ConocoPhillips, Shell, Eni and TotalEnergies), \"majors\", and \"independents\" or \"jobbers\". In recent years however, National Oil Companies (NOC, as opposed to IOC, International Oil Companies) have come to control the rights over the largest oil reserves; by this measure the top ten companies all are NOC. The following table shows the ten largest national oil companies ranked by reserves[29][30] and by production in 2012.[31]\n| Rank | Company (Reserves) | Worldwide Liquids Reserves (109 bbl) | Worldwide Natural Gas Reserves (1012 ft3) | Total Reserves in Oil Equivalent Barrels (109 bbl) | Company (Production) | Output (Millions bbl/day)[1] | |\n|---|---|---|---|---|---|---|---|\n| 1 | Saudi Aramco | 260 | 254 | 303 | Saudi Aramco | 12.5 | |\n| 2 | NIOC | 138 | 948 | 300 | NIOC | 6.4 | |\n| 3 | QatarEnergy | 15 | 905 | 170 | ExxonMobil | 5.3 | |\n| 4 | INOC | 116 | 120 | 134 | PetroChina | 4.4 | |\n| 5 | PDVSA | 99 | 171 | 129 | BP | 4.1 | |\n| 6 | ADNOC | 92 | 199 | 126 | Royal Dutch Shell | 3.9 | |\n| 7 | Pemex | 102 | 56 | 111 | Pemex | 3.6 | |\n| 8 | NNPC | 36 | 184 | 68 | Chevron | 3.5 | |\n| 9 | NOC | 41 | 50 | 50 | Kuwait Petroleum Corporation | 3.2 | |\n| 10 | Sonatrach | 12 | 159 | 39 | ADNOC | 2.9 | |\n| ^1 : Total energy output, including natural gas (converted to bbl of oil) for companies producing both. |\nMost upstream work in the oil field or on an oil well is contracted out to drilling contractors and oil field service companies.[citation needed]\nAside from the NOCs which dominate the Upstream sector, there are many international companies that have a market share. For example:[32]\n- BG Group\n- BHP\n- ConocoPhillips\n- Chevron\n- Eni\n- ExxonMobil\n- First Texas Energy Corporation\n- Hess\n- Marathon Oil\n- OMV\n- TotalEnergies\n- Tullow Oil\n- Rosneft\nMidstream operations are sometimes classified within the downstream sector, but these operations compose a separate and discrete sector of the petroleum industry. Midstream operations and processes include the following:\n- Gathering: The gathering process employs narrow, low-pressure pipelines to connect oil- and gas-producing wells to larger, long-haul pipelines or processing facilities.[33]\n- Processing/refining: Processing and refining operations turn crude oil and gas into marketable products. In the case of crude oil, these products include heating oil, gasoline for use in vehicles, jet fuel, and diesel oil.[34] Oil refining processes include distillation, vacuum distillation, catalytic reforming, catalytic cracking, alkylation, isomerization and hydrotreating.[34] Natural gas processing includes compression; glycol dehydration; amine treating; separating the product into pipeline-quality natural gas and a stream of mixed natural gas liquids; and fractionation, which separates the stream of mixed natural gas liquids into its components. The fractionation process yields ethane, propane, butane, isobutane, and natural gasoline.\n- Transportation: Oil and gas are transported to processing facilities, and from there to end users, by pipeline, tanker/barge, truck, and rail. Pipelines are the most economical transportation method and are most suited to movement across longer distances, for example, across continents.[35] Tankers and barges are also employed for long-distance, often international transport. Rail and truck can also be used for longer distances but are most cost-effective for shorter routes.\n- Storage: Midstream service providers provide storage facilities at terminals throughout the oil and gas distribution systems. These facilities are most often located near refining and processing facilities and are connected to pipeline systems to facilitate shipment when product demand must be met. While petroleum products are held in storage tanks, natural gas tends to be stored in underground facilities, such as salt dome caverns and depleted reservoirs.\n- Technological applications: Midstream service providers apply technological solutions to improve efficiency during midstream processes. Technology can be used during compression of fuels to ease flow through pipelines; to better detect leaks in pipelines; and to automate communications for better pipeline and equipment monitoring.\nWhile some upstream companies carry out certain midstream operations, the midstream sector is dominated by a number of companies that specialize in these services. Midstream companies include:\n- Aux Sable\n- Bridger Group\n- DCP Midstream Partners\n- Enbridge Energy Partners\n- Enterprise Products Partners\n- Genesis Energy\n- Gibson Energy\n- Inergy Midstream\n- Kinder Morgan Energy Partners\n- Oneok Partners\n- Plains All American\n- Sunoco Logistics\n- Targa Midstream Services\n- Targray Natural Gas Liquids\n- TransCanada\n- Williams Companies\n- Petrolink\nThe oil and gas industry spends only 0.4% of its net sales on research & development (R&D) which is in comparison with a range of other industries the lowest share.[36] Governments such as the United States government provide a heavy public subsidy to petroleum companies, with major tax breaks at various stages of oil exploration and extraction, including the costs of oil field leases and drilling equipment.[37] In recent years, enhanced oil recovery techniques – most notably multi-stage drilling and hydraulic fracturing (\"fracking\") – have moved to the forefront of the industry as this new technology plays a crucial and controversial role in new methods of oil extraction.[38]\nSome petroleum industry operations have been responsible for water pollution through by-products of refining and oil spills. Though hydraulic fracturing has significantly increased natural gas extraction, there is some belief and evidence to support that consumable water has seen increased in methane contamination due to this gas extraction.[39] Leaks from underground tanks and abandoned refineries may also contaminate groundwater in surrounding areas. Hydrocarbons that comprise refined petroleum are resistant to biodegradation and have been found to remain present in contaminated soils for years.[40] To hasten this process, bioremediation of petroleum hydrocarbon pollutants is often employed by means of aerobic degradation.[41] More recently, other bioremediative methods have been explored such as phytoremediation and thermal remediation.[42][43]\nThe industry is the largest industrial source of emissions of volatile organic compounds (VOCs), a group of chemicals that contribute to the formation of ground-level ozone (smog).[44] The combustion of fossil fuels produces greenhouse gases and other air pollutants as by-products. Pollutants include nitrogen oxides, sulphur dioxide, volatile organic compounds and heavy metals.\nResearchers have discovered that the petrochemical industry can produce ground-level ozone pollution at higher amounts in winter than in summer.[45]\nGreenhouse gases caused by burning fossil fuels drive climate change. In 1959, at a symposium organised by the American Petroleum Institute for the centennial of the American oil industry, the physicist Edward Teller warned of the danger of global climate change.[46] Edward Teller explained that carbon dioxide \"in the atmosphere causes a greenhouse effect\" and that burning more fossil fuels could \"melt the icecaps and submerge New York\".[46]\nThe Intergovernmental Panel on Climate Change, founded by the United Nations in 1988, concludes that human-sourced greenhouse gases are responsible for most of the observed temperature increase since the middle of the twentieth century.\nAs a result of climate change concerns, many people have begun using other methods of energy such as solar and wind. This recent shift has some petroleum enthusiasts skeptical about the future of the industry.[47]\n- Industry pioneers\n- Faustino Piaggio, an early oil industry pioneer\n- Oil production\n- Corrosion inhibitors for petroleum industry\n- Peak oil\n- Oil terminal\n- Oil supplies\n- Integrated operations\n- Instrumentation in petrochemical industries\n- Standardization in oil industry\n- ISO/TC 67\n- List of crude oil products\n- Financial and political\n- List of oil exploration and production companies\n- List of largest oil and gas companies by revenue\n- Chronology of world oil market events (1970–2005)\n- Energy crisis: 1973 oil crisis, 1979 energy crisis\n- Energy development\n- Petroleum politics\n- World oil market chronology from 2003\n- Oil-storage trade\n- Oil and gas law in the United States\n- Fossil fuels lobby\n- Environmental issues\n- Oil geology\n- Oil-producing areas\n- History of the petroleum industry in Canada\n- History of the petroleum industry in the United States\n- List of oil fields\n- Oil megaprojects\n- List of countries by oil production\n- Oil industry in Azerbaijan\n- Industry Research Projects\n- Other articles\n- Sönnichsen, N. \"Daily global crude oil demand 2006–2020\". Statista. Retrieved 9 October 2020.\n- \"Country Comparison :: Refined Petroleum Products – Consumption\". Central Intelligence Agency – World Factbook. Archived from the original on 16 June 2013. Retrieved 9 October 2020.\n- Speight, James (2014). The Chemistry and Technology of Petroleum. Chemical Industries (5th ed.). CRC Press. doi:10.1201/b16559. ISBN 978-1439873892.\n- Halliday, Fred. The Middle East in International Relations: Cambridge University Press: US, p. 270 [ISBN missing]\n- \"World Energy Investment 2023\" (PDF). IEA.org. International Energy Agency. May 2023. p. 61. Archived (PDF) from the original on 7 August 2023.\n- Bousso, Ron (8 February 2023). \"Big Oil doubles profits in blockbuster 2022\". Reuters. Archived from the original on 31 March 2023.\"Why are BP, Shell, and other oil giants making so much money right now?\". BBC. Archived from the original on 22 April 2023.\n- \"Crude oil including lease condensate production (Mb/d)\". U.S. Energy Information Administration. Retrieved 14 April 2020.\n- N.Y. Krylov, A.A. Bokserman, E.R.Stavrovsky. The Oil Industry of the Former Soviet Union. CRC Press, 1998. P. 187.\n- Altstadt, Audrey L. (1980). Economic Development and Political Reform in Baku: The Response of the Azerbaidzhani Bourgeoisie. Wilson Center, Kennan Institute for Advanced Russian Studies.\n- Daintith, Terence (2010). Finders Keepers?: How the Law of Capture Shaped the World Oil Industry. Earthscan. ISBN 978-1-936331-76-5.\n- Shirin Akiner, Anne Aldis. The Caspian: Politics, Energy and Security. Routledge, 2004. p. 5.\n- United States Congress, Joint Economic Committee. The Former Soviet Union in Transition. M.E. Sharpe, 1993. p. 463.\n- Quoted from: Tatyana Saiko. Environmental Crises. Pearson Education, 2000. p. 223.\n- Frank, Alison Fleig (2005). Oil Empire: Visions of Prosperity in Austrian Galicia (Harvard Historical Studies). Harvard University Press. ISBN 978-0-674-01887-7.\n- \"Black Gold: Canada's Oil Heritage\". The Corporation of the County of Lambton. Archived from the original on 29 July 2013. Retrieved 30 July 2013.\nThe North American oil industry began in Oil Springs in 1858 in less spectacular fashion. James Miller Williams, a coachmaker from Hamilton, dug into the tar-like gum beds of Enniskillen Township to find their source. At a depth of fourteen feet, he struck oil. Williams immediately built a small refinery and began to produce illuminating oil for lamps – kerosene. It was Williams who was able to take full advantage of the ancient resource. Not only was he astute enough to look below the surface of the gum beds to find oil and to realize its commercial potential, but the timing of his discovery was perfect.\n- Turnbull Elford, Jean. Canada West's Last Frontier. Lambton County Historical Society, 1982, p. 110\n- Sarnia Observer and Lambton Advertiser, \"Important Discovery in the Township of Enniskillen Archived 2015-04-03 at the Wayback Machine,\" 5 August 1858, p. 2.\n- \"Extraordinary Flowing Oil Well\". Hamilton Times. 20 January 1862. p. 2. Archived from the original on 3 April 2015. Retrieved 30 July 2013.\nOur correspondent writes us from the Oil Springs, under date of the 16th inst., [an] interesting account of a flowing Oil well which has just been tapped. He says: I have just time to mention that to-day at half past eleven o'clock, a.m., Mr. John Shaw, from Kingston, C. W., tapped a vein of oil in his well, at a depth of one hundred and fifty-eight feet in the rock, which filled the surface well, (forty-five feet to the rock) and the conductors [sic] in the course of fifteen minutes, and immediately commenced flowing. It will hardly be credited, but nevertheless such is the case, that the present enormous flow of oil cannot be estimated at less than two thousand barrels per day, (twenty-four hours), of pure oil, and the quantity increasing every hour. I saw three men in the course of one hour, fill fifty barrels from the flow of oil, which is running away in every direction; the flat presenting the appearance of a sea of oil. The excitement is intense, and hundreds are rushing from every quarter to see this extraordinary well. Experience oil well diggers from the other side, affirm that this week equals their best flowing wells in Pennsylvania, and they pronounced the oil as being of a superior quality. This flowing well is situation on lot No. 10, Range B, Messrs. Sanborn & Co.'s Oil Territory.\n- John Steele Gordon Archived 2008-04-20 at the Wayback Machine \"10 Moments That Made American Business,\" American Heritage, February/March 2007, \"Drake, who seems to have awarded himself the title of colonel by which he is often known, had a great deal of trouble persuading a salt-drilling crew to try to drill for oil, but on August 27, 1859, he struck it at 69 feet.\"\n-\nVassiliou, Marius S. (2 March 2009). \"Titusville\". Historical Dictionary of the Petroleum Industry. Historical Dictionaries of Professions and Industries, No. 3. Lanham, Maryland: Scarecrow Press (published 2009). p. 508. ISBN 978-0810862883. Retrieved 22 February 2021.\nIn August 1859, an important early well was drilled by Edwin Drake outside Titusville, initiating the Pennsylvania oil boom.\n- Vassiliou, Marius (2018). Historical Dictionary of the Petroleum Industry, 2nd Ed. Lanham, MD: Rowman and Littlefield, 621 pp.\n- Tolf, Robert W. (1976). \"4: The World's First Oil Tankers\". The Russian Rockefellers: The Saga of the Nobel Family and the Russian Oil Industry. Hoover Press. ISBN 0-8179-6581-5. p. 55.\n- Wells, Bruce (9 December 2021). \"Horse-Drawn Oil Wagon seeks Museum\". American Oil & Gas Historical Society. Retrieved 21 September 2024.\n- Ref accessed 02-12-89 by technical aspects and coast mapping. Kerr-McGee\n- \"Project Redsand\". www.project-redsand.com.\n- Wells, Bruce. \"Offshore Petroleum History\". American Oil & Gas Historical Society. Retrieved 11 November 2014.\n- Stanley, Rachel (24 July 2018). Comparison of Two Active Hydrocarbon Production Regions in Texas to Determine Boomtown Growth and Development: A Geospatial Analysis of Active Well Locations and Demographic Changes, 2000–2017 (PDF) (Thesis). Texas State University. Archived from the original (PDF) on 7 July 2022.\n- \"Industry Sectors\", American Petroleum Institute, archived from the original on 25 January 2012, retrieved 12 May 2008\n- \"Ranked in order of 2007 worldwide oil equivalent reserves as reported in \"OGJ 200/100\". Oil & Gas Journal. 15 September 2008.\n- Pirog, Robert (21 August 2007). The Role of National Oil Companies in the International Oil Market (PDF) (Report). Congressional Research Service. Retrieved 17 September 2009.\n- Helman, Christopher (16 July 2012). \"The World's 25 Biggest Oil Companies\". Forbes.\n- \"Membership\". International Association of oil and Gas Producers. Archived from the original on 22 November 2013. Retrieved 4 November 2013.\n- \"The Transportation of Natural Gas\". NaturalGas.org. Archived from the original on 1 January 2011. Retrieved 14 December 2012.\n- \"Refining and Product Specifications Module Overview\". Petroleum Online. International Human Resources Development Corporation. Retrieved 14 December 2012.\n- Trench, Cheryl J. (December 2001). \"How Pipelines Make the Oil Market Work – Their Networks, Operation and Regulation\" (PDF). Allegro Energy Group. Archived from the original (PDF) on 28 December 2013.\n- \"The Pharmaceutical Industry in Figures Key Data 2021\" (PDF). European Federation of Pharmaceutical Industries and Associations. Retrieved 28 June 2022.\n- Kocieniewski, David (3 July 2010). \"As Oil Industry Fights a Tax, It Reaps Subsidies\". The New York Times. ISSN 0362-4331. Retrieved 4 August 2022.\n- Boudet, Hilary; Clarke, Christopher; Bugden, Dylan; Maibach, Edward; Roser-Renouf, Connie; Leiserowitz, Anthony (1 February 2014). \"Energy Policy. 65: 57–67. doi:10.1016/j.enpol.2013.10.017. ISSN 0301-4215.\n- Osborn, Stephen G.; Vengosh, Avner; Warner, Nathaniel R.; Jackson, Robert B. (17 May 2011). \"Methane contamination of drinking water accompanying gas-well drilling and hydraulic fracturing\". Proceedings of the National Academy of Sciences. 108 (20): 8172–8176. Bibcode:2011PNAS..108.8172O. doi:10.1073/pnas.1100682108. ISSN 0027-8424. PMC 3100993. PMID 21555547.\n- Diphare, Motshumi., Muzenda, Edison., Remediation of Contaminated Soils: A Review. Intl' Conf. on Chemical, Integrated Waste Management & Environmental Engineering (ICCIWEE'2014) April 15–16, 2014 Johannesburg.\n- M D Yuniati 2018 IOP Conf. Ser.: Earth Environ. Sci. 118 012063\n- Liu, Rui., Jadeja, N. Rajendrasinh., Zhou, Qixing., Liu, Zhe. Treatment and Remediation of Petroleum-Contaminated Soils Using Selective Ornament Plants. Environmental Engineering Sci. 2012 Jun; 29(6): 494–501.\n- Lim, Wei Mei., Lau, Von Ee., Poh, Eong Phaik. A comprehensive guide of remediation technologies for oil contaminated soil — Present works and future directions. Marine Pollution Bulletin. Volume 109, Issue 1, 15 August 2016, Pages 14-45.\n- \"Air Quality Planning and Standards\". Archived from the original on 19 February 2012.\n- Zamora, Robert; Yuan, Bin; Young, Cora J.; Wild, Robert J.; Warneke, Carsten; Washenfelder, Rebecca A.; Veres, Patrick R.; Tsai, Catalina; Trainer, Michael K.; Thompson, Chelsea R.; Sweeney, Colm; Stutz, Jochen; Soltis, Jeffrey; Senff, Christoph J.; Parrish, David D.; Murphy, Shane M.; Stuart A. McKeen; Li, Shao-Meng; Li, Rui; Lerner, Brian M.; Lefer, Barry L.; Langford, Andrew O.; Koss, Abigail; Helmig, Detlev; Graus, Martin; Gilman, Jessica B.; Flynn, James H.; Field, Robert A.; Dubé, William P.; deGouw, Joost A.; Banta, Robert M.; Ahmadov, Ravan; Roberts, James M.; Brown, Steven S.; Edwards, Peter M. (1 October 2014). \"High winter ozone pollution from carbonyl photolysis in an oil and gas basin\". Nature. 514 (7522): 351–354. Bibcode:2014Natur.514..351E. doi:10.1038/nature13767. PMID 25274311. S2CID 4466316.\n- Benjamin Franta, \"On its 100th birthday in 1959, Edward Teller warned the oil industry about global warming\", The Guardian, 1 January 2018 (page visited on 2 January 2018).\n- Martín, Mariano, ed. (2016). Alternative Energy Sources and Technologies. doi:10.1007/978-3-319-28752-2. ISBN 978-3-319-28750-8.\n- Mau, Mark; Edmundson, Henry (2015). Groundbreakers: the Story of Oilfield Technology and the People Who Made It Happen. UK: FastPrint. ISBN 978-178456-187-1.\n- Nevins, Alan. John D. Rockefeller The Heroic Age Of American Enterprise (1940); 710pp; favorable scholarly biography; online\n- Ordons Oil & Gas Information & News\n- Robert Sobel The Money Manias: The Eras of Great Speculation in America, 1770–1970 (1973) reprinted (2000).\n- Daniel Yergin, The Prize: The Epic Quest for Oil, Money, and Power, (Simon and Schuster 1991; paperback, 1993), ISBN 0-671-79932-0.\n- Matthew R. Simmons, Twilight in the Desert: The Coming Saudi Oil Shock and the World Economy, John Wiley & Sons, 2005, ISBN 0-471-73876-X.\n- Matthew Yeomans, Oil: Anatomy of an Industry (New Press, 2004), ISBN 1-56584-885-3.\n- Smith, GO (1920): Where the World Gets Its Oil: National Geographic, February 1920, pp 181–202\n- Marius Vassiliou, Historical Dictionary of the Petroleum Industry, 2nd Ed.. Lanham, MD: Rowman & Littlefield, 2018, 621 pp. ISBN 978-1-5381-1159-8.\n- Ronald W. Ferrier; J. H. Bamberg (1982). The History of the British Petroleum Company: Volume 1, The Developing Years, 1901–1932. Cambridge UP. pp. A–13. ISBN 978-0521246477.\n- Miryusif Mirbabayev, Concise History of Azerbaijani Oil. Baku, Azerneshr, (2008), 340pp.\n- Miryusif Mirbabayev, \"Brief history of the first drilled oil well; and the people involved\". Oil-Industry History (USA), 2017, v. 18, #1, pp. 25–34.\n- James Douet, The Heritage of the Oil Industry TICCIH Thematic Study , The International Committee for the Conservation of the Industrial Heritage, 2020, 79pp.",
    "pharmaceutical industry": "The pharmaceutical industry is a medical industry that discovers, develops, produces, and markets pharmaceutical goods such as medications. Medications are then administered to (or self-administered by) patients for curing or preventing disease or for alleviating symptoms of illness or injury.[1][2]\nGeneric drugs are typically not protected by patents, whereas branded drugs are covered by patents. The industry's various subdivisions include distinct areas, such as manufacturing biologics and total synthesis. The industry is subject to a variety of laws and regulations that govern the patenting, efficacy testing, safety evaluation, and marketing of these drugs.\nThe global pharmaceutical market was valued at approximately US$1.48 trillion in 2022, reflecting steady growth from 2020 and continuing expansion despite the impacts of the COVID-19 pandemic.[3] The sector showed a compound annual growth rate (CAGR) of 1.8% in 2021, including the effects of the COVID-19 pandemic.[4]\nIn historical terms, the pharmaceutical industry, as an intellectual concept, arose in the middle to late 1800s in nation-states with developed economies such as Germany, Switzerland, and the United States. Some businesses engaging in synthetic organic chemistry, such as several firms generating dyestuffs derived from coal tar on a large scale, were seeking out new applications for their artificial materials in terms of human health. This trend of increased capital investment occurred in tandem with the scholarly study of pathology as a field advancing significantly, and a variety of businesses set up cooperative relationships with academic laboratories evaluating human injury and disease. Examples of industrial companies with a pharmaceutical focus that have endured to this day after such distant beginnings include Bayer (based out of Germany) and Pfizer (based out of the U.S.).[5]\nThe pharmaceutical industry has faced extensive criticism for its marketing practices, including undue influence on physicians through pharmaceutical sales representatives, biased continuing medical education, and disease mongering to expand markets. Pharmaceutical lobbying has made it one of the most powerful influences on health policy, particularly in the United States. There are documented cases of pharmaceutical fraud, including off-label promotion and kickbacks, resulting in multi-billion dollar settlements. Drug pricing continues to be a major issue, with many unable to afford essential prescription drugs. Regulatory agencies like the FDA have been accused of being too lenient due to revolving doors with industry. During the COVID-19 pandemic, major pharmaceutical companies received public funding while retaining intellectual property rights, prompting calls for greater transparency and access.\nThe modern era of the pharmaceutical industry began with local apothecaries that expanded their traditional role of distributing botanical drugs such as morphine and quinine to wholesale manufacture in the mid-1800s. Intentional drug discovery from plants began with the extraction of morphine – an analgesic and sleep-inducing agent – from opium by the German apothecary assistant Friedrich Sertürner somewhere between 1803 and 1805. Sertürner later named this compound after the Greek god of dreams, Morpheus. Multinational corporations including Merck, Hoffman-La Roche, Burroughs-Wellcome (now part of GSK), Abbott Laboratories, Eli Lilly, and Upjohn (now part of Pfizer) began as local apothecary shops in the mid-1800s. By the late 1880s, German dye manufacturers had perfected the purification of individual organic compounds from tar and other mineral sources and had also established rudimentary methods in organic chemical synthesis.[5] The development of synthetic chemical methods allowed scientists to systematically vary the structure of chemical substances, and growth in the emerging science of pharmacology expanded their ability to evaluate the biological effects of these structural changes.[citation needed]\nBy the 1890s, the profound effect of adrenal extracts on many different tissue types had been discovered, setting off a search both for the mechanism of chemical signaling and efforts to exploit these observations for the development of new drugs. The blood pressure raising and vasoconstrictive effects of adrenal extracts were of particular interest to surgeons as hemostatic agents and as a treatment for shock, and several companies developed products based on adrenal extracts containing varying purities of the active substance. In 1897, John Abel at the Johns Hopkins University identified the active substance as epinephrine, which he isolated in an impure state as the sulfate salt. Industrial chemist Jōkichi Takamine later developed a method for obtaining epinephrine in a pure state and licensed the technology to Parke-Davis. Parke-Davis marketed epinephrine under the trade name Adrenalin. Injected epinephrine proved to be especially efficacious for the acute treatment of asthma attacks, and an inhaled version is sold over the counter in the United States. (Primatene Mist).[6][7] By 1929 epinephrine had been formulated into an inhaler for use in the treatment of nasal congestion.\nWhile highly effective, the requirement for injection limited the use of epinephrine[clarification needed] and orally active derivatives were sought. A structurally similar compound, ephedrine, was identified by Japanese chemists in the Ma Huang plant and marketed by Eli Lilly as an oral treatment for asthma. Following the work of Henry Dale and George Barger at Burroughs-Wellcome, academic chemist Gordon Alles synthesized amphetamine and tested it in asthma patients in 1929. The drug proved to have only modest anti-asthma effects but produced sensations of exhilaration and palpitations. Amphetamine was developed by Smith, Kline and French as a nasal decongestant under the trade name Benzedrine Inhaler. Amphetamine was eventually developed for the treatment of narcolepsy, post-encephalitic parkinsonism, and mood elevation in depression and other psychiatric indications. It received approval as a New and Nonofficial Remedy from the American Medical Association for these uses in 1937,[8] and remained in common use for depression until the development of tricyclic antidepressants in the 1960s.[7]\nIn 1903, Hermann Emil Fischer and Joseph von Mering disclosed their discovery that diethylbarbituric acid, formed from the reaction of diethylmalonic acid, phosphorus oxychloride and urea, induces sleep in dogs. The discovery was patented and licensed to Bayer pharmaceuticals, which marketed the compound under the trade name Veronal as a sleep aid beginning in 1904. Systematic investigations of the effect of structural changes on potency and duration of action led to the discovery of phenobarbital at Bayer in 1911 and the discovery of its potent anti-epileptic activity in 1912. Phenobarbital was among the most widely used drugs for the treatment of epilepsy through the 1970s, and as of 2023, it remains on the World Health Organization's List of Essential Medicines.[9]\nThe 1950s and 1960s saw increased awareness of the addictive properties and abuse potential of barbiturates and amphetamines and led to increasing restrictions on their use and growing government oversight of prescribers. Today, amphetamine is largely restricted to use in the treatment of attention deficit disorder and phenobarbital in the treatment of epilepsy.[10][11]\nIn 1958, Leo Sternbach discovered the first benzodiazepine, chlordiazepoxide (Librium). Dozens of other benzodiazepines have been developed and are in use, some of the more popular drugs being diazepam (Valium), alprazolam (Xanax), clonazepam (Klonopin), and lorazepam (Ativan). Due to their far superior safety and therapeutic properties, benzodiazepines have largely replaced the use of barbiturates in medicine, except in certain special cases. When it was later discovered that benzodiazepines, like barbiturates, significantly lose their effectiveness and can have serious side effects when taken long-term, Heather Ashton researched benzodiazepine dependence and developed a protocol to discontinue their use.[citation needed]\nA series of experiments performed from the late 1800s to the early 1900s revealed that diabetes is caused by the absence of a substance normally produced by the pancreas. In 1869, Oskar Minkowski and Joseph von Mering found that diabetes could be induced in dogs by surgical removal of the pancreas. In 1921, Canadian professor Frederick Banting and his student Charles Best repeated this study and found that injections of pancreatic extract reversed the symptoms produced by pancreas removal. Soon, the extract was demonstrated to work in humans, but the development of insulin therapy as a routine medical procedure was delayed by difficulties in producing the material in sufficient quantity and with reproducible purity. The researchers sought assistance from industrial collaborators at Eli Lilly and Co. based on the company's experience with large-scale purification of biological materials. Chemist George B. Walden of Eli Lilly and Company found that careful adjustment of the pH of the extract allowed a relatively pure grade of insulin to be produced. Under pressure from Toronto University and a potential patent challenge by academic scientists who had independently developed a similar purification method, an agreement was reached for the non-exclusive production of insulin by multiple companies. Before the discovery and widespread availability of insulin therapy, the life expectancy of diabetics was only a few months.[12]\nThe development of drugs for the treatment of infectious diseases was a major focus of early research and development efforts; in 1900, pneumonia, tuberculosis, and diarrhea were the three leading causes of death in the United States and mortality in the first year of life exceeded 10%.[13][14][failed verification]\nIn 1911 arsphenamine, the first synthetic anti-infective drug, was developed by Paul Ehrlich and chemist Alfred Bertheim of the Institute of Experimental Therapy in Berlin. The drug was given the commercial name Salvarsan.[15] Ehrlich, noting both the general toxicity of arsenic and the selective absorption of certain dyes by bacteria, hypothesized that an arsenic-containing dye with similar selective absorption properties could be used to treat bacterial infections. Arsphenamine was prepared as part of a campaign to synthesize a series of such compounds and exhibited partially selective toxicity. Arsphenamine proved to be the first effective treatment for syphilis, a disease that until then had been incurable and led inexorably to severe skin ulceration, neurological damage, and death.[16]\nEhrlich's approach of systematically varying the chemical structure of synthetic compounds and measuring the effects of these changes on biological activity was pursued broadly by industrial scientists, including Bayer scientists Josef Klarer, Fritz Mietzsch, and Gerhard Domagk. This work, also based on the testing of compounds available from the German dye industry, led to the development of Prontosil, the first representative of the sulfonamide class of antibiotics. Compared to arsphenamine, the sulfonamides had a broader spectrum of activity and were far less toxic, rendering them useful for infections caused by pathogens such as streptococci.[17] In 1939, Domagk received the Nobel Prize in Medicine for this discovery.[18][19] Nonetheless, the dramatic decrease in deaths from infectious diseases that occurred before World War II was primarily the result of improved public health measures such as clean water and less crowded housing, and the impact of anti-infective drugs and vaccines was significant mainly after World War II.[20][21]\nIn 1928, Alexander Fleming discovered the antibacterial effects of penicillin, but its exploitation for the treatment of human disease awaited the development of methods for its large-scale production and purification. These were developed by a U.S. and British government-led consortium of pharmaceutical companies during World War II.[22]\nThere was early progress toward the development of vaccines throughout this period, primarily in the form of academic and government-funded basic research directed toward the identification of the pathogens responsible for common communicable diseases. In 1885, Louis Pasteur and Pierre Paul Émile Roux created the first rabies vaccine. The first diphtheria vaccines were produced in 1914 from a mixture of diphtheria toxin and antitoxin (produced from the serum of an inoculated animal), but the safety of the inoculation was marginal and it was not widely used. The United States recorded 206,000 cases of diphtheria in 1921, resulting in 15,520 deaths. In 1923, parallel efforts by Gaston Ramon at the Pasteur Institute and Alexander Glenny at the Wellcome Research Laboratories (later part of GlaxoSmithKline) led to the discovery that a safer vaccine could be produced by treating diphtheria toxin with formaldehyde.[23] In 1944, Maurice Hilleman of Squibb Pharmaceuticals developed the first vaccine against Japanese Encephalitis.[24] Hilleman later moved to Merck, where he played a key role in the development of vaccines against measles, mumps, chickenpox, rubella, hepatitis A, hepatitis B, and meningitis.\nPrior to the 20th century, drugs were generally produced by small scale manufacturers with little regulatory control over manufacturing or claims of safety and efficacy. To the extent that such laws did exist, enforcement was lax. In the United States, increased regulation of vaccines and other biological drugs was spurred by tetanus outbreaks and deaths caused by the distribution of contaminated smallpox vaccine and diphtheria antitoxin.[25] The Biologics Control Act of 1902 required that federal government grant premarket approval for every biological drug and for the process and facility producing such drugs. This Act was followed in 1906 by the Pure Food and Drugs Act, which forbade the interstate distribution of adulterated or misbranded foods and drugs. A drug was considered misbranded if it contained alcohol, morphine, opium, cocaine, or any of several other potentially dangerous or addictive drugs, and if its label failed to indicate the quantity or proportion of such drugs. The government's attempts to use the law to prosecute manufacturers for making unsupported claims of efficacy were undercut by a Supreme Court ruling restricting the federal government's enforcement powers to cases of incorrect specification of the drug's ingredients.[26]\nIn 1937 over 100 people died after ingesting \"Elixir Sulfanilamide\" manufactured by S.E. Massengill Company of Tennessee. The product was formulated in diethylene glycol, a highly toxic solvent that is now widely used as antifreeze.[27] Under the laws extant at that time, prosecution of the manufacturer was possible only under the technicality that the product had been called an \"elixir\", which implied a solution in ethanol. In response to this episode, the U.S. Congress passed the Federal Food, Drug, and Cosmetic Act of 1938 (FD&C Act), which for the first time required pre-market demonstration of safety before a drug could be sold, and explicitly prohibited false therapeutic claims.[28]\nThe aftermath of World War II saw an explosion in the discovery of new classes of antibacterial drugs[29] including the cephalosporins (developed by Eli Lilly based on the seminal work of Giuseppe Brotzu and Edward Abraham),[30][31] streptomycin (discovered during a Merck-funded research program in Selman Waksman's laboratory[32]), the tetracyclines[33] (discovered at Lederle Laboratories, now a part of Pfizer), erythromycin (discovered at Eli Lilly and Co.)[34] and their extension to an increasingly wide range of bacterial pathogens. Streptomycin, discovered during a Merck-funded research program in Selman Waksman's laboratory at Rutgers in 1943, became the first effective treatment for tuberculosis. At the time of its discovery, sanitoriums for the isolation of tuberculosis-infected people were a ubiquitous feature of cities in developed countries, with 50% dying within 5 years of admission.[32][35]\nA Federal Trade Commission report issued in 1958 attempted to quantify the effect of antibiotic development on American public health. The report found that over the period 1946–1955, there was a 42% drop in the incidence of diseases for which antibiotics were effective and only a 20% drop in those for which antibiotics were not effective. The report concluded that \"it appears that the use of antibiotics, early diagnosis, and other factors have limited the epidemic spread and thus the number of these diseases which have occurred\". The study further examined mortality rates for eight common diseases for which antibiotics offered effective therapy (syphilis, tuberculosis, dysentery, scarlet fever, whooping cough, meningococcal infections, and pneumonia), and found a 56% decline over the same period.[36] Notable among these was a 75% decline in deaths due to tuberculosis.[37]\nDuring the years 1940–1955, the rate of decline in the U.S. death rate accelerated from 2% per year to 8% per year, then returned to the historical rate of 2% per year. The dramatic decline in the immediate post-war years has been attributed to the rapid development of new treatments and vaccines for infectious disease that occurred during these years.[39][21]\nVaccine development continued to accelerate, with the most notable achievement of the period being Jonas Salk's 1954 development of the polio vaccine under the funding of the non-profit National Foundation for Infantile Paralysis. The vaccine process was never patented but was instead given to pharmaceutical companies to manufacture as a low-cost generic. In 1960 Maurice Hilleman of Merck Sharp & Dohme identified the SV40 virus, which was later shown to cause tumors in many mammalian species. It was later determined that SV40 was present as a contaminant in polio vaccine lots that had been administered to 90% of the children in the United States.[40][41] The contamination appears to have originated both in the original cell stock and in monkey tissue used for production. In 2004 the National Cancer Institute announced that it had concluded that SV40 is not associated with cancer in people.[42]\nOther notable new vaccines of the period include those for measles (1962, John Franklin Enders of Children's Medical Center Boston, later refined by Maurice Hilleman at Merck), Rubella (1969, Hilleman, Merck) and mumps (1967, Hilleman, Merck)[43] The United States incidences of rubella, congenital rubella syndrome, measles, and mumps all fell by >95% in the immediate aftermath of widespread vaccination.[44] The first 20 years of licensed measles vaccination in the U.S. prevented an estimated 52 million cases of the disease, 17,400 cases of mental retardation, and 5,200 deaths.[45]\nHypertension is a risk factor for atherosclerosis,[46] heart failure,[47] coronary artery disease,[48][49] stroke,[50] renal disease,[51][52] and peripheral arterial disease,[53][54] and is the most important risk factor for cardiovascular morbidity and mortality, in industrialized countries.[55] Prior to 1940 approximately 23% of all deaths among persons over age 50 were attributed to hypertension. Severe cases of hypertension were treated by surgery.[56]\nEarly developments in the field of treating hypertension included quaternary ammonium ion sympathetic nervous system blocking agents, but these compounds were never widely used due to their severe side effects, because the long-term health consequences of high blood pressure had not yet been established, and because they had to be administered by injection.\nIn 1952 researchers at CIBA (Gesellschaft für Chemische Industrie in Basel, predecessor to Novartis) discovered the first orally available vasodilator, hydralazine.[57] A major shortcoming of hydralazine monotherapy was that it lost its effectiveness over time (tachyphylaxis). In the mid-1950s Karl H. Beyer, James M. Sprague, John E. Baer, and Frederick C. Novello of Merck and Co. discovered and developed chlorothiazide, which remains the most widely used antihypertensive drug today.[58] This development was associated with a substantial decline in the mortality rate among people with hypertension.[59] The inventors were recognized by a Public Health Lasker Award in 1975 for \"the saving of untold thousands of lives and the alleviation of the suffering of millions of victims of hypertension\".[60]\nA 2009 Cochrane review concluded that thiazide antihypertensive drugs reduce the risk of death (RR 0.89), stroke (RR 0.63), coronary heart disease (RR 0.84), and cardiovascular events (RR 0.70) in people with high blood pressure.[61] In the ensuing years other classes of the antihypertensive drug were developed and found wide acceptance in combination therapy, including loop diuretics (Lasix/furosemide, Hoechst Pharmaceuticals, 1963),[62] beta blockers (ICI Pharmaceuticals, 1964)[63] ACE inhibitors, and angiotensin receptor blockers. ACE inhibitors reduce the risk of new-onset kidney disease [RR 0.71] and death [RR 0.84] in diabetic patients, irrespective of whether they have hypertension.[64]\nPrior to World War II, birth control was prohibited in many countries, and in the United States even the discussion of contraceptive methods sometimes led to prosecution under Comstock laws. The history of the development of oral contraceptives is thus closely tied to the birth control movement and the efforts of activists Margaret Sanger, Mary Dennett, and Emma Goldman. Based on fundamental research performed by Gregory Pincus and synthetic methods for progesterone developed by Carl Djerassi at Syntex and by Frank Colton at G.D. Searle & Co., the first oral contraceptive, Enovid, was developed by G.D. Searle & Co. and approved by the FDA in 1960. The original formulation incorporated vastly excessive doses of hormones and caused severe side effects. Nonetheless, by 1962, 1.2 million American women were on the pill, and by 1965 the number had increased to 6.5 million.[65][66][67][68] The availability of a convenient form of temporary contraceptive led to dramatic changes in social mores including expanding the range of lifestyle options available to women, reducing the reliance of women on men for contraceptive practice, encouraging the delay of marriage, and increasing pre-marital co-habitation.[69]\nIn the U.S., a push for revisions of the FD&C Act emerged from Congressional hearings led by Senator Estes Kefauver of Tennessee in 1959. The hearings covered a wide range of policy issues, including advertising abuses, questionable efficacy of drugs, and the need for greater regulation of the industry. While momentum for new legislation temporarily flagged under extended debate, a new tragedy emerged that underscored the need for more comprehensive regulation and provided the driving force for the passage of new laws.\nOn 12 September 1960, an American licensee, the William S. Merrell Company of Cincinnati, submitted a new drug application for Kevadon (thalidomide), a sedative that had been marketed in Europe since 1956. The FDA medical officer in charge of reviewing the compound, Frances Kelsey, believed that the data supporting the safety of thalidomide was incomplete. The firm continued to pressure Kelsey and the FDA to approve the application until November 1961, when the drug was pulled off the German market because of its association with grave congenital abnormalities. Several thousand newborns in Europe and elsewhere suffered the teratogenic effects of thalidomide. Without approval from the FDA, the firm distributed Kevadon to over 1,000 physicians there under the guise of investigational use. Over 20,000 Americans received thalidomide in this \"study,\" including 624 pregnant patients, and about 17 known newborns suffered the effects of the drug.[citation needed]\nThe thalidomide tragedy resurrected Kefauver's bill to enhance drug regulation that had stalled in Congress, and the Kefauver-Harris Amendment became law on 10 October 1962. Manufacturers henceforth had to prove to the FDA that their drugs were effective as well as safe before they could go on the US market. The FDA received authority to regulate the advertising of prescription drugs and to establish good manufacturing practices. The law required that all drugs introduced between 1938 and 1962 had to be effective. A collaborative study by the FDA and the National Academy of Sciences showed that nearly 40 percent of these products were not effective. A similarly comprehensive study of over-the-counter products began ten years later.[70]\nIn 1971, Akira Endo, a Japanese biochemist working for the pharmaceutical company Sankyo, identified mevastatin (ML-236B), a molecule produced by the fungus Penicillium citrinum, as an inhibitor of HMG-CoA reductase, a critical enzyme used by the body to produce cholesterol. Animal trials showed very good inhibitory effects as in clinical trials, however a long-term study in dogs found toxic effects at higher doses and as a result, mevastatin was believed to be too toxic for human use. Mevastatin was never marketed, because of its adverse effects of tumors, muscle deterioration, and sometimes death in laboratory dogs.\nP. Roy Vagelos, chief scientist and later CEO of Merck & Co, was interested and made several trips to Japan starting in 1975. By 1978, Merck had isolated lovastatin (mevinolin, MK803) from the fungus Aspergillus terreus, first marketed in 1987 as Mevacor.[71][72][73]\nIn April 1994, the results of a Merck-sponsored study, the Scandinavian Simvastatin Survival Study, were announced. Researchers tested simvastatin, later sold by Merck as Zocor, on 4,444 patients with high cholesterol and heart disease. After five years, the study concluded that patients saw a 35% reduction in their cholesterol, and their chances of dying of a heart attack were reduced by 42%.[74] In 1995, Zocor and Mevacor both made Merck over US$1 billion. Endo was awarded the 2006 Japan Prize, and the Lasker-DeBakey Clinical Medical Research Award in 2008 for his \"pioneering research into a new class of molecules\" for \"lowering cholesterol\".[75][76]\nSince several decades, biologics have been rising in importance in comparison with small molecule treatments. The biotech subsector, animal health and the Chinese pharmaceutical sector have also grown substantially. On the organisational side, big international pharmaceutical corporations have experienced a substantial decline of their value share. Also, the core generic sector (substitutions for off-patent brands) has been down valued due to competition.[77]\nTorreya estimated the pharmaceutical industry to have a market valuation of US$7.03 trillion by February 2021 from which US$6.1 trillion is the value of the publicly traded companies. Small Molecules modality had 58.2% of the valuation share down from 84.6% in 2003. Biologics was up at 30.5% from 14.5%. The valuation share of Chinese Pharma grew from 2003 to 2021 from 1% to 12% overtaking Switzerland who is now ranked number 3 with 7.7%. The United States had still by far the most valued pharmaceutical industry with 40% of global valuation.[78] 2023 was a year of layoffs for at least 10,000 people across 129 public biotech firms globally, albeit mostly small firms; this was a significant increase in reductions versus 2022 in part due to worsening global financial conditions and a reduction in investment by \"generalist investors\".[79] Private firms also saw a significant reduction in venture capital investment in 2023, continuing a downward trend started in 2021, which also led to a reduction in initial public offerings being floated.[79]\nA 2022 article articulated this notion succinctly by saying \"In the business of drug development, deals can be just as important as scientific breakthroughs\", typically referred to as pharmaceutical M&A (for mergers and acquisitions).[80] It highlighted that some of the most impactful of the remedies of the early 21st Century were only made possible through M&A activities, specifically noting Keytruda and Humira.[80]\nDrug discovery is the process by which potential drugs are discovered or designed. In the past, most drugs have been discovered either by isolating the active ingredient from traditional remedies or by serendipitous discovery. Modern biotechnology often focuses on understanding the metabolic pathways related to a disease state or pathogen, and manipulating these pathways using molecular biology or biochemistry. A great deal of early-stage drug discovery has traditionally been carried out by universities and research institutions.\nDrug development refers to activities undertaken after a compound is identified as a potential drug in order to establish its suitability as a medication. Objectives of drug development are to determine appropriate formulation and dosing, as well as to establish safety. Research in these areas generally includes a combination of in vitro studies, in vivo studies, and clinical trials. The cost of late stage development has meant it is usually done by the larger pharmaceutical companies.[81] The pharmaceuticals and biotechnology industry spends more than 15% of its net sales for Research & Development which is in comparison with other industries by far the highest share.[82]\nOften, large multinational corporations exhibit vertical integration, participating in a broad range of drug discovery and development, manufacturing and quality control, marketing, sales, and distribution. Smaller organizations, on the other hand, often focus on a specific aspect such as discovering drug candidates or developing formulations. Often, collaborative agreements between research organizations and large pharmaceutical companies are formed to explore the potential of new drug substances. More recently, multi-nationals are increasingly relying on contract research organizations to manage drug development.[83]\nDrug discovery and development are very expensive; of all compounds investigated for use in humans only a small fraction are eventually approved in most nations by government-appointed medical institutions or boards, who have to approve new drugs before they can be marketed in those countries. In 2010 18 NMEs (New Molecular Entities) were approved and three biologics by the FDA, or 21 in total, which is down from 26 in 2009 and 24 in 2008. On the other hand, there were only 18 approvals in total in 2007 and 22 back in 2006. Since 2001, the Center for Drug Evaluation and Research has averaged 22.9 approvals a year.[84] This approval comes only after heavy investment in pre-clinical development and clinical trials, as well as a commitment to ongoing safety monitoring. Drugs which fail part-way through this process often incur large costs, while generating no revenue in return. If the cost of these failed drugs is taken into account, the cost of developing a successful new drug (new chemical entity, or NCE), has been estimated at US$1.3 billion[85] (not including marketing expenses). Professors Light and Lexchin reported in 2012, however, that the rate of approval for new drugs has been a relatively stable average rate of 15 to 25 for decades.[86]\nIndustry-wide research and investment reached a record $65.3 billion in 2009.[87] While the cost of research in the U.S. was about $34.2 billion between 1995 and 2010, revenues rose faster (revenues rose by $200.4 billion in that time).[86]\nA study by the consulting firm Bain & Company reported that the cost for discovering, developing and launching (which factored in marketing and other business expenses) a new drug (along with the prospective drugs that fail) rose over a five-year period to nearly $1.7 billion in 2003.[88] According to Forbes, by 2010 development costs were between $4 billion to $11 billion per drug.[89]\nSome of these estimates also take into account the opportunity cost of investing capital many years before revenues are realized (see Time-value of money). Because of the very long time needed for the discovery, development, and approval of pharmaceuticals, these costs can accumulate to nearly half the total expense. A direct consequence within the pharmaceutical industry value chain is that major pharmaceutical multinationals tend to increasingly outsource risks related to fundamental research, which somewhat reshapes the industry ecosystem with biotechnology companies playing an increasingly important role, and overall strategies being redefined accordingly.[90] Some approved drugs, such as those based on re-formulation of an existing active ingredient (also referred to as Line-extensions) are much less expensive to develop.\nIn the United States, new pharmaceutical products must be approved by the Food and Drug Administration (FDA) as being both safe and effective. This process generally involves the submission of an Investigational New Drug (IND) filing with sufficient pre-clinical data to support proceeding with human trials. Following IND approval, three phases of progressively larger human clinical trials may be conducted. Phase I generally studies toxicity using healthy volunteers. Phase II can include pharmacokinetics and dosing in patients, and Phase III is a very large study of efficacy in the intended patient population. Following the successful completion of Phase III testing, a New Drug Application is submitted to the FDA. The FDA reviews the data and if the product is seen as having a positive benefit-risk assessment, approval to market the product in the US is granted.[91]\nA fourth phase of post-approval surveillance is also often required due to the fact that even the largest clinical trials cannot effectively predict the prevalence of rare side effects. Postmarketing surveillance ensures that after marketing the safety of a drug is monitored closely. In certain instances, its indication may need to be limited to particular patient groups, and in others, the substance is withdrawn from the market completely.\nThe FDA provides information about approved drugs at the Orange Book site.[92]\nIn the UK, the Medicines and Healthcare products Regulatory Agency (MHRA) approves and evaluates drugs for use. Normally an approval in the UK and other European countries comes later than one in the USA. Then it is the National Institute for Health and Care Excellence (NICE), for England and Wales, who decides if and how the National Health Service (NHS) will allow (in the sense of paying for) their use. The British National Formulary is the core guide for pharmacists and clinicians.\nIn many non-US western countries, a 'fourth hurdle' of cost effectiveness analysis has developed before new technologies can be provided. This focuses on the 'efficacy price tag' (in terms of, for example, the cost per QALY) of the technologies in question. In England and Wales NICE decides whether and in what circumstances drugs and technologies will be made available by the NHS, whilst similar arrangements exist with the Scottish Medicines Consortium in Scotland, and the Pharmaceutical Benefits Advisory Committee in Australia. A product must pass the threshold for cost-effectiveness if it is to be approved. Treatments must represent 'value for money' and a net benefit to society.\nThere are special rules for certain rare diseases (\"orphan diseases\") in several major drug regulatory territories. For example, diseases involving fewer than 200,000 patients in the United States, or larger populations in certain circumstances are subject to the Orphan Drug Act.[93] Because medical research and development of drugs to treat such diseases is financially disadvantageous, companies that do so are rewarded with tax reductions, fee waivers, and market exclusivity on that drug for a limited time (seven years), regardless of whether the drug is protected by patents.\n| Company | Pharma revenue ($ million) |\n|---|---|\n| Johnson & Johnson | 88,800 |\n| Roche | 65,300 |\n| Merck & Co | 64,200 |\n| Pfizer | 63,600 |\n| Abbvie | 56,300 |\n| AstraZeneca / | 54,100 |\n| Novartis | 50,300 |\n| Bristol Myers Squibb | 48,300 |\n| Eli Lilly and Company | 45,000 |\n| Sanofi | 44,460 |\n| Novo Nordisk | 42,100 |\n| GSK | 40,100 |\n| Amgen | 33,400 |\n| Takeda Pharmaceutical Company | 30,900 |\n| Boehringer Ingelheim | 29,000 |\n| Gilead Sciences | 28,600 |\n| Bayer | 26,000 |\n| Merck KGaA | 19,100 |\n| Teva Pharmaceuticals | 16,500 |\n| CSL Limited | 15,200 |\nIn 2011, global spending on prescription drugs topped $954 billion, even as growth slowed somewhat in Europe and North America. The United States accounts for more than a third of the global pharmaceutical market, with $340 billion in annual sales followed by the EU and Japan.[95] Emerging markets such as China, Russia, South Korea and Mexico outpaced that market, growing a huge 81 percent.[96][97]\nThe top ten best-selling drugs of 2013 totaled $75.6 billion in sales, with the anti-inflammatory drug Humira being the best-selling drug worldwide at $10.7 billion in sales. The second and third best selling were Enbrel and Remicade, respectively.[98] The top three best-selling drugs in the United States in 2013 were Abilify ($6.3 billion,) Nexium ($6 billion) and Humira ($5.4 billion).[99] The best-selling drug ever, Lipitor, averaged $13 billion annually and netted $141 billion total over its lifetime before Pfizer's patent expired in November 2011.\nIMS Health publishes an analysis of trends expected in the pharmaceutical industry in 2007, including increasing profits in most sectors despite loss of some patents, and new 'blockbuster' drugs on the horizon.[100]\nDepending on a number of considerations, a company may apply for and be granted a patent for the drug, or the process of producing the drug, granting exclusivity rights typically for about 20 years.[101] However, only after rigorous study and testing, which takes 10 to 15 years on average, will governmental authorities grant permission for the company to market and sell the drug.[102] Patent protection enables the owner of the patent to recover the costs of research and development through high profit margins for the branded drug. When the patent protection for the drug expires, a generic drug is usually developed and sold by a competing company. The development and approval of generics are less expensive, allowing them to be sold at a lower price. Often the owner of the branded drug will introduce a generic version before the patent expires in order to get a head start in the generic market.[103] Restructuring has therefore become routine, driven by the patent expiration of products launched during the industry's \"golden era\" in the 1990s and companies' failure to develop sufficient new blockbuster products to replace lost revenues.[104]\nIn the U.S., the value of prescriptions increased over the period of 1995 to 2005 by 3.4 billion annually, a 61 percent increase. Retail sales of prescription drugs jumped 250 percent from $72 billion to $250 billion, while the average price of prescriptions more than doubled from $30 to $68.[105]\nAdvertising is common in healthcare journals as well as through more mainstream media routes. In some countries, notably the US, they are allowed to advertise directly to the general public. Pharmaceutical companies generally employ salespeople (often called 'drug reps' or, an older term, 'detail men') to market directly and personally to physicians and other healthcare providers. In some countries, notably the US, pharmaceutical companies also employ lobbyists to influence politicians. Marketing of prescription drugs in the US is regulated by the federal Prescription Drug Marketing Act of 1987. The pharmaceutical marketing plan incorporates the spending plans, channels, and thoughts which will take the drug association, and its items and administrations, forward in the current scene.\nThe book Bad Pharma also discusses the influence of drug representatives, how ghostwriters are employed by the drug companies to write papers for academics to publish, how independent the academic journals really are, how the drug companies finance doctors' continuing education, and how patients' groups are often funded by industry.[106]\nSince the 1980s, new methods of marketing prescription drugs to consumers have become important. Direct-to-consumer media advertising was legalised in the FDA Guidance for Industry on Consumer-Directed Broadcast Advertisements.\nIn 2011 four of the top 20 corporate charitable donations and eight of the top 30 corporate charitable donations came from pharmaceutical manufacturers. The bulk of corporate charitable donations (69% as of 2012) comes by way of non-cash charitable donations, the majority of which again were donations contributed by pharmaceutical companies.[107]\nCharitable programs and drug discovery & development efforts by pharmaceutical companies include:\n- \"Merck's Gift\", wherein billions of river blindness drugs were donated in Africa[108]\n- Pfizer's gift of free/discounted fluconazole and other drugs for AIDS in South Africa[109]\n- GSK's commitment to give free albendazole tablets to the WHO for, and until, the elimination of lymphatic filariasis worldwide.\n- In 2006, Novartis committed US$755 million in corporate citizenship initiatives around the world, particularly focusing on improving access to medicines in the developing world through its Access to Medicine projects, including donations of medicines to patients affected by leprosy, tuberculosis, and malaria; Glivec patient assistance programs; and relief to support major humanitarian organisations with emergency medical needs.[110]\nThere have been many controversies surrounding pharmaceutical marketing and influence. There have been accusations and findings of influence on doctors and other health professionals through drug representatives including the constant provision of marketing 'gifts' and biased information to health professionals.[111] As well as highly prevalent advertising in journals and conferences, funding independent healthcare organizations and health promotion campaigns, being at a time the most lobbied industry in the US,[112] sponsorship of medical schools or nurse training, sponsorship of continuing educational events, with influence on the curriculum,[113] and hiring physicians and doctors as paid consultants on medical advisory boards.[citation needed]\nSome advocacy groups, such as No Free Lunch and AllTrials, have criticized the effect of drug marketing to physicians because they say it biases physicians to prescribe the marketed drugs even when others might be cheaper or better for the patient.[114]\nThere have been related accusations of disease mongering[115] (over-medicalising) to expand the market for medications. An inaugural conference on that subject took place in Australia in 2006.[116] In 2009, the Government-funded National Prescribing Service launched the \"Finding Evidence – Recognising Hype\" program, aimed at educating GPs on methods for independent drug analysis.[117]\nMeta-analyses have shown that psychiatric studies sponsored by pharmaceutical companies are several times more likely to report positive results, and if a drug company employee is involved the effect is even larger.[118][119][120] Influence has also extended to the training of doctors and nurses in medical schools, which is being fought.\nIt has been argued that the design of the Diagnostic and Statistical Manual of Mental Disorders and the expansion of the criteria represents an increasing medicalization of human nature, or \"disease mongering\", driven by drug company influence on psychiatry.[121] The potential for direct conflict of interest has been raised, partly because roughly half the authors who selected and defined the DSM-IV psychiatric disorders had or previously had financial relationships with the pharmaceutical industry.[122]\nIn the US, starting in 2013, under the Physician Financial Transparency Reports (part of the Sunshine Act), the Centers for Medicare & Medicaid Services has to collect information from applicable manufacturers and group purchasing organizations in order to report information about their financial relationships with physicians and hospitals. Data are made public on the Centers for Medicare & Medicaid Services website. The expectation is that the relationship between doctors and the Pharmaceutical industry will become fully transparent.[123]\nIn a report conducted by OpenSecrets, there were more than 1,100 lobbyists working in some capacity for the pharmaceutical business in 2017. In the first quarter of 2017, the health products and pharmaceutical industry spent $78 million on lobbying members of the United States Congress.[124]\nThe pricing of pharmaceuticals is becoming a major challenge for health systems.[125] A November 2020 study by the West Health Policy Center stated that more than 1.1 million senior citizens in the U.S. Medicare program is expected to die prematurely over the next decade because they will be unable to afford their prescription medications, requiring an additional $17.7 billion to be spent annually on avoidable medical costs due to health complications.[126]\nBen Goldacre has argued that regulators – such as the Medicines and Healthcare products Regulatory Agency (MHRA) in the UK, or the Food and Drug Administration (FDA) in the United States – advance the interests of the drug companies rather than the interests of the public due to revolving door exchange of employees between the regulator and the companies and friendships develop between regulator and company employees.[127] He argues that regulators do not require that new drugs offer an improvement over what is already available, or even that they be particularly effective.[127]\nOthers have argued that excessive regulation suppresses therapeutic innovation and that the current cost of regulator-required clinical trials prevents the full exploitation of new genetic and biological knowledge for the treatment of human disease. A 2012 report by the President's Council of Advisors on Science and Technology made several key recommendations to reduce regulatory burdens to new drug development, including 1) expanding the FDA's use of accelerated approval processes, 2) creating an expedited approval pathway for drugs intended for use in narrowly defined populations, and 3) undertaking pilot projects designed to evaluate the feasibility of a new, adaptive drug approval process.[128]\nPharmaceutical fraud involves deceptions that bring financial gain to a pharmaceutical company. It affects individuals and public and private insurers. There are several different schemes[129] used to defraud the health care system which are particular to the pharmaceutical industry. These include: Good Manufacturing Practice (GMP) Violations, Off Label Marketing, Best Price Fraud, CME Fraud, Medicaid Price Reporting, and Manufactured Compound Drugs.[130] Of this amount $2.5 billion was recovered through False Claims Act cases in FY 2010. Examples of fraud cases include the GlaxoSmithKline $3 billion settlement, Pfizer $2.3 billion settlement and Merck & Co. $650 million settlement. Damages from fraud can be recovered by use of the False Claims Act, most commonly under the qui tam provisions which reward an individual for being a \"whistleblower\", or relator (law).[131]\nEvery major company selling atypical antipsychotics—Bristol-Myers Squibb, Eli Lilly and Company, Pfizer, AstraZeneca and Johnson & Johnson—has either settled recent government cases, under the False Claims Act, for hundreds of millions of dollars or is currently under investigation for possible health care fraud. Following charges of illegal marketing, two of the settlements set records in 2009 for the largest criminal fines ever imposed on corporations. One involved Eli Lilly's antipsychotic Zyprexa, and the other involved Bextra, an anti-inflammatory medication used for arthritis. In the Bextra case, the government also charged Pfizer with illegally marketing another antipsychotic, Geodon; Pfizer settled that part of the claim for $301 million, without admitting any wrongdoing.[132]\nIn July 2012, GlaxoSmithKline pleaded guilty to criminal charges and agreed to a $3 billion settlement of the largest health-care fraud case in the U.S. and the largest payment by a drug company.[133] The settlement is related to the company's illegal promotion of prescription drugs, its failure to report safety data,[134] bribing doctors, and promoting medicines for uses for which they were not licensed. The drugs involved were Paxil, Wellbutrin, Advair, Lamictal, and Zofran for off-label, non-covered uses. Those and the drugs Imitrex, Lotronex, Flovent, and Valtrex were involved in the kickback scheme.[135][136][137]\nThe following is a list of the four largest settlements reached with pharmaceutical companies from 1991 to 2012, rank ordered by the size of the total settlement. Legal claims against the pharmaceutical industry have varied widely over the past two decades, including Medicare and Medicaid fraud, off-label promotion, and inadequate manufacturing practices.[138][139]\n| Company | Settlement | Violation(s) | Year | Product(s) | Laws allegedly violated (if applicable) |\n|---|---|---|---|---|---|\n| GlaxoSmithKline[140] | $3 billion | Off-label promotion/ failure to disclose safety data |\n2012 | Avandia/Wellbutrin/Paxil | False Claims Act/FDCA |\n| Pfizer[141] | $2.3 billion | Off-label promotion/kickbacks | 2009 | Bextra/Geodon/ Zyvox/Lyrica |\nFalse Claims Act/FDCA |\n| Abbott Laboratories[142] | $1.5 billion | Off-label promotion | 2012 | Depakote | False Claims Act/FDCA |\n| Eli Lilly[143] | $1.4 billion | Off-label promotion | 2009 | Zyprexa | False Claims Act/FDCA |\nIn May 2015, the New England Journal of Medicine emphasized the importance of pharmaceutical industry-physician interactions for the development of novel treatments and argued that moral outrage over industry malfeasance had unjustifiably led many to overemphasize the problems created by financial conflicts of interest. The article noted that major healthcare organizations, such as National Center for Advancing Translational Sciences of the National Institutes of Health, the President's Council of Advisors on Science and Technology, the World Economic Forum, the Gates Foundation, the Wellcome Trust, and the Food and Drug Administration had encouraged greater interactions between physicians and industry in order to improve benefits to patients.[144][145]\nIn November 2020 several pharmaceutical companies announced successful trials of COVID-19 vaccines, with efficacy of 90 to 95% in preventing infection. Per company announcements and data reviewed by external analysts, these vaccines are priced at $3 to $37 per dose.[146] The Wall Street Journal ran an editorial calling for this achievement to be recognized with a Nobel Peace Prize.[147]\nDoctors Without Borders warned that high prices and monopolies on medicines, tests, and vaccines would prolong the pandemic and cost lives. They urged governments to prevent profiteering, using compulsory licenses as needed, as had already been done by Canada, Chile, Ecuador, Germany, and Israel.[148]\nOn 20 February, 46 US lawmakers called for the US government not to grant monopoly rights when giving out taxpayer development money for any coronavirus vaccines and treatments, to avoid giving exclusive control of prices and availability to private manufacturers.[149]\nIn the United States, the government signed agreements in which research and development or the building of manufacturing plants for potential COVID-19 therapeutics was subsidized. Typically, the agreement involved the government taking ownership of a certain number of doses of the product without further payment. For example, under the auspices of Operation Warp Speed in the United States, the government subsidized research related to COVID-19 vaccines and therapeutics at Regeneron,[150] Johnson and Johnson, Moderna, AstraZeneca, Novavax, Pfizer, and GSK. Typical terms involved research subsidies of $400 million to $2 billion, and included government ownership of the first 100 million doses of any COVID-19 vaccine successfully developed.[151]\nAmerican pharmaceutical company Gilead sought and obtained orphan drug status for remdesivir from the US Food and Drug Administration (FDA) on 23 March 2020. This provision is intended to encourage the development of drugs affecting fewer than 200,000 Americans by granting strengthened and extended legal monopoly rights to the manufacturer, along with waivers on taxes and government fees.[152][153] Remdesivir is a candidate for treating COVID-19; at the time the status was granted, fewer than 200,000 Americans had COVID-19, but numbers were climbing rapidly as the COVID-19 pandemic reached the US, and crossing the threshold soon was considered inevitable.[152][153] Remdesivir was developed by Gilead with over $79 million in U.S. government funding.[153] In May 2020, Gilead announced that it would provide the first 940,000 doses of remdesivir to the federal government free of charge.[154] After facing strong public reactions, Gilead gave up the \"orphan drug\" status for remdesivir on 25 March.[155] Gilead retains 20-year remdesivir patents in more than 70 countries.[148] In May 2020, the company further announced that it was in discussions with several generics companies to provide rights to produce remdesivir for developing countries, and with the Medicines Patent Pool to provide broader generic access.[156]\nPatents have been criticized in the developing world, as they are thought[who?] to reduce access to existing medicines.[157] Reconciling patents and universal access to medicine would require an efficient international policy of price discrimination. Moreover, under the TRIPS agreement of the World Trade Organization, countries must allow pharmaceutical products to be patented. In 2001, the WTO adopted the Doha Declaration, which indicates that the TRIPS agreement should be read with the goals of public health in mind, and allows some methods for circumventing pharmaceutical monopolies: via compulsory licensing or parallel imports, even before patent expiration.[158]\nIn March 2001, 40 multi-national pharmaceutical companies brought litigation against South Africa for its Medicines Act, which allowed the generic production of antiretroviral drugs (ARVs) for treating HIV, despite the fact that these drugs were on-patent.[159] HIV was and is an epidemic in South Africa, and ARVs at the time cost between US$10,000 and US$15,000 per patient per year. This was unaffordable for most South African citizens, and so the South African government committed to providing ARVs at prices closer to what people could afford. To do so, they would need to ignore the patents on drugs and produce generics within the country (using a compulsory license), or import them from abroad. After an international protest in favour of public health rights (including the collection of 250,000 signatures by Médecins Sans Frontières), the governments of several developed countries (including The Netherlands, Germany, France, and later the US) backed the South African government, and the case was dropped in April of that year.[160]\nIn 2016, GlaxoSmithKline (the world's sixth largest pharmaceutical company) announced that it would be dropping its patents in poor countries so as to allow independent companies to make and sell versions of its drugs in those areas, thereby widening the public access to them.[161] GlaxoSmithKline published a list of 50 countries they would no longer hold patents in, affecting one billion people worldwide.\n- List of industrial complexes – Socioeconomic concept\n- Big Pharma conspiracy theories – Conspiracy theories about the pharmaceutical industry\n- Clinical trial – Phase of clinical research in medicine\n- Drug development – Process of bringing a new pharmaceutical drug to the market\n- Drug discovery – Pharmaceutical procedure\n- Legal drug trade\n- List of pharmaceutical companies\n- Licensed production – Production under license of technology developed elsewhere\n- Outsourcing – Contracting internal tasks to an external organization\n- Pharmaceutical marketing – Advertising by pharmaceutical companies\n- Pharmacy – Clinical health science\n- Pharmacy benefit management – Administration of prescription drug programs in the United States\n- Unitaid – Global health initiative\n- Valuation (finance) § Valuation of intangible assets\n- McGuire, John L.; Hasskarl, Horst; Bode, Gerd; Klingmann, Ingrid; Zahn, Manuel (2007). \"Pharmaceuticals, General Survey\". Ullmann's Encyclopedia of Industrial Chemistry. Wiley. doi:10.1002/14356007.a19_273.pub2. ISBN 978-3-527-30673-2.\n- Bozenhardt, Erich H.; Bozenhardt, Herman F. (18 October 2018). \"Are You Asking Too Much From Your Filler?\". Pharmaceutical Online (Guest column). VertMarkets. Archived from the original on 17 November 2020. Retrieved 30 October 2018.\nThe core mission of the pharmaceutical industry is to manufacture products for patients to cure them, vaccinate them, or alleviate a symptom, often by manufacturing a liquid injectable or an oral solid, among other therapies.\n- \"Pharmaceutical market worldwide – statistics & facts\". Statista. 2023. Retrieved 24 August 2025.\n- Markets, Research and (31 March 2021). \"Global Pharmaceuticals Market Report 2021: Market is Expected to Grow from $1228.45 Billion in 2020 to $1250.24 Billion in 2021 - Long-term Forecast to 2025 & 2030\". GlobeNewswire News Room (Press release). Archived from the original on 29 November 2021. Retrieved 29 November 2021.\n- \"Emergence of Pharmaceutical Science and Industry: 1870-1930\". Chem Eng News. 83 (25). 20 June 2005. Archived from the original on 10 November 2018. Retrieved 23 July 2022.\n- Sneader, Walter (31 October 2005). \"13 Neurohormones\". Drug Discovery: A History. John Wiley & Sons. pp. 155–156. ISBN 978-0-470-01552-0. Retrieved 23 July 2022.\n- Rasmussen, Nicolas (2006). \"Making the First Anti-Depressant: Amphetamine in American Medicine, 1929-1950\". J Hist Med Allied Sci. 61 (3): 288–323. doi:10.1093/jhmas/jrj039. PMID 16492800. S2CID 24974454.\n- Rasmussen N (June 2008). \"America's First Amphetamine Epidemic 1929–1971\". Am J Public Health. 98 (6): 974–985. doi:10.2105/AJPH.2007.110593. PMC 2377281. PMID 18445805.\n- \"WHO Model List of Essential Medicines – 23rd list (2023)\". World Health Organization. 26 July 2023. Retrieved 24 August 2025.\n- \"Drug Abuse Control Amendments of 1965\". NEJM (Editorial). 273 (22): 1222–1223. 25 November 1965. doi:10.1056/NEJM196511252732213.\nOfficers of the Food and Drug Administration, aware of the seriousness of the problem, estimate that approximately half the 9,000,000,000 barbiturate and amphetamine capsules and tablets manufactured annually in this country are diverted to illegal use. The profits to be gained from the illegal sale of these drugs have proved an attraction to organized crime, for amphetamine can be purchased at wholesale for less than $1 per 1000 capsules, but when sold on the illegal market, it brings $30 to $50 per 1000 and when retailed to the individual buyer, a tablet may bring as much as 10 to 25 cents.\n- \"Sedative-Hypnotic Drugs — The Barbiturates — I\". NEJM. 255 (24): 1150–1151. 1956. doi:10.1056/NEJM195612132552409. PMID 13378632.\nThe barbiturates, introduced into medicine by E. Fischer and J. von Mering in 1903, are certainly among the most widely used and abused drugs in medicine. Approximately 400 tons of these agents are manufactured each year; this is enough to put approximately 9,000,000 people to sleep each night for that period if each were given a 0.1-gm. dose\n- Rosenfeld L (December 2002). \"Insulin: discovery and controversy\". Clin Chem. 48 (12): 2270–88. doi:10.1093/clinchem/48.12.2270. PMID 12446492.\n- \"Leading Causes of Death, 1900-1998\" (PDF). CDC.gov. Archived (PDF) from the original on 13 December 2020. Retrieved 23 July 2022.\n- Anderson, Robert N. (13 December 1999). \"United States Life Tables, 1997\" (PDF). National Vital Statistics Reports. 47 (28): 1–37. PMID 10635683. Archived from the original (PDF) on 25 October 2020. Retrieved 23 July 2022.\n- Sepkowitz, Kent A. (July 2011). \"One hundred years of Salvarsan\". N. Engl. J. Med. (Perspective). 365 (4): 291–3. doi:10.1056/NEJMp1105345. PMID 21793743.\n- Williams, KJ (1 August 2009). \"The introduction of 'chemotherapy' using arsphenamine – the first magic bullet\". J. R. Soc. Med. 102 (8): 343–348. doi:10.1258/jrsm.2009.09k036. ISSN 0141-0768. PMC 2726818. PMID 19679737.\n- Aminov, Rustam I. (8 December 2010). \"A brief history of the antibiotic era: lessons learned and challenges for the future\". Front. Microbiol. 1: 134. doi:10.3389/fmicb.2010.00134. PMC 3109405. PMID 21687759.\n- Hager, Thomas (2006). The Demon Under the Microscope (1st ed.). New York: Harmony Books. ISBN 978-1-4000-8213-1.\n- \"All Nobel Prizes in Physiology or Medicine\". The Nobel Prize. Retrieved 22 July 2022.\n- Cutler, David M.; Meara, Ellen (October 2001). Changes in the Age Distribution of Mortality Over the 20th Century (PDF) (Report). National Bureau of Economic Research. doi:10.3386/w8556. Retrieved 23 July 2022.\n- Klein, Herbert (2012). A Population History of the United States. Cambridge University Press. p. 167.\n- Parascandola, John (1980). The History of antibiotics: a symposium. American Institute of the History of Pharmacy No. 5. ISBN 978-0-931292-08-8.\n- \"Diphtheria — Timelines — History of Vaccines\". Archived from the original on 14 May 2016. Retrieved 24 February 2022.\n- Ii, Thomas H. Maugh (13 April 2005). \"Maurice R. Hilleman, 85; Scientist Developed Many Vaccines That Saved Millions of Lives\". Los Angeles Times. Archived from the original on 7 November 2014.\n- \"Significant Dates in U.S. Food and Drug Law History\". Food and Drug Administration. Archived from the original on 6 March 2013. Retrieved 16 December 2019.\n- \"FDAReview.org, a project of The Independent Institute\". Archived from the original on 2 December 2015. Retrieved 24 February 2022.\n- \"Sulfanilamide Disaster\". Food and Drug Administration. Archived from the original on 25 November 2020. Retrieved 16 December 2019.\n- \"FDA History - Part II\". Food and Drug Administration. Archived from the original on 1 January 2018. Retrieved 16 December 2019.\n- Zaffiri L, Gardner J, Toledo-Pereyra LH (April 2012). \"History of antibiotics. From salvarsan to cephalosporins\". J Invest Surg. 25 (2): 67–77. doi:10.3109/08941939.2012.664099. PMID 22439833. S2CID 30538825.\n- Hamilton-Miller JM (March 2008). \"Development of the semi-synthetic penicillins and cephalosporins\". Int. J. Antimicrob. Agents. 31 (3): 189–92. doi:10.1016/j.ijantimicag.2007.11.010. PMID 18248798.\n- Abraham EP (1987). \"Cephalosporins 1945-1986\". Drugs. 34 Suppl 2 (Supplement 2): 1–14. doi:10.2165/00003495-198700342-00003. PMID 3319494. S2CID 12014890.\n- Kingston W (July 2004). \"Streptomycin, Schatz v. Waksman, and the balance of credit for discovery\". J Hist Med Allied Sci. 59 (3): 441–62. doi:10.1093/jhmas/jrh091. PMID 15270337. S2CID 27465970.\n- Nelson ML, Levy SB (December 2011). \"The history of the tetracyclines\". Ann. N. Y. Acad. Sci. 1241 (1): 17–32. Bibcode:2011NYASA1241...17N. doi:10.1111/j.1749-6632.2011.06354.x. PMID 22191524. S2CID 34647314.\n- \"ERYTHROMYCIN\". Br Med J. 2 (4793): 1085–6. November 1952. doi:10.1136/bmj.2.4793.1085. PMC 2022076. PMID 12987755.\n- Anderson, Rosaleen (2012). Antibacterial agents chemistry, mode of action, mechanisms of resistance, and clinical applications. Oxford: WiBlackwell. ISBN 978-0-470-97245-8.\n- Federal Trade Commission Report of Antibiotics Manufacture, June 1958 (Washington D.C., Government Printing Office, 1958) pages 98-120\n- Federal Trade Commission Report of Antibiotics Manufacture, June 1958 (Washington D.C., Government Printing Office, 1958) page 277\n- Anderson, Robert N. (13 December 1999). \"United States Life Tables, 1997\" (PDF). National Vital Statistics Reports: From the Centers for Disease Control and Prevention, National Center for Health Statistics, National Vital Statistics System. 47 (28): 1–37. PMID 10635683. Archived (PDF) from the original on 25 October 2020. Retrieved 8 September 2017.\n- Cutler, David; Meara, Ellen (October 2001). \"Changes in the Age Distribution of Mortality Over the 20th Century\" (PDF). NBER Working Paper No. 8556. doi:10.3386/w8556. Archived (PDF) from the original on 30 July 2020. Retrieved 24 February 2022.\n- Sweet BH, Hilleman MR (November 1960). \"The vacuolating virus, S.V. 40\". Proc. Soc. Exp. Biol. Med. 105 (2): 420–7. doi:10.3181/00379727-105-26128. PMID 13774265. S2CID 38744505.\n- Shah K, Nathanson N (January 1976). \"Human exposure to SV40: review and comment\". Am. J. Epidemiol. 103 (1): 1–12. doi:10.1093/oxfordjournals.aje.a112197. PMID 174424.\n- \"Studies:No Evidence That SV40 is Related to Cancer\". Archived from the original on 28 October 2014.\n- \"History of Vaccines — A Vaccine History Project of The College of Physicians of Philadelphia\". Archived from the original on 19 February 2022. Retrieved 24 February 2022.\n- \"Prevention of Measles, Rubella, Congenital Rubella Syndrome, and Mumps, 2013\". Archived from the original on 10 November 2014. Retrieved 8 September 2017.\n- Bloch AB, Orenstein WA, Stetler HC, et al. (1985). \"Health impact of measles vaccination in the United States\". Pediatrics. 76 (4): 524–32. doi:10.1542/peds.76.4.524. PMID 3931045. S2CID 6512947.\n- Insull W (January 2009). \"The pathology of atherosclerosis: plaque development and plaque responses to medical treatment\". The American Journal of Medicine. 122 (1 Suppl): S3 – S14. doi:10.1016/j.amjmed.2008.10.013. PMID 19110086.\n- Gaddam KK, Verma A, Thompson M, Amin R, Ventura H (May 2009). \"Hypertension and cardiac failure in its various forms\". The Medical Clinics of North America. 93 (3): 665–80. doi:10.1016/j.mcna.2009.02.005. PMID 19427498. Retrieved 20 June 2009.\n- Agabiti-Rosei E (September 2008). \"From macro- to microcirculation: benefits in hypertension and diabetes\". Journal of Hypertension. 26 (Suppl 3): S15–21. doi:10.1097/01.hjh.0000334602.71005.52. PMID 19363848.\n- Murphy BP, Stanton T, Dunn FG (May 2009). \"Hypertension and myocardial ischemia\". The Medical Clinics of North America. 93 (3): 681–95. doi:10.1016/j.mcna.2009.02.003. hdl:10072/411754. PMID 19427499. Retrieved 20 June 2009.\n- White WB (May 2009). \"Defining the problem of treating the patient with hypertension and arthritis pain\". The American Journal of Medicine. 122 (5 Suppl): S3–9. doi:10.1016/j.amjmed.2009.03.002. PMID 19393824.\n- Truong LD, Shen SS, Park MH, Krishnan B (February 2009). \"Diagnosing nonneoplastic lesions in nephrectomy specimens\". Archives of Pathology & Laboratory Medicine. 133 (2): 189–200. doi:10.5858/133.2.189. PMID 19195963. Retrieved 20 June 2009.\n- Tracy RE, White S (February 2002). \"A method for quantifying adrenocortical nodular hyperplasia at autopsy: some use of the method in illuminating hypertension and atherosclerosis\". Annals of Diagnostic Pathology. 6 (1): 20–9. doi:10.1053/adpa.2002.30606. PMID 11842376.\n- Aronow WS (August 2008). \"Hypertension and the older diabetic\". Clinics in Geriatric Medicine. 24 (3): 489–501, vi–vii. doi:10.1016/j.cger.2008.03.001. PMID 18672184. Retrieved 20 June 2009.\n- Gardner AW, Afaq A (2008). \"Management of Lower Extremity Peripheral Arterial Disease\". Journal of Cardiopulmonary Rehabilitation and Prevention. 28 (6): 349–57. doi:10.1097/HCR.0b013e31818c3b96. PMC 2743684. PMID 19008688.\n- Novo S, Lunetta M, Evola S, Novo G (January 2009). \"Role of ARBs in the blood hypertension therapy and prevention of cardiovascular events\". Current Drug Targets. 10 (1): 20–5. doi:10.2174/138945009787122897. PMID 19149532. Archived from the original on 12 January 2013. Retrieved 20 June 2009.\n- Craig WM (1939). \"Surgical Treatment of Hypertension\". Br Med J. 2 (4120): 1215–9. doi:10.1136/bmj.2.4120.1215. PMC 2178707. PMID 20782854.\n- Sneader, Walter (2005). Drug Discovery. A History. New York: Wiley. p. 371.\n- Beyer KH (1993). \"Chlorothiazide. How the thiazides evolved as antihypertensive therapy\". Hypertension. 22 (3): 388–91. doi:10.1161/01.hyp.22.3.388. PMID 8349332.\n- Borhani NO, Hechter HH (1964). \"Recent Changes in CVR Disease Mortality in California: An Epidemiologic Appraisal\". Public Health Rep. 79 (2): 147–60. doi:10.2307/4592077. JSTOR 4592077. PMC 1915335. PMID 14119789.\n- \"The Lasker Foundation - Awards\". Archived from the original on 23 December 2015. Retrieved 24 February 2022.\n- Wright, James M.; Musini, Vijaya M.; Gill, Rupam (18 April 2018). \"First-line drugs for hypertension\". The Cochrane Database of Systematic Reviews. 2018 (4) CD001841. doi:10.1002/14651858.CD001841.pub3. ISSN 1469-493X. PMC 6513559. PMID 29667175.\n- Stason WB, Cannon PJ, Heinemann HO, Laragh JH (November 1966). \"Furosemide. A clinical evaluation of its diuretic action\". Circulation. 34 (5): 910–20. doi:10.1161/01.cir.34.5.910. PMID 5332332. S2CID 886870.\n- Black JW, Crowther AF, Shanks RG, Smith LH, Dornhorst AC (1964). \"A new adrenergic betareceptor antagonist\". The Lancet. 283 (7342): 1080–1081. doi:10.1016/S0140-6736(64)91275-9. PMID 14132613.\n- Lv J, Perkovic V, Foote CV, Craig ME, Craig JC, Strippoli GF (2012). \"Antihypertensive agents for preventing diabetic kidney disease\". Cochrane Database Syst Rev. 12 (8) CD004136. doi:10.1002/14651858.CD004136.pub3. PMC 11357690. PMID 23235603.\n- \"A brief history of the birth control pill - The pill timeline | Need to Know\". PBS. 7 May 2010. Archived from the original on 19 January 2018. Retrieved 8 September 2017.\n- Magazine, Smithsonian. \"Why the Oral Contraceptive Is Just Known as \"The Pill\". Smithsonian Magazine. smithsonianmag.com. Archived from the original on 28 April 2021. Retrieved 24 February 2022.\n- \"BBC News | HEALTH | A short history of the pill\". Archived from the original on 6 July 2021. Retrieved 24 February 2022.\n- \"FDA's Approval of the First Oral Contraceptive, Enovid\". Food and Drug Administration. Archived from the original on 23 July 2017. Retrieved 16 December 2019.\n- Cafe, Rebecca (4 December 2011). \"How the contraceptive pill changed Britain\". BBC News. Archived from the original on 16 June 2019. Retrieved 21 June 2018.\n- \"Brochure: The History of Drug Regulation in the United States\". Food and Drug Administration. Archived from the original on 23 July 2017. Retrieved 16 December 2019.\n- Tobert, Jonathan A. (July 2003). \"Lovastatin and beyond: the history of the HMG-CoA reductase inhibitors\". Nature Reviews Drug Discovery. 2 (7): 517–526. doi:10.1038/nrd1112. ISSN 1474-1776. PMID 12815379. S2CID 3344720.\n- Endo A (1 November 1992). \"The discovery and development of HMG-CoA reductase inhibitors\". Journal of Lipid Research. 33 (11): 1569–82. doi:10.1016/S0022-2275(20)41379-3. PMID 1464741.\n- Endo, Akira (2004). \"The origin of the statins\". International Congress Series. 1262: 3–8. doi:10.1016/j.ics.2003.12.099.\n- Scandinaviansimvastatinsurvival (November 1994). \"Randomised trial of cholesterol lowering in 4444 patients with coronary heart disease: the Scandinavian Simvastatin Survival Study (4S)\". Lancet. 344 (8934): 1383–9. doi:10.1016/S0140-6736(94)90566-5. PMID 7968073. S2CID 5965882.\n- \"National Inventors Hall of Fame Honors 2012 Inductees\". PRNewswire. Archived from the original on 12 May 2014. Retrieved 11 May 2014.\n- \"How One Scientist Intrigued by Molds Found First Statin\". Wall Street Journal. Archived from the original on 24 February 2022. Retrieved 11 May 2014.\n- \"Top Global Pharmaceutical Company Report - The Pharma 1000\" (PDF). Torreya. Retrieved 19 August 2022.\n- \"Top Global Pharmaceutical Company Report\" (PDF). The Pharma 1000. November 2021. Retrieved 29 December 2022.\n- Alvarado, Delilah; Pagliarulo, Ned (8 January 2024). \"Year of biotech layoffs leaves industry looking for spark\". BioPharma Dive. Retrieved 10 January 2024.\n- Bell, Jacob (20 December 2022). \"Biotech M&A is picking back up. Here are the latest deal\". BiopharmaDive. Archived from the original on 24 December 2022. Retrieved 23 December 2022.\n- \"Annual Impact Report\". Tufts Center for the Study of Drug Development. Archived from the original on 3 February 2022. Retrieved 24 February 2022.\n- \"The Pharmaceutical Industry in Figures Key Data 2021\" (PDF). European Federation of Pharmaceutical Industries and Associations. Retrieved 30 April 2022.\n- Outsourcing-Pharma.com (25 May 2011). \"Pfizer teams with Parexel and Icon in CRO sector's latest strategic deals\". Outsourcing-Pharma.com. Archived from the original on 11 October 2013. Retrieved 24 February 2022.\n- \"How Many New Drugs Did FDA Approve Last Year?\". pharmalot.com. Archived from the original on 8 May 2011. Retrieved 23 April 2011.\n- \"Research\". Archived from the original on 20 July 2011. Retrieved 24 November 2006.\n- Perry, Susan (8 August 2012). \"Donald Light and Joel Lexchin in BMJ 2012;345:e4348, quoted in: Big Pharma's claim of an 'innovation crisis' is a myth, BMJ authors say\". MinnPost. Archived from the original on 11 August 2012. Retrieved 8 August 2012.\n- \"About PhRMA\". Archived from the original on 4 January 2013. Retrieved 23 April 2011.\n- \"Has the Pharmaceutical Blockbuster Model Gone Bust?\". bain.com. Archived from the original on 24 March 2016. Retrieved 19 May 2016.\n- Harper, Matthew (10 February 2012). \"The Truly Staggering Cost Of Inventing New Drugs\". Forbes. Archived from the original on 9 December 2020. Retrieved 8 September 2017.\n- IMS Health (18 June 2015). \"Are European biotechnology companies sufficiently protected?\". Portal of Competitive Intelligence. Archived from the original on 30 June 2015. Retrieved 27 June 2015.\n- Liberti L, McAuslane JN, Walker S (2011). \"Standardizing the Benefit-Risk Assessment of New Medicines: Practical Applications of Frameworks for the Pharmaceutical Healthcare Professional\". Pharm Med. 25 (3): 139–46. doi:10.1007/BF03256855. S2CID 45729390. Archived from the original on 6 February 2012. Retrieved 18 October 2011.\n- \"Electronic Orange Book\". U.S. Food and Drug Administration. Archived from the original on 7 April 2020. Retrieved 31 May 2007.\n- \"The Orphan Drug Act (as amended)\". U.S. Food and Drug Administration. Archived from the original on 7 April 2020. Retrieved 24 September 2007.\n- \"The top 20 pharma companies by 2024 revenue\". 21 April 2025.\n- \"Standardseite der Domain www.vfa.de\" (PDF). Archived from the original (PDF) on 11 August 2016. Retrieved 24 March 2008.\n- Herper, Matthew & Kang, Peter (22 March 2006). \"The World's Ten Best-Selling Drugs\". Forbes. Archived from the original on 5 May 2006. Retrieved 31 May 2007.\n- \"Creating Connected Solutions for Better Healthcare Performance\". IMS Health. Archived from the original (PDF) on 10 May 2020. Retrieved 23 February 2022.\n- Kollewe, Julia (27 March 2014). \"World's 10 bestselling prescription drugs made $75bn last year\". the Guardian. Archived from the original on 7 April 2020. Retrieved 12 December 2016.\n- \"Top 100 Drugs for 2013 by Sales - U.S. Pharmaceutical Statistics\". Archived from the original on 31 March 2014. Retrieved 23 January 2018.\n- \"IMS Health Forecasts 5 to 6 Percent Growth for Global Pharmaceutical Market in 2007\". IMS Health. 24 October 2006. Archived from the original on 3 May 2011. Retrieved 19 June 2007.\n- World Intellectual Property Organization. Frequently Asked Questions: Patents\n- \"New Drug Approvals in 2006\" (PDF). March 2007. Archived from the original (PDF) on 28 February 2008. Retrieved 23 February 2008.\n- \"Assessment of Authorized Generics in the U.S\" (PDF). IMS Consulting. June 2006. Archived from the original (PDF) on 28 February 2008. Retrieved 23 February 2008.\n- \"Sanofi Laying Off 1,700 in US\". Drug Discovery & Development. Archived from the original on 11 September 2011. Retrieved 24 February 2022.\n- \"2007 Health and Nutrition - Census\" (PDF). U.S. Census Bureau. Archived (PDF) from the original on 31 July 2020. Retrieved 19 May 2016.\n- Goldacre, Ben (2014). Bad pharma: how drug companies mislead doctors and harm patients (First American Paperback ed.). Macmillan. ISBN 978-0-86547-806-0.\n- \"Bumper Year for Corporate Donations Reveals Profit Motives\". corpwatch.org. Archived from the original on 11 November 2017. Retrieved 24 February 2022.\n- \"Merk\". Archived from the original on 26 August 2006. Retrieved 30 August 2006.\n- \"Pfizer Will Donate Fluconazole to South Africa\". Archived from the original on 24 October 2010. Retrieved 30 August 2006.\n- \"Corporate Responsibility: Novartis\". novartis.com. Archived from the original on 1 September 2017. Retrieved 19 May 2016.\n- Kaufman, Marc (6 May 2005). \"Merck CEO Resigns as Drug Probe Continues\". Washington Post. Archived from the original on 9 November 2020. Retrieved 23 May 2007.\n- \"Drug Lobby Second to None: How the pharmaceutical industry gets its way in Washington\". publicintegrity.org. 7 July 2005. Archived from the original on 9 June 2007. Retrieved 23 May 2007.\n- Moynihan, R. (29 May 2003). \"Drug company sponsorship of education could be replaced at a fraction of its cost\". BMJ. 326 (7400): 1163. doi:10.1136/bmj.326.7400.1163. PMC 1126044. PMID 12775595.\n- \"Dr. No Free Lunch\". Mother Jones. Archived from the original on 16 November 2020. Retrieved 19 May 2016.\n- Moynihan, Ray; Cassels, Alan (2005). Selling Sickness: How the Drug Companies are Turning Us All into Patients. Crows Nest, N.S.W.: Allen & Unwin. ISBN 978-1-74114-579-3.\n- \"A Collection of Articles on Disease Mongering\". Public Library of Science. Archived from the original on 7 June 2007. Retrieved 23 May 2007.\n- \"Pharmaceutical Market Research, Trends And Analysis Reports\". literated.com. Archived from the original on 19 January 2016. Retrieved 17 January 2016.\n- Buchkowsky, SS; Jewesson, PJ (April 2004). \"Industry sponsorship and authorship of clinical trials over 20 years\". Ann Pharmacother. 38 (4): 579–85. doi:10.1345/aph.1D267. PMID 14982982. S2CID 43544256.\n- Perlis RH, Perlis CS, Wu Y, Hwang C, Joseph M, Nierenberg AA (October 2005). \"Industry sponsorship and financial conflict of interest in the reporting of clinical trials in psychiatry\". Am J Psychiatry. 162 (10): 1957–60. doi:10.1176/appi.ajp.162.10.1957. PMID 16199844.\n- Tungaraza, T; Poole, R (July 2007). \"Influence of drug company authorship and sponsorship on drug trial outcomes\". Br J Psychiatry. 191 (1): 82–3. doi:10.1192/bjp.bp.106.024547. PMID 17602130.\n- Healy, D (2006). \"The Latest Mania: Selling Bipolar Disorder\". PLOS Med. 3 (4) e185. doi:10.1371/journal.pmed.0030185. PMC 1434505. PMID 16597178.\n- Cosgrove, Lisa; Krimsky, Sheldon; Vijayaraghavan, Manisha; Schneider, Lisa (2006). \"Financial Ties between DSM-IV Panel Members and the Pharmaceutical Industry\". Psychotherapy and Psychosomatics. 75 (3): 154–160. doi:10.1159/000091772. PMID 16636630. S2CID 11909535.\n- \"Open Payments\". February 2019. Archived from the original on 22 February 2022. Retrieved 24 February 2022.\n- Lipton, Eric; Thomas, Katie (29 May 2017). \"Drug Lobbyists' Battle Cry Over Prices: Blame the Others\". New York Times. Archived from the original on 20 November 2020. Retrieved 30 May 2017.\n- Morgan, Steven G.; Bathula, Hannah S.; Moon, Suerie (2020). \"Pricing of pharmaceuticals is becoming a major challenge for health systems\". BMJ. 368 l4627. doi:10.1136/bmj.l4627. PMID 31932289. S2CID 210192662. Archived from the original on 27 November 2020. Retrieved 14 November 2020.\n- \"High Drug Prices and Patient Costs: Millions of Lives and Billions of Dollars Lost\". www.cidsa.org. West Health Council for Informed Drug Spending Analysis. 18 November 2020. Retrieved 20 February 2023.\n- Goldacre, Ben (2014). Bad pharma: how drug companies mislead doctors and harm patients (First American Paperback ed.). Macmillan. pp. 123–124. ISBN 978-0-86547-806-0.\n- \"Archived copy\" (PDF). Office of Science and Technology Policy. Archived (PDF) from the original on 21 January 2017. Retrieved 1 March 2021 – via National Archives.\n{{cite web}}\n: CS1 maint: archived copy as title (link) - \"Financial Crimes to the Public Report 2006\". FBI. 2006. Archived from the original on 29 May 2016. Retrieved 28 July 2016.\n- \"FBI-Health Care Fraud\". FBI. Archived from the original on 2 July 2016. Retrieved 28 July 2016.\n- \"Department of Justice\". Department of Justice. 19 March 2015. Archived from the original on 9 November 2014. Retrieved 22 November 2020.\n- Wilson, Duff (2 October 2010). \"Side Effects May Include Lawsuits\". The New York Times. Archived from the original on 23 June 2017. Retrieved 25 February 2017.\n- \"GlaxoSmithKline\". BBC News. 4 July 2012. Archived from the original on 17 November 2020. Retrieved 21 June 2018.\n- \"GlaxoSmithKline Agrees to Pay $3 Billion in U.S. Drug Settlement\". Bloomberg. 2 July 2012. Archived from the original on 14 May 2014. Retrieved 11 March 2017.\n- Mogul, Fred (2 July 2012). \"NY to Get Millions in GlaxoSmithKlein Settlement\". WNYC. Archived from the original on 19 April 2013. Retrieved 2 July 2012.\n- \"BBC News -GlaxoSmithKline to pay $3bn in US drug fraud scandal\". BBC Online. 2 July 2012. Archived from the original on 17 November 2020. Retrieved 2 July 2012.\n- Thomas, Katie & Schmidt, Michael S. (2 July 2012). \"Glaxo Agrees to Pay $3 Billion in Fraud Settlement\". The New York Times. Archived from the original on 2 March 2017. Retrieved 3 July 2012.\n- \"Rapidly Increasing Criminal and Civil Penalties Against the Pharmaceutical Industry: 1991-2010\". citizen.org. Archived from the original on 16 May 2016. Retrieved 19 May 2016.\n- Thomas, Katie; Schmidt, Michael S. (2 July 2012). \"GlaxoSmithKline Agrees to Pay $3 Billion in Fraud Settlement\". The New York Times. Archived from the original on 12 November 2020. Retrieved 25 February 2017.\n- \"GlaxoSmithKline to Plead Guilty and Pay $3 Billion to Resolve Fraud Allegations and Failure to Report Safety Data\". 2 July 2012. Archived from the original on 9 September 2014. Retrieved 22 November 2020.\n- \"Justice Department Announces Largest Health Care Fraud\" (PDF). US department of Justice. Archived (PDF) from the original on 2 December 2020. Retrieved 19 May 2016.\n- \"Abbott Labs to Pay $1.5 Billion to Resolve Criminal & Civil Investigations of Off-label Promotion of Depakote\". 7 May 2012. Archived from the original on 21 August 2014. Retrieved 22 November 2020.\n- \"#09-038: Eli Lilly and Company Agrees to Pay $1.415 Billion to Resolve Allegationsof Off-label Promotion of Zyprexa (2009-01-15)\". Archived from the original on 13 March 2016. Retrieved 22 November 2020.\n- Drazen, Jeffrey M. (2015). \"Revisiting the Commercial–Academic Interface\". New England Journal of Medicine. 372 (19): 1853–1854. doi:10.1056/NEJMe1503623. PMID 25946285.\n- Rosenbaum, Lisa (2015). \"Reconnecting the Dots — Reinterpreting Industry–Physician Relations\". New England Journal of Medicine. 372 (19): 1860–1864. doi:10.1056/NEJMms1502493. PMID 25946288.\n- \"Covid vaccine front-runners: How much they cost, who's bought them and how they're stored\". CNBC. 17 November 2020. Archived from the original on 1 December 2020. Retrieved 2 December 2020.\n- Henninger, Daniel (2 December 2020). \"Opinion | Pharma Deserves the Nobel Peace Prize for the Covid Vaccines\". Wall Street Journal. Archived from the original on 3 February 2021. Retrieved 4 December 2020.\n- \"No profiteering on COVID-19 drugs and vaccines, says MSF\". Médecins Sans Frontières (MSF) International. Archived from the original on 26 November 2021. Retrieved 22 April 2020.\n- Mazzucato, Mariana; Momenghalibaf, Azzi (18 March 2020). \"Drug Companies Will Make a Killing From Coronavirus\". The New York Times. Archived from the original on 23 November 2020. Retrieved 22 April 2020.\n- \"HHS, DOD Collaborate with Regeneron on Large-Scale Manufacturing Demonstration Project of COVID-19 Investigational Therapeutic Treatment\". 6 July 2020. Archived from the original on 18 December 2020. Retrieved 2 December 2020.\n- \"COVID-19 Vaccines\". 12 December 2020. Archived from the original on 19 December 2020. Retrieved 2 December 2020.\n- Lupkin, Sydney (24 March 2020). \"FDA Grants Experimental Coronavirus Drug Benefits For Rare Disease Treatments\". NPR. Archived from the original on 14 December 2020. Retrieved 24 March 2020.\n- Conley, Julia (24 March 2020). \". Common Dreams. Archived from the original on 8 December 2020. Retrieved 22 April 2020.\n- Boodman, Eric (18 May 2020). \"Gilead ups its donation of the Covid-19 drug remdesivir for U.S. hospitals\". statnews.com. Archived from the original on 20 December 2020. Retrieved 19 July 2020.\n- Lawson, Alex (25 March 2020). \"Don't Let Big Pharma Make a Killing by Profiteering Off COVID-19 Treatments\". Common Dreams. Archived from the original on 9 November 2020. Retrieved 22 April 2020.\n- \"Gilead Sciences Statement on Expanding Global Supply of Investigational Antiviral Remdesivir | Gilead\". Archived from the original on 11 December 2020. Retrieved 16 July 2020.\n- See for example 't Hoen, Ellen. \"TRIPS, Pharmaceutical Patents, and Access to Essential Medicines: A Long Way from Seattle to Doha\". Chicago Journal of International Law, 27(43), 2002; Musungu, Sisule F., and Cecilia Oh. \"The Use of Flexibilities in TRIPS by Developing Countries: Can They Provide Access to Medicines?\" Commission on Intellectual Property Rights, Innovation and Public Health, The World Health Organization, 2005.\n- \"Declaration on the TRIPS agreement and public health\". World Trade Organization. Archived from the original on 20 June 2016. Retrieved 19 May 2016.\n- Pharmaceutical Manufacturer's Association v. The President of South Africa (PMA), 2002 (2) SA 674 (CC) (S. Africa).\n- Helfer, Laurence R.; Austin, Graeme W. (7 March 2011). Human Rights and Intellectual Property: Mapping the Global Interface. Cambridge University Press. pp. 145–148. ISBN 978-1-139-49691-9. Archived from the original on 16 November 2020. Retrieved 28 July 2016.\n- \"GlaxoSmithKline to 'drop patents in poor countries for better drug access'. BBC News. Archived from the original on 9 November 2020. Retrieved 19 May 2016.\n- Quotations related to Pharmaceutical industry at Wikiquote\n- \"Global Medicines Use in 2020\". IMS Institute for Healthcare Informatics. November 2015.\n- \"The pharmaceutical industry and global health – Facts & figures 2017\" (PDF). International Federation of Pharmaceutical Manufacturers & Associations. February 2017. Archived from the original (PDF) on 12 December 2020. Retrieved 18 November 2020.\n- \"Licensing Agreements in the Pharmaceutical Industry\".\n- \"The Pharmaceutical Industry in Figures – Key Data 2018\" (PDF). European Federation of Pharmaceutical Industries and Associations.",
    "public utility": "A public utility company (usually just utility) is an organization that maintains the infrastructure for a public service (often also providing a service using that infrastructure). Public utilities are subject to forms of public control and regulation ranging from local community-based groups to statewide government monopolies.\nPublic utilities are meant to supply goods and services that are considered essential; water, gas, electricity, telephone, waste disposal, and other communication systems represent much of the public utility market. The transmission lines used in the transportation of electricity, or natural gas pipelines, have natural monopoly characteristics. A monopoly can occur when it finds the best way to minimize its costs through economies of scale to the point where other companies cannot compete with it.[1] If the infrastructure already exists in a given area, minimal benefit is gained through competing. In other words, these industries are characterized by economies of scale in production.[2] Though it can be mentioned that these natural monopolies are handled or watched by a public utilities commission, or an institution that represents the government.[1]\nThere are many different types of public utilities. Some, especially large companies, offer multiple products, such as electricity and natural gas. Other companies specialize in one specific product, such as water. Modern public utilities may also be partially (or completely) sourced from clean and renewable energy in order to produce sustainable electricity. Of these, wind turbines and solar panels are those used most frequently.\nWhether broadband internet access should be a public utility is a question that was being discussed with the rise of internet usage. This is a question that was being asked due to the telephone service being considered a public utility. Since arguably broadband internet access has taken over telephone service, perhaps it should be a public utility. The Federal Communications Commission (FCC) in the United States in 2015 made their stance on this issue clear.[1] Due to the telephone service having been considered a public utility, the FCC made broadband internet access a public utility in the United States.[1]\nPublic utilities have historically been considered to be a natural monopoly. This school of thought holds that the most cost-efficient way of doing business is through a single firm because these are capital-intensive businesses with unusually large economies of scale and high fixed costs associated with building and operating the infrastructure, e.g. power plants, telephone lines and water treatment facilities.[3] However, over the past several decades, traditional public utilities' monopoly position has eroded. For instance, wholesale electricity generation markets, electric transmission networks,[4] electricity retailing and customer choice,[5] telecommunications, some types of public transit and postal services have become competitive in some countries and the trend towards liberalization, deregulation and privatization of public utilities is growing. However, the infrastructure used to distribute most utility products and services has remained largely monopolistic.[citation needed]\nKey players in the public utility sector include:[6]\n- Generators produce or collect the specific product to be used by customers: for example, electricity or water.\n- Network operators (grid operators, regional network operators, and distribution network operators) sell access to their networks to retail service providers, who deliver the product to the end user.\n- Traders and marketers buy and sell the actual product and create further complex structured products, combined services and derivatives products. Depending on the product structure, these companies may provide utilities and businesses with a reliable supply of a product like electricity at a stable, predictable price, or a shorter term supply at a more volatile price.\n- Service providers and retailers are the last segment in the supply chain, selling directly to the final consumer. In some markets, final consumers can choose their own retail service provider.\nPublic utilities must pursue the following objective given the social responsibility their services attribute to them:\n- Ensuring services are of the highest quality and responsive to the needs and wishes of patients;\n- Ensuring that health services are effectively targeted so as to improve the health of local populations;\n- Improving the efficiency of the services so the volume of well-targeted effective services is the widest, given the available resources.[7]\nThe management of public utilities continues to be important for local and general governments. By creating, expanding, and improving upon public utilities, a governmental body may attempt to improve its image or attract investment. Traditionally, public services have been provided by public legal entities, which operate much like corporations, but differ in that profit is not necessary for a functional business. A significant factor in government ownership has been to reduce the risk that an activity, if left to private initiative, may be considered not sufficiently profitable and neglected. Many utilities are essential for human life, national defense, or commerce, and the risk of public harm with mismanagement is considerably greater than with other goods. The principle of universality of utilities maintains that these services are best owned by, and operating for, the public. The government and the society itself would like to see these services being economically accessible to all or most of the population. Furthermore, other economic reasons based the idea: public services need huge investments in infrastructures, crucial for competitiveness but with a slow return of capital; last, technical difficulties can occur in the management of plurality of networks, example in the city subsoil.[7]\nPublic pressure for renewable energy as a replacement for legacy fossil fuel power has steadily increased since the 1980s. As the technology needed to source the necessary amount of energy from renewable sources is still under study, public energy policy has been focused on short term alternatives such as natural gas (which still produces substantial carbon dioxide) or nuclear power. In 2021 a power and utilities industry outlook report by Deloitte identified a number of trends for the utilities industry:\n- Enhanced competition, sparked by regulations such as FERC's Order 2222 that open up the market to smaller, innovative firms using renewable energy sources, like wind or solar power\n- Expansions in infrastructure, to manage new renewable energy sources\n- Greater electrification of transportation, and longer-range batteries for cars and trucks\n- Oil companies and other traditional-energy players entering the renewable-energy field\n- A greater emphasis on disaster readiness[8]\nIssues faced by public utilities include:\n- Service area: regulators need to balance the economic needs of the companies and the social equity needed to guarantee to everyone the access to primary services.\n- Autonomy: Economic efficiency requires that markets be left to work by themselves with little intervention. Such instances are often not equitable for some consumers that might be priced out of the market.\n- Pricing: Equity requires that all citizens get the service at a fair price.[9]\nAlternative pricing methods include:[citation needed]\n- Average production costs: the utility calculates the break-even point and then set the prices equal to average costs. The equity issue is basically overcome since most of the market is being served. As a defect regulated firms do not have incentives to minimize costs.\n- Rate of return regulation: regulators let the firms set and charge any price, as long as the rate of return on invested capital does not exceed a certain rate. This method is flexible and allows for pricing freedom, forcing regulators to monitor prices. The drawback is that this method could lead to overcapitalization. For example, if the rate of return is set at five percent, then the firm can charge a higher price simply by investing more in capital than what it is actually needed (i.e., 5% of $10 million is greater than 5% of $6 million).\n- Price cap regulation: regulators directly set a limit on the maximum price. This method can result in a loss of service area. One benefit of this method is that it gives firms an incentive to seek cost-reducing technologies as a strategy to increase utility profits.\nUtility stocks are considered stable investments because they typically provide regular dividends to shareholders and have more stable demand.[10] Even in periods of economic downturns characterized by low interest rates, such stocks are attractive because dividend yields are usually greater than those of other stocks, so the utility sector is often part of a long-term buy-and-hold strategy.[6]\nUtilities require expensive critical infrastructure which needs regular maintenance and replacement. Consequently, the industry is capital intensive, requiring regular access to the capital markets for external financing. A utility's capital structure may have a significant debt component, which exposes the company to interest rate risk.[11] Should rates rise, the company must offer higher yields to attract bond investors, driving up the utility's interest expenses. If the company's debt load and interest expense becomes too large, its credit rating will deteriorate, further increasing the cost of capital and potentially limiting access to the capital markets.[12]\nPublic utilities in Kazakhstan include heating, water supply, sewerage, electricity and communications systems.\n- They are mainly represented by centralized networks, with the exception of some rural areas.\n- Various types of fuels are used, including coal, natural gas and fuel oil.\n- Many systems need to be upgraded to increase their efficiency and reduce their environmental impact.\n- They provide the population with drinking and industrial water.\n- The sources of water are rivers, lakes and groundwater.\n- The level of water quality in some regions is of concern.\n- It is necessary to increase the efficiency of water resources use and improve water quality.\n- Wastewater is diverted from residential and industrial facilities.\n- The level of wastewater treatment in some regions does not meet modern standards.\n- Sewerage systems need to be expanded and upgraded to protect the environment.\n- It is provided by power plants running on various types of fuels, including coal, natural gas, hydropower and nuclear energy.\n- There are problems with power outages, especially in rural areas.\n- It is necessary to modernize the power grid and increase their efficiency.\n- The heating, water supply and sewerage systems of Kazakhstan, although functioning, require urgent modernization. The technical capabilities of these networks are becoming outdated, which leads to an increase in operating costs and a decrease in their reliability.\nA report by the European Bank for Reconstruction and Development (EBRD) notes that additional investments are needed to improve the efficiency and reliability of these systems.[13]\nThe analysis conducted by the EBRD revealed a number of problems faced by heating, water supply and sewerage systems in Kazakhstan.\n- Outdated technologies: In many cases, the infrastructure has exhausted its resource and needs to be replaced.\n- Low energy efficiency: Existing systems consume a lot of energy, which leads to unjustified costs.\n- Unreliability: Worn-out networks often fail, which leads to interruptions in the supply of water and heat, as well as leaks.\nThe report also provides examples of cities where networks are being upgraded with the support of the EBRD. These projects demonstrate how the introduction of modern technologies can improve the efficiency, reliability and environmental friendliness of heating, water supply and sewerage systems.\nUpgrading infrastructure is not just a matter of convenience. It is of vital importance for public health, environmental protection and ensuring the sustainable development of the economy of Kazakhstan.\nIn most cases, public utilities in Kazakhstan are state-owned, which means that their activities are directly regulated by akimats. This creates a system with an administrative nature of relations, where the authorities have the authority to issue mandatory instructions for these companies.\nProponents of such a system emphasize that it allows the authorities to directly influence the commercial activities of public utilities, ensuring their compliance with state interests. This can be expressed in:\n- Tariff control: Akimats can set tariffs for housing and communal services, making them accessible to the public.\n- Ensuring the quality of services: The State can influence the standards of service by ensuring the provision of public services of appropriate quality.\n- Implementation of social programs: Public utilities can participate in social programs aimed at supporting vulnerable segments of the population.\nHowever, such a system has its drawbacks. Excessive government intervention can lead to:\n- Reduced efficiency: Bureaucratic procedures and restrictions in decision-making can slow down the work of enterprises and hinder the introduction of innovations.\n- Unreasonable expenses: Administrative barriers and inefficient management can lead to an increase in inappropriate expenses.\n- Limiting investments: The uncertainty of government policy and the risks of interference from akimats may deter potential investors.\nResource efficiency:\nDespite these limitations, utilities within the framework of this system can demonstrate high efficiency in the use of labor resources and management costs.[13]\nResidents of Kazakhstan receive water, sewerage and heating from companies recognized by the state as natural monopolies. This means that there is no competition in these areas, and tariffs are set by a special state body – the Committee for Regulation of Natural Monopolies, Competition and Consumer Protection (CRNM and CP).[14][15]\nIn order to ensure the smooth operation of public utilities, the state also controls the investment programs of monopolistic companies. This is handled by the Committee on Construction and Housing and Communal Services. Such a system allows you to regulate prices for utilities and direct investments to infrastructure development.[16] However, this system also has its disadvantages. For example, the lack of competition can lead to a decrease in the efficiency of monopolistic companies.\nTo protect the interests of consumers from unjustified overpricing and substandard service, there are special regulatory bodies whose powers are regulated by the Law \"On Natural Monopolies\" and other regulatory acts.\nMain functions:\n- Investment promotion: Development of tariff calculation methods that are attractive to both consumers and private investors interested in investing in the modernization of public infrastructure.[17]\n- Control over the use of funds from IFIs: Determining the specifics of regulating the activities of natural monopolies that attract financing from international financial institutions (IFIs). This allows you to track the intended use of borrowed funds.[18]\n- Formation of a transparent tariff policy: Establishment of rules obliging monopolistic companies to publicly disclose information about tariffs, as well as infrastructure development plans.[19]\n- Analysis of investment programs: Evaluation of investment programs of natural monopolies, approval of development plans and control over their implementation.[20]\nInteraction at different levels:\nIt is important to note that the powers to regulate the activities of natural monopolies are distributed between federal and local authorities. Effective coordination of their actions is necessary to ensure coordinated work and achieve common goals.\nAs a result, the activities of the regulatory authorities of natural monopolies are aimed at ensuring a balance between the interests of consumers, utility companies and the state.\n2017 was marked by a new round of cooperation between Kazakhstan and the European Bank for Reconstruction and Development (EBRD). The parties signed a three-year agreement with the aim of working together to modernize the country's infrastructure.\nAs part of this agreement, the EBRD will allocate funds for the implementation of a number of important projects aimed at:\n- Improving urban infrastructure: Upgrading water supply, sewerage, heating and other vital facilities will be a priority.\n- Optimization of customs procedures: Joint efforts will be made to simplify customs processes, which should lead to stimulating trade and accelerating economic growth.\nIn addition to these two key areas, the EBRD will continue to support other initiatives aimed at improving the well-being of citizens of Kazakhstan.[13]\nIn the United Kingdom and Ireland, the state, private firms, and charities ran the traditional public utilities. For instance, the Sanitary Districts were established in England and Wales in 1875 and in Ireland in 1878.[citation needed]\nThe term can refer to the set of services provided by various organizations that are used in everyday life by the public, such as: electricity generation, electricity retailing, electricity supplies, natural gas supplies, water supplies, sewage works, sewage systems and broadband internet services.[21] They are regulated by Ofgem, Ofwat, Ofcom, the Water Industry Commission for Scotland and the Utility Regulator in the United Kingdom, and the Commission for Regulation of Utilities and the Commission for Communications Regulation in the Republic of Ireland. Disabled community transport services may occasionally be included within the definition. They were mostly privatised in the UK during the 1980s.\nThe first public utility in the United States was a grist mill erected on Mother Brook in Dedham, Massachusetts, in 1640.[22]\nIn the U.S., public utilities provide services at the consumer level, be it residential, commercial, or industrial consumer. Utilities, merchant power producers and very large consumers buy and sell bulk electricity at the wholesale level through a network of regional transmission organizations (RTO) and independent system operators (ISO) within one of three grids, the Eastern Interconnection, the Texas Interconnection, which is a single ISO, and the Western Interconnection.[citation needed]\nU.S. utilities historically operated with a high degree of financial leverage and low interest coverage ratios compared to industrial companies. Investors accepted these credit characteristics because of the regulation of the industry and the belief that there was minimal bankruptcy risk because of the essential services they provide. In recent decades several high-profile utility company bankruptcies have challenged this perception.[23]\nPublic utilities were historically regarded as natural monopolies because the infrastructure required to produce and deliver a product such as electricity or water is very expensive to build and maintain. Once assets such as power plants or transmission lines are in place, the cost of adding another customer is small, and duplication of facilities would be wasteful.[24] As a result, utilities were either government monopolies, or if investor-owned, regulated by a public utilities commission.[25][26]\nIn the electric utility industry, the monopoly approach began to change in the 1990s. In 1996, the Federal Energy Regulatory Commission (FERC) issued its Order No. 888, which mandated that electric utilities open access to their transmission systems to enhance competition and \"functionally unbundle\" their transmission service from their other operations. The order also promoted the role of an independent system operator to manage power flow on the electric grid.[27][28] Later, FERC Order No. 889 established an electronic information system called OASIS (open access same-time information system) which would give new users of transmission lines access to the same information available to the owner of the network.[29] The result of these and other regulatory rulings was the eventual restructuring of the traditional monopoly-regulated regime to one in which all bulk power sellers could compete. A further step in industry restructuring, \"customer choice\", followed in some 19 states, giving retail electric customers the option to be served by non-utility retail power marketers.[30][31][32]\nPublic utilities can be privately owned or publicly owned. Publicly owned utilities include cooperative and municipal utilities. Municipal utilities may actually include territories outside of city limits or may not even serve the entire city. Cooperative utilities are owned by the customers they serve. They are usually found in rural areas. Publicly owned utilities are non-profit.[citation needed] Private utilities, also called investor-owned utilities, are owned by investors,[33][34][35] and operate for profit, often referred to as a rate of return.\nA public utilities commission is a governmental agency in a particular jurisdiction that regulates the commercial activities related to associated electric, natural gas, telecommunications, water, railroad, rail transit, and/or passenger transportation companies. For example, the California Public Utilities Commission (CPUC)[36] and the Public Utility Commission of Texas regulate the utility companies in California and Texas, respectively, on behalf of their citizens and ratepayers (customers). These public utility commissions (PUCs) are typically composed of commissioners, who are appointed by their respective governors, and dedicated staff that implement and enforce rules and regulations, approve or deny rate increases, and monitor/report on relevant activities.[37]\nRatemaking practice in the U.S. holds that rates paid by a utility's customers should be set at a level which assures that the utility can provide reliable service at reasonable cost.[38]\nOver the years, various changes have dramatically re-shaped the mission and focus of many public utility commissions. Their focus has typically shifted from the up-front regulation of rates and services to the oversight of competitive marketplaces and enforcement of regulatory compliance.[citation needed]\n- Building block model, form of public utility regulation common in Australia\n- Public utility building\n- \"What is a public utility? Definition and meaning\". Market Business News. Retrieved 2023-04-25.\n- \"Public Utility | Encyclopedia.com\". www.encyclopedia.com. Retrieved 2021-04-27.\n- Ulbrich, Holley H. (1991). \"Natural Monopoly in Principles Textbooks: A Pedagogical Note\". The Journal of Economic Education. 22 (2 (Spring 1991)): 179–182. doi:10.1080/00220485.1991.10844706. JSTOR 1182423.\n- \"FERC Order 888\".\n- Clark, Doug (5 November 2019). \"Electricity customer choice program participation examined (Nov, 15, 2019)\". Daily Energy Insider. Retrieved 14 May 2021.\n- Murphy, Chris B. \"How the Utilities Sector is Used by Investors for Dividends and Safety\". Investopedia.\n- Gilardoni, A (2015). Public Utilities e Infrastrutture. Profili economici e gestionali. Agici.\n- \"2021 Power and Utilities Industry Outlook\". Deloitte United States. Retrieved 2021-04-29.\n- Yescombe, E. R.; Farquharson, Edward (2018). Public-Private Partnerships for Infrastructure. Elsevier Science. ISBN 9780081007662.[page needed]\n- Murphy, Chris B. \"How the Utilities Sector is Used by Investors for Dividends and Safety\". Investopedia. Retrieved 2021-04-27.\n- \"Utilities Sector Definition & Meaning in Stock Market with Example\". kalkinemedia.com. Retrieved December 14, 2022.\n- Berg, Sanford, Tschirhart (1998). natural monopoly regulation. Cambridge University.\n{{cite book}}\n: CS1 maint: multiple names: authors list (link)[page needed] - \"Commercialising the utilities sector in Kazakhstan\" (PDF). European Bank for Reconstruction and Development.\n- \"О естественных монополиях - ИПС \"Әділет\". adilet.zan.kz. Retrieved 2024-04-26.\n- \"Об утверждении Положения о Комитете по регулированию естественных монополий, защите конкуренции и прав потребителей Министерства национальной экономики Республики Казахстан и признании утратившими силу некоторых приказов Министра национальной экономики Республики Казахстан - ИПС \"Әділет\". adilet.zan.kz. Retrieved 2024-04-26.\n- \"Об утверждении Положения республиканского государственного учреждения \"Комитет по делам строительства и жилищно-коммунального хозяйства Министерства по инвестициям и развитию Республики Казахстан\" - ИПС \"Әділет\". adilet.zan.kz. Retrieved 2024-04-26.\n- \"Об утверждении Методики расчета тарифа с учетом стимулирующих методов тарифообразования - ИПС \"Әділет\". adilet.zan.kz. Retrieved 2024-04-26.\n- \"Об утверждении Особого порядка регулирования деятельности субъектов естественных монополий, привлекающих займы международных финансовых организаций и входящих в перечень субъектов естественных монополий, привлекающих займы международных финансовых организаций - ИПС \"Әділет\". adilet.zan.kz. Retrieved 2024-04-26.\n- \"Об утверждении Правил утверждения тарифов (цен, ставок сборов) и тарифных смет на регулируемые услуги (товары, работы) субъектов естественных монополий - ИПС \"Әділет\". adilet.zan.kz. Retrieved 2024-04-26.\n- \"Об утверждении Правил утверждения инвестиционных программ (проектов) субъекта естественной монополии, их корректировки, а также проведения анализа информации об их исполнении - ИПС \"Әділет\". adilet.zan.kz. Retrieved 2024-04-26.\n- \"Utilities Websites\". Uk250.co.uk. Archived from the original on 2011-11-04. Retrieved 2011-10-11.\n- \"Where Growth Centers\". The Salina Evening Journal. Salina, Kansas. November 6, 1922. p. 13. Archived from the original on April 2, 2015. Retrieved March 17, 2015 – via Newspapers.com.\n- Howe, Jane Tripp (1997). Handbook of Fixed Income Securities; Frank J. Fabozzi, editor (Fifth ed.). New York NY: McGraw-Hill. pp. 392–393. ISBN 0-7863-1095-2.\n- Tomain, Joseph; Cudahy, Richard (2004). Energy Law in a Nutshell. St. Paul, Minnesota: West Publishing Company. pp. 120–121. ISBN 0-314-15058-7.\n- \"Public utility - Definition\". Merriam-Webster Dictionary. Archived from the original on 2011-11-05. Retrieved 2011-10-11.\n- \"public utility definition\". Investorwords.com. Archived from the original on 2011-09-28. Retrieved 2011-10-11.\n- Melvin, Jasmin (26 February 2021). \"Former FERC, DOE officials mull Texas, climate, transmission policy quandaries (28 Feb 2021)\". S&P Global Platts. Retrieved 15 May 2021.\n- \"Order No. 888\". Federal Energy Regulatory Commission. Retrieved 14 May 2021.\n- Tomain and Cudahy op cit. pp. 278–279.\n- Clark, Doug (5 November 2019). \"Electricity customer choice program participation examined (Nov, 5, 2019)\". Daily Energy Insider. Retrieved 14 May 2021.\n- \"Can electric utility customers choose their electricity supplier?\". U.S. Energy Information Administration. Retrieved 14 May 2021.\n- \"Participation in electricity customer choice programs has remained unchanged since 2013\". U.S. Energy Information Administration. Retrieved 14 May 2021.\n- \"investor-owned utility (IOU), private utility, private power company\". www.energyvortex.com. Archived from the original on 2 February 2017. Retrieved 8 May 2018.\n- \"Electric Utilities\". www.utilityconnection.com. Archived from the original on 27 October 2017. Retrieved 8 May 2018.\n- Pentland, William. \"Investor-Owned Utilities: Asleep at the Switch or Above the Law?\". forbes.com. Archived from the original on 29 July 2017. Retrieved 8 May 2018.\n- \"California Public Utilities Commission\". Cpuc.ca.gov. 2007-03-23. Archived from the original on 2011-10-10. Retrieved 2011-10-11.\n- \"Public Utilities Commission of Texas\". Public Utilities Commission of Texas. Archived from the original on 14 August 2012. Retrieved 17 February 2017.\n- Louiselle, Bruce M. and Heilman, Jane E. (1982). \"The Case for the Use of an Appropriate Capital Structure in Utility Ratemaking: The General Rule Versus Minnesota\". William Mitchell Law Review, Mitchell Hamline School of Law. 8 (2): 426. Retrieved 12 May 2021.\n{{cite journal}}\n: CS1 maint: multiple names: authors list (link)",
    "radio": "Radio is the technology of communicating using radio waves.[1][2][3] Radio waves are electromagnetic waves of frequency between 3 hertz (Hz) and 300 gigahertz (GHz). They are generated by an electronic device called a transmitter connected to an antenna which radiates the waves. They can be received by other antennas connected to a radio receiver; this is the fundamental principle of radio communication. In addition to communication, radio is used for radar, radio navigation, remote control, remote sensing, and other applications.\nIn radio communication, used in radio and television broadcasting, cell phones, two-way radios, wireless networking, and satellite communication, among numerous other uses, radio waves are used to carry information across space from a transmitter to a receiver, by modulating the radio signal (impressing an information signal on the radio wave by varying some aspect of the wave) in the transmitter. In radar, used to locate and track objects like aircraft, ships, spacecraft and missiles, a beam of radio waves emitted by a radar transmitter reflects off the target object, and the reflected waves reveal the object's location to a receiver that is typically colocated with the transmitter. In radio navigation systems such as GPS and VOR, a mobile navigation instrument receives radio signals from multiple navigational radio beacons whose position is known, and by precisely measuring the arrival time of the radio waves the receiver can calculate its position on Earth. In wireless radio remote control devices like drones, garage door openers, and keyless entry systems, radio signals transmitted from a controller device control the actions of a remote device.\nThe existence of radio waves was first proven by German physicist Heinrich Hertz on 11 November 1886.[4] In the mid-1890s, building on techniques physicists were using to study electromagnetic waves, Italian physicist Guglielmo Marconi developed the first apparatus for long-distance radio communication,[5] sending a wireless Morse Code message to a recipient over a kilometer away in 1895,[6] and the first transatlantic signal on 12 December 1901.[7] The first commercial radio broadcast was transmitted on 2 November 1920, when the live returns of the 1920 United States presidential election were broadcast by Westinghouse Electric and Manufacturing Company in Pittsburgh, under the call sign KDKA.[8]\nThe emission of radio waves is regulated by law, coordinated by the International Telecommunication Union (ITU), which allocates frequency bands in the radio spectrum for various uses.\nThe word radio is derived from the Latin word radius, meaning \"spoke of a wheel, beam of light, ray.\" It was first applied to communications in 1881 when, at the suggestion of French scientist Ernest Mercadier , Alexander Graham Bell adopted radiophone (meaning \"radiated sound\") as an alternate name for his photophone optical transmission system.[9][10]\nFollowing Hertz's discovery of the existence of radio waves in 1886, the term Hertzian waves was initially used for this radiation.[11] The first practical radio communication systems, developed by Marconi in 1894–1895, transmitted telegraph signals by radio waves,[4] so radio communication was first called wireless telegraphy. Up until about 1910 the term wireless telegraphy also included a variety of other experimental systems for transmitting telegraph signals without wires, including electrostatic induction, electromagnetic induction and aquatic and earth conduction, so there was a need for a more precise term referring exclusively to electromagnetic radiation.[12][13]\nThe French physicist Édouard Branly, who in 1890 developed the radio wave detecting coherer, called it in French a radio-conducteur.[14][15] The radio- prefix was later used to form additional descriptive compound and hyphenated words, especially in Europe. For example, in early 1898 the British publication The Practical Engineer included a reference to the radiotelegraph and radiotelegraphy.[14][16]\nThe use of radio as a standalone word dates back to at least 30 December 1904, when instructions issued by the British Post Office for transmitting telegrams specified that \"The word 'Radio'... is sent in the Service Instructions.\"[14][17] This practice was universally adopted, and the word \"radio\" introduced internationally, by the 1906 Berlin Radiotelegraphic Convention, which included a Service Regulation specifying that \"Radiotelegrams shall show in the preamble that the service is 'Radio'\".[14]\nThe switch to radio in place of wireless took place slowly and unevenly in the English-speaking world. Lee de Forest helped popularize the new word in the United States—in early 1907, he founded the DeForest Radio Telephone Company, and his letter in the 22 June 1907 Electrical World about the need for legal restrictions warned that \"Radio chaos will certainly be the result until such stringent regulation is enforced.\"[18] The United States Navy would also play a role. Although its translation of the 1906 Berlin Convention used the terms wireless telegraph and wireless telegram, by 1912 it began to promote the use of radio instead. The term started to become preferred by the general public in the 1920s with the introduction of broadcasting.\nElectromagnetic waves were predicted by James Clerk Maxwell in his 1873 theory of electromagnetism, now called Maxwell's equations, who proposed that a coupled oscillating electric field and magnetic field could travel through space as a wave, and proposed that light consisted of electromagnetic waves of short wavelength. On 11 November 1886, German physicist Heinrich Hertz, attempting to confirm Maxwell's theory, first observed radio waves he generated using a primitive spark-gap transmitter.[4] Experiments by Hertz and physicists Jagadish Chandra Bose, Oliver Lodge, Lord Rayleigh, and Augusto Righi, among others, showed that radio waves like light demonstrated reflection, refraction, diffraction, polarization, standing waves, and traveled at the same speed as light, confirming that both light and radio waves were electromagnetic waves, differing only in frequency.[19] In 1895, Guglielmo Marconi developed the first radio communication system, using a spark-gap transmitter to send Morse code over long distances. By December 1901, he had transmitted across the Atlantic Ocean.[4][5][6][7] Marconi and Karl Ferdinand Braun shared the 1909 Nobel Prize in Physics \"for their contributions to the development of wireless telegraphy\".[20]\nDuring radio's first two decades, called the radiotelegraphy era, the primitive radio transmitters could only transmit pulses of radio waves, not the continuous waves which were needed for audio modulation, so radio was used for person-to-person commercial, diplomatic and military text messaging. Starting around 1908 industrial countries built worldwide networks of powerful transoceanic transmitters to exchange telegram traffic between continents and communicate with their colonies and naval fleets. During World War I the development of continuous wave radio transmitters, rectifying electrolytic, and crystal radio receiver detectors enabled amplitude modulation (AM) radiotelephony to be achieved by Reginald Fessenden and others, allowing audio to be transmitted. On 2 November 1920, the first commercial radio broadcast was transmitted by Westinghouse Electric and Manufacturing Company in Pittsburgh, under the call sign KDKA featuring live coverage of the 1920 United States presidential election.[8]\nRadio waves are radiated by electric charges undergoing acceleration.[21][22] They are generated artificially by time-varying electric currents, consisting of electrons flowing back and forth in a metal conductor called an antenna.[23][24]\nAs they travel farther from the transmitting antenna, radio waves spread out so their signal strength (intensity in watts per square meter) decreases (see Inverse-square law), so radio transmissions can only be received within a limited range of the transmitter, the distance depending on the transmitter power, the antenna radiation pattern, receiver sensitivity, background noise level, and presence of obstructions between transmitter and receiver. An omnidirectional antenna transmits or receives radio waves in all directions, while a directional antenna transmits radio waves in a beam in a particular direction, or receives waves from only one direction.[25][26][27][28]\nRadio waves travel at the speed of light in vacuum[29] and at slightly lower velocity in air.[30]\nThe other types of electromagnetic waves besides radio waves, infrared, visible light, ultraviolet, X-rays and gamma rays, can also carry information and be used for communication. The wide use of radio waves for telecommunication is mainly due to their desirable propagation properties stemming from their longer wavelength.[24] Radio waves have the ability to pass through the atmosphere in any weather, foliage, and at longer wavelengths through most building materials. By diffraction, longer wavelengths can bend around obstructions, and unlike other electromagnetic waves they tend to be scattered rather than absorbed by objects larger than their wavelength.\nIn radio communication systems, information is carried across space using radio waves. At the sending end, the information to be sent is converted by some type of transducer to a time-varying electrical signal called the modulation signal.[24][31] The modulation signal may be an audio signal representing sound from a microphone, a video signal representing moving images from a video camera, or a digital signal consisting of a sequence of bits representing binary data from a computer. The modulation signal is applied to a radio transmitter. In the transmitter, an electronic oscillator generates an alternating current oscillating at a radio frequency, called the carrier wave because it serves to generate the radio waves that carry the information through the air. The modulation signal is used to modulate the carrier, varying some aspect of the carrier wave, impressing the information in the modulation signal onto the carrier. Different radio systems use different modulation methods:[32]\n- Amplitude modulation (AM) – in an AM transmitter, the amplitude (strength) of the radio carrier wave is varied by the modulation signal;[32]: 3\n- Frequency modulation (FM) – in an FM transmitter, the frequency of the radio carrier wave is varied by the modulation signal;[32]: 33\n- Frequency-shift keying (FSK) – used in wireless digital devices to transmit digital signals, the frequency of the carrier wave is shifted between frequencies.[32]: 58\n- Orthogonal frequency-division multiplexing (OFDM) – a family of digital modulation methods widely used in high-bandwidth systems such as Wi-Fi networks, cellphones, digital television broadcasting, and digital audio broadcasting (DAB) to transmit digital data using a minimum of radio spectrum bandwidth. It has higher spectral efficiency and more resistance to fading than AM or FM. In OFDM, multiple radio carrier waves closely spaced in frequency are transmitted within the radio channel, with each carrier modulated with bits from the incoming bitstream so multiple bits are being sent simultaneously, in parallel. At the receiver, the carriers are demodulated and the bits are combined in the proper order into one bitstream.[33]\nMany other types of modulation are also used. In some types, the carrier wave is suppressed, and only one or both modulation sidebands are transmitted.[34]\nThe modulated carrier is amplified in the transmitter and applied to a transmitting antenna which radiates the energy as radio waves. The radio waves carry the information to the receiver location.[35] At the receiver, the radio wave induces a tiny oscillating voltage in the receiving antenna – a weaker replica of the current in the transmitting antenna.[24][31] This voltage is applied to the radio receiver, which amplifies the weak radio signal so it is stronger, then demodulates it, extracting the original modulation signal from the modulated carrier wave. The modulation signal is converted by a transducer back to a human-usable form: an audio signal is converted to sound waves by a loudspeaker or earphones, a video signal is converted to images by a display, while a digital signal is applied to a computer or microprocessor, which interacts with human users.[32]\nThe radio waves from many transmitters pass through the air simultaneously without interfering with each other because each transmitter's radio waves oscillate at a different frequency, measured in hertz (Hz), kilohertz (kHz), megahertz (MHz) or gigahertz (GHz). The receiving antenna typically picks up the radio signals of many transmitters. The receiver uses tuned circuits to select the radio signal desired out of all the signals picked up by the antenna and reject the others. A tuned circuit acts like a resonator, similar to a tuning fork.[31] It has a natural resonant frequency at which it oscillates. The resonant frequency of the receiver's tuned circuit is adjusted by the user to the frequency of the desired radio station; this is called tuning. The oscillating radio signal from the desired station causes the tuned circuit to oscillate in sympathy, and it passes the signal on to the rest of the receiver. Radio signals at other frequencies are blocked by the tuned circuit and not passed on.[36]\nA modulated radio wave, carrying an information signal, occupies a range of frequencies. The information in a radio signal is usually concentrated in narrow frequency bands called sidebands (SB) just above and below the carrier frequency. The width in hertz of the frequency range that the radio signal occupies, the highest frequency minus the lowest frequency, is called its bandwidth (BW).[32][37] For any given signal-to-noise ratio, a given bandwidth can carry the same amount of information regardless of where in the radio frequency spectrum it is located; bandwidth is a measure of information-carrying capacity. The bandwidth required by a radio transmission depends on the data rate of the information being sent, and the spectral efficiency of the modulation method used; how much data it can transmit in each unit of bandwidth. Different types of information signals carried by radio have different data rates. For example, a television signal has a greater data rate than an audio signal.[32][38]\nThe radio spectrum, the total range of radio frequencies that can be used for communication in a given area, is a limited resource.[37][3] Each radio transmission occupies a portion of the total spectrum available. Radio spectrum is regarded as an economic good which has a monetary cost and is in increasing demand. In some parts of the radio spectrum, the right to use a frequency band or even a single radio channel is bought and sold for millions of dollars. So there is an incentive to employ technology to minimize the spectrum used by radio services.[38]\nA slow transition from analog to digital radio transmission technologies began in the late 1990s.[39][40] Part of the reason for this is that digital modulation can transmit more information in a given bandwidth than analog modulation; the modulation itself is more efficient and loss compression further improves efficiency. Digital modulation also has greater noise immunity than analog, associated digital signal processors have more power and flexibility than analog circuits, and a wide variety of information can be transmitted using the same digital modulation.[32]\nBecause it is a fixed resource which is in demand by an increasing number of users, the radio spectrum has become increasingly congested in recent decades, and the need to use it more effectively is driving many additional radio innovations such as trunked radio systems, spread spectrum (ultra-wideband) transmission, frequency reuse, dynamic spectrum management, frequency pooling, and cognitive radio.[38]\nThe ITU arbitrarily divides the radio spectrum into 12 bands, each beginning at a wavelength which is a power of ten (10n) metres, with corresponding frequency of 3 times a power of ten, and each covering a decade of frequency or wavelength.[3][41] Each of these bands has a traditional name:[42]\nBand name Abbreviation Frequency Wavelength Extremely\nlow frequencyELF 3–30 Hz 100,000–10,000 km Super\nlow frequencySLF 30–300 Hz 10,000–1,000 km Ultra\nlow frequencyULF 300–3,000 Hz 1,000–100 km Very\nlow frequencyVLF 3–30 kHz 100–10 km Low\nfrequencyLF 30–300 kHz 10–1 km Medium\nfrequencyMF 300–3,000 kHz 1,000–100 m\nBand name Abbreviation Frequency Wavelength High\nfrequencyHF 3–30 MHz 100–10 m Very\nhigh frequencyVHF 30–300 MHz 10–1 m Ultra\nhigh frequencyUHF 300–3,000 MHz 100–10 cm Super\nhigh frequencySHF 3–30 GHz 10–1 cm Extremely\nhigh frequencyEHF 30–300 GHz 10–1 mm Tremendously\nhigh frequencyTHF 300–3,000 GHz\n(0.3–3.0 THz)1.0–0.1 mm\nIt can be seen that the bandwidth, the absolute range of frequencies, contained in each band is not equal but increases exponentially as the frequency increases; each band contains ten times the bandwidth of the preceding band.[43]\nThough not defined by the ITU,[42] the term tremendously low frequency (TLF) has been used for wavelengths from 1–3 Hz (300,000–100,000 km).[44]\nThe airwaves are a resource shared by many users. Two radio transmitters in the same area that attempt to transmit on the same frequency will interfere with each other, causing garbled reception, often to the extent that neither transmission may be received clearly.[37] Interference with radio transmissions can not only have a large economic cost, but it can also be life-threatening (for example, in the case of interference with emergency communications or air traffic control).[45][46]\nTo prevent interference between different users, the emission of radio waves is strictly regulated by national laws, and coordinated by an international body, the International Telecommunication Union (ITU), which allocates bands in the radio spectrum for different uses.[37][3] Radio transmitters must be licensed by governments, under a variety of license classes depending on use, and are restricted to certain frequencies and power levels. In some classes, such as radio and television broadcasting stations, the transmitter is given a unique identifier consisting of a string of letters and numbers called a call sign, which must be used in all transmissions.[47] In order to adjust, maintain, or internally repair radio transmitters, individuals must hold a government license, such as the general radiotelephone operator license in the US, obtained by taking a test demonstrating adequate technical and legal knowledge of safe radio operation.[48]\nExceptions to the above rules allow the unlicensed operation by the public of low power short-range transmitters in consumer products such as cell phones, cordless phones, wireless devices, walkie-talkies, citizens band radios, wireless microphones, garage door openers, and baby monitors. In the US, these fall under Part 15 of the Federal Communications Commission (FCC) regulations. Many of these devices use the ISM bands, a series of frequency bands throughout the radio spectrum reserved for unlicensed use. Although they can be operated without a license, like all radio equipment, these devices generally must be type-approved before the sale.[49]\nRadio jamming is the deliberate radiation of radio signals designed to interfere with the reception of other radio signals. Jamming devices are called signal suppressors or interference generators or just jammers.[9] During wartime, militaries use jamming to interfere with enemies' tactical radio communication. Since radio waves can pass beyond national borders, some totalitarian countries that practice censorship use jamming to prevent their citizens from listening to broadcasts from radio stations in other countries. Jamming is usually accomplished by a powerful transmitter that generates noise on the same frequency as the target transmitter.[10][11] US Federal law prohibits the nonmilitary operation or sale of any type of jamming devices, including ones that interfere with GPS, cellular, Wi-Fi and police radars.[15]\nRadio has many practical applications, which include broadcasting, voice communication, data communication, radar, radiolocation, and remote control.\n- Electromagnetic radiation and health\n- Internet radio\n- List of radios – List of specific models of radios\n- Outline of radio\n- Radio quiet zone\n- \"Radio\". Oxford Living Dictionaries. Oxford University Press. 2019. Archived from the original on 24 March 2019. Retrieved 26 February 2019.\n- \"Definition of radio\". Encyclopedia. PCMagazine website, Ziff-Davis. 2018. Archived from the original on 24 March 2019. Retrieved 26 February 2019.\n- Ellingson, Steven W. (2016). Radio Systems Engineering. Cambridge University Press. pp. 1–4. ISBN 978-1316785164.\n- \"125 Years Discovery of Electromagnetic Waves\". Karlsruhe Institute of Technology. 16 May 2022. Archived from the original on 14 July 2022. Retrieved 14 July 2022.\n- Bondyopadhyay, Prebir K. (1995) \"Guglielmo Marconi – The father of long distance radio communication – An engineer's tribute\" Archived 2022-10-14 at the Wayback Machine, 25th European Microwave Conference: Volume 2, pp. 879–85\n- \"1890s – 1930s: Radio\". Elon University. Archived from the original on 8 June 2022. Retrieved 14 July 2022.\n- Belrose, John S. (5–7 September 1995). \"Radio's First Message -- Fessenden and Marconi\". Institute of Electrical and Electronics Engineers. Retrieved 6 November 2022.\n- \"History of Commercial Radio\". Federal Communications Commission. 23 October 2020. Archived from the original on 1 January 2022. Retrieved 14 July 2022.\n- \"radio (n.)\". Online Etymology Dictionary. Retrieved 13 July 2022.\n- Bell, Alexander Graham (July 1881). \"Production of Sound by Radiant Energy\". Popular Science Monthly. pp. 329–330.\n[W]e have named the apparatus for the production and reproduction of sound in this way the \"photophone\", because an ordinary beam of light contains the rays which are operative. To avoid in future any misunderstandings upon this point, we have decided to adopt the term \"radiophone\", proposed by M. Mercadier, as a general term signifying the production of sound by any form of radiant energy...\n- Manning, Trevor (2009). Microwave Radio Transmission Design Guide. Artech House. p. 2.\n- Maver, William Jr. (1903). American Telegraphy and Encyclopedia of the Telegraph: Systems, Apparatus, Operation. New York: Maver Publishing Co. p. 333.\nwireless telegraphy.\n- Steuart, William Mott; et al. (1906). Special Reports: Telephones and Telegraphs 1902. Washington D.C.: U.S. Bureau of the Census. pp. 118–119.\n- https://earlyradiohistory.us/sec022.htm Archived 2019-11-15 at the Wayback Machine Thomas H. White, United States Early Radio History, Section 22\n- Collins, A. Frederick (10 May 1902). \"The Genesis of Wireless Telegraphy\". Electrical World and Engineer. p. 811.\n- \"Wireless Telegraphy\". The Practical Engineer. 25 February 1898. p. 174.\nDr. O. J. Lodge, who preceded Marconi in making experiments in what may be called \"ray\" telegraphy or radiotelegraphy by a year or two, has devised a new method of sending and receiving the messages. The reader will understand that in the radiotelegraph electric waves forming the signals of the message starting from the sending instrument and travel in all directions like rays of light from a lamp, only they are invisible.\n- \"Wireless Telegraphy\", The Electrical Review (London), 20 January 1905, page 108, quoting from the British Post Office's 30 December 1904 Post Office Circular.\n- \"Interference with Wireless Messages\", Electrical World, 22 June 1907, page 1270.\n- Sungook Hong (2001), Wireless: From Marconi's Black-box to the Audion, MIT Press, pp. 5–10\n- \"The Nobel Prize in Physics 1909\". NobelPrize.org. 2023. Archived from the original on 31 July 2023. Retrieved 31 July 2023.\n- Kraus, John D. (1988). Antennas (2nd ed.). Tata-McGraw Hill. p. 50. ISBN 0074632191.\n- Serway, Raymond; Faughn, Jerry; Vuille, Chris (2008). College Physics, 8th Ed. Cengage Learning. p. 714. ISBN 978-0495386933.\n- Balanis, Constantine A. (2005). Antenna theory: Analysis and Design, 3rd Ed. John Wiley and Sons. p. 10. ISBN 978-1118585733.\n- Ellingson, Steven W. (2016). Radio Systems Engineering. Cambridge University Press. pp. 16–17. ISBN 978-1316785164.\n- Visser, Hubregt J. (2012). Antenna Theory and Applications. John Wiley & Sons. ISBN 978-1119990253. Retrieved 29 August 2022.\n- Zainah Md Zain; Hamzah Ahmad; Dwi Pebrianti; Mahfuzah Mustafa; Nor Rul Hasma Abdullah; Rosdiyana Samad; Maziyah Mat Noh (2020). Proceedings of the 11th National Technical Seminar on Unmanned System Technology 2019: NUSYS'19. Springer Nature. p. 535. ISBN 978-9811552816. Archived from the original on 2024-10-03. Retrieved 2022-08-27.Extract of pp. 535–536 Archived 2024-10-03 at the Wayback Machine\n- Hurley, Chris; Rogers, Russ; Thornton, Frank; Connelly, Daniel; Baker, Brian (2007). \"Understanding Antennas and Antenna Theory\". WarDriving and Wireless Penetration Testing. pp. 31–61. doi:10.1016/B978-159749111-2/50027-1. ISBN 978-1-59749-111-2.\n- Neely, Matthew; Hamerstone, Alex; Sanyk, Chris (2013). \"Basic Radio Theory and Introduction to Radio Systems\". Wireless Reconnaissance in Penetration Testing. pp. 7–43. doi:10.1016/B978-1-59-749731-2.00002-8. ISBN 978-1-59749-731-2.\n- \"Electromagnetic Radiation\". NASA. Archived from the original on 23 May 2016. Retrieved 18 August 2022.\n- de Podesta, M. (2002). Understanding the Properties of Matter. CRC Press. p. 131. ISBN 978-0-415-25788-6. Archived from the original on 2024-10-03. Retrieved 2024-09-23.\n- Brain, Marshall (7 December 2000). \"How Radio Works\". HowStuffWorks.com. Archived from the original on 2 October 2009. Retrieved 11 September 2009.\n- Faruque, Saleh (2016). Radio Frequency Modulation Made Easy. Springer Publishing. ISBN 978-3319412023. Archived from the original on 3 October 2024. Retrieved 29 August 2022.\n- Ergen, Mustafa (2009). Mobile Broadband. doi:10.1007/978-0-387-68192-4. ISBN 978-0-387-68189-4.[page needed]\n- Tony Dorbuck (ed.), The Radio Amateur's Handbook, Fifty-Fifth Edition, American Radio Relay League, 1977, p. 368\n- John Avison, The World of Physics, Nelson · 2014, page 367\n- C-W and A-M Radio Transmitters and Receivers, United States. Department of the Army – 1952, pp. 167–168\n- \"Spectrum 101\" (PDF). US National Aeronautics and Space Administration (NASA). February 2016. Archived (PDF) from the original on 11 February 2017. Retrieved 2 December 2019.\n- Pogorel, Girard; Chaduc, Jean-Marc (2010). The Radio Spectrum: Managing a Strategic Resource. Wiley). ISBN 978-0470393529. Archived from the original on 3 October 2024. Retrieved 29 August 2022.\n- Norberg, Bob (27 November 2022). \"Digital Radio Is Coming, But Analog Isn't Dead Yet\". The Ledger. Archived from the original on 3 September 2022. Retrieved 3 September 2022.\n- \"Analogue To Digital: Radio Slow To Tune Into Transition\". Financial Express. 13 October 2005. Archived from the original on 3 September 2022. Retrieved 3 September 2022.\n- \"Radio Regulations, 2016 Edition\" (PDF). International Telecommunication Union. 3 November 2016. Archived from the original on 13 December 2021. Retrieved 9 November 2019.\n- Nomenclature of the frequency and wavelength bands used in telecommunications (PDF) (Report). Geneva: International Telecommunications Union. 2015. ITU-R V.431-8. Archived (PDF) from the original on 3 October 2024. Retrieved 6 April 2023.\n- Communications-electronics Management of the Electromagnetic Spectrum (Report). Headquarters, Department of the Army. United States Department of the Army. 1973. p. 2.\n- Duncan, Christopher; Gkountouna, Olga; Mahabir, Ron (2021). \"Theoretical Applications of Magnetic Fields at Tremendously Low Frequency in Remote Sensing and Electronic Activity Classification\". In Arabnia, Hamid R.; Deligiannidis, Leonidas; Shouno, Hayaru; Tinetti, Fernando G.; Tran, Quoc-Nam (eds.). Advances in Computer Vision and Computational Biology. Transactions on Computational Science and Computational Intelligence. Cham: Springer International Publishing. pp. 235–247. doi:10.1007/978-3-030-71051-4_18. ISBN 978-3030710507. S2CID 238934419. Archived from the original on 2024-10-03. Retrieved 2023-04-06.\n- \"Radio Frequency Interference Best Practices Guidebook - CISA - Feb. 2020\" (PDF). Cybersecurity and Infrastructure Security Agency SAFECOM/National Council of Statewide Interoperability Coordinators. USDepartment of Homeland Security. Retrieved 29 August 2022.\n- Mazar (Madjar), Haim (2016). Radio Spectrum Management: Policies, Regulations and Techniques. Wiley. ISBN 978-1118511794. Archived from the original on 3 October 2024. Retrieved 29 August 2022.\n- \"ARTICLE 19 Identification of stations\" (PDF). International Telecommunication Union. Archived (PDF) from the original on 3 October 2024. Retrieved 29 August 2022.\n- \"Commercial Radio Operator Types of Licenses\". Federal Communications Commission. 6 May 2016. Archived from the original on 8 August 2021. Retrieved 29 August 2022.\n- Dichoso, Joe (October 9, 2007). \"FCC Basics of Unlicensed Transmitters\" (PDF). Federal Communications Commission. Archived (PDF) from the original on 29 August 2022. Retrieved 29 August 2022.\n- Basic Radio Principles and Technology – Elsevier Science\n- The Electronics of Radio – Cambridge University Press\n- Radio Systems Engineering – Cambridge University Press\n- Radio-Electronic Transmission Fundamentals – SciTech Publishing\n- Analog Electronics, Analog Circuitry Explained – Elsevier Science\n- \"Radio\". Merriam-Webster.com Dictionary. Merriam-Webster.",
    "rail transport": "Rail transport (also known as train transport) is a means of transport using wheeled vehicles running on tracks, which usually consist of two parallel steel rails.[1] Rail transport is one of the two primary means of land transport, next to road transport. It is used for about 8% of passenger and freight transport globally,[2] thanks to its energy efficiency[2] and potentially high speed. Also, the track spreads the weight of the train which means larger amounts can be carried than with trucks on roads.\n| Part of a series on |\n| Rail transport |\n|---|\n|\n|\n| Infrastructure |\n|\n|\n| Rolling stock |\n|\n|\n| Urban rail transit |\n|\n|\n| Other topics |\n| Transport portal |\nRolling stock on rails generally encounters lower frictional resistance than rubber-tyred road vehicles, allowing rail cars to be coupled into longer trains. Power is usually provided by diesel or electric locomotives. While railway transport is capital-intensive and less flexible than road transport, it can carry heavy loads of passengers and cargo with greater energy efficiency and safety.[a]\nPrecursors of railways driven by human or animal power, have existed since antiquity, but modern rail transport began with the invention of the steam locomotive in the United Kingdom at the beginning of the 19th century. The first passenger railway, the Stockton and Darlington Railway, opened in 1825. The quick spread of railways throughout Europe and North America, following the 1830 opening of the first intercity connection in England, was a key component of the Industrial Revolution. The adoption of rail transport lowered shipping costs compared to transport by water or wagon, and led to \"national markets\" in which prices varied less from city to city.[3][4][5][6][7][8]\nRailroads not only increased the speed of transport, they also dramatically lowered its cost. For example, the first transcontinental railroad in the United States resulted in passengers and freight being able to cross the country in a matter of days instead of months and at one tenth the cost of stagecoach or wagon transport. With economical transportation in the West (which had been referred to as the Great American Desert), now farming, ranching and mining could be done at a profit. As a result, railroads transformed the country, particularly the West (which had few navigable rivers).[9][10][11][12][13][14]\nIn the 1880s, railway electrification began with tramways and rapid transit systems. Starting in the 1940s, steam locomotives were replaced by diesel locomotives. The first high-speed railway system was introduced in Japan in 1964, and high-speed rail lines now connect many cities in Europe, East Asia, and the eastern United States. Following some decline due to competition from cars and aeroplanes, rail transport has had a revival in recent decades due to road congestion and rising fuel prices, as well as governments investing in rail as a means of reducing CO2 emissions.\nSmooth, durable road surfaces have been made for wheeled vehicles since prehistoric times. In some cases, they were narrow and in pairs to support only the wheels. That is, they were wagonways or tracks. Some had grooves or flanges or other mechanical means to keep the wheels on track.\nFor example, evidence indicates that a 6 to 8.5 km long Diolkos paved trackway transported boats across the Isthmus of Corinth in Greece from around 600 BC. The Diolkos was in use for over 650 years, until at least the 1st century AD.[15] Paved trackways were also later built in Roman Egypt.[16]\nIn 1515, Cardinal Matthäus Lang wrote a description of the Reisszug, a funicular railway at the Hohensalzburg Fortress in Austria. The line originally used wooden rails and a hemp haulage rope and was operated by human or animal power, through a treadwheel.[17] The line is still operational, although in updated form and is possibly the oldest operational railway.[18]\nWagonways (or tramways) using wooden rails, hauled by horses, started appearing in the 1550s to facilitate the transport of ore tubs to and from mines and soon became popular in Europe. Such an operation was illustrated in Germany in 1556 by Georgius Agricola in his work De re metallica.[19] This line used \"Hund\" carts with unflanged wheels running on wooden planks and a vertical pin on the truck fitting into the gap between the planks to keep it going the right way. The miners called the wagons Hunde (\"dogs\") from the noise they made on the tracks.[20]\nThere are many references to their use in central Europe in the 16th century.[21] Such a transport system was later used by German miners at Caldbeck, Cumbria, England, perhaps from the 1560s.[22] A wagonway was built at Prescot, near Liverpool, sometime around 1600, possibly as early as 1594. Owned by Philip Layton, the line carried coal from a pit near Prescot Hall to a terminus about one-half mile (800 m) away.[23] A funicular railway was also made at Broseley in Shropshire some time before 1604. This carried coal for James Clifford from his mines down to the River Severn to be loaded onto barges and carried to riverside towns.[24] The Wollaton Wagonway, completed in 1604 by Huntingdon Beaumont, has sometimes erroneously been cited as the earliest British railway. It ran from Strelley to Wollaton near Nottingham.[25]\nThe Middleton Railway in Leeds, which was built in 1758, later became the world's oldest operational railway (other than funiculars), albeit now in an upgraded form. In 1764, the first railway in the Americas was built in Lewiston, New York.[26]\nIn the late 1760s, the Coalbrookdale Company began to fix plates of cast iron to the upper surface of the wooden rails. This allowed a variation of gauge to be used. At first only balloon loops could be used for turning, but later, movable points were taken into use that allowed for switching.[27]\nA system was introduced in which unflanged wheels ran on L-shaped metal plates, which came to be known as plateways. John Curr, a Sheffield colliery manager, invented this flanged rail in 1787, though the exact date of this is disputed. The plate rail was taken up by Benjamin Outram for wagonways serving his canals, manufacturing them at his Butterley ironworks. In 1803, William Jessop opened the Surrey Iron Railway, a double track plateway, erroneously sometimes cited as world's first public railway, in south London.[28]\nWilliam Jessop had earlier used a form of all-iron edge rail and flanged wheels successfully for an extension to the Charnwood Forest Canal at Nanpantan, Loughborough, Leicestershire in 1789. In 1790, Jessop and his partner Outram began to manufacture edge rails. Jessop became a partner in the Butterley Company in 1790. The first public edgeway (thus also first public railway) built was Lake Lock Rail Road in 1796. Although the primary purpose of the line was to carry coal, it also carried passengers.\nThese two systems of constructing iron railways, the \"L\" plate-rail and the smooth edge-rail, continued to exist side by side until well into the early 19th century. The flanged wheel and edge-rail eventually proved its superiority and became the standard for railways.\nCast iron used in rails proved unsatisfactory because it was brittle and broke under heavy loads. The wrought iron invented by John Birkinshaw in 1820 replaced cast iron. Wrought iron, usually simply referred to as \"iron\", was a ductile material that could undergo considerable deformation before breaking, making it more suitable for iron rails. But iron was expensive to produce until Henry Cort patented the puddling process in 1784. In 1783 Cort also patented the rolling process, which was 15 times faster at consolidating and shaping iron than hammering.[29] These processes greatly lowered the cost of producing iron and rails. The next important development in iron production was hot blast developed by James Beaumont Neilson (patented 1828), which considerably reduced the amount of coke (fuel) or charcoal needed to produce pig iron.[30] Wrought iron was a soft material that contained slag or dross. The softness and dross tended to make iron rails distort and delaminate and they lasted less than 10 years. Sometimes they lasted as little as one year under high traffic. All these developments in the production of iron eventually led to the replacement of composite wood/iron rails with superior all-iron rails. The introduction of the Bessemer process, enabling steel to be made inexpensively, led to the era of great expansion of railways that began in the late 1860s. Steel rails lasted several times longer than iron.[31][32][33] Steel rails made heavier locomotives possible, allowing for longer trains and improving the productivity of railroads.[34] The Bessemer process introduced nitrogen into the steel, which caused the steel to become brittle with age. The open hearth furnace began to replace the Bessemer process near the end of the 19th century, improving the quality of steel and further reducing costs. Thus steel completely replaced the use of iron in rails, becoming standard for all railways.\nThe first passenger horsecar or tram, Swansea and Mumbles Railway, was opened between Swansea and Mumbles in Wales in 1807.[35] Horses remained the preferable mode for tram transport even after the arrival of steam engines until the end of the 19th century, because they were cleaner compared to steam-driven trams which caused smoke in city streets.\nIn 1784, James Watt, a Scottish inventor and mechanical engineer, patented a design for a steam locomotive. Watt had improved the steam engine of Thomas Newcomen, hitherto used to pump water out of mines, and developed a reciprocating engine in 1769 capable of powering a wheel. This was a large stationary engine, powering cotton mills and a variety of machinery; the state of boiler technology necessitated the use of low-pressure steam acting upon a vacuum in the cylinder, which required a separate condenser and an air pump. Nevertheless, as the construction of boilers improved, Watt investigated the use of high-pressure steam acting directly upon a piston, raising the possibility of a smaller engine that might be used to power a vehicle. Following his patent, Watt's employee William Murdoch produced a working model of a self-propelled steam carriage in that year.[36]\nThe first full-scale working railway steam locomotive was built in the United Kingdom in 1804 by Richard Trevithick, a British engineer born in Cornwall. This used high-pressure steam to drive the engine by one power stroke. The transmission system employed a large flywheel to even out the action of the piston rod. On 21 February 1804, the world's first steam-powered railway journey took place when Trevithick's unnamed steam locomotive hauled a train along the tramway of the Penydarren ironworks, near Merthyr Tydfil in South Wales.[37][38] Trevithick later demonstrated a locomotive operating upon a piece of circular rail track in Bloomsbury, London, the Catch Me Who Can, but never got beyond the experimental stage with railway locomotives, not least because his engines were too heavy for the cast-iron plateway track then in use.[39]\nThe first commercially successful steam locomotive was Matthew Murray's rack locomotive Salamanca built for the Middleton Railway in Leeds in 1812. This twin-cylinder locomotive was light enough to not break the edge-rails track and solved the problem of adhesion by a cog-wheel using teeth cast on the side of one of the rails. Thus it was also the first rack railway.\nThis was followed in 1813 by the locomotive Puffing Billy built by Christopher Blackett and William Hedley for the Wylam Colliery Railway, the first successful locomotive running by adhesion only. This was accomplished by the distribution of weight between a number of wheels. Puffing Billy is now on display in the Science Museum in London, and is the oldest locomotive in existence.[40][41]\nIn 1814, George Stephenson, inspired by the early locomotives of Trevithick, Murray and Hedley, persuaded the manager of the Killingworth colliery where he worked to allow him to build a steam-powered machine. Stephenson played a pivotal role in the development and widespread adoption of the steam locomotive. His designs considerably improved on the work of the earlier pioneers. He built the locomotive Blücher, also a successful flanged-wheel adhesion locomotive. In 1825 he built the locomotive Locomotion for the Stockton and Darlington Railway in the northeast of England, which became the first public steam railway in the world in 1825, although it used both horse power and steam power on different runs. In 1829, he built the locomotive Rocket, which entered in and won the Rainhill Trials. This success led to Stephenson establishing his company as the pre-eminent builder of steam locomotives for railways in Great Britain and Ireland, the United States, and much of Europe.[42]: 24–30 The first public railway which used only steam locomotives, all the time, was Liverpool and Manchester Railway, built in 1830.[43]\nSteam power continued to be the dominant power system in railways around the world for more than a century.\nThe first known electric locomotive was built in 1837 by chemist Robert Davidson of Aberdeen in Scotland, and it was powered by galvanic cells (batteries). Thus it was also the earliest battery-electric locomotive. Davidson later built a larger locomotive named Galvani, exhibited at the Royal Scottish Society of Arts Exhibition in 1841. The seven-ton vehicle had two direct-drive reluctance motors, with fixed electromagnets acting on iron bars attached to a wooden cylinder on each axle, and simple commutators. It hauled a load of six tons at four miles per hour (6 kilometres per hour) for a distance of one and a half miles (2.4 kilometres). It was tested on the Edinburgh and Glasgow Railway in September of the following year, but the limited power from batteries prevented its general use. It was destroyed by railway workers, who saw it as a threat to their job security.[44][45][46] By the middle of the nineteenth century most european countries had military uses for railways.[47]\nWerner von Siemens demonstrated an electric railway in 1879 in Berlin. The world's first electric tram line, Gross-Lichterfelde Tramway, opened in Lichterfelde near Berlin, Germany, in 1881. It was built by Siemens. The tram ran on 180 volts DC, which was supplied by running rails. In 1891 the track was equipped with an overhead wire and the line was extended to Berlin-Lichterfelde West station. The Volk's Electric Railway opened in 1883 in Brighton, England. The railway is still operational, thus making it the oldest operational electric railway in the world. Also in 1883, Mödling and Hinterbrühl Tram opened near Vienna in Austria. It was the first tram line in the world in regular service powered from an overhead line. Five years later, in the US electric trolleys were pioneered in 1888 on the Richmond Union Passenger Railway, using equipment designed by Frank J. Sprague.[48]\nThe first use of electrification on a main line was on a four-mile section of the Baltimore Belt Line of the Baltimore and Ohio Railroad (B&O) in 1895 connecting the main portion of the B&O to the new line to New York through a series of tunnels around the edges of Baltimore's downtown. Electricity quickly became the power supply of choice for subways, abetted by the Sprague's invention of multiple-unit train control in 1897. By the early 1900s most street railways were electrified.\nThe London Underground, the world's oldest underground railway, opened in 1863, and it began operating electric services using a fourth rail system in 1890 on the City and South London Railway, now part of the London Underground Northern line. This was the first major railway to use electric traction. The world's first deep-level electric railway, it runs from the City of London, under the River Thames, to Stockwell in south London.[49]\nThe first practical AC electric locomotive was designed by Charles Brown, then working for Oerlikon, Zürich. In 1891, Brown had demonstrated long-distance power transmission, using three-phase AC, between a hydro-electric plant at Lauffen am Neckar and Frankfurt am Main West, a distance of 280 km (170 mi). Using experience he had gained while working for Jean Heilmann on steam–electric locomotive designs, Brown observed that three-phase motors had a higher power-to-weight ratio than DC motors and, because of the absence of a commutator, were simpler to manufacture and maintain.[b] However, they were much larger than the DC motors of the time and could not be mounted in underfloor bogies: they could only be carried within locomotive bodies.[51]\nIn 1894, Hungarian engineer Kálmán Kandó developed a new type 3-phase asynchronous electric drive motors and generators for electric locomotives. Kandó's early 1894 designs were first applied in a short three-phase AC tramway in Évian-les-Bains (France), which was constructed between 1896 and 1898.[52][53]\nIn 1896, Oerlikon installed the first commercial example of the system on the Lugano Tramway. Each 30-tonne locomotive had two 110 kW (150 hp) motors run by three-phase 750 V 40 Hz fed from double overhead lines. Three-phase motors run at a constant speed and provide regenerative braking, and are well suited to steeply graded routes, and the first main-line three-phase locomotives were supplied by Brown (by then in partnership with Walter Boveri) in 1899 on the 40 km Burgdorf–Thun line, Switzerland.\nItalian railways were the first in the world to introduce electric traction for the entire length of a main line rather than a short section. The 106 km Valtellina line was opened on 4 September 1902, designed by Kandó and a team from the Ganz works.[54][55] The electrical system was three-phase at 3 kV 15 Hz. In 1918,[56] Kandó invented and developed the rotary phase converter, enabling electric locomotives to use three-phase motors whilst supplied via a single overhead wire, carrying the simple industrial frequency (50 Hz) single phase AC of the high-voltage national networks.[55]\nAn important contribution to the wider adoption of AC traction came from SNCF of France after World War II. The company conducted trials at AC 50 Hz, and established it as a standard. Following SNCF's successful trials, 50 Hz, now also called industrial frequency was adopted as standard for main-lines across the world.[57]\nEarliest recorded examples of an internal combustion engine for railway use included a prototype designed by William Dent Priestman. Sir William Thomson examined it in 1888 and described it as a \"Priestman oil engine mounted upon a truck which is worked on a temporary line of rails to show the adaptation of a petroleum engine for locomotive purposes.\"[58][59] In 1894, a 20 hp (15 kW) two axle machine built by Priestman Brothers was used on the Hull Docks.[60]\nIn 1906, Rudolf Diesel, Adolf Klose and the steam and diesel engine manufacturer Gebrüder Sulzer founded Diesel-Sulzer-Klose GmbH to manufacture diesel-powered locomotives. Sulzer had been manufacturing diesel engines since 1898. The Prussian State Railways ordered a diesel locomotive from the company in 1909. The world's first diesel-powered locomotive was operated in the summer of 1912 on the Winterthur–Romanshorn railway in Switzerland, but was not a commercial success.[61] The locomotive weight was 95 tonnes and the power was 883 kW with a maximum speed of 100 km/h (62 mph).[62] Small numbers of prototype diesel locomotives were produced in a number of countries through the mid-1920s. The Soviet Union operated three experimental units of different designs since late 1925, though only one of them (the E el-2) proved technically viable.[63]\nA significant breakthrough occurred in 1914, when Hermann Lemp, a General Electric electrical engineer, developed and patented a reliable direct current electrical control system (subsequent improvements were also patented by Lemp).[64] Lemp's design used a single lever to control both engine and generator in a coordinated fashion, and was the prototype for all diesel–electric locomotive control systems. In 1914, world's first functional diesel–electric railcars were produced for the Königlich-Sächsische Staatseisenbahnen (Royal Saxon State Railways) by Waggonfabrik Rastatt with electric equipment from Brown, Boveri & Cie and diesel engines from Swiss Sulzer AG. They were classified as DET 1 and DET 2 (de.wiki). The first regular used diesel–electric locomotives were switcher (shunter) locomotives. General Electric produced several small switching locomotives in the 1930s (the famous \"44-tonner\" switcher was introduced in 1940) Westinghouse Electric and Baldwin collaborated to build switching locomotives starting in 1929.\nIn 1929, the Canadian National Railways became the first North American railway to use diesels in mainline service with two units, 9000 and 9001, from Westinghouse.[65]\nAlthough steam and diesel services reaching speeds up to 200 km/h (120 mph) were started before the 1960s in Europe, they were not very successful.\nThe first electrified high-speed rail Tōkaidō Shinkansen was introduced in 1964 between Tokyo and Osaka in Japan. Since then high-speed rail transport, functioning at speeds up to and above 300 km/h (190 mph), has been built in Japan, Spain, France, Germany, Italy, the People's Republic of China, Taiwan (Republic of China), the United Kingdom, South Korea, Scandinavia, Belgium and the Netherlands. The construction of many of these lines has resulted in the dramatic decline of short-haul flights and automotive traffic between connected cities, such as the London–Paris–Brussels corridor, Madrid–Barcelona, Milan–Rome–Naples, as well as many other major lines.[citation needed]\nHigh-speed trains normally operate on standard gauge tracks of continuously welded rail on grade-separated right-of-way that incorporates a large turning radius in its design. While high-speed rail is most often designed for passenger travel, some high-speed systems also offer freight service.\nSince 1980, rail transport has changed dramatically, but a number of heritage railways continue to operate as part of living history to preserve and maintain old railway lines for services of tourist trains.\nA train is a connected series of rail vehicles that move along the track, most commonly through adhesion traction. Propulsion for the train is provided by a separate locomotive or from individual motors in self-propelled multiple units. Most trains carry a revenue load, although non-revenue cars exist for the railway's own use, such as for maintenance-of-way purposes. The engine driver (engineer in North America) controls the locomotive or other power cars, although people movers and some rapid transits are under automatic control.\nTraditionally, trains are pulled using a locomotive. This involves one or more powered vehicles being located at the front of the train, providing sufficient tractive force to haul the weight of the full train. This arrangement remains dominant for freight trains and is often used for passenger trains. A push–pull train has the end passenger car equipped with a driver's cab so that the engine driver can remotely control the locomotive. This allows one of the locomotive-hauled train's drawbacks to be removed, since the locomotive need not be moved to the front of the train each time the train changes direction. A railroad car is a vehicle used for the haulage of either passengers or freight.\nA multiple unit has powered wheels throughout the whole train. These are used for rapid transit and tram systems, as well as many both short- and long-haul passenger trains. A railcar is a single, self-powered car, and may be electrically propelled or powered by a diesel engine. Multiple units have a driver's cab at each end of the unit, and were developed following the ability to build electric motors and other engines small enough to fit under the coach. There are only a few freight multiple units, most of which are high-speed post trains.\nSteam locomotives are locomotives with a steam engine that provides adhesion. Coal, petroleum, or wood is burned in a firebox, boiling water in the boiler to create pressurized steam. The steam travels through the smokebox before leaving via the chimney or smoke stack. In the process, it powers a piston that transmits power directly through a connecting rod (US: main rod) and a crankpin (US: wristpin) on the driving wheel (US main driver) or to a crank on a driving axle. Steam locomotives have been phased out in most parts of the world for economical and safety reasons, although many are preserved in working order by heritage railways.\nElectric locomotives draw power from a stationary source via an overhead wire or third rail. Some also or instead use a battery. In locomotives that are powered by high-voltage alternating current, a transformer in the locomotive converts the high-voltage low-current power to low-voltage high current used in the traction motors that power the wheels. Modern locomotives may use three-phase AC induction motors or direct current motors. Under certain conditions, electric locomotives are the most powerful traction.[citation needed] They are also the cheapest to run and provide less noise and no local air pollution.[citation needed] However, they require high capital investments both for the overhead lines and the supporting infrastructure, as well as the generating station that is needed to produce electricity. Accordingly, electric traction is used on urban systems, lines with high traffic and for high-speed rail.[citation needed]\nDiesel locomotives use a diesel engine as the prime mover. The energy transmission may be either diesel–electric, diesel-mechanical or diesel–hydraulic but diesel–electric is dominant. Electro-diesel locomotives are built to run as diesel–electric on unelectrified sections and as electric locomotives on electrified sections.[citation needed]\nAlternative methods of motive power include magnetic levitation, horse-drawn, cable, rack and pinion, gravity, pneumatics and gas turbine.[citation needed]\nA passenger train stops at stations where passengers may embark and disembark. The oversight of the train is the duty of a guard/train manager/conductor. Passenger trains are part of public transport and often make up the stem of the service, with buses feeding to stations. Passenger trains provide long-distance intercity travel, daily commuter trips, or local urban transit services, operating with a diversity of vehicles, operating speeds, right-of-way requirements, and service frequency (in Europe, operaters use train categories accordingly). Service frequencies are often expressed as a number of trains per hour (tph).[66] Passenger trains can usually be into two types of operation, intercity railway and intracity transit. Whereas intercity railway involve higher speeds, longer routes, and lower frequency (usually scheduled), intracity transit involves lower speeds, shorter routes, and higher frequency (especially during peak hours).[67]\nIntercity trains are long-haul trains that operate with few stops between cities. Trains typically have amenities such as a dining car. Some lines also provide over-night services with sleeping cars. Some long-haul trains have been given a specific name. Regional trains are medium distance trains that connect cities with outlying, surrounding areas, or provide a regional service, making more stops and having lower speeds. Commuter trains serve suburbs of urban areas, providing a daily commuting service. Airport rail links provide quick access from city centres to airports.\nHigh-speed rail are special inter-city trains that operate at much higher speeds than conventional railways, the limit being regarded at 200 to 350 kilometres per hour (120 to 220 mph). High-speed trains are used mostly for long-haul service and most systems are in Western Europe and East Asia. Magnetic levitation trains such as the Shanghai maglev train use under-riding magnets which attract themselves upward towards the underside of a guideway and this line has achieved somewhat higher peak speeds in day-to-day operation than conventional high-speed railways, although only over short distances. Due to their heightened speeds, route alignments for high-speed rail tend to have broader curves than conventional railways, but may have steeper grades that are more easily climbed by trains with large kinetic energy.\nHigh kinetic energy translates to higher horsepower-to-ton ratios (e.g. 20 horsepower per short ton or 16 kilowatts per tonne); this allows trains to accelerate and maintain higher speeds and negotiate steep grades as momentum builds up and recovered in downgrades (reducing cut and fill and tunnelling requirements). Since lateral forces act on curves, curvatures are designed with the highest possible radius. All these features are dramatically different from freight operations, thus justifying exclusive high-speed rail lines if it is economically feasible.[67]\nHigher-speed rail services are intercity rail services that have top speeds higher than conventional intercity trains but the speeds are not as high as those in the high-speed rail services. These services are provided after improvements to the conventional rail infrastructure to support trains that can operate safely at higher speeds.\nRapid transit refers to systems built in large cities and has the highest capacity of any passenger transport system. It is grade-separated and commonly built underground or elevated. Due to the lack of uniformity of rapid transit systems, route alignment varies, with diverse rights-of-way (private land, side of road, street median) and geometric characteristics (sharp or broad curves, steep or gentle grades). For instance, the Chicago 'L' trains are designed with extremely short cars to negotiate the sharp curves in the Loop. New Jersey's PATH has similar-sized cars to accommodate curves in the trans-Hudson tunnels. San Francisco's BART operates large cars on its routes.[67]\nAt street level, smaller trams can be used. Light rail systems use upgraded tram technology that have their own right-of-way and sometimes sections underground. Monorail systems are elevated, medium-capacity systems. A people mover is a driver-less, grade-separated vehicle that serves only a few stations, often as a shuttle or in a loop. Systems with larger capacity are designated automated guideway transit.\nFreight trains carry cargo using freight cars specialized for the type of goods. Freight trains are very efficient, with economy of scale and high energy efficiency.[68] However, their use can be reduced by lack of flexibility, if there is need of transshipment at both ends of the trip due to lack of tracks to the points of pick-up and delivery. Authorities often encourage the use of cargo rail transport due to its efficiency and to reduce road traffic.[69]\nContainer trains have become widely used in many places for general freight, particularly in North America, where double stacking reduces costs. Containers can easily be transshipped between other modes, such as ships and trucks, and at breaks of gauge. Containers have succeeded the boxcar (wagon-load), where the cargo had to be loaded and unloaded into the train manually. The intermodal containerization of cargo has revolutionized the supply chain logistics industry, reducing shipping costs significantly. In Europe, the sliding wall wagon has largely superseded the ordinary covered wagons. Other types of cars include refrigerator cars, stock cars for livestock and autoracks for road vehicles. When rail is combined with road transport, a roadrailer will allow trailers to be driven onto the train, allowing for easy transition between road and rail.\nBulk handling represents a key advantage for rail transport. Low or even zero transshipment costs combined with energy efficiency and low inventory costs allow trains to handle bulk much cheaper than by road. Typical bulk cargo includes coal, ore, grains and liquids. Bulk is transported in open-topped cars, hopper cars and tank cars.\nRapid transit or mass rapid transit (MRT) or heavy rail,[71][72] commonly referred to as metro, is a type of high-capacity public transport that is generally built in urban areas. A grade separated rapid transit line below ground surface through a tunnel can be regionally called a subway, tube, metro or underground.[73][74][75][76] They are sometimes grade-separated on elevated railways, in which case some are referred to as el trains – short for \"elevated\" – or skytrains. Rapid transit systems are usually electric railways, that unlike buses or trams operate on an exclusive right-of-way, which cannot be accessed by pedestrians or other vehicles.[77]\nModern services on rapid transit systems are provided on designated lines between stations typically using electric multiple units on railway tracks. Some systems use guided rubber tires, magnetic levitation (maglev), or monorail. The stations typically have high platforms, without steps inside the trains, requiring custom-made trains in order to minimize gaps between train and platform. They are typically integrated with other public transport and often operated by the same public transport authorities. Some rapid transit systems have at-grade intersections between a rapid transit line and a road or between two rapid transit lines.[78]\nThe world's first rapid transit system was the partially underground Metropolitan Railway which opened in 1863 using steam locomotives, and now forms part of the London Underground.[79] In 1868, New York opened the elevated West Side and Yonkers Patent Railway, initially a cable-hauled line using stationary steam engines.\nAs of 2021[update], China has the largest number of rapid transit systems in the world – 40 in number,[80] running on over 4,500 km (2,800 mi) of track – and was responsible for most of the world's rapid-transit expansion in the 2010s.[81][82][83] The world's longest single-operator rapid transit system by route length is the Shanghai Metro.[84][85] The world's largest single rapid transit service provider by number of stations (472 stations in total)[86] is the New York City Subway. The busiest rapid transit systems in the world by annual ridership are the Shanghai Metro, Tokyo subway system, Seoul Metro and the Moscow Metro.\nRailway tracks are laid upon land owned or leased by the railway company. Owing to the desirability of maintaining modest grades, in hilly or mountainous terrain rails will often be laid in circuitous routes. Route length and grade requirements can be reduced by the use of alternating cuttings, bridges and tunnels – all of which can greatly increase the capital expenditures required to develop a right-of-way, while significantly reducing operating costs and allowing higher speeds on longer radius curves. In densely urbanized areas, railways are sometimes laid in tunnels to minimize the effects on existing properties.\nTrack consists of two parallel steel rails, anchored perpendicular to members called sleepers (ties) of timber, concrete, steel, or plastic to maintain a consistent distance apart, or rail gauge. Other variations are also possible, such as \"slab track\", in which the rails are fastened to a concrete foundation resting on a prepared subsurface.\nRail gauges are usually categorized as standard gauge (used on approximately 70% of the world's existing railway lines), broad gauge, and narrow gauge.[87] In addition to the rail gauge, the tracks will be laid to conform with a loading gauge which defines the maximum height and width for railway vehicles and their loads to ensure safe passage through bridges, tunnels and other structures.\nThe track guides the conical, flanged wheels, keeping the cars on the track without active steering and therefore allowing trains to be much longer than road vehicles. The rails and ties are usually placed on a foundation made of compressed earth on top of which is placed a bed of ballast to distribute the load from the ties and to prevent the track from buckling as the ground settles over time under the weight of the vehicles passing above.\nThe ballast also serves as a means of drainage. Some more modern track in special areas is attached directly without ballast. Track may be prefabricated or assembled in place. By welding rails together to form lengths of continuous welded rail, additional wear and tear on rolling stock caused by the small surface gap at the joints between rails can be counteracted; this also makes for a quieter ride.\nOn curves, the outer rail may be at a higher level than the inner rail. This is called superelevation or cant. This reduces the forces tending to displace the track and makes for a more comfortable ride for standing livestock and standing or seated passengers. A given amount of superelevation is most effective over a limited range of speeds.\nPoints and switches—also known as turnouts—are the means of directing a train onto a diverging section of track. Laid similar to normal track, a point typically consists of a frog (common crossing), check rails and two switch rails. The switch rails may be moved left or right, under the control of the signalling system, to determine which path the train will follow.\nSpikes in wooden ties can loosen over time, but split and rotten ties may be individually replaced with new wooden ties or concrete substitutes. Concrete ties can also develop cracks or splits, and can also be replaced individually. Should the rails settle due to soil subsidence, they can be lifted by specialized machinery and additional ballast tamped under the ties to level the rails.\nPeriodically, ballast must be removed and replaced with clean ballast to ensure adequate drainage. Culverts and other passages for water must be kept clear lest water is impounded by the trackbed, causing landslips. Where trackbeds are placed along rivers, additional protection is usually placed to prevent streambank erosion during times of high water. Bridges require inspection and maintenance, since they are subject to large surges of stress in a short period of time when a heavy train crosses.\nThe use of different track gauges in different regions of the world, and sometimes within the same country, can impede the movement of passengers and freight. Often elaborate transfer mechanisms are installed where two lines of different gauge meet to facilitate movement across the break of gauge. Countries with multiple gauges in use, such as India and Australia, have invested heavily to unify their rail networks. China is developing a modernized Eurasian Land Bridge to move goods by rail to Western Europe.\nThe inspection of railway equipment is essential for the safe movement of trains. Many types of defect detectors are in use on the world's railroads. These devices use technologies that vary from a simplistic paddle and switch to infrared and laser scanning, and even ultrasonic audio analysis. Their use has avoided many rail accidents over the 70 years they have been used.\nRailway signalling is a system used to control railway traffic safely to prevent trains from colliding. Being guided by fixed rails which generate low friction, trains are uniquely susceptible to collision since they frequently operate at speeds that do not enable them to stop quickly or within the driver's sighting distance; road vehicles, which encounter a higher level of friction between their rubber tyres and the road surface, have much shorter braking distances. Most forms of train control involve movement authority being passed from those responsible for each section of a rail network to the train crew. Not all methods require the use of signals, and some systems are specific to single track railways.\nThe signalling process is traditionally carried out in a signal box, a small building that houses the lever frame required for the signalman to operate switches and signal equipment. These are placed at various intervals along the route of a railway, controlling specified sections of track. More recent technological developments have made such operational doctrine superfluous, with the centralization of signalling operations to regional control rooms. This has been facilitated by the increased use of computers, allowing vast sections of track to be monitored from a single location. The common method of block signalling divides the track into zones guarded by combinations of block signals, operating rules, and automatic-control devices so that only one train may be in a block at any time.\nThe electrification system provides electrical energy to the trains, so they can operate without a prime mover on board. This allows lower operating costs, but requires large capital investments along the lines. Mainline and tram systems normally have overhead wires, which hang from poles along the line. Grade-separated rapid transit sometimes use a ground third rail.\nPower may be fed as direct (DC) or alternating current (AC). The most common DC voltages are 600 and 750 V for tram and rapid transit systems, and 1,500 and 3,000 V for mainlines. The two dominant AC systems are 15 kV and 25 kV.\nA railway station serves as an area where passengers can board and alight from trains. A goods station is a yard which is exclusively used for loading and unloading cargo. Large passenger stations have at least one building providing conveniences for passengers, such as purchasing tickets and food. Smaller stations typically only consist of a platform. Early stations were sometimes built with both passenger and goods facilities.[88]\nPlatforms are used to allow easy access to the trains, and are connected to each other via underpasses, footbridges and level crossings. Some large stations are built as culs-de-sac, with trains only operating out from one direction. Smaller stations normally serve local residential areas, and may have connection to feeder bus services. Large stations, in particular central stations, serve as the main public transport hub for the city, and have transfer available between rail services, and to rapid transit, tram or bus services.\nSince the 1980s, there has been an increasing trend to split up railway companies, with companies owning the rolling stock separated from those owning the infrastructure. This is particularly true in Europe, where this arrangement is required by the European Union. This has allowed open access by any train operator to any portion of the European railway network. In the UK, the railway track is state owned, with a public controlled body (Network Rail) running, maintaining and developing the track, while Train Operating Companies have run the trains since privatization in the 1990s.[89]\nIn the US, virtually all rail networks and infrastructure outside the Northeast corridor are privately owned by freight lines. Passenger lines, primarily Amtrak, operate as tenants on the freight lines. Consequently, operations must be closely synchronized and coordinated between freight and passenger railroads, with passenger trains often being dispatched by the host freight railroad. Due to this shared system, both are regulated by the Federal Railroad Administration (FRA) and may follow the AREMA recommended practices for track work and AAR standards for vehicles.[67]\nThe main source of income for railway companies is from ticket revenue (for passenger transport) and shipment fees for cargo.[90][91] Discounts and monthly passes are sometimes available for frequent travellers (e.g. season ticket and rail pass). Freight revenue may be sold per container slot or for a whole train. Sometimes, the shipper owns the cars and only rents the haulage. For passenger transport, advertisement income can be significant.\nGovernments may choose to give subsidies to rail operation, since rail transport has fewer externalities than other dominant modes of transport. If the railway company is state-owned, the state may simply provide direct subsidies in exchange for increased production. If operations have been privatized, several options are available. Some countries have a system where the infrastructure is owned by a government agency or company – with open access to the tracks for any company that meets safety requirements. In such cases, the state may choose to provide the tracks free of charge, or for a fee that does not cover all costs. This is seen as analogous to the government providing free access to roads. For passenger operations, a direct subsidy may be paid to a public-owned operator, or public service obligation tender may be held, and a time-limited contract awarded to the lowest bidder. Total EU rail subsidies amounted to €73 billion in 2005.[92]\nVia Rail Canada and US passenger rail service Amtrak are private railroad companies chartered by their respective national governments. As private passenger services declined because of competition from cars and airlines, they became shareholders of Amtrak either with a cash entrance fee or relinquishing their locomotives and rolling stock. The government subsidizes Amtrak by supplying start-up capital and making up for losses at the end of the fiscal year.[93][page needed]\nSome trains travel faster than road vehicles. They are heavy and unable to deviate from the track, and have longer stopping distances. Possible accidents include derailment (jumping the track) and collisions with another train or a road vehicle, or with pedestrians at level crossings, which account for the majority of all rail accidents and casualties. To minimize the risk, the most important safety measures are strict operating rules, e.g. railway signalling, and gates or grade separation at crossings. Train whistles, bells, or horns warn of the presence of a train, while trackside signals maintain the distances between trains. Another method used to increase safety is the addition of platform screen doors to separate the platform from train tracks. These prevent unauthorized incursion on to the train tracks which can result in accidents that cause serious harm or death, as well as providing other benefits such as preventing litter build up on the tracks which can pose a fire risk.\nOn many high-speed inter-city networks, such as Japan's Shinkansen, the trains run on dedicated railway lines without any level crossings. This is an important element in the safety of the system as it effectively eliminates the potential for collision with automobiles, other vehicles, or pedestrians, and greatly reduces the probability of collision with other trains. Another benefit is that services on the inter-city network remain punctual.\nAs in any infrastructure asset, railways must keep up with periodic inspection and maintenance to minimize the effect of infrastructure failures that can disrupt freight revenue operations and passenger services. Because passengers are considered the most crucial cargo and usually operate at higher speeds, steeper grades, and higher capacity/frequency, their lines are especially important. Inspection practices include track geometry cars or walking inspection. Curve maintenance especially for transit services includes gauging, fastener tightening, and rail replacement.\nRail corrugation is a common issue with transit systems due to the high number of light-axle, wheel passages which result in grinding of the wheel/rail interface. Since maintenance may overlap with operations, maintenance windows (nighttime hours, off-peak hours, altering train schedules or routes) must be closely followed. In addition, passenger safety during maintenance work (inter-track fencing, proper storage of materials, track work notices, hazards of equipment near states) must be regarded at all times. At times, maintenance access problems can emerge due to tunnels, elevated structures, and congested cityscapes. Here, specialized equipment or smaller versions of conventional maintenance gear are used.[67]\nUnlike highways or road networks where capacity is disaggregated into unlinked trips over individual route segments, railway capacity is fundamentally considered a network system. As a result, many components are causes and effects of system disruptions. Maintenance must acknowledge the vast array of a route's performance (type of train service, origination/destination, seasonal impacts), a line's capacity (length, terrain, number of tracks, types of train control), trains throughput (max speeds, acceleration/ deceleration rates), and service features with shared passenger-freight tracks (sidings, terminal capacities, switching routes, and design type).[67]\nTransport by rail is an energy-efficient[96] but capital-intensive[97] means of mechanized land transport. The tracks provide smooth and hard surfaces on which the wheels of the train can roll with a relatively low level of friction.\nA typical modern wagon can hold up to 113 tonnes (125 short tons) of freight on two four-wheel bogies. The track distributes the weight of the train evenly, allowing significantly greater loads per axle and wheel than in road transport, leading to greater energy efficiency. Trains have a smaller frontal area in relation to the load they are carrying, which reduces air resistance and thus energy usage.\nIn addition, the presence of track guiding the wheels allows for very long trains to be pulled by one or a few engines and driven by a single operator, even around curves, which allows for economies of scale in both manpower and energy use; by contrast, in road transport, more than two articulations causes fishtailing and makes the vehicle unsafe.\nConsidering only the energy spent to move the means of transport, and using the example of the urban area of Lisbon, electric trains seem to be on average 20 times more efficient than automobiles for transportation of passengers, if we consider energy spent per passenger-distance with similar occupation ratios.[98] Considering an automobile with a consumption of around 6 L/100 km (47 mpg‑imp; 39 mpg‑US) of fuel, the average car in Europe has an occupancy of around 1.2 passengers per automobile (occupation ratio around 24%) and that one litre of fuel amounts to about 8.8 kWh (32 MJ), equating to an average of 441 Wh (1,590 kJ) per passenger-km. This compares to a modern train with an average occupancy of 20% and a consumption of about 8.5 kW⋅h/km (31 MJ/km; 13.7 kW⋅h/mi), equating to 21.5 Wh (77 kJ) per passenger-km, 20 times less than the automobile.\nDue to these benefits, rail transport is a major form of passenger and freight transport in many countries.[97] It is ubiquitous in Europe, with an integrated network covering virtually the whole continent. In India, China, South Korea and Japan, many millions use trains as regular transport. In North America, freight rail transport is widespread and heavily used, but intercity passenger rail transport is relatively scarce outside the Northeast Corridor, due to increased preference of other modes, particularly automobiles and aeroplanes.[93][page needed][99] However, implementing new and improved ways such as making it easily accessible within neighbourhoods can aid in reducing commuters from using private vehicles and aeroplanes.[100]\nSouth Africa, northern Africa and Argentina have extensive rail networks, but some railways elsewhere in Africa and South America are isolated lines. Australia has a generally sparse network befitting its population density but has some areas with significant networks, especially in the southeast. In addition to the previously existing east–west transcontinental line in Australia, a line from north to south has been constructed. The highest railway in the world is the line to Lhasa, in Tibet,[101] partly running over permafrost territory. Western Europe has the highest railway density in the world and many individual trains there operate through several countries despite technical and organizational differences in each national network.\nHistorically, railways have been considered central to modernity and ideas of progress.[102] The process of modernization in the 19th century involved a transition from a spatially oriented world to a time-oriented world. Timekeeping became of heightened importance, resulting in clock towers for railway stations, clocks in public places, and pocket watches for railway workers and travellers. Trains followed exact schedules and never left early, whereas in the premodern era, passenger ships left whenever the captain had enough passengers. In the premodern era, local time was set at noon, when the sun was at its highest; this changed with the introduction of standard time zones. Printed timetables were a convenience for travellers, but more elaborate timetables, called train orders, were essential for train crews, the maintenance workers, the station personnel, and for the repair and maintenance crews. The structure of railway timetables were later adapted for different uses, such as schedules for buses, ferries, and aeroplanes, for radio and television programmes, for school schedules, and for factory time clocks.[103]\nThe invention of the electrical telegraph in the early 19th century also was crucial for the development and operation of railroad networks. If bad weather disrupted the system, telegraphers relayed immediate corrections and updates throughout the system. Additionally, most railroads were single-track, with sidings and signals to allow lower priority trains to be sidetracked and have scheduled meets.\nScholars have linked railroads to successful nation-building efforts by states.[104]\nAccording to historian Henry Adams, a railroad network needed:\n- the energies of a generation, for it required all the new machinery to be created – capital, banks, mines, furnaces, shops, power-houses, technical knowledge, mechanical population, together with a steady remodelling of social and political habits, ideas, and institutions to fit the new scale and suit the new conditions. The generation between 1865 and 1895 was already mortgaged to the railways, and no one knew it better than the generation itself.[105]\nThe impact can be examined through five aspects: shipping, finance, management, careers, and popular reaction.\nRailroads form an efficient network for shipping freight and passengers across a large national market; their development thus was beneficial to many aspects of a nation's economy, including manufacturing, retail and wholesale, agriculture, and finance. By the 1940s, the United States had an integrated national market comparable in size to that of Europe, but free of internal barriers or tariffs, and supported by a common language, financial system, and legal system.[106]\nFinancing of railroads provided the basis for a dramatic expansion of the private (non-governmental) financial system. Construction of railroads was far more expensive than factories: in 1860, the combined total of railroad stocks and bonds was $1.8 billion; in 1897, it reached $10.6 billion (compared to a total national debt of $1.2 billion).[107]\nFunding came from financiers in the Northeastern United States and from Europe, especially Britain.[108] About 10 per cent of the funding came from the government, particularly in the form of land grants that were realized upon completion of a certain amount of trackage.[109] The emerging American financial system was based on railroad bonds, and by 1860, New York was the dominant financial market. The British invested heavily in railroads around the world, but nowhere more than in the United States; the total bond value reached about $3 billion by 1914. However, in 1914–1917, the British liquidated their American assets to pay for war supplies.[110][111]\nRailroad management designed complex systems that could handle far more complicated simultaneous relationships than those common in other industries at the time. Civil engineers became the senior management of railroads. The leading American innovators were the Western Railroad of Massachusetts and the Baltimore and Ohio Railroad in the 1840s, the Erie Railroad in the 1850s, and the Pennsylvania Railroad in the 1860s.[112]\nThe development of railroads led to the emergence of private-sector careers for both blue-collar workers and white-collar workers. Railroading became a lifetime career for young men; women were almost never hired. A typical career path would see a young man hired at age 18 as a shop labourer, be promoted to skilled mechanic at age 24, brakemen at 25, freight conductor at 27, and passenger conductor at age 57. White-collar career paths likewise were delineated: educated young men started in clerical or statistical work and moved up to station agents or bureaucrats at the divisional or central headquarters, acquiring additional knowledge, experience, and human capital at each level. Being very hard to replace, they were virtually guaranteed permanent jobs and provided with insurance and medical care.\nHiring, firing, and wage rates were set not by foremen, but by central administrators, to minimize favouritism and personality conflicts. Everything was done by the book, whereby an increasingly complex set of rules dictated to everyone exactly what should be done in every circumstance, and exactly what their rank and pay would be. By the 1880s, career railroaders began retiring, and pension systems were invented for them.[113]\nRailways contribute to social vibrancy and economic competitiveness by transporting multitudes of customers and workers to city centres and inner suburbs. Hong Kong has recognized rail as \"the backbone of the public transit system\" and as such developed their franchised bus system and road infrastructure in comprehensive alignment with their rail services.[114] China's large cities such as Beijing, Shanghai, and Guangzhou recognize rail transit lines as the framework and bus lines as the main body to their metropolitan transportation systems.[115] The Japanese Shinkansen was built to meet the growing traffic demand in the \"heart of Japan's industry and economy\" situated on the Tokyo-Kobe line.[116]\nRail transport can be important for military activity. During the 1860s, railways provided a means for rapid movement of troops and supplies during the American Civil War,[117] as well as in the Austro-Prussian and Franco-Prussian Wars[118] Throughout the 20th century, rail was a key element of war plans for rapid military mobilization, allowing for the quick and efficient transport of large numbers of reservists to their mustering-points, and infantry soldiers to the front lines.[119] So-called strategic railways were or are constructed for a primarily military purpose. The Western Front in France during World War I required many trainloads of munitions a day.[120] Conversely, owing to their strategic value, rail yards and bridges in Germany and occupied France were major targets of Allied air raids during World War II.[121] Rail transport and infrastructure continues to play an important role in present-day conflicts like the Russian invasion of Ukraine, where sabotage of railways in Belarus and in Russia also influenced the course of the war.\nRailways channel growth towards dense city agglomerations and along their arteries.[citation needed] This contrasts with highway expansion, indicative of the US transportation policy post-World War II, which instead encourages development of suburbs at the periphery of metropolitan areas, contributing to increased vehicle miles travelled, carbon emissions, development of greenfield spaces, and depletion of natural reserves.[dubious – discuss][citation needed] These arrangements revalue city spaces, local taxes,[122] housing values, and promotion of mixed use development.[123][124]\nThere has also been some opposition to the development of railway networks. For instance, the arrival of railways and steam locomotives to Austria during the 1840s angered locals because of the noise, smell, and pollution caused by the trains and the damage to homes and the surrounding land caused by the engine's soot and fiery embers; and since most travel did not occur over long distances, few people utilized the new line.[125]\nA 2018 study found that the opening of the Beijing Subway caused a reduction in \"most of the air pollutants concentrations (PM2.5, PM10, SO2, NO2, and CO) but had little effect on ozone pollution.\"[126]\nEuropean development economists have argued that the existence of modern rail infrastructure is a significant indicator of a country's economic advancement: this perspective is illustrated notably through the Basic Rail Transportation Infrastructure Index (known as BRTI Index).[127]\nIn 2010, annual rail spending in China was ¥840 billion (US$178 billion in 2023), from 2014 to 2017 China had an annual target of ¥800 billion (US$168 billion in 2023) and planned to spend ¥3.5 trillion (US$31 trillion in 2023) over 2016–2020.[128]\nThe Indian Railways are subsidized by around ₹260 billion (US$5 billion in 2023), of which around 60% goes to commuter rail and short-haul trips.[129]\nAccording to the 2017 European Railway Performance Index for intensity of use, quality of service and safety performance, the top tier European national rail systems consists of Switzerland, Denmark, Finland, Germany, Austria, Sweden, and France.[131] Performance levels reveal a positive correlation between public cost and a given railway system's performance, and also reveal differences in the value that countries receive in return for their public cost. Denmark, Finland, France, Germany, the Netherlands, Sweden, and Switzerland capture relatively high value for their money, while Luxembourg, Belgium, Latvia, Slovakia, Portugal, Romania, and Bulgaria underperform relative to the average ratio of performance to cost among European countries.[131]\n| Country | Subsidy in billions of Euros | Year |\n|---|---|---|\n| Germany | 17.0 | 2014[132] |\n| France | 13.2 | 2013[133] |\n| Italy | 8.1 | 2009[134] |\n| Switzerland | 5.8 | 2012[135] |\n| Spain | 5.1 | 2015[136] |\n| United Kingdom | 4.5 | 2015[137] |\n| Belgium | 3.4 | 2008[130] |\n| Netherlands | 2.5 | 2014[138] |\n| Austria | 2.3 | 2009[130] |\n| Denmark | 1.7 | 2008[130] |\n| Sweden | 1.6 | 2009[139] |\n| Poland | 1.4 | 2008[140] |\n| Ireland | 0.91 | 2008[140] |\nIn 2016, Russian Railways received 94.9 billion roubles (around US$1.4 billion) from the government.[141]\nIn 2015, funding from the US federal government for Amtrak was around US$1.4 billion.[142] By 2018, appropriated funding had increased to approximately US$1.9 billion.[143]\n- Battery electric multiple unit – Zero-emissions unwired train\n- Electric multiple unit – Electric train with no locomotive\n- Electric–steam locomotive – Steam locomotive with boiler heated electrically\n- Environmental design in rail transportation\n- Ground-effect train – Type of train\n- History of tram and light rail transit systems by country\n- History of transport\n- Hydrogen train – Train transporting or using hydrogen\n- International Union of Railways – International rail transport industry body\n- List of countries by rail transport network size\n- List of countries by rail usage\n- List of railroad-related periodicals\n- List of railway companies\n- List of railway industry occupations\n- Mega project – Extremely large-scale construction and investment project\n- Mine railway – Type of railway that operates in a mine\n- Outline of rail transport – Overview of and topical guide to rail transport\n- Passenger rail terminology – Terms used for passenger railway lines and equipment\n- Rail transport by country\n- Railway systems engineering – Study of engineering principles necessary for railway construction and operation\n- Steam turbine locomotive – Locomotive using a steam turbine\n- Vactrain – Train inside a vacuum tube\n- According to [Norman Bradbury (November 2002). Face the facts on transport safety (PDF). Railwatch (Report). Archived from the original (PDF) on 11 October 2010.air transport is safe only on a per-mile basis.\n- Heilmann evaluated both AC and DC electric transmission for his locomotives, but eventually settled on a design based on Thomas Edison's DC system.[50]\n- \"History, Invention, & Facts\". Britannica. Archived from the original on 1 October 2023. Retrieved 2 December 2023.\n- IEA (2019). The Future of Rail. Paris: International Energy Agency. Archived from the original on 17 November 2023. Retrieved 2 December 2023.\n- Schwantes, Carlos A. and Ronda, James P. The West the Railroads Made, pp. 4-5, 9, 11, 28-9, 91, 105, 127, University of Washington Press, Seattle and London, 2008. ISBN 978-0-295-98769-9\n- Hilton, George W. American Narrow Gauge Railroads, p. 41, Stanford University Press, Stanford, California, 1990.\n- Floyd, Donald R. California Narrow Gauge: The Role of Narrow-Gauge Railroads in California's Transportation Network, pp. 19-20, 22, The Gibson Press, Mountain View, California, 1970.\n- Athearn, Robert G. Rebel of the Rockies: A History of the Denver and Rio Grande Western Railroad, pp. 4-5, 16-25, Yale University Press, New Haven, Connecticut, 1962.\n- Beebe, Lucius and Clegg, Charles. Narrow Gauge in the Rockies, p. 31, Howell-North, Berkeley, California, 1958.\n- Jensen, Oliver. The American Heritage History of Railroads in America, pp. 7, 32, 84, 104, American Heritage Publishing Company, New York, New York, 1975.\n- \"Building the Transcontinental Railroad\". Digital History. University of Houston. 2021.\n- Schwantes, Carlos A. and Ronda, James P. The West the Railroads Made, pp. 4-5, 9, 11, 28-9, 91, 105, 127, University of Washington Press, Seattle and London, 2008. ISBN 978-0-295-98769-9\n- Athearn, Robert G. Rebel of the Rockies: A History of the Denver and Rio Grande Western Railroad, pp. 4-5, 16-25, Yale University Press, New Haven, Connecticut, 1962.\n- Beebe, Lucius and Clegg, Charles. Narrow Gauge in the Rockies, p. 31, Howell-North, Berkeley, California, 1958.\n- Davidson, James West, et al. American Nation: Independence Through 1914, p. 304, Prentice-Hall, Upper Saddle River, New Jersey, 2000. ISBN 0-13-434888-5.\n- Blum, John M. et al. The National Experience: A History of the United States, pp. 298-9, Harcourt, Brace & World, Inc., New York, New York, 1963.\n- Lewis, M. J. T. (2001). \"Railways in the Greek and Roman world\" (PDF). In Guy, A.; Rees, J. (eds.). Early Railways. A Selection of Papers from the First International Early Railways Conference. pp. 8–19. Archived from the original (PDF) on 21 July 2011.\n- Fraser, P. M. (December 1961). \"The ΔΙΟΛΚΟΣ of Alexandria\". The Journal of Egyptian Archaeology. 47: 134–138. doi:10.2307/3855873. JSTOR 3855873.\n- \"Der Reiszug: Part 1 – Presentation\". Funimag. Archived from the original on 20 October 2021. Retrieved 22 April 2009.\n- Kriechbaum, Reinhard (15 May 2004). \"Die große Reise auf den Berg\". der Tagespost (in German). Archived from the original on 28 June 2012. Retrieved 22 April 2009.\n- Georgius Agricola (trans Hoover), De re metallica (1913), p. 156.\n- Lee, Charles E. (1943). \"The Evolution of Railways\". Railway Gazette (2nd ed.). London. p. 16. OCLC 1591369.\n- Lewis, Early wooden railways, pp. 8–10.\n- Warren Allison, Samuel Murphy and Richard Smith, An Early Railway in the German Mines of Caldbeck in G. Boyes (ed.), Early Railways 4: Papers from the 4th International Early Railways Conference 2008 (Six Martlets, Sudbury, 2010), pp. 52–69.\n- Jones, Mark (2012). Lancashire Railways – The History of Steam. Newbury: Countryside Books. p. 5. ISBN 978-1-84674-298-9.\n- Peter King, The First Shropshire Railways in G. Boyes (ed.), Early Railways 4: Papers from the 4th International Early Railways Conference 2008 (Six Martlets, Sudbury, 2010), pp. 70–84.\n- \"Huntingdon Beaumont's Wollaton to Strelley Waggonway\". Nottingham Hidden History. 30 July 2013. Archived from the original on 27 November 2022. Retrieved 23 August 2017.\n- Porter, Peter (1914). Landmarks of the Niagara Frontier. Privately printed. OCLC 1044424468.\n- Vaughan, A. (1997). Railwaymen, Politics and Money. London: John Murray. ISBN 978-0-7195-5746-0.\n- \"Surrey Iron Railway 200th – 26th July 2003\". Early Railways. Stephenson Locomotive Society. Archived from the original on 12 May 2009.\n- Landes, David. S. (1969). The Unbound Prometheus: Technological Change and Industrial Development in Western Europe from 1750 to the Present. Cambridge, New York: Press Syndicate of the University of Cambridge. p. 91. ISBN 978-0-521-09418-4.\n- Landes 1969, pp. 92\n- Wells, David A. (1890). Recent Economic Changes and Their Effect on Production and Distribution of Wealth and Well-Being of Society. New York: D. Appleton and Co. OCLC 2607599.\n- Grübler, Arnulf (1990). The Rise and Fall of Infrastructures: Dynamics of Evolution and Technological Change in Transport (PDF). Heidelberg and New York: Physica-Verlag. Archived from the original (PDF) on 1 March 2012. Retrieved 11 October 2017.\n- Fogel, Robert W. (1964). Railroads and American Economic Growth: Essays in Econometric History. Baltimore and London: The Johns Hopkins Press. OCLC 237790.\n- Rosenberg, Nathan (1982). Inside the Black Box: Technology and Economics. Cambridge, New York: Cambridge University Press. p. 60. ISBN 978-0-521-27367-1.\n- \"Early Days of Mumbles Railway\". BBC. 15 February 2007. Archived from the original on 27 March 2009. Retrieved 19 September 2007.\n- Gordon, W. J. (1910). Our Home Railways, volume one. London: Frederick Warne and Co. pp. 7–9.\n- \"Richard Trevithick's steam locomotive\". National Museum Wales. Archived from the original on 15 April 2011.\n- \"Steam train anniversary begins\". BBC. 21 February 2004. Archived from the original on 3 June 2020. Retrieved 13 June 2009.\nA south Wales town has begun months of celebrations to mark the 200th anniversary of the invention of the steam locomotive. Merthyr Tydfil was the location where, on 21 February 1804, Richard Trevithick took the world into the railway age when he set one of his high-pressure steam engines on a local iron master's tram rails\n- Hamilton Ellis (1968). The Pictorial Encyclopedia of Railways. The Hamlyn Publishing Group. p. 12.\n- \". collection.sciencemuseumgroup.org.uk. Archived from the original on 19 May 2023. Retrieved 26 May 2021.\n- Hamilton Ellis (1968). The Pictorial Encyclopedia of Railways. The Hamlyn Publishing Group. pp. 20–22.\n- Ellis, Hamilton (1968). The Pictorial Encyclopedia of Railways. Hamlyn Publishing Group.\n- \"First in the world: The making of the Liverpool and Manchester Railway\". Science and Industry Museum. Archived from the original on 2 May 2020. Retrieved 15 April 2022.\n- Day, Lance; McNeil, Ian (1966). \"Davidson, Robert\". Biographical dictionary of the history of technology. London: Routledge. ISBN 978-0-415-06042-4.\n- Gordon, William (1910). \"The Underground Electric\". Our Home Railways. Vol. 2. London: Frederick Warne and Co. p. 156.\n- Renzo Pocaterra, Treni, De Agostini, 2003\n- Jean Denis G.G Lepage, Military Trains and Railways: an illustrated history, Jefferson, North Carolina: McFarland & Company, Inc., Publishers, 2017. Print. pp. 9-11.\n- \"Richmond Union Passenger Railway\". IEEE History Center. Archived from the original on 1 December 2008. Retrieved 18 January 2008.\n- \"A brief history of the Underground\". Transport for London.gov.uk. 15 October 2017. Archived from the original on 12 June 2018. Retrieved 16 October 2017.\n- Duffy (2003), pp. 39–41.\n- Duffy (2003), p. 129.\n- Andrew L. Simon (1998). Made in Hungary: Hungarian Contributions to Universal Culture. Simon Publications. p. 264. ISBN 978-0-9665734-2-8.\nEvian-les-Bains kando.\n- Francis S. Wagner (1977). Hungarian Contributions to World Civilization. Alpha Publications. p. 67. ISBN 978-0-912404-04-2.\n- Duffy (2003), p. 120–121.\n- Hungarian Patent Office. \"Kálmán Kandó (1869–1931)\". mszh.hu. Archived from the original on 8 October 2010. Retrieved 10 August 2008.\n- Duffy (2003), p. 137.\n- Duffy (2003), p. 273.\n- \"Motive power for British Railways\" (PDF), The Engineer, vol. 202, p. 254, 24 April 1956, archived from the original (PDF) on 4 March 2014, retrieved 11 October 2017\n- Thomson, William (4 May 1888), \"Priestmans' Petroleum Engine\", The Electrical Review, 22: 474, hdl:2027/mdp.39015084630964 – via Haithi Trust,\nA small double cylinder engine has been mounted upon a truck, which is worked on a temporary line of rails, in order to show the adaptation of a petroleum engine for locomotive purposes, on tramways\n- Diesel Railway Traction, vol. 17, 1963, p. 25,\nIn one sense a dock authority was the earliest user of an oil-engined locomotive, for it was at the Hull docks of the North Eastern Railway that the Priestman locomotive put in its short period of service in 1894\n- Churella, Albert J. (1998). From Steam to Diesel: Managerial Customs and Organizational Capabilities in the Twentieth-Century American Locomotive Industry. Princeton, New Jersey: Princeton University Press. p. 12. ISBN 978-0-691-02776-0.\n- Glatte, Wolfgang (1993). Deutsches Lok-Archiv: Diesellokomotiven 4. Auflage. Berlin: Transpress. ISBN 978-3-344-70767-5.\n- Westwood, J. N. (1982). Soviet Locomotive Technology During Industrialization, 1928—1952. Macmillan Press. ISBN 978-1-349-05013-0.\n- US 1154785, Lemp, Hermann, \"Controlling mechanism for internal-combustion engines\", issued 28 September 1915\n- Pinkepank, Jerry A. (1973). The Second Diesel Spotter's Guide. Milwaukee WI: Kalmbach Books. p. 409. ISBN 978-0-89024-026-7.\n- STANDS4 LLC, 2020, TPH Archived 19 July 2020 at the Wayback Machine, abbreviations.com, accessed 19 July 2020\n- American Railway Engineering and Maintenance of Way Association Committee 24 – Education and Training. (2003). Practical Guide to Railway Engineering. AREMA, 2nd Ed.\n- \"Rail freight in the next decade: Potential for performance improvements?\". Global Railway Review. Archived from the original on 1 February 2021. Retrieved 27 January 2021.\n- \"Environmental Issues\". The Environmental Blog. 3 April 2007. Archived from the original on 11 January 2012. Retrieved 10 October 2010.\n- Marcomin, Fabio (11 October 2024). \"Effetto M4: la metro di Milano entra nella top europea\". Milano Città Stato (in Italian). Retrieved 12 October 2024.\n- \"Mass transit - Urban Mobility, Efficiency, Environment\". Britannica. 4 September 2024. Retrieved 29 September 2024.\n- \"Fact Book Glossary\". American Public Transportation Association. Retrieved 29 September 2024.\n- \"Rapid transit\". Merriam-Webster. Archived from the original on 20 July 2013. Retrieved 31 July 2013.\n- UITP (2011). \"Recommended basic reference for developing a minimum set of standards for voluntary use in the field of urban rail, according to mandate M/486\" (PDF). Archived from the original on 22 February 2014. Retrieved 16 February 2014.\n- \"Glossary of Transit Terminology\" (PDF). American Public Transportation Association. Archived (PDF) from the original on 12 May 2013. Retrieved 31 July 2013.\n- Fouracre, Phil; Dunkerley, Christian; Gardner, Geoff (2003). \"Mass rapid transit systems for cities in the developing world\". Transport Reviews. 23 (3). Taylor & Francis Online: 299–310. doi:10.1080/0144164032000083095. S2CID 154931412. Retrieved 2 April 2023.\n- \"Rapid Transit\". Encyclopædia Britannica. Archived from the original on 17 October 2014. Retrieved 28 November 2014.\n- \"Chicago\". Archived from the original on 16 April 2015. Retrieved 24 April 2015.\n- Transport for London (1981). London Underground: History. Capital Transport. ISBN 978-0-904711-30-1. Archived from the original on 16 January 2013. Retrieved 2 January 2013.\n- \"Luoyang and Ji'nan open metro lines\". International Railway Journal. 29 March 2021. Retrieved 7 June 2021.\n- \"China's Metro Boom Continues to Drive Rapid Transit Growth – Institute for Transportation and Development Policy\". Institute for Transportation and Development Policy. 30 July 2018. Archived from the original on 20 November 2018. Retrieved 20 November 2018.\n- \"Metro Data\". metro-data.info. Archived from the original on 29 September 2018. Retrieved 28 September 2018.\n- \"Rapid Transit Trends Show Record Growth in 2016, with Huge Increases in China, Brazil – Institute for Transportation and Development Policy\". Institute for Transportation and Development Policy. 17 February 2017. Archived from the original on 23 October 2018. Retrieved 20 November 2018.\n- \"Shanghai now the world's longest metro\". Railway Gazette International. 4 May 2010. Archived from the original on 15 May 2010. Retrieved 4 May 2010.\n- Smith, Stephen J. (6 January 2014). \"New Starts: Shanghai Metro World's Longest, Panama Canal Drama, Japan's Maglev\". Next City. Archived from the original on 25 September 2014. Retrieved 21 September 2014.\n- \"Facts – Subway and Bus Ridership\". Metropolitan Transportation Authority (MTA). Archived from the original on 12 September 2014. Retrieved 21 September 2014.\n- Rodrigue, Jean-Paul (2020). The geography of transport systems (Fifth ed.). Abingdon, Oxon: Routledge. ISBN 978-0-429-34632-3. OCLC 1133662497.\n- \"The Inception of the English Railway Station\". Architectural History. 4: 63–76. 1961. doi:10.2307/1568245. JSTOR 1568245. S2CID 246043093.\n- \"About Us\". Archived from the original on 9 October 2014.\n- Guan, Xueyi; Qin, Jin; Mao, Chenghui; Zhou, Wenliang (January 2023). \"A Literature Review of Railway Pricing Based on Revenue Management\". Mathematics. 11 (4): 857. doi:10.3390/math11040857. ISSN 2227-7390.\n- \"Shipping Tariffs\". Old Dominion Freight Line. Retrieved 7 April 2024.\n- \"EU Technical Report 2007\". Archived from the original on 23 January 2018. Retrieved 26 January 2016.\n- EuDaly, Kevin; et al. (2009). The Complete Book of North American Railroading. Minneapolis: Voyageur Press. ISBN 978-0-7603-2848-4. OCLC 209631579.\n- \"Statistics database for transports\". epp.eurostat.ec.europa.eu (statistical database). Eurostat, European Commission. 20 April 2014. Archived from the original on 3 June 2012. Retrieved 12 May 2014.\n- Vojtech Eksler, ed. (5 May 2013). \"Intermediate report on the development of railway safety in the European Union 2013\" (PDF). www.era.europa.eu (report). Safety Unit, European Railway Agency & European Union. p. 1. Archived (PDF) from the original on 29 August 2017. Retrieved 12 May 2014.\n- American Association of Railroads. \"Railroad Fuel Efficiency Sets New Record\". Archived from the original on 26 November 2013. Retrieved 12 April 2009.\n- \"What is Rail Transport? Definition of Rail Transport, Rail Transport Meaning\". The Economic Times. Archived from the original on 13 April 2021. Retrieved 27 January 2021.\n- Publicada por João Pimentel Ferreira. \"Carro ou comboio?\". Veraveritas.eu. Archived from the original on 8 April 2015. Retrieved 3 January 2015.\n- \"Public Transportation Ridership Statistics\". American Public Transportation Association. 2007. Archived from the original on 15 August 2007. Retrieved 10 September 2007.\n- Baum-Snow, Nathaniel; Kahn, Matthew E. (August 2000). \"The effects of new public projects to expand urban rail transit\". Journal of Public Economics. 77 (2): 241–263. doi:10.1016/S0047-2727(99)00085-7. Archived from the original on 14 March 2022. Retrieved 16 March 2022.\n- \"New height of world's railway born in Tibet\". Xinhua News Agency. 24 August 2005. Archived from the original on 13 September 2005. Retrieved 8 May 2011.\n- Schivelbusch, G. (1986) The Railway Journey: Industrialization and Perception of Time and Space in the 19th Century. Oxford: Berg.\n- Tony Judt, When the Facts Change: Essays 1995–2010 (2015) pp. 287–288.\n- Cermeño, Alexandra L.; Enflo, Kerstin; Lindvall, Johannes (2021). \"Railroads and Reform: How Trains Strengthened the Nation State\". British Journal of Political Science. 52 (2): 715–735. doi:10.1017/S0007123420000654. ISSN 0007-1234.\n- Adams, Henry (1918). \"The Press (1868)\". The Education of Henry Adams. p. 240. Archived from the original on 18 March 2017. Retrieved 11 May 2017.\n- Jenks, Leland H. (1944). \"Railroads as an Economic Force in American Development\". The Journal of Economic History. 4 (1): 1–20. doi:10.1017/S002205070008400X. JSTOR 2113700. S2CID 154883188.\n- Edward C. Kirkland, Industry comes of age: Business, labor, and public policy, 1860–1897 (1961) pp. 52, 68–74.\n- Chandler, Alfred D. (1954). \"Patterns of American Railroad Finance, 1830–50\". The Business History Review. 28 (3): 248–263. doi:10.2307/3111573. JSTOR 3111573. S2CID 154702721.\n- Kirkland, Industry comes of age (1961) pp. 57–68.\n- Jenks, Leland H. (1951). \"Capital Movement and Transportation: Britain and American Railway Development\". The Journal of Economic History. 11 (4): 375–388. doi:10.1017/S0022050700085119. JSTOR 2113694. S2CID 153714837.\n- Saul Engelbourg, The man who found the money: John Stewart Kennedy and the financing of the western railroads (1996).\n- Alfred D. Chandler and Stephen Salsbury. \"The railroads: Innovators in modern business administration.\" in Bruce Mazlish, ed., The Railroad and the Space Program (MIT Press, 1965) pp. 127–162\n- Licht, Walter (1983). Working for the Railroad: The Organization of Work in the Nineteenth Century. Princeton, N.J. : Princeton University Press. pp. 262–263, 289. ISBN 9780691047003.\n- Hong Kong Information Services Department of the Hong Kong SAR Government. Hong Kong 2009\n- Hu, Hua; Gao, Yun-Feng; Liu, Zhi-Gang; Yang, Xiao-Guang (2010). \"Effect of integrated multi-modal transit information on modal shift\". 13th International IEEE Conference on Intelligent Transportation Systems. pp. 1753–1757. doi:10.1109/ITSC.2010.5625187. ISBN 978-1-4244-7657-2. S2CID 38806085.\n- Straszak, A. (1977). The Shinkansen High-Speed Rail Network of Japan: Proceedings of an IIASA Conference, June 27–30, 1977. Elsevier. ISBN 978-1-4831-8916-1.[page needed]\n- Christopher R. Gabel, \"Railroad Generalship: Foundations of Civil War Strategy\" (Army Command And General Staff College, Combat Studies Inst, 1997) online Archived 7 August 2019 at the Wayback Machine.\n- Dennis E. Showalter, Railroads and Rifles: soldiers, technology, and the unification of Germany (1975).\n- Stevenson, D. (1 February 1999). \"War by Timetable? The Railway Race Before 1914\". Past & Present (162): 163–194. doi:10.1093/past/162.1.163.\n- Denis Bishop and W. J. K. Davies, Railways and War Before 1918 (London: Blandford Press, 1972); Bishop and Davies, Railways and War Since 1917 (1974).\n- Lytton, Henry D (1 April 1983). \"Bombing Policy in the Rome and Pre-Normandy Invasion Aerial Campaigns of World War II: Bridge-Bombing Strategy Vindicated – and Railyard-Bombing Strategy Invalidated\". Military Affairs. 47 (2). Lexington: 53–58. doi:10.2307/1988491. JSTOR 1988491. ProQuest 1296644342.\n- Lewandowski, Krzysztof (December 2015). \"New coefficients of rail transport usage\" (PDF). International Journal of Engineering and Innovative Technology. 5 (6): 89–91. Archived (PDF) from the original on 31 October 2020. Retrieved 27 October 2020.\n- Squires, G. Ed. (2002) Urban Sprawl: Causes, Consequences, & Policy Responses. The Urban Institute Press.\n- Puentes, R. (2008). A Bridge to Somewhere: Rethinking American Transportation for the 21st Century. Brookings Institution Metropolitan Policy Report: Blueprint for American Prosperity series report.\n- Bryant, Chad (April 2009). \"Into an Uncertain Future: Railroads and Vormärz Liberalism in Brno, Vienna, and Prague\". Austrian History Yearbook. 40: 183–201. doi:10.1017/S0067237809000150.\n- Guo, Shihong; Chen, Liqiang (March 2019). \"Can urban rail transit systems alleviate air pollution? Empirical evidence from Beijing: XXXX\". Growth and Change. 50 (1): 130–144. doi:10.1111/grow.12266.\n- Firzli, M. Nicolas J. (1 July 2013). \"Transportation Infrastructure and Country Attractiveness\". Revue Analyse Financière. Paris. Archived from the original on 4 September 2015. Retrieved 26 April 2014.\n- \"China plans to spend $115 billion on railways in 2017: Xinhua\". Reuters. 4 January 2017. Archived from the original on 23 March 2023. Retrieved 23 March 2023.\n- \"Govt defends fare hike, says rail subsidy burden was too heavy\". The Times of India. 22 June 2014. Archived from the original on 9 July 2023. Retrieved 30 June 2016.\n- \"ANNEX to Proposal for a Regulation of the European Parliament and of the Council amending Regulation (EC) No 1370/2007 concerning the opening of the market for domestic passenger transport services by rail\" (PDF) (Commission Staff Working Document: Impact Assessment). Brussels: European Commission. 2013. pp. 6, 44, 45. Archived from the original (PDF) on 3 May 2013.\n2008 data is not provided for Italy, so 2007 data is used instead\n- \"the 2017 European Railway Performance Index\". Boston Consulting Group. 18 April 2017. Archived from the original on 31 May 2020. Retrieved 8 January 2021.\n- \"German Railway Financing\" (PDF). p. 2. Archived from the original (PDF) on 10 March 2016.\n- \"Efficiency indicators of Railways in France\" (PDF). Archived from the original (PDF) on 17 November 2015.\n- \"The age of the train\" (PDF). Archived from the original (PDF) on 17 November 2015. Retrieved 27 January 2016.\n- \"Facts and arguments in favour of Swiss public transport\". p. 24. Archived from the original on 26 October 2014. Retrieved 3 July 2016.\n6.3 billion Swiss francs\n- \"Spanish railways battle profit loss with more investment\". 17 September 2015. Archived from the original on 24 November 2020. Retrieved 10 March 2016.\n- \"GB rail industry financial information 2014–15\" (PDF). 9 March 2016. Archived (PDF) from the original on 9 March 2016. Retrieved 9 March 2016.\n£3.5 billion\n- \"ProRail report 2015\" (PDF). p. 30. Archived from the original (PDF) on 3 March 2016. Retrieved 22 February 2016.\n- \"The evolution of public funding to the rail sector in 5 European countries – a comparison\" (PDF). p. 6. Archived from the original (PDF) on 4 March 2016. Retrieved 27 January 2016.\n- \"European rail study report\" (PDF). pp. 44, 45. Archived from the original (PDF) on 3 May 2013.\nIncludes both \"Railway subsidies\" and \"Public Service Obligations\".\n- \"Government support for Russian Railways\". Archived from the original on 26 November 2018. Retrieved 26 November 2018.\n- \"FY15 Budget, Business Plan 2015\" (PDF). Archived (PDF) from the original on 4 February 2016. Retrieved 9 March 2016.\n- \"Management's Discussion and Analysis of Financial Condition and Results of Operations and Consolidated Financial Statements With Report of Independent Auditors\" (PDF). Amtrak. 28 January 2019. p. 33. Archived (PDF) from the original on 3 November 2019. Retrieved 3 November 2019.\n- Duffy, Michael C. (2003). Electric Railways 1880–1990. IET. ISBN 978-0-85296-805-5.\n- Burton, Anthony. Railway Empire: How the British Gave Railways to the World (2018) excerpt\n- Chant, Christopher. The world's railways: the history and development of rail transport (Chartwell Books, 2001).\n- Faith, Nicholas. The World the Railways Made (2014) excerpt\n- Freeman, Michael. \"The Railway as Cultural Metaphor: 'What Kind of Railway History?' Revisited.\" Journal of Transport History 20.2 (1999): 160–167.\n- Mukhopadhyay, Aparajita. Imperial Technology and 'Native'Agency: A Social History of Railways in Colonial India, 1850–1920 (Taylor & Francis, 2018).\n- Nock, O. S. Railways then and now: a world history (1975) online\n- Nock, O. S. World atlas of railways (1978) online\n- Nock, O. S. 150 years of main line railways (1980) online\n- Pirie, Gordon. \"Tracking railway histories.\" Journal of Transport History 35.2 (2014): 242–248.\n- Sawai, Minoru, ed. The Development of Railway Technology in East Asia in Comparative Perspective (#Sringer, 2017)\n- Trains Magazine. The Historical Guide to North American Railroads (3rd ed. 2014)\n- Wolmar, Christian. Blood, iron, and gold: How the railroads transformed the world (Public Affairs, 2011).",
    "real estate economics": "Real estate economics is the application of economic techniques to real estate markets. It aims to describe and predict economic patterns of supply and demand. The closely related field of housing economics is narrower in scope, concentrating on residential real estate markets, while the research on real estate trends focuses on the business and structural changes affecting the industry. Both draw on partial equilibrium analysis (supply and demand), urban economics, spatial economics, basic and extensive research, surveys, and finance.\nThe main participants in real estate markets are:\n- Users: These people are both owners and tenants. They purchase houses or commercial property as an investment and also to live in or utilize as a business. Businesses may or may not require buildings to use land. The land can be used in other ways, such as for agriculture, forestry or mining.\n- Owners: These people are pure investors. They do not occupy the real estate that they purchase. Typically, they rent out or lease the property to other parties.\n- Renters: They are pure consumers.\n- Developers: These people are involved in developing land for buildings for sale in the market.\n- Renovators: They supply refurbished properties to the market.\n- Facilitators: This group includes banks, real estate brokers, lawyers, government regulators, and others that facilitate the purchase and sale of real estate.\nThe choices of users, owners, and renters form the demand side of the market, while the choices of owners, developers and renovators form the supply side. In order to apply simple supply and demand analysis to real estate markets, a number of modifications need to be made to standard microeconomic assumptions and procedures. In particular, the unique characteristics of the real estate market must be accommodated. These characteristics include:\n- Durability. Real estate is durable. A building can last for decades or even centuries, and the land underneath it is practically indestructible. As a result, real estate markets are modelled as a stock/flow market. Although the proportion is highly variable over time, the vast majority of the building supply consists of the stock of existing buildings, while a small proportion consists of the flow of new development. The stock of real estate supply in any period is determined by the existing stock in the previous period, the rate of deterioration of the existing stock, the rate of renovation of the existing stock, and the flow of new development in the current period. The effect of real estate market adjustments tend to be mitigated by the relatively large stock of existing buildings.\n- Heterogeneity. Every unit of real estate is unique in terms of its location, the building, and its financing. This makes pricing difficult, increases search costs, creates information asymmetry, and greatly restricts substitutability. To get around this problem, economists, beginning with Muth (1960), define supply in terms of service units; that is, any physical unit can be deconstructed into the services that it provides. Olsen (1969) describes these units of housing services as an unobservable theoretical construct. Housing stock depreciates, making it qualitatively different from new buildings. The market-equilibrating process operates across multiple quality levels. Further, the real estate market is typically divided into residential, commercial, and industrial segments. It can also be further divided into subcategories like recreational, income-generating, historical or protected, and the like.\n- High transaction costs. Buying and/or moving into a home costs much more than most types of transactions. The costs include search costs, real estate fees, moving costs, legal fees, land transfer taxes, and deed registration fees. Transaction costs for the seller typically range between 1.5% and 6% of the purchase price. In some countries in continental Europe, transaction costs for both buyer and seller can range between 15% and 20%.\n- Long time delays. The market adjustment process is subject to time delays due to the length of time it takes to finance, design, and construct new supply and also due to the relatively slow rate of change of demand. Because of these lags, there is great potential for disequilibrium in the short run. Adjustment mechanisms tend to be slow relative to more fluid markets.\n- Both an investment good and a consumption good. Real estate can be purchased with the expectation of attaining a return (an investment good), with the intention of using it (a consumption good), or both. These functions may be separated (with market participants concentrating on one or the other function) or combined (in the case of the person that lives in a house that they own). This dual nature of the good means that it is not uncommon for people to over-invest in real estate,[1] that is, to invest more money in an asset than it is worth on the open market.\n- Immobility. Real estate is locationally immobile (save for mobile homes, but the land underneath them is still immobile). Consumers come to the good rather than the good going to the consumer. Because of this, there can be no physical marketplace. This spatial fixity means that market adjustment must occur by people moving to dwelling units, rather than the movement of the goods. For example, if tastes change and more people demand suburban houses, people must find housing in the suburbs, because it is impossible to bring their existing house and lot to the suburb (even a mobile homeowner, who could move the house, must still find a new lot). Spatial fixity combined with the close proximity of housing units in urban areas suggest the potential for externalities inherent in a given location.\nThe housing industry is the development, construction, and sale of homes. Its interests are represented in the United States by the National Association of Home Builders (NAHB).[2] In Australia the trade association representing the residential housing industry is the Housing Industry Association.[3] It also refers to the housing market which means the supply and demand for houses, usually in a particular country or region. Housing market includes features as supply of housing, demand for housing, house prices, rented sector and government intervention in the Housing market.\nThe main determinants of the demand for housing are demographic. But other factors, like income, price of housing, cost and availability of credit, consumer preferences, investor preferences, price of substitutes, and price of complements, all play a role.\nThe core demographic variables are population size and population growth: the more people in the economy, the greater the demand for housing. But this is an oversimplification. It is necessary to consider family size, the age composition of the family, the number of first and second children, net migration (immigration minus emigration), non-family household formation, the number of double-family households, death rates, divorce rates, and marriages. In housing economics, the elemental unit of analysis is not the individual, as it is in standard partial equilibrium models. Rather, it is households, which demand housing services: typically one household per house. The size and demographic composition of households is variable and not entirely exogenous. It is endogenous to the housing market in the sense that as the price of housing services increase, household size will tend also to increase.[citation needed]\nIncome is also an important determinant. Empirical measures of the income elasticity of demand in North America range from 0.5 to 0.9 (De Leeuw 1971). If permanent income elasticity is measured, the results are slightly higher (Kain and Quigley 1975) because transitory income varies from year to year and across individuals, so positive transitory income will tend to cancel out negative transitory income. Many housing economists use permanent income rather than annual income because of the high cost of purchasing real estate. For many people, real estate will be the costliest item they will ever buy.\nThe price of housing is also an important factor. The price elasticity of the demand for housing services in North America is estimated as negative 0.7 by Polinsky and Ellwood (1979), and as negative 0.9 by Maisel, Burnham, and Austin (1971).\nAn individual household's housing demand can be modelled with standard utility/choice theory. A utility function, such as , can be constructed, in which the household's utility is a function of various goods and services (). This will be subject to a budget constraint such as , where is the household's available income and the are the prices for the various goods and services. The equality indicates that the money spent on all the goods and services must be equal to the available income. Because this is unrealistic, the model must be adjusted to allow for borrowing and saving. A measure of wealth, lifetime income, or permanent income is required. The model must also be adjusted to account for the heterogeneity of real estate. This can be done by deconstructing the utility function. If housing services () are separated into its constituent components (), the utility function can be rewritten as . By varying the price of housing services () and solving for points of optimal utility, the household's demand schedule for housing services can be constructed. Market demand is calculated by summing all individual household demands.\nDevelopers produce housing supply using land, labour, and various inputs, such as electricity and building materials. The quantity of new supply is determined by the cost of these inputs, the price of the existing stock of houses, and the technology of production. For a typical single-family dwelling in suburban North America, one can assign approximate cost percentages as follows: acquisition costs, 10%; site improvement costs, 11%; labour costs, 26%; materials costs, 31%; finance costs, 3%; administrative costs, 15%; and marketing costs, 4%. Multi-unit residential dwellings typically break down as follows: acquisition costs, 7%; site improvement costs, 8%; labour costs, 27%; materials costs, 33%; finance costs, 3%; administrative costs, 17%; and marketing costs, 5%. Public-subdivision requirements can increase development costs by up to 3%, depending on the jurisdiction. Differences in building codes account for about a 2% variation in development costs. However, these subdivision and building-code costs typically increase the market value of the buildings by at least the amount of their cost outlays. A production function such as can be constructed in which is the quantity of houses produced, is the amount of labour employed, is the amount of land used, and is the amount of other materials. This production function must, however, be adjusted to account for the refurbishing and augmentation of existing buildings. To do this, a second production function is constructed that includes the stock of existing housing and their ages as determinants. The two functions are summed, yielding the total production function. Alternatively, a hedonic pricing model can be regressed.\nThe long-run price elasticity of supply is quite high. George Fallis (1985) estimates it as 8.2, but in the short run, supply tends to be very price-inelastic. Supply-price elasticity depends on the elasticity of substitution and supply restrictions. There is significant substitutability, both between land and materials and between labour and materials. In high-value locations, developers can typically construct multi-story concrete buildings to reduce the amount of expensive land used. As labour costs have increased since the 1950s, new materials and capital-intensive techniques have been employed to reduce the amount of labour used. However, supply restrictions can significantly affect substitutability. In particular, the lack of supply of skilled labour (and labour-union requirements) can constrain the substitution from capital to labour. Land availability can also constrain substitutability if the area of interest is delineated (i.e., the larger the area, the more suppliers of land, and the more substitution that is possible). Land-use controls such as zoning bylaws can also reduce land substitutability.\nThe basic adjustment mechanism is a stock/flow model to reflect the fact that about 98% the market is existing stock and about 2% is the flow of new buildings.\nIn the adjacent diagram, the stock of housing supply is presented in the left panel while the new flow is in the right panel. There are four steps in the basic adjustment mechanism. First, the initial equilibrium price (Ro) is determined by the intersection of the supply of existing housing stock (SH) and the demand for housing (D). This rent is then translated into value (Vo) via discounting cash flows. Value is calculated by dividing current period rents by the discount rate, that is, as a perpetuity. Then value is compared to construction costs (CC) in order to determine whether profitable opportunities exist for developers. The intersection of construction costs and the value of housing services determine the maximum level of new housing starts (HSo). Finally the amount of housing starts in the current period is added to the available stock of housing in the next period. In the next period, supply curve SH will shift to the right by amount HSo.\nThe diagram to the right shows the effects of depreciation. If the supply of existing housing deteriorates due to wear, then the stock of housing supply depreciates. Because of this, the supply of housing (SHo) will shift to the left (to SH1) resulting in a new equilibrium demand of R1 (since the number of homes decreased, but demand still exists). The increase of demand from Ro to R1 will shift the value function up (from Vo to V1). As a result, more houses can be produced profitably and housing starts will increase (from HSo to HS1). Then the supply of housing will shift back to its initial position (SH1 to SHo).\nThe diagram on the right shows the effects of an increase in demand in the short run. If there is an increase in the demand for housing, such as the shift from Do to D1 there will be either a price or quantity adjustment, or both. For the price to stay the same, the supply of housing must increase. That is, supply SHo must increase by HS.\nThe diagram on the right shows the effects of an increase in costs in the short-run. If construction costs increase (say from CCo to CC1), developers will find their business less profitable and will be more selective in their ventures. In addition some developers may leave the industry. The quantity of housing starts will decrease (HSo to HS1). This will eventually reduce the level of supply (from SHo to SH1) as the existing stock of housing depreciates. Prices will tend to rise (from Ro to R1).\nGlobal real estate markets experienced a 15% drop in housing affordability due to central bank rate hikes in 2024.[4]\nThere are different ways of real estate financing: governmental and commercial sources and institutions. A homebuyer or builder can obtain financial aid from savings and loan associations, commercial banks, savings banks, mortgage bankers and brokers, life insurance companies, credit unions, federal agencies, individual investors, and builders.\nOver the last decade, residential prices increased every year on average by double digits in Beijing or Shanghai. However many observers and researchers argue that fundamentals of the housing sector, both sector-specific and macroeconomic, may have been the driving force behind housing price volatility.[5]\nThe most important purpose of these institutions is to make mortgage loans on residential property. These organizations, which also are known as savings associations, building and loan associations, cooperative banks (in New England), or homestead associations (in Louisiana), are the primary source of financial assistance to a large segment of American homeowners.[6] As home-financing institutions, they give primary attention to single-family residences and are equipped to make loans in this area.\nSome of the most important characteristics of a savings and loan association are:[6]\n- It is generally a locally owned and privately managed home-financing institution.\n- It receives individuals' savings and uses these funds to make long-term amortized loans to home purchasers.\n- It makes loans for the construction, purchase, repair, or refinancing of houses.\n- It is state or federally chartered.\nDue to changes in banking laws and policies, commercial banks are increasingly active in home financing. In acquiring mortgages on real estate, these institutions follow two main practices:[6]\n- Some banks maintain active and well-organized departments whose primary function is to compete actively for real estate loans. In areas lacking specialized real estate financial institutions, these banks become the source for residential and farm mortgage loans.\n- Banks acquire mortgages by simply purchasing them from mortgage bankers or dealers.\nIn addition, dealer service companies, which were originally used to obtain car loans for permanent lenders such as commercial banks, wanted to broaden their activity beyond their local area. In recent years, however, such companies have concentrated on acquiring mobile home loans in volume for both commercial banks and savings and loan associations. Service companies obtain these loans from retail dealers, usually on a non-recourse basis. Almost all bank or service company agreements contain a credit insurance policy that protects the lender if the consumer defaults.[6]\nThese depository financial institutions are federally chartered, primarily accept consumer deposits, and make home mortgage loans.[6]\nMortgage bankers are companies or individuals that originate mortgage loans, sell them to other investors, service the monthly payments, and may act as agents to dispense funds for taxes and insurance.\nMortgage brokers present homebuyers with loans from a variety of loan sources. Their income comes from the lender making the loan, just like with any other bank. Because they can tap a variety of lenders, they can shop on behalf of the borrower and achieve the best available terms. Despite legislation that could favor major banks, mortgage bankers and brokers keep the market competitive so the largest lenders must continue to compete on price and service. According to Don Burnette of Brightgreen Homeloans in Port Orange, Florida, \"The mortgage banker and broker conduit is vital to maintain competitive balance in the mortgage industry. Without it, the largest lenders would be able to unduly influence rates and pricing, potentially hurting the consumer. Competition drives every organization in this industry to constantly improve on their performance, and the consumer is the winner in this scenario.\"[6]\nLife insurance companies are another source of financial assistance. These companies lend on real estate as one form of investment and adjust their portfolios from time to time to reflect changing economic conditions. Individuals seeking a loan from an insurance company can deal directly with a local branch office or with a local real estate broker who acts as loan correspondent for one or more insurance companies.[6]\nThese cooperative financial institutions are organized by people who share a common bond—for example, employees of a company, labor union, or religious group. Some credit unions offer home loans in addition to other financial services.[6]\nUnder certain conditions and fund limitations, the Veterans Administration (VA) makes direct loans to creditworthy veterans in housing credit shortage areas designated by the VA's administrator. Such areas are generally rural and small cities and towns not near the metropolitan or commuting areas of large cities—areas where GI loans from private institutions are not available.\nThe federally supported agencies referred to here do not include the so-called second-layer lenders who enter the scene after the mortgage is arranged between the lending institution and the individual home buyer.[6]\nReal estate investment trusts (REITs), which began when the Real Estate Investment Trust Act became effective on January 1, 1961, are available. REITs, like savings and loan associations, are committed to real estate lending and can and do serve the national real estate market, although some specialization has occurred in their activities.[6]\nIn the United States, REITs generally pay little or no federal income tax but are subject to a number of special requirements set forth in the Internal Revenue Code, one of which is the requirement to annually distribute at least 90% of their taxable income in the form of dividends to shareholders.\nIndividual investors constitute a fairly large but somewhat declining source of money for home mortgage loans. Experienced observers claim that these lenders prefer shorter-term obligations and usually restrict their loans to less than two-thirds of the value of the residential property. Likewise, building contractors sometimes accept second mortgages in partial payment of the construction price of a home if the purchaser is unable to raise the total amount of the down payment above the first mortgage money offered.[6]\nIn addition, homebuyers or builders can save their money using FSBO in order not to pay extra fees.\nA 2022 study published by three professors from the University of California found that people in the United States broadly misunderstand the role that supply plays in counteracting the price of housing. Although most renters and homeowners were able to predict the effect of increasing supply on the market for other goods, the researchers found that only 30 to 40 percent of both groups could correctly predict the effect of new supply when applied to the market for homes. A majority of both renters and homeowners were found to prefer lower rent and housing prices for their city, but struggled to connect this preferred policy outcome to the supply-side solutions advocated for by economists. “Supply skepticism,” as the study labelled this phenomenon, was found to predict opposition to constructing new housing as well as opposition to state level policies that reduce local barriers like exclusionary zoning.[7][8][9]\nReal estate offers perspectives on understanding some of the factors in social mobility and economic decision-making, both at the macro and the micro levels. It has had a profound impact on not only government policies, but also meaningful discussions and choices for individuals looking to become homeowners. In recent years, liberalization of the mortgage markets and complex finance operations using mortgage as collateral (See Mortgage-backed security) have led to the expansion of the world economy. (See Financialization)\nWhile popular culture tends to link home ownership with right-wing voting, studies conducted across Europe tend to show mixed results. In Sweden, homeowners from left-wing social classes are likelier to report themselves as right-wing.[10] In France, middle-class voters were three times more likely to vote for Nicolas Sarkozy in the 2012 French presidential election, but results showed few variations between homeowners and tenants among lower-class and upper-class voters.[11] In Germany, homeowners were more likely to vote for conservative parties when house prices were rising.[12] In the UK, studies on the Housing Act 1980 and the 1983 United Kingdom general election tend to show that while purchasing council houses was linked to a decreased likelihood of voting for the Labour Party (UK), it is mostly the Alliance (center-left) that gained those defecting voters.[13] Studies in the UK and Germany have also highlighted links between home ownership and the redirection of voting patterns towards center-left parties. In line with results from the 1983 general election, a more recent study has argued that as part of a broader process of ‘gentrification’ of Labour electoral interests, UK homeowners tend to divert from the Conservative party (UK) towards a party that reconciles economic interests and left-wing ideals.[14] In Germany, one study has also pointed out a similar ‘embourgeoisement’ effect of the SPD vote.[12]\nRegarding preferences for policy proposals, some studies from the UK tend to demonstrate that, as houses are fixed assets, right-wing homeowners who have seen an increase in their property value tend to be less favorable to redistributive policies and social insurance programs. As their property value increases, Conservative voters tend to consider, to a larger degree, houses, a form of self-supplied insurance, which disincentivizes support for such programs. Those policy preferences are likely to be present to a greater extent when it comes to long-term social insurance and redistributive programs such as pensions due to the fixed nature of houses.[15] (See below “The trade-off between Social policies and home ownership)\nRecently, several studies conducted in several European countries sought to determine the influence of housing on right-wing populist electoral results. While political spectrums and housing markets differ according to countries, studies highlight some cross-national trends.\nStudies regarding the relationship between variation in house prices and populist electoral results have found that voters living in areas where house prices increased the least were more prone to vote for right-wing populist parties. One explanation may lie in the fact that as the housing map created winners (those owning in dynamic areas) and losers (those holding in less prosperous areas), those who experienced a relative decline in the value of their homes tended to feel left out of a significant component of household wealth formation, and therefore were inclined to favorite populist political parties which challenged a status quo that did not benefit them.[16] In the UK, some have highlighted a correlation between the relative deflation of housing prices and an increased likelihood of voting in favor of Brexit. Research in France shows that those who saw their home prices increase tended to vote for candidates other than Marine Le Pen in the 2017 French presidential election.[16] In Nordic countries, studies tend to come to similar findings, with data showing an inverse relationship between house price increases and support for right-wing populist parties. Those living in ‘left-behind’ areas (where house prices have decreased by 15%) tended to vote 10% higher for the Danish People’s Party than in ‘booming’ areas (where house prices have increased by 100% [17] In Germany, studies show that die AfD scores are higher in areas where house prices have not risen as much as the average rate.[12] Recent work by Julia Cagé and Thomas Piketty seems to corroborate the existence of areas’ prosperity determinants in the vote for right-wing populist parties. Describing the Rassemblement National vote as “a vote of little-middle access to home ownership,” they argue that home ownership is twice as frequent in towns and villages as in cities [18] (the formers generally being considered as less prosperous areas), represent to some a sign of upward social mobility towards neither affluent nor disadvantaged class and who do not felt represented by traditional right-wing political parties, which they consider representing a more favorited population, or by left-wing political parties, which they regard representing less deserving class and not supporting their efforts.[19] Such analysis, combined with previous presentations on house price variations, point in the direction that right-wing populist electoral results are, at least partly, driven by geosocial factors, with lower middle-class people living in less populated areas not feeling supported by traditional political parties and afraid of social downgrading.[20]\nAround Europe, debates around generational inequalities have been the subject of several news outlets. Regarding ownership inequality in Europe, data points to a positive relationship between age and home ownership. In England, those over 65 owned 35.8% of all houses in 2022, while they only represented 18.6% of the population in 2021.[21] In Germany, 50.4% of 60-69-year-olds owned their homes, while only 18.4% of 20-29-year-olds did.[22] As older people tend to have more time to accumulate wealth, academics highlight that these inequalities are wider than decades ago. Research shows that such inequalities exist due to a significant increase in housing prices to the annual income, also known as the wealth-to-income ratio. (See below Wealth-to-Income Ratio) Data collected from the Bank of England show that, in 1982, a house cost, on average, only 4.16 times an average British person’s annual income, but it has now climbed to 8.68 times the yearly income in 2023.[23] Several European countries enacted in the 1990s different public policies aimed to promote home ownership. In the UK during the 1980s, the Thatcher premiership passed the ‘right to buy scheme,’ which saw 3 million council houses sold at a price between 30% and 70% below market prices.[24] In France, liberal housing policies gained ground in the 1970s, enabling the rise of residential suburbs.[25] Nonetheless, some have also nuanced the extent to which countries have uniformly incentivized homeownership during that period. Studies on Nordic countries have highlighted the difference in housing models promoted by public policies, arguing that while Norway has been promoting cooperative and private ownership, it has not so much been the case with Denmark, which has, for example, institutionalized nonprofit renting.[26]\nAcademics have also pointed out that the strain on capital accumulation that resulted from WWII and post-war era interventionist and redistributionist policies have helped workers – i.e., those who earn a large share of their income through work, to earn a larger share of national income,[27] translating into a greater ability to become homeowners. Such theories would tend to favor the idea that intergenerational homeownership inequalities are more a product of class-based inequalities than intergenerational inequalities as such, as young people struggle to a larger extent not because older people have ‘hoarded’ the housing market but because the capital class, which is not constituted via age but rather by intra-familial transfers and wealth accumulation, have exploited the labor class to a greater extent since the end of the 1970s.[28] In line with this argument, some highlight the importance of considering intragenerational housing wealth inequalities; studies regarding the UK have demonstrated that such household housing wealth inequalities are the most important within the baby-boomer generation, suggesting limits to the intergenerational divide theories.[29]\nWhile several news outlets have framed a growing generational conflict around housing ownership, some studies have argued that if, from an objective perspective, millennials recognized that baby boomers were better off, a relational analysis demonstrated that they did not resent the older generation for their situations but rather the government for out-of-touch policies. As for the baby boomers, they tended to resent sympathy for the younger generations, recognizing that they were facing more significant barriers to home ownership.[30] Similarly, research argues that if the probability of housing being a personal issue significantly decreases with age, the tendency to consider it a country-wide problem, i.e., a public policy issue, remains similar across generations, which would tend to affirm the prominence of inter-generational solidarity rather than inter-generational conflict.\nMany government policies in social welfare states view houses as assets – a way for families to hedge their risks against eventual retirement and have a safe form of savings alternative to other pensions. Since the 1980s, these governments have often focused on making the housing market more liquid by broadening the access to financing of houses.[31] Bohle and Seabrooke argue that there are three paradigms of housing:[32]\n- Social Right - All citizens deserve fair housing. It is the obligation of the state to provide society with the ability to own homes by intervening in the market. (ex. Rent controls, tenure legislation, housing allowances, public/cooperative housing provision, management of housing by public or non-profit corporations, etc.) An example that the scholars offer is the post-war Scandinavian housing policies. Sweden believed that all citizens should have fair access to the housing market and that the state must play an active role in shaping the market to this nature.[33]\n- Asset - Houses are individual properties, and the markets work in the supply/demand fluctuation to provide opportunities. Essential for “asset-based welfare.” Furthermore, it serves as collateral for debt, which in turn serves as an investment outlet. (See neoliberal capitalism) Pensions are often complementary to housing-related financial products. Government programs would include the privatization of home ownership, deregulation of mortgage markets, the establishment of credit scores, fiscal and tax policies geared to home ownership, and assurances from central banks to stabilize mortgage bond markets.[34]\n- Patrimony - Family houses are passed on to younger generations: inheritance laws, family-based tax breaks, and subsidies. Family is seen as the stabilizing force of sharing political and economic preferences, and thus, patrimony is often seen under strong conservative connotation.\nThere are clear examples in which these three paradigms served as the basis for structural changes in which states’ housing policies evolved based upon the economic changes. In Ireland, the 1980s housing market reflected a patrimony-based housing market – but since then, neoliberal policies have led to cutting social housing programs and increasing private home constructions. Housing finance became even stronger with the EU accession, and banks began asset-based lending. By 2016, the Irish households were the fourth most indebted in the EU, a fifth with residential mortgage debts.:[35] After the Great Recession, Ireland suffered from the Troika, resulting in Irish domestic laws undermining the social policies in favor of its financial health. The Land and Conveyancing Law Reform Bill 2013 made it possible for lenders to repossess homes from borrowers - an action aimed at protecting the financial sector rather than having a coherent housing policy. The vacancy rate of housing in Ireland rose to 12.8%, leaving behind ghost towns. Ultimately, wealthier households in Ireland pass their houses to children while lower-income families are excluded from ever owning property – watching the paradigm of Ireland shift from asset to patrimony.[36]\nIn Denmark, the persistence of tax breaks for mortgage debt led to Danish consumers becoming one of the most indebted people in the world, with an average of 250% of debt per capita relative to personal income. Denmark used a mortgage-based covered bond system as its form of “privatized monetary policy,” in 1986, the housing bubble burst, leading to the coalition government reducing the mortgage interest deductibility from taxes. After the 1989 reform of the mortgage financing system (in line with the EU’s Second Banking Directive) and the 1990 Social Democratic government’s liberalized mortgage product policies, the credit market and available credit for housing boomed. In the 2000s, cracks began to show between the elites and masses - 2007 reforms allowed Danish banks to enter the mortgage market more aggressively while the foreign investment interests in Danish mortgage bond markets increased. (Increased financialization, the continued road to the housing as asset policies). Continued marketization of housing led some apartments in Copenhagen to triple in price within five years.[37]\nIn Hungary, foreign capital began flowing in during its accession to the EU era, and banks in Hungary were encouraged to increase their access to lending and lower borrowing costs, creating a risky housing market. When the housing bubble burst in 2008, the socialist Gordon Bajnai administration (2009-2010) focused on reducing public debt and deficit rather than the private side (over-indebted population). Orban’s government took a pivot from these policies - it angled its attacks on the foreign banks and lenders as the predators for why Hungary fell under economic downfall; the government levied special taxes on banks, insurance companies, and financial sectors. It tried to alleviate the burdens of households of foreign currency loans by allowing borrowers to pay in Hungarian forint (currency) at a preferential rate if they could pay their loans in one lump sum. Lenders were compelled to compensate borrowers for discrepancies between the exchange rate they used for loan repayment and the market exchange rate. However, this pushed the lower-income part of the society even further down; the cut down on subsidies to housing for these groups made homelessness even a crime. The ultraconservative policies pushed the cost of the housing onto the banks rather than taxpayers, while Hungary’s housing deprivation problems and issues with dampness, rot, lack of bathroom facilities, and overcrowding are among the worst in Central and Eastern Europe.[38]\nThe popular academic discourse surrounding the financialization of real estate is that liquidity and furthering of credit stimulate economic growth. Deregulation and liberalization are ways financial regulators intended for the markets to grow – through the increasing utilization of real estate as collateral for other financial products.[39] Such decisions have led to the creation of complex financial transactions that eventually led to the government’s continued neoliberal policies of opening the housing markets to financialization.\nThe academic debate around the causes for rising levels of mortgage debts concerns their focus on the supply or the demand side of the housing market. Recent scholars focusing on the demand side explain that consumers purchasing and owning houses seek mortgage lending to complete their purchases, ultimately increasing house prices. Schwartz states that the 1980s deregulation of mortgage markets increased potential credit, resulting in higher demand for real estate and rising prices.[39] In addition, Johnston and Regan showed that increased wages led to households having more liquidity to finance real estate properties, leading to higher demand for houses and, therefore, even more mortgage lending.[40] This side of the academic debate presents an argument that seeks to use increased demand for housing over the years as the primary reason for rising levels of mortgage debt worldwide.\nOn the other hand, Anderson and Kurzer argued that drivers of housing supply led to a rising level of mortgages and household indebtedness – while also interacting with the demand levels for housing. They studied the Netherlands, Denmark, and Sweden – three countries with the highest levels of outstanding mortgage debts compared to their disposable income and the highest levels of mortgage debts as part of their GDP.[41] In summary, the study presented that the three countries rode the waves of political policies that were formed around the right/center-right governments’ desire in the 1990s to stimulate home ownership and reduce social housing expenses and build a society of self-sufficient home-owners.[42] However, when the more left-leaning governments came to power, they did not reverse these policies. Instead, they introduced further deregulation of mortgage markets to allow more working-class consumers to become homeowners.\nAs a result, the continued neoliberal policies around the mortgage markets in these three countries led to the growth of banking power. Danish banks saw their annual growth rates in lending exceeding 50% between 2003 and 2007, while in the Netherlands, the Dutch market for securitized assets (in this case, mortgage-backed securities) became the second largest in Europe after the UK in 2008. In Sweden, the Swedish-covered bonds (securities, usually backed by mortgages) were at 55% of GDP in 2014 and more than double the Swedish government bonds.[43] In summary, the scholars argue that the Netherlands, Denmark, and Sweden mortgage markets were liberalized to encourage financial innovation and promote homeownership. Still, residential construction remained stagnant, leading to an inelastic housing supply. Government officials and regulators liberalized the mortgage market using credit and financial products such as special mortgage packages and consumer tax incentives to bypass this issue. Because all three countries have very high tax rates, the fiscal relief offered by tax incentives from having mortgages seemed even more lucrative, increasing the demand. At the same time, the supply of housing continued to stay inelastic. Anderson and Kurzer conclude that this led to the collapse of housing markets under the crumbling legs of complex mortgage-backed financial products.[44]\nUltimately, the debate around the rising mortgage debt levels worldwide centers around financialization and the political agenda of homeownership. There are strong connections to government programs that reflect the political ideologies of homeownership and the economic tools to achieve those means. In the case of the Netherlands, Sweden, and Denmark, Anderson and Kurzer showed that the center-right governments began increasing homeownership to cut social housing costs and reduce social policy dependence. The center-left government that subsequently followed also used similar tools of neo-liberal housing policies to enable homeownership for working-class citizens.\nAcademic debates surround the nature of the trade-off between social welfare and house ownership. In the 1980s, Jim Kemeney presented that homeownership and social welfare policies have an inverse relationship. First, Kemeney argued that citizens living in a country with meager retirement pensions and/or lacking government support of public welfare policies would tend to make private contributions in their earlier phases of life towards retirement – often in the form of housing. Homeowners would feel that their home is a valuable asset that would safeguard them from the risks of eventual retirement and aging. Thus, they would feel less inclined to rely on or support the government’s public welfare policies. The government’s social welfare policies would further undermine the value of the houses because the public support of the social housing upkeep will ultimately drive the value of the homes downward. Kemeney showed these findings from his analysis of eight OECD Countries, including Sweden, the Netherlands, the UK, the USA, Canada, Australia, and others. About twenty years later, Frank Castles, a professor of political science at the Australian National University, conducted more in-depth research on Kemeney’s thesis and strongly confirmed his case. Castles would adjust Kemeny’s thesis to show that the “really big trade-off” was between homeownership and pensions instead of the welfare state.[45]\nKemeney’s main argument is presented in his work:\n“My overall argument was that high rates of home ownership impacted on society through various forms of privatisation, influencing urban form, public transport, life-styles, gender roles, systems of welfare and social security as well as other dimensions of social structure. I argued that an overwhelming emphasis on home ownership created a lifestyle based on detached housing, privatised urban transport and its resulting ‘‘one-household’’ (and increasingly ‘‘one-person’’) car ownership, a traditional gendered division of labour based on female housewifery and the fulltime working male, and strong resistance to public expenditure that necessitated the high taxes needed to fund quality universal welfare provision.” [46]\nIn 2020, Gunten and Kohl returned to Kemeny’s thesis. They presented a different side of the academic research, presenting in an updated study that this inverse relationship between social welfare and house ownership converges upwards to what they labeled the “dual ratchet effect.” Huber and Stephens argued that the political costs of stopping social policies could be damaging, and thus, social policies are more resistant to their opposition.[47] Gunten and Kohl reciprocate this argument for homeownership – homeownership is also used to garner political support due to its popularity amongst citizens – and thus, the damaging political costs from withdrawing the benefits of having public policies favoring homeownership (ex. In the form of tax breaks, subsidies, etc.) lead to a resiliency against its opposition. This inelasticity of both social policies and homeownership resulted in the fact that high costs associated with decreasing either of the policies resulted in them being more responsive to upward drivers rather than downward effects.[48] Governments bypassed the issue of unloading the problems of social policies on homeowners by using the credit markets – resorting to inflation in the 70s, public debt in the 80s, and private debt in the 2000s. This was labeled as the buying time hypothesis by Gunten and Kohl and will be further supported by their capital supply hypothesis – where the amount of capital available will increase due to the deregulation of the international financial market since the 1970s and the growth of private pension fund assets leading to an abundance of available capital. In conclusion, Gunten and Kohl present a case where the inverse relationship between homeownership and social policies existed in the 80s but has changed towards the dual ratchet effect of simultaneous, upward convergence. Furthermore, they state that if the trade-off in the long run still holds, the correction costs of homeownership and pensions will eventually correct themselves in the long run when the amount of capital begins to dwindle and the credit market runs dry.[49]\n- Affordable housing\n- Affordability of housing in the United Kingdom\n- Australian property market\n- Effective gross income\n- Housing affordability index\n- Investment rating for real estate\n- Land value tax\n- Property Management\n- Real estate trends\n- Real estate business\n- Real estate development\n- Real-estate bubble\n- 2000s United States housing bubble\n- Sunshine tax\n- \"Overinvestment in residential real estate: an analysis of the impact across levels of economic diversification\". Gale Academic Onfile.\n- About the National Association of Home Builders Archived 2010-09-22 at the Wayback Machine, accessed September 16, 2010\n- Homepage Housing Industry Association\n- \"The World Bank | IMF Reports\".\n- Deng, Yongheng; Girardin, Eric; Joyeux, Roselyne (2018). \"Fundamentals and the volatility of real estate prices in China: A sequential modelling strategy\" (PDF). China Economic Review. 48: 205–222. doi:10.1016/j.chieco.2016.10.011. Archived from the original (PDF) on 2017-08-08. Retrieved 2019-12-14.\n- Mishler, Lon; Cole, Robert E. (1995). Consumer and business credit management. Homewood: Irwin. pp. 123–128. ISBN 978-0-256-13948-8.\n- Nall, Clayton; Elmendorf, Christopher; Oklobdzija, Stan (15 Nov 2022). \"Folk Economics and the Persistence of Political Opposition to New Housing\". doi:10.2139/ssrn.4266459. SSRN 4266459.\n{{cite journal}}\n: Cite journal requires|journal=\n(help) - Levitz, Eric (2023-08-04). \"Rent Growth Is Slowing (Where Housing Got Built)\". Intelligencer. Retrieved 2023-08-04.\n- Kazis, Noah (July 2023). \"Learning From Land Use Reforms: Housing Outcomes and Regulatory Change\" (PDF). Cityscape. 25 (2): 93–105 – via Office of Policy Development and Research (PD&R) of the U.S. Department of Housing and Urban Development.\n[T]his collection does not include the voices of 'supply skeptics' who hold that increased supply will do little to improve, and may even hurt, overall housing affordability (Been, Ellen, and O'Regan, 2019). Such perspectives remain fairly popular among the public at large and with a small-and-declining number of scholars (Nall, Elmendorf, and Oklobdzija, 2022). However, this 'supply skepticism' is not backed by the weight of the evidence.\n- (Davidsson, 2018)\n- (IFOP, 2012)\n- (Beckmann, Fulda and Kohl, 2020)\n- (Williams, Sewel and Twine, 1987)\n- (Hadziabdic and Kohl, 2022)\n- (Ansell, 2014)\n- (Adler and Ansell, 2020)\n- (Ansell et al., 2022)\n- (Piketty and Cagé, 2023, p. 134)\n- (Piketty and Cagé, 2023, p. 593)\n- (« Le grand ressort du vote Marine Le Pen, c’est la peur du déclassement », 2015)\n- (England: homeowners by age 2022, no date)\n- (Living situations by age group Germany 2023, no date)\n- (Frank, 2022)\n- (Bugeja, 2011)\n- (Bourdieu and Christin, 1990)\n- (Ruonavaara, 2008)\n- (Milanovic, 2014)\n- (Christophers, 2018)\n- (Searle and McCollum, 2014)\n- (Hoolachan and McKee, 2019)\n- (Bohle and Seabrooke 2020, 413)\n- (Bohle and Seabrooke 2020, 414–16)\n- (Bengtsson 2001, 264–65)\n- (Reisenbichler 2020)\n- (Bank of Ireland 2016)\n- (Bohle and Seabrooke 2020, 418–19)\n- (Bohle and Seabrooke 2020, 420–23)\n- (Bohle and Seabrooke 2020, 423–27)\n- (Schwartz 2009)\n- (Johnston and Regan 2017)\n- (Anderson and Kurzer 2020, 367)\n- (Ronald 2008)\n- (Anderson and Kurzer 2020, 379–80)\n- (Anderson and Kurzer 2020, 380–82)\n- (Kemeny 2005) / (Castles 1998) / (Van Gunten and Kohl 2020, 438)\n- (Kemeny 2005, 60)\n- (Huber and Stephens 2001; Pierson 2011)\n- (Huber and Stephens 2001, 443)\n- (Van Gunten and Kohl 2020)\n- Davidsson, S. (2018). Left-right Orientation, Homeownership and Class Position in Sweden. Scandinavian Political Studies, 41(4), pp. 309–331. doi:https://doi.org/10.1111/1467-9477.12131.\n- Bonneval, L. and Fourquet, J. (2012). La France des propriétaires, vote à droite ? [online] Available at: https://www.ifop.com/publication/france-des-proprietaires-vote/#.\n- Beckmann, P., Fulda, B. and Kohl, S. (2020). Housing and voting in Germany: Multi-level evidence for the association between house prices and housing tenure and party outcomes, 1980-2017. MPIfG Discussion Paper. [online] Available at: https://ideas.repec.org/p/zbw/mpifgd/206.html [Accessed 19 Nov. 2023].\n- Williams, N.J., Sewel, J.B. and Twine, F.E. (1987). Council house sales and the electorate: Voting behaviour and ideological implications. Housing Studies, 2(4), pp. 274–282. doi:https://doi.org/10.1080/02673038708720607.\n- HADZIABDIC, S. and KOHL, S. (2021). Is the left right? The creeping embourgeoisement of social democracy through homeownership. European Journal of Political Research. doi:https://doi.org/10.1111/1475-6765.12479.\n- ANSELL, B. (2014). The Political Economy of Ownership: Housing Markets and the Welfare State. American Political Science Review, 108(2), pp. 383–402.\n- Adler, D. and Ansell, B. (2019). Housing and populism. West European Politics, 43(2), pp. 344–365. doi:https://doi.org/10.1080/01402382.2019.1615322.\n- Ansell, B., Hjorth, F., Nyrup, J. and Larsen, M.V. (2021). Sheltering Populists? House Prices and the Support for Populist Parties. The Journal of Politics.\n- Piketty, T. and Cagé, J. (2023). Une histoire du conflit politique. Seuil. P. 134.\n- Piketty, T. and Cagé, J. (2023). Une histoire du conflit politique. Seuil. P. 593.\n- l’Opinion. (2015). ‘Le grand ressort du vote Marine Le Pen, c’est la peur du déclassement’. [online] Available at: https://www.lopinion.fr/politique/le-grand-ressort-du-vote-marine-le-pen-cest-la-peur-du-declassement [Accessed 19 Nov. 2023]\n- Statista (2022). Age distribution of home owners in England 2022. [online] Statista. Available at: https://www.statista.com/statistics/321065/uk-england-home-owners-age-groups/.\n- Statista. (2023). Living situations by age group Germany 2023. [online] Available at: https://www.statista.com/statistics/974222/living-situations-age-group-germany/.\n- Frank, S. (2022). Home Price to Income Ratio (US & UK) - 73 Year Chart | Longtermtrends. [online] www.longtermtrends.net. Available at: https://www.longtermtrends.net/home-price-median-annual-income-ratio/.\n- Bugeja, F. (2011). Les inégalités d’accès à la propriété et leurs déterminants institutionnels. Revue française de sociologie, Vol. 52(1), pp. 37–69.\n- Bourdieu, P. and Christin, R. (1990). La construction du marché [Le champ administratif et la production de la ‘politique du logement’]. Actes de la recherche en sciences sociales, 81(1), pp. 65–85. doi:https://doi.org/10.3406/arss.1990.2927.\n- Ruonavaara, H. (2008). Home ownership and the Nordic housing policies in the 'Retrenchment phase\". repository.tudelft.nl. [online] Available at: http://resolver.tudelft.nl/uuid:9d5bbec2-06e7-4a26-8e16-77ab78e3d56c.\n- Milanovic, B. (2014). The Return of ‘Patrimonial Capitalism’: A Review of Thomas Piketty’sCapital in the Twenty-First Century. Journal of Economic Literature, [online] 52(2), pp. 519–534. doi:https://doi.org/10.1257/jel.52.2.519.\n- Christophers, B. (2017). Intergenerational Inequality? Labour, Capital, and Housing Through the Ages. Antipode, [online] 50(1), pp. 101–121. doi:https://doi.org/10.1111/anti.12339.\n- Searle, B.A. and McCollum, D. (2014). Property-based welfare and the search for generational equality. International Journal of Housing Policy, 14(4), pp. 325–343. doi:https://doi.org/10.1080/14616718.2014.955334.\n- Hoolachan, J. and McKee, K. (2018). Inter-generational housing inequalities: ‘Baby Boomers’ versus the ‘Millennials’. Urban Studies, 56(1), pp. 210–225. doi:https://doi.org/10.1177/0042098018775363.\n- Bourne, L. S. and Hitchcock, J. R. editors., (1978) Urban Housing Markets :Recent directions in research and policy, University of Toronto Press, Toronto, 1978.\n- De Leeuw, Frank (1971). \"The Demand for Housing: A Review of Cross-Section Evidence\". The Review of Economics and Statistics. 53 (1): 1–10. doi:10.2307/1925374. JSTOR 1925374.\n- Fallis, G. (1985) Housing Economics, Butterworth, Toronto, 1985.\n- Harris, Richard (2016). \"The Rise of Filtering Down\". Social Science History. 37 (4): 515–549. doi:10.1017/S0145553200011950. S2CID 152079349.\n- Kain J. F. and Quigley J. M. (1975) Housing Markets and Racial Discrimination, National Bureau of Economic Research, New York.\n- Kawaguchi, Y., (2013), Real Estate Economics, Seibunsha, Tokyo.\n- Kawaguchi, Y., (2001), Real Estate Financial Engineering, Seibunsha, Tokyo.\n- Maisel, Sherman J.; Burnham, James B.; Austin, John S. (1971). \"The Demand for Housing: A Comment\". The Review of Economics and Statistics. 53 (4): 410–413. doi:10.2307/1928748. JSTOR 1928748.\n- Muth, R. (1960) “The demand for non-farm housing”, in A. C. Harberger, ed., The demand for durable goods, University of Chicago Press, Chicago, 1960.\n- Olsen, Edgar O. (September 1969). \"A Competitive Theory of the Housing Market\". The American Economic Review. 59 (4, Part 1): 612–22. JSTOR 1813226.\n- Polinsky, A. Mitchell; Ellwood, David T. (1979). \"An Empirical Reconciliation of Micro and Grouped Estimates of the Demand for Housing\". The Review of Economics and Statistics. 61 (2): 199–205. doi:10.2307/1924587. JSTOR 1924587.\n- Anderson, Karen M., and Paulette Kurzer. 2020. “The Politics of Mortgage Credit Expansion in the Small Coordinated Market Economies.” West European Politics 43 (2): 366–89. https://doi.org/10.1080/01402382.2019.1596421.\n- Bank of Ireland. 2016. “Statistical Release, Quarterly Financial Accounts.” https://www.centralbank.ie/docs/default-source/statistics/data-and-analysis/financial-accounts/gns-6-2-4-qfa-2016-q1.pdf?sfvrsn=5.\n- Bengtsson, Bo. 2001. “Housing as a Social Right: Implications for Welfare State Theory.” Scandinavian Political Studies 24 (4): 255–75. https://doi.org/10.1111/1467-9477.00056.\n- Bohle, Dorothee, and Leonard Seabrooke. 2020. “From Asset to Patrimony: The Re-Emergence of the Housing Question.” West European Politics 43 (2): 412–34. https://doi.org/10.1080/01402382.2019.1663630.\n- Castles, Frank. 1998. “The Really Big Trade-Off: Home Ownership and the Welfare State in The New World and the Old.” Acta Politica, 5–19.\n- Huber, Evelyne, and John D. Stephens. 2001. Development and Crisis of the Welfare State: Parties and Policies in Global Markets. Chicago: The University of Chicago Press.\n- Johnston, Alison, and Aidan Regan. 2017. “Global Finance, Labor Politics, and the Political Economy of Housing Prices.” Politics & Society 45 (3): 327–58. https://doi.org/10.1177/0032329217702102.\n- Kemeny, Jim. 2005. “‘The Really Big Trade‐Off’ between Home Ownership and Welfare: Castles’ Evaluation of the 1980 Thesis, and a Reformulation 25 Years On.” Housing, Theory and Society 22 (2): 59–75. https://doi.org/10.1080/14036090510032727.\n- Pierson, Paul. 2011. “The Welfare State over the Very Long Run.” ZeSArbeitspapier.\n- Reisenbichler, Alexander. 2020. “The Politics of Quantitative Easing and Housing Stimulus by the Federal Reserve and European Central Bank, 2008‒2018.” West European Politics 43 (2): 464–84. https://doi.org/10.1080/01402382.2019.1612160.\n- Ronald, Richard. 2008. The Ideology of Home Ownership. London: Palgrave Macmillan UK. https://doi.org/10.1057/9780230582286.\n- Schwartz, Herman M. 2009. Subprime Nation: American Power, Global Capital, and the Housing Bubble. Cornell Studies in Money. Ithaca (N.Y.): Cornell university press.\n- Van Gunten, Tod, and Sebastian Kohl. 2020. “The Inversion of the ‘Really Big Trade-off’: Homeownership and Pensions in Long-Run Perspective.” West European Politics 43 (2): 435–63. https://doi.org/10.1080/01402382.2019.1609285.\n- Jose Francisco Bellod Redondo, University of Málaga, Detection of real estate bubbles: the Spanish case: performance of Spanish housing market between 1989 and 2009 (in Spanish).",
    "residential property": "A residential area is a land used in which housing predominates, as opposed to industrial and commercial areas.[1][2]\nHousing may vary significantly between, and through, residential areas. These include single-family housing, multi-family residential, or mobile homes. Zoning for residential use may permit some services or work opportunities or may totally exclude business and industry. It may permit high density land use or only permit low density uses. Residential zoning usually includes a smaller FAR (floor area ratio) than business, commercial or industrial/manufacturing zoning. The area may be large or small.[3][4][5]\nIn certain residential areas, especially rural, large tracts of land may have no services whatever, such that residents seeking services must use a motor vehicle or other transportation, so the need for transportation has resulted in land development following existing or planned transport infrastructure such as rail and road. Development patterns may be regulated by restrictive covenants contained in the deeds to the properties in the development and may also result from or be reinforced by zoning. Restrictive covenants are not easily changed when the agreement of all property owners (many of whom may not live in the area) is required. The area so restricted may be large or small.\nResidential areas may be subcategorized in the concentric zone model and other schemes of urban geography.\nResidential development is real estate development for residential purposes. Some such developments are called a subdivision, when the land is divided into lots with houses constructed on each lot. Such developments became common during the late nineteenth century, particularly in the form of streetcar suburbs.\nIn previous centuries, residential development was mainly of two kinds. Rich people bought a townlot, hired an architect and/or contractor, and built a bespoke / customized house or mansion for their family. Poor urban people lived in shantytowns or in tenements built for rental. Single-family houses were seldom built on speculation, that is for future sale to residents not yet identified. When cities and the middle class expanded greatly and mortgage loans became commonplace, a method that had been rare became commonplace to serve the expanding demand for home ownership.\nPost–World War II economic expansion in major cities of the United States, especially New York City and Los Angeles produced a demand for thousands of new homes, which was largely met by speculative building. Its large-scale practitioners disliked the term \"property speculator\" and coined the new name \"residential development\" for their activity. Entire farms and ranches were subdivided and developed, often with one individual or company controlling all aspects of entitlement (permits), land development (streets and grading), infrastructure (utilities and sewage disposal), and housing. Communities like Levittown, Long Island or Lakewood south of Los Angeles saw new homes sold at unprecedented rates—more than one a day. Many techniques which had made the automobile affordable made housing affordable: standardization of design and small, repetitive assembly tasks, advertising, and a smooth flow of capital. Mass production resulted in a similar uniformity of product, and a more comfortable lifestyle than cramped apartments in the cities. With the advent of government-backed mortgages, it could actually be cheaper to own a house in a new residential development than to rent.\nAs with other products, continual refinements appeared. Curving streets, greenbelt parks, neighborhood pools, and community entry monumentation appeared. Diverse floor plans with differing room counts, and multiple elevations (different exterior \"looks\" for the same plan) appeared. Developers remained competitive with each other on everything, including location, community amenities, kitchen appliance packages, and price.\nToday, a typical residential development in the United States might include traffic calming features such as a slowly winding street, dead-end road, or looped road lined with homes.\nSuburban developments help form the stereotypical image of a \"suburban America\" and are generally associated with the American middle-class. Most offer homes in a narrow range of age, price, size and features, thus potential residents having different needs, wishes or resources must look elsewhere. Some residential developments are gated communities or residential communities.\nCriticisms of residential developments may include the following:\n- They do not mesh well with the greater community. Some are isolated, with only one entrance, or otherwise connected with the rest of the community in few ways.\n- Being commuter towns, they serve no more purpose for the greater community than other specialized settlements do and thus require residents to go to the greater community for commercial or other purposes, whereas mixed-use developments provide for commerce and other activities, so residents need not go as often to the greater community.\n- Lodging advancements can frequently be isolated with only one way in and one way out. Without great streets and ways to different regions, getting around can take a pointlessly lengthy timespan - making it harder for individuals to walk and cycle.\n- Front nurseries with low walls will quite often be very much taken care of, with inhabitants keeping an eye on their front nurseries and covertly attempting to outperform their neighbors. Numerous designers lessen costs by eliminating these unobtrusive yet significant qualifications among public and confidential space. The outcome is many times puts that become unused, disliked and neglected.\n- Current roads are packed with unattended vehicles, which is not just unattractive but blocks pavements, makes roads more unsafe for kids and is also often the source of arguments with neighbours.\n- Everybody cherishes a tree-lined road, however new improvements frequently overlook them. Numerous expressways specialists deter trees and hedgerows making green and verdant roads progressively difficult to come by. As an outcome, many modern developments are dominated by hard materials and often appear colorless.\n- Santiago, Jolie (March 7, 2024). \"Bobcat tracks spotted in residential neighborhood\". www.wwnytv.com.\n- DeParle, Jason; Altman, Bobby (March 1, 2024). \"Developers Got Backing for Affordable Housing. Then the Neighborhood Found Out\". The New York Times.\n- \"New Shwapno outlet opens in Bashundhara residential area\". The Business Standard. December 28, 2023.\n- \"Watch: 4 leopards spotted roaming in Maharashtra residential area\". India Today. 2024-03-07.\n- \"Israeli attack on residential area in south Gaza kills at least 29 people\". Al Jazeera. 2023-12-19.\nThe dictionary definition of residential at Wiktionary\n- Meadowbrook symbol of postwar housing boom - Pantagraph (Bloomington, Illinois newspaper)",
    "retail": "This article has multiple issues. Please help improve it or discuss these issues on the talk page. (Learn how and when to remove these messages)\n|\nRetail is the sale of goods and services to consumers, in contrast to wholesaling, which is the sale to business or institutional customers. A retailer purchases goods in large quantities from manufacturers, directly or through a wholesaler, and then sells in smaller quantities to consumers for a profit. Retailers are the final link in the supply chain from producers to consumers.\nRetail markets and shops have a long history, dating back to antiquity. Some of the earliest retailers were itinerant peddlers. Over the centuries, retail shops were transformed from little more than \"rude booths\" to the sophisticated shopping malls of the modern era. In the digital age, an increasing number of retailers are seeking to reach broader markets by selling through multiple channels, including both bricks and mortar and online retailing. Digital technologies are also affecting the way that consumers pay for goods and services. Retailing support services may also include the provision of credit, delivery services, advisory services, stylist services and a range of other supporting services. Retail workers are the employees of such stores.\nMost modern retailers typically make a variety of strategic level decisions including the type of store, the market to be served, the optimal product assortment, customer service, supporting services, and the store's overall market positioning. Once the strategic retail plan is in place, retailers devise the retail mix which includes product, price, place, promotion, personnel, and presentation.\nThe word retail comes from the Old French verb retaillier, meaning \"to shape by cutting\" (c. 1365). It was first recorded as a noun in 1433 with the meaning of \"a sale in small quantities\" from the Middle French verb retailler meaning \"a piece cut off, shred, scrap, paring\".[1] At present, the meaning of the word retail (in English, French, Dutch, German and Spanish) refers to the sale of small quantities of items to consumers (as opposed to wholesale).\nRetail refers to the activity of selling goods or services directly to consumers or end-users.[2] Some retailers may sell to business customers, and such sales are termed non-retail activity. In some jurisdictions or regions, legal definitions of retail specify that at least 80 percent of sales activity must be to end-users.[3] In the banking industry \"wholesale\" usually refers to wholesale banking, providing tailored services to large customers, in contrast with retail banking, providing standardized services to large numbers of smaller customers.\nRetailing often occurs in retail stores or service establishments, but may also occur through direct selling such as through vending machines, door-to-door sales or electronic channels.[4] Although the idea of retail is often associated with the purchase of goods, the term may be applied to service providers that sell to consumers. Retail service providers include retail banking, tourism, insurance, private healthcare, private education, private security firms, legal firms, publishers, public transport, and others. For example, a tourism provider might have a retail division that books travel and accommodation for consumers plus a wholesale division that purchases blocks of accommodation, hospitality, transport, and sightseeing which are subsequently packaged into a holiday tour for sale to retail travel agents.\nSome retailers badge their stores as \"wholesale outlets\" offering \"wholesale prices\". While this practice may encourage consumers to imagine that they have access to lower prices, while being prepared to trade-off reduced prices for cramped in-store environments, in a strictly legal sense, a store that sells the majority of its merchandise directly to consumers, is defined as a retailer rather than a wholesaler. Different jurisdictions set parameters for the ratio of consumer to business sales that define a retail business.\nObtaining goods in the required quantities and locating them where consumers will purchase them are core retail activities, so purchasing and supply management are essential features of a retail strategy.[5]\nThe distinction between \"strategic\" and \"managerial\" decision-making is commonly used to distinguish \"two phases having different goals and based on different conceptual tools. Strategic planning concerns the choice of policies aiming at improving the competitive position of the firm, taking account of challenges and opportunities proposed by the competitive environment. On the other hand, managerial decision-making is focused on the implementation of specific targets.\"[6]\nIn retailing, the strategic plan is designed to set out the vision and provide guidance for retail decision-makers and provide an outline of how the product and service mix will optimize customer satisfaction. As part of the strategic planning process, it is customary for strategic planners to carry out a detailed environmental scan which seeks to identify trends and opportunities in the competitive environment, market environment, economic environment and statutory-political environment. The retail strategy is normally devised or reviewed every three to five years by the chief executive officer. The profit margins of retailers depend largely on their ability to achieve market competitive transaction costs.\nThe strategic retail analysis typically includes following elements:[7]\n- Market analysis – Market size, stage of market, market competitiveness, market attractiveness, market trends\n- Customer analysis – Market segmentation, demographic, geographic, and psychographic profile, values and attitudes, shopping habits, brand preferences, analysis of needs and wants, and media habits\n- Internal analysis – Other capacities including human resource capability, technological capability, financial capability, ability to generate scale economies or economies of scope, trade relations, reputation, positioning, and past performance\n- Competition analysis – Availability of substitutes, competitor's strengths and weaknesses, perceptual mapping, competitive trends\n- Review of product mix – :: Sales per square foot, stock-turnover rates, profitability per product line\n- Review of distribution channels – Lead-times between placing order and delivery, cost of distribution, cost efficiency of intermediaries\n- Evaluation of the economics of the strategy – Cost-benefit analysis of planned activities\nAt the conclusion of the retail analysis, retail marketers should have a clear idea of which groups of customers are to be the target of marketing activities. Not all elements are, however, equal, often with demographics, shopping motivations, and spending directing consumer activities.[8] Retail research studies suggest that there is a strong relationship between a store's positioning and the socio-economic status of customers.[9] In addition, the retail strategy, including service quality, has a significant and positive association with customer loyalty.[10] A marketing strategy effectively outlines all key aspects of firms' targeted audience, demographics, preferences. In a highly competitive market, the retail strategy sets up long-term sustainability. It focuses on customer relationships, stressing the importance of added value, customer satisfaction and highlights how the store's market positioning appeals to targeted groups of customers.[11]\nA retail mix is devised for the purpose of coordinating day-to-day tactical decisions. The retail marketing mix typically consists of six broad decision layers including product decisions, place decisions, promotion, price, personnel and presentation (also known as physical evidence). The retail mix is loosely based on the marketing mix, but has been expanded and modified in line with the unique needs of the retail context. A number of scholars have argued for an expanded marketing, mix with the inclusion of two new Ps, namely, Personnel and Presentation since these contribute to the customer's unique retail experience and are the principal basis for retail differentiation. Yet other scholars argue that the Retail Format (i.e. retail formula) should be included.[12] The modified retail marketing mix that is most commonly cited in textbooks is often called the 6 Ps of retailing (see diagram at right).[13][14]\nThe primary product-related decisions facing the retailer are the product assortment (what product lines, how many lines and which brands to carry); the type of customer service (high contact through to self-service) and the availability of support services (e.g. credit terms, delivery services, after sales care). These decisions depend on careful analysis of the market, demand, competition as well as the retailer's skills and expertise.\nCustomer service is the \"sum of acts and elements that allow consumers to receive what they need or desire from [the] retail establishment.\" Retailers must decide whether to provide a full service outlet or minimal service outlet, such as no-service in the case of vending machines; self-service with only basic sales assistance or a full service operation as in many boutiques and speciality stores. In addition, the retailer needs to make decisions about sales support such as customer delivery and after sales customer care.\nPlace decisions are primarily concerned with consumer access and may involve location, space utilisation and operating hours. Retailers may consider a range of both qualitative and quantitative factors to evaluate to potential sites under consideration. Macro factors include market characteristics (demographic, economic and socio-cultural), demand, competition and infrastructure (e.g. the availability of power, roads, public transport systems). Micro factors include the size of the site (e.g. availability of parking), access for delivery vehicles. A major retail trend has been the shift to multi-channel retailing. To counter the disruption caused by online retail, many bricks and mortar retailers have entered the online retail space, by setting up online catalogue sales and e-commerce websites. However, many retailers have noticed that consumers behave differently when shopping online. For instance, in terms of choice of online platform, shoppers tend to choose the online site of their preferred retailer initially, but as they gain more experience in online shopping, they become less loyal and more likely to switch to other retail sites.[15] Online stores are usually available 24 hours a day, and many consumers across the globe have Internet access both at work and at home.\nThe broad pricing strategy is normally established in the company's overall strategic plan. In the case of chain stores, the pricing strategy would be set by head office. Broadly, there are six approaches to pricing strategy mentioned in the marketing literature: operations-oriented,[16] revenue-oriented,[16] customer-oriented,[16] value-based,[17][18] relationship-oriented,[19] and socially-oriented.[20] When decision-makers have determined the broad approach to pricing (i.e., the pricing strategy), they turn their attention to pricing tactics. Tactical pricing decisions are shorter term prices, designed to accomplish specific short-term goals. Pricing tactics that are commonly used in retail include discount pricing,[21] everyday low prices,[22] high-low pricing,[22][23] loss leaders, product bundling,[24] promotional pricing, and psychological pricing.[25] Two strategies to entice the buyer, money back guarantee and buy one get one free, were devised by 18th-century retail entrepreneur Josiah Wedgwood.[26][27] Retailers must also plan for customer preferred payment modes – e.g. cash, credit, lay-by, Electronic Funds Transfer at Point-of-Sale (EFTPOS). All payment options require some type of handling and attract costs.[28] Contrary to common misconception, price is not the most important factor for consumers, when deciding to buy a product.[29]\nBecause patronage at a retail outlet varies, flexibility in scheduling is desirable. Employee scheduling software is sold, which, using known patterns of customer patronage, more or less reliably predicts the need for staffing for various functions at times of the year, day of the month or week, and time of day. Usually needs vary widely. Conforming staff utilization to staffing needs requires a flexible workforce which is available when needed but does not have to be paid when they are not, part-time workers; as of 2012 70% of retail workers in the United States were part-time. This may result in financial problems for the workers, who while they are required to be available at all times if their work hours are to be maximized, may not have sufficient income to meet their family and other obligations.[30] Retailers can employ different techniques to enhance sales volume and to improve the customer experience, such as Add-on, Upsell or Cross-sell; Selling on value;[31] and knowing when to close the sale.[32]\nTransactional marketing aims to find target consumers, then negotiate, trade, and finally end relationships to complete the transaction. In this one-time transaction process, both parties aim to maximize their own interests. As a result, transactional marketing raises follow-up problems such as poor after-sales service quality and a lack of feedback channels for both parties. In addition, because retail enterprises needed to redevelop client relationships for each transaction, marketing costs were high and customer retention was low. All these downsides to transactional marketing gradually pushed the retail industry towards establishing long-term cooperative relationships with customers. Through this lens, enterprises began to focus on the process from transaction to relationship.[33] While expanding the sales market and attracting new customers is very important for the retail industry, it is also important to establish and maintain long term good relationships with previous customers, hence the name of the underlying concept, \"relational marketing\". Under this concept, retail enterprises value and attempt to improve relationships with customers, as customer relationships are conducive to maintaining stability in the current competitive retail market, and are also the future of retail enterprises.\nPresentation refers to the physical evidence that signals the retail image. Physical evidence may include a diverse range of elements – the store itself including premises, offices, exterior facade and interior layout, websites, delivery vans, warehouses, staff uniforms. The environment in which the retail service encounter occurs is sometimes known as the retail servicescape.[34] The store environment consists of many elements such as aromas, the physical environment (furnishings, layout, and functionality), ambient conditions (lighting, air temperature, and music) as well as signs, symbols, and artifacts (e.g. sales promotions, shelf space, sample stations, visual communications). Retail designers pay close attention to the front of the store, which is known as the decompression zone. In order to maximize the number of selling opportunities, retailers generally want customers to spend more time in a retail store. However, this must be balanced against customer expectations surrounding convenience, access and realistic waiting times.[35] The way that brands are displayed is also part of the overall retail design. Where a product is placed on the shelves has implications for purchase likelihood as a result of visibility and access.[36] Ambient conditions, such as lighting, temperature and music, are also part of the overall retail environment.[37] It is common for a retail store to play music that relates to their target market.[38]\nTwo different strands of research have investigated shopper behaviour. One is primarily concerned with shopper motivations. The other stream of research seeks to segment shoppers according to common, shared characteristics. To some extent, these streams of research are inter-related, but each stream offers different types of insights into shopper behaviour.\nBabin et al. carried out some of the earliest investigations into shopper motivations and identified two broad motives: utilitarian and hedonic. Utilitarian motivations are task-related and rational. For the shopper with utilitarian motives, purchasing is a work-related task that is to be accomplished in the most efficient and expedient manner. On the other hand, hedonic motives refer to pleasure. The shopper with hedonic motivations views shopping as a form of escapism where they are free to indulge fantasy and freedom. Hedonic shoppers are more involved in the shopping experience.[39]\nMany different shopper profiles can be identified. Retailers develop customised segmentation analyses for each unique outlet. However, it is possible to identify a number of broad shopper profiles. One of the most well-known and widely cited shopper typologies is that developed by Sproles and Kendal in the mid-1980s.[40][41][42] Sproles and Kendall's consumer typology has been shown to be relatively consistent across time and across cultures.[43][44] Their typology is based on the consumer's approach to making purchase decisions.[45]\n- Quality conscious/Perfectionist: Quality-consciousness is characterised by a consumer's search for the very best quality in products; quality conscious consumers tend to shop systematically making more comparisons and shopping around.\n- Brand-conscious: Brand-consciousness is characterised by a tendency to buy expensive, well-known brands or designer labels. Those who score high on brand-consciousness tend to believe that the higher prices are an indicator of quality and exhibit a preference for department stores or top-tier retail outlets.\n- Recreation-conscious/Hedonistic: Recreational shopping is characterised by the consumer's engagement in the purchase process. Those who score high on recreation-consciousness regard shopping itself as a form of enjoyment.\n- Price-conscious: A consumer who exhibits price-and-value consciousness. Price-conscious shoppers carefully shop around seeking lower prices, sales or discounts and are motivated by obtaining the best value for money.\n- Novelty/fashion-conscious: characterised by a consumer's tendency to seek out new products or new experiences for the sake of excitement; who gain excitement from seeking new things; they like to keep up-to-date with fashions and trends, variety-seeking is associated with this dimension.\n- Impulsive: Impulsive consumers are somewhat careless in making purchase decisions, buy on the spur of the moment and are not overly concerned with expenditure levels or obtaining value. Those who score high on impulsive dimensions tend not to be engaged with the object at either a cognitive or emotional level.\n- Confused (by overchoice): characterised by a consumer's confusion caused by too many product choices, too many stores or an overload of product information; tend to experience information overload.\n- Habitual/brand loyal: characterised by a consumer's tendency to follow a routine purchase pattern on each purchase occasion; consumers have favourite brands or stores and have formed habits in choosing; the purchase decision does not involve much evaluation or shopping around.\nSome researchers have adapted Sproles and Kendall's methodology for use in specific countries or cultural groups.[46] Consumer decision styles are important for retailers and marketers because they describe behaviours that are relatively stable over time and for this reason, they are useful for market segmentation.\nRetail formats (also known as retail formulas) influence the consumer's store choice and addresses the consumer's expectations. At its most basic level, a retail format is a simple marketplace, that is; a location where goods and services are exchanged. In some parts of the world, the retail sector is still dominated by small family-run stores, but large retail chains are increasingly dominating the sector, because they can exert considerable buying power and pass on the savings in the form of lower prices. Many of these large retail chains also produce their own private labels which compete alongside manufacturer brands. Considerable consolidation of retail stores has changed the retail landscape, transferring power away from wholesalers and into the hands of the large retail chains.[47] In Britain and Europe, the retail sale of goods is designated as a service activity. The European Service Directive applies to all retail trade including periodic markets, street traders and peddlers.\nRetail stores may be classified by the type of product carried. Softline retailers sell goods that are consumed after a single-use, or have a limited life (typically under three years) in they are normally consumed. Soft goods include clothing, other fabrics, footwear, toiletries, cosmetics, medicines and stationery.[48][49] Grocery stores, including supermarkets and hypermarkets, along with convenience stores carry a mix of food products and consumable household items such as detergents, cleansers, personal hygiene products. Retailers selling consumer durables are sometimes known as hardline retailers[50] – automobiles, appliances, electronics, furniture, sporting goods, lumber, etc., and parts for them. Specialist retailers operate in many industries such as the arts e.g. green grocers, contemporary art galleries, bookstores, handicrafts, musical instruments, gift shops.\nWhen discussing the impact of technology on shopping and retail, e-commerce is often the first thing that comes to mind for retailers. However, technologies such as big data, artificial intelligence, computer vision and the Internet of Things have used data to transform every part of the shopping experience, from browsing to checkout.[51]\nIt is important for organizations to embrace digital disruption in order to gain a competitive advantage. When an industry experiences digital disruption, it typically signals that consumer needs are shifting. Retailers enhance their analytics process and make better informed decisions thanks to big data, artificial intelligence, computer vision, and the Internet of Things. The use of data by retailers is mostly evident in the following aspects, based on the above-mentioned new technologies:[52][53]\n- Enhance marketing by Personalizing customer experience\n- Optimize supply chain management\n- Adjust prices to maximize profits\nMany leading brands actively target tourists who travel specifically to shop or allocate a significant portion of their spending to retail while on vacation. According to the Global Retail Tourism Market Report 2019–2023, the global shopping tourism market was valued at approximately $1.2 trillion in 2018. The report projected steady growth, with a compound annual growth rate (CAGR) of 6.7% between 2019 and 2023. Building on this trend, Kogan Page published the book Leading Travel and Tourism Retail in 2023, offering an in-depth analysis of the travel retail sector and its evolution in the post-COVID era.\nRetail markets have existed since ancient times. Archaeological evidence for trade, probably involving barter systems, dates back more than 10,000 years. As civilizations grew, barter was replaced with retail trade involving coinage. Selling and buying are thought to have emerged in Asia Minor (modern Turkey) in around the 7th-millennium BCE.[54] In ancient Greece, markets operated within the agora, an open space where, on market days, goods were displayed on mats or temporary stalls.[55] In ancient Rome, trade took place in the forum.[56] The Roman forum was arguably the earliest example of a permanent retail shop-front.[57]\nResearch from July 2008 suggests that China exhibited a rich history of early retail systems.[58] From as early as 200 BCE, Chinese packaging and branding were used to signal family, place names and product quality, and the use of government imposed product branding was used between 600 and 900 CE.[59] Eckhart and Bengtsson have argued that during the Song dynasty (960–1127), Chinese society developed a consumerist culture, where a high level of consumption was attainable for a wide variety of ordinary consumers rather than just the elite.[60]\nIn Medieval England and Europe, relatively few permanent shops were to be found; instead, customers walked into the tradesman's workshops where they discussed purchasing options directly with tradesmen.[61] In the more populous cities, a small number of shops were beginning to emerge by the 13th century.[62] Outside the major cities, most consumable purchases were made through markets or fairs.[63] Market-places appear to have emerged independently outside Europe. The Grand Bazaar in Istanbul is often cited as the world's oldest continuously operating market; its construction began in 1455. The Spanish conquistadors wrote glowingly of markets in the Americas. In the 15th century, the Mexica (Aztec) market of Tlatelolco was the largest in all the Americas.[64]\nBy the 17th century, permanent shops with more regular trading hours were beginning to supplant markets and fairs as the main retail outlet. Provincial shopkeepers were active in almost every English market town.[65] As the number of shops grew, they underwent a transformation. The trappings of a modern shop, which had been entirely absent from the 16th- and early 17th-century store, gradually made way for store interiors and shopfronts that are more familiar to modern shoppers. Prior to the 18th century, the typical retail store had no counter, display cases, chairs, mirrors, changing rooms, etc. However, the opportunity for the customer to browse merchandise, touch and feel products began to be available, with retail innovations from the late 17th and early 18th centuries.[66]\nBy the late 18th century, grand shopping arcades began to emerge across Europe and in the Antipodes. A shopping arcade refers to a multiple-vendor space, operating under a covered roof. Typically, the roof was constructed of glass to allow for natural light and to reduce the need for candles or electric lighting. Some of the earliest examples of shopping arcade appeared in Paris, due to its lack of pavement for pedestrians.[67] While the arcades were the province of the bourgeoisie, a new type of retail venture emerged to serve the needs of the working poor. John Stuart Mill wrote about the rise of the co-operative retail store, which he witnessed first-hand in the mid-19th century.[68]\nThe modern era of retailing is defined as the period from the industrial revolution to the 21st century.[69] In major cities, the department store emerged in the mid- to late 19th century, and permanently reshaped shopping habits, and redefined concepts of service and luxury.[70] Many of the early department stores were more than just a retail emporium; rather they were venues where shoppers could spend their leisure time and be entertained.[71] Retail, using mail order, came of age during the mid-19th century. Although catalogue sales had been used since the 15th century, this method of retailing was confined to a few industries such as the sale of books and seeds. However, improvements in transport and postal services led several entrepreneurs on either side of the Atlantic to experiment with catalogue sales.[72]\nIn the post-war period, an American architect, Victor Gruen developed a concept for a shopping mall; a planned, self-contained shopping complex complete with an indoor plaza, statues, planting schemes, piped music, and car-parking. Gruen's vision was to create a shopping atmosphere where people felt so comfortable, they would spend more time in the environment, thereby enhancing opportunities for purchasing. The first of these malls opened at Northland Mall near Detroit in 1954.[73] Throughout the twentieth century, a trend towards larger store footprints became discernible. The average size of a U.S. supermarket grew from 31,000 square feet (2,900 m2) square feet in 1991 to 44,000 square feet (4,100 m2) square feet in 2000.[74] By the end of the twentieth century, stores were using labels such as \"mega-stores\" and \"warehouse\" stores to reflect their growing size.[75] The upward trend of increasing retail space was not consistent across nations and led in the early 21st century to a 2-fold difference in square footage per capita between the United States and Europe.[76]\nAs the 21st century takes shape, some indications suggest that large retail stores have come under increasing pressure from online sales models and that reductions in store size are evident.[77] Under such competition and other issues such as business debt,[78] there has been a noted business disruption called the retail apocalypse in recent years which several retail businesses, especially in North America, are sharply reducing their number of stores, or going out of business entirely.\nAmong retailers and retails chains a lot of consolidation has appeared over the last couple of decades. Between 1988 and 2010, worldwide 40,788 mergers and acquisitions with a total known value of US$2.255 trillion have been announced.[79] The largest transactions with involvement of retailers in/from the United States have been: the acquisition of Albertson's Inc. for US$17 billion in 2006,[80] the merger between Federated Department Stores Inc with May Department Stores valued at 16.5 bil. USD in 2005[81] – now Macy's, and the merger between Kmart Holding Corp and Sears Roebuck & Co with a value of US$10.9 billion in 2004.[82]\nBetween 1985 and 2018 there have been 46,755 mergers or acquisitions conducted globally in the retail sector (either acquirer or target from the retail industry). These deals cumulate to an overall known value of around US$2,561 billion. The three major Retail M&A waves took place in 2000, 2007 and lately in 2017. However the all-time high in terms of number of deals was in 2016 with more than 2,700 deals. In terms of added value 2007 set the record with the US$225 billion.[83]\nHere is a list of the top ten largest deals (ranked by volume) in the Retail Industry:[citation needed]\n| Date Announced | Acquiror Name | Acquiror Mid Industry | Acquiror Nation | Target Name | Target Mid Industry | Target Nation | Value of Transaction ($mil) |\n| 11 January 2006 | CVS Corp | Other Retailing | United States | Caremark Rx Inc | Healthcare Providers & Services (HMOs) | United States | 26,293.58 |\n| 3 September 2007 | AB Acquisitions Ltd | Other Financials | United Kingdom | Alliance Boots PLC | Other Retailing | United Kingdom | 19,604.19 |\n| 18 December 2000 | Shareholders | Other Financials | United Kingdom | Granada Compass-Hospitality | Food & Beverage Retailing | United Kingdom | 17,914.68 |\n| 20 January 2006 | AB Acquisition LLC | Other Financials | United States | Albertsons Inc | Food & Beverage Retailing | United States | 17,543.85 |\n| 26 February 2013 | Home Depot Inc | Home Improvement Retailing | United States | Home Depot Inc | Home Improvement Retailing | United States | 17,000.00 |\n| 28 February 2005 | Federated Department Stores | Discount and Department Store Retailing | United States | May Department Stores Co | Non Residential | United States | 16,465.87 |\n| 30 August 1999 | Carrefour SA | Food & Beverage Retailing | France | Promodes | Food & Beverage Retailing | France | 15,837.48 |\n| 19 June 2012 | Walgreen Co | Other Retailing | United States | Alliance Boots GmbH | Other Retailing | Switzerland | 15,292.48 |\n| 7 February 2007 | Wesfarmers Ltd | Food & Beverage Retailing | Australia | Coles Group Ltd | Food & Beverage Retailing | Australia | 15,287.79 |\n| 6 March 2011 | Wal-Mart Stores Inc | Discount and Department Store Retailing | United States | Wal-Mart Stores Inc | Discount and Department Store Retailing | United States | 14,288.00 |\nAs of 2016, China was the largest retail market in the world.[84]\n| Worldwide top ten retailers[85] | |||||\n|---|---|---|---|---|---|\n| Rank | Company | Headquarters | 2020 total revenue (US$ billion)[85] | Business foundation | Number of countries of operation 2020 |\n| 1 | Walmart | United States | $519.93 | Hypermarket/supercenter/superstore | 27 |\n| 2 | Amazon | United States | $280.52 | Ecommerce | 18 |\n| 3 | Costco | United States | $163.22 | Cash & carry/warehouse club | 12 |\n| 4 | Schwarz Gruppe (Lidl) | Germany | $133.89 | Discount grocery store | 33 |\n| 5 | Aldi | Germany | $116.06 | Discount grocery store | 18 |\n| 6 | JD.com | China | $82.86 | Ecommerce | – |\n| 7 | Carrefour | France | $82.60 | Hypermarket/supermarket | 32 |\n| 8 | Ahold Delhaize | Netherlands | $78.17 | Grocery store | 10 |\n| 9 | Alibaba | China | $71.99 | Ecommerce | 7 |\n| 10 | IKEA | Sweden | $45.18 | Furniture | 60 |\nThe National Retail Federation and Kantar annually rank the nation's top retailers according to sales.[86] The National Retail Federation also separately ranks the 100 fastest-growing U.S. retailers based on increases in domestic sales.[87][86]\nSince 1951, the U.S. Census Bureau has published the Retail Sales report every month. It is a measure of consumer spending, an important indicator of the US GDP. Retail firms provide data on the dollar value of their retail sales and inventories. A sample of 12,000 firms is included in the final survey and 5,000 in the advanced one. The advanced estimated data is based on a subsample from the US CB complete retail and food services sample.[88]\nRetail is the largest private-sector employer in the United States, supporting 52 million working Americans.[89]\nIn 2011, the grocery market in six countries of Central Europe was worth nearly €107bn, 2.8% more than the previous year when expressed in local currencies. The increase was generated foremost by the discount stores and supermarket segments, and was driven by the skyrocketing prices of foodstuffs. This information is based on the latest PMR report entitled Grocery retail in Central Europe 2012[90]\nNational accounts show a combined total of retail and wholesale trade, with hotels and restaurants. in 2012 the sector provides over a fifth of GDP in tourist-oriented island economies, as well as in other major countries such as Brazil, Pakistan, Russia, and Spain. In all four of the latter countries, this fraction is an increase over 1970, but there are other countries where the sector has declined since 1970, sometimes in absolute terms, where other sectors have replaced its role in the economy. In the United States the sector has declined from 19% of GDP to 14%, though it has risen in absolute terms from $4,500 to $7,400 per capita per year. In China the sector has grown from 7.3% to 11.5%, and in India even more, from 8.4% to 18.7%. Emarketer predicts China will have the largest retail market in the world in 2016.[91]\nIn 2016, China became the largest retail market in the world.[84]\nIn the Republic of Armenia, retail trade has been increasing recently. In October 2022, it increased by 23.1% year by year, which was the most considerable rise since April 2021, faster than the 20.7 per cent increase recorded a month earlier. Retail dropped by 1.9% after accumulating 2.1%in the earlier month. For the first 10 months of 2022, retail sales increased by 15.5% by measuring the exact time of 2021. Among its bordering countries, on retail trade percentage of GDP, Armenia ranks more increased than Turkey, but it is still lower than Georgia.[92]\nTo achieve and maintain a foothold in an existing market, a prospective retail establishment must overcome the following hurdles:\n- regulatory barriers including:\n- restrictions on real-estate purchases, especially as imposed by local governments and against \"big-box\" chain retailers\n- restrictions on foreign investment in retailers, in terms of both absolute amount of financing provided and percentage share of voting stock (e.g. common stock) purchased\n- unfavorable taxation structures, especially those designed to penalize or keep out \"big box\" retailers (see \"Regulatory\" above)\n- absence of developed supply-chain and integrated IT management\n- high competitiveness among existing market participants and resulting low profit margins, caused in part by:\n- constant advances in product design resulting in constant threat of product obsolescence and price declines for existing inventory\n- partially due to loss in business: lack of work-force, often including management, that is properly educated and trained\n- lack of educational infrastructure enabling prospective market entrants to respond to the above challenges\n- direct e-tailing (for example, through the Internet) and direct delivery to consumers from manufacturers and suppliers, cutting out any retail middle man.[93]\n- Automated retail\n- Direct-to-consumer\n- Business-to-business\n- B2G\n- Consumer behaviour\n- Convenience store\n- Department store\n- Dollar store\n- Dry goods store\n- Final goods\n- Five and dime\n- General store\n- Grey pound\n- Hanseatic League\n- High Street\n- History of marketing\n- Hyper market\n- Like for like\n- List of department stores by country\n- Point of sales\n- Sales promotion\n- Retail concentration\n- Retail design\n- Retail software\n- Retailtainment\n- Revenge buying\n- Sales density\n- Shopping\n- Store manager\n- Super market\n- Super store\n- Variety store\n- Visual merchandising\n- Licensed victualler\n- Wardrobing\n- Window shopping\n- Large-scale retail in France\n- Harper, Douglas. \"retail\". Online Etymology Dictionary. Retrieved 16 March 2008.\n- \"retail\". Archived from the original on 11 August 2020. Retrieved 17 January 2018 – via The Free Dictionary.\n- Pride, W.M., Ferrell, O.C. Lukas, B.A., Schembri, S. Niininen, O. and Cassidy, R., Marketing Principles, 3rd Asia-Pacific ed., Cengage, 2018, pp. 449–50\n- Pride, W.M., Ferrell, O.C. Lukas, B.A., Schembri, S. Niininen, O. and Cassidy, R., Marketing Principles, 3rd Asia-Pacific ed., Cengage, 2018, p. 451\n- Chartered Institute of Procurement & Supply, \"Linking Strategy and Purchasing\", CIPS Positions on Practice, n.d., page 3\n- Volpato, Giuseppe; Stocchetti, Andrea (2009). \"Old and new approaches to marketing. The quest of their epistemological roots\". The Proceedings of 10th International Conference Marketing Trends (30841): 34. Archived from the original on 3 February 2017 – via Munich Personal RePEc Archive.\n- Lambda, A.J., The Art Of Retailing, McGraw-Hill, (2003), 2008, pp. 315–26\n- Parker, Christopher J.; Wenyu, Lu (13 May 2019). \"What influences Chinese fashion retail? Shopping motivations, demographics and spending\". Journal of Fashion Marketing and Management. 23 (2): 158–175. doi:10.1108/JFMM-09-2017-0093. ISSN 1361-2026. S2CID 170031856. Archived from the original on 28 October 2020. Retrieved 3 September 2020.\n- Fill, C., Marketing Communications: Framework, Theories and Application, London, Prentice Hall, 1995, p. 70\n- Yu-Jia, H. (2012). \"The Moderating Effect of Brand Equity and the Mediating Effect of Marketing Mix Strategy On the Relationship Between Service Quality and Customer Loyalty\". International Journal of Organizational Innovation, 155–62.\n- Morschett, D., Swoboda, B. and Schramm, H., \"Competitive Strategies in Retailing: An Investigation of the Applicability of Porter's Framework for Food Retailers Journal of Retailing and Consumer Services, Vol. 13, 2006, pp. 275–87\n- Constantinides, E., \"The Marketing Mix Revisited: Towards the 21st Century Marketing\", Journal of Marketing Management, Vo. 22, 2006, pp. 422–423\n- Berens, J.S., \"The Marketing Mix, the Retailing Mix and the Use of Retail Strategy Continua\", Proceedings of the 1983 Academy of Marketing Science (AMS), [Part of the series Developments in Marketing Science], pp. 323–27\n- Lamb, C.W., Hair, J.F. and McDaniel, C., MKTG 2010, Mason, OH, Cengage, pp. 193–94\n- Verhoef, P., Kannan, P.K. and Inman, J., \"From Multi-channel Retailing to Omni-channel Retailing: Introduction to the Special Issue on Multi-channel Retailing\", Journal of Retailing, vol. 91, pp. 174–81. doi:10.1016/j.jretai.2015.02.005\n- Dibb, S., Simkin, L., Pride, W.C. and Ferrell, O.C., Marketing: Concepts and Strategies, Cengage, 2013, Chapter 12\n- Nagle, T., Hogan, J. and Zale, J., The Strategy and Tactics of Pricing: A Guide to Growing More Profitably, Oxon, Routledge, 2016, p. 1 and 6\n- Brennan, R., Canning, L. and McDowell, R., Business-to-Business Marketing, 2nd ed., London, Sage, 2011, p. 331\n- Neumeier, M., The Brand Flip: Why customers now run companies and how to profit from it (Voices That Matter), 2008, p. 55\n- Irvin, G. (1978). Modern Cost-Benefit Methods. Macmillan. pp. 137–160. ISBN 978-0-333-23208-8.\n- Rao, V.R. and Kartono, B., \"Pricing Strategies and Objectives: A Cross-cultural Survey\", in Handbook of Pricing Research in Marketing, Rao, V.R. (ed), Northampton, MA, Edward Elgar, 2009, p. 15\n- Hoch, Steven J.; Drèze, Xavier; Purk, Mary E. (October 1994). \"EDLP, Hi-Lo, and Margin Arithmetic\" (PDF). The Journal of Marketing. 58 (4): 16–27. doi:10.1177/002224299405800402. S2CID 18134783. Archived (PDF) from the original on 20 December 2018. Retrieved 19 December 2018.\n- Kaufmann, P., \"Deception in retailer high-low pricing: A 'rule of reason' approach\", Journal of Retailing, Volume 70, Issue 2, 1994, pp. 115–1383.\n- Guiltnan, J.P., \"The Price Bundling of Services\", Journal of Marketing, April 1987\n- Poundstone, W., Priceless: The Myth of Fair Value (and How to Take Advantage of It), New York: Hill and Wang, 2011, pp. 184–200\n- Flanders, Judith (9 January 2009). \"They Broke It\". The New York Times.\n- \"Josiah Wedgwood, an Industrial Revolution pioneer\". Adam Smith Institute. Retrieved 8 June 2024.\n- Barr, A., \"PayPal Deepens Retail Drive in Discover Payments Deal\", Technology News. 22 August 2012\n- Romis, Rafael. \"Council Post: Three Ways To Crush E-Commerce: Busting Common Misconceptions\". Forbes. Archived from the original on 6 February 2019. Retrieved 6 February 2019.\n- Steven Greenhouse (27 October 2012). \"A Part-Time Life, as Hours Shrink and Shift\". The New York Times. Archived from the original on 27 November 2020. Retrieved 28 October 2012.\n- Hee, J.K., \"Stand-alone Sale of a Free Gift: Is it effective to accentuate promotion value?\" Social Behavior & Personality, Vol. 43, no. 10, 2015, pp. 1593–1606\n- Cant, M.C.; van Heerden, C.H. (2008). Personal Selling. Juta Academic. p. 176. ISBN 978-0-7021-6636-5.\n- \"Retail Mix\". Monash University. Archived from the original on 18 July 2018. Retrieved 19 June 2024.\n- \"The Impact of Retail Servicescape on Buying Behaviour\", BVIMSR's Journal of Management Research, Vol 6, No. 2, 2014, pp. 10–17\n- Wakefield, L.K. and Blodgett, G J., \"The Effect of the Servicescape on Customers' Behavioral Intentions in Leisure Service Settings\", The Journal of Services Marketing, Vol. 10, No. 6, pp. 45–61.\n- Hall, C.M. and Mitchell, R., Wine Marketing: A Practical Guide, pp. 182–83\n- Bailey, P. (April 2015). Marketing to the senses: A multisensory strategy to align the brand touchpoints. Admap, 2–7.\n- Hul, Michael K.; Dube, Laurette; Chebat, Jean-Charles (1 March 1997). \"The impact of music on consumers' reactions to waiting for services\". Journal of Retailing. 73 (1): 87–104. doi:10.1016/S0022-4359(97)90016-6.\n- Babin, Barry J.; Darden, William R.; Griffin, Mitch (1994). \"Work and/or Fun: Measuring Hedonic and Utilitarian Shopping Value\". Journal of Consumer Research. 20 (4): 644. doi:10.1086/209376.\n- Durvasula, S., Lysonski, S. and Andrews, J.C. (1993), \"Cross-cultural generalizability of a scale for profiling consumers' decision-making styles\", The Journal of Consumer Affairs, Vol. 27 No. 1, pp. 55–65\n- Sproles, G.B. (1985), \"From perfectionism to faddism: measuring consumers' decision-making styles\", in Schnittgrund, K.P. (Ed.), American Council on Consumer Interests (ACCI), Conference Proceedings, Columbia, MO, pp. 79–85.\n- Sproles, G.B. (1983). Conceptualisation and measurement of optimal consumer decision making. Journal of Consumer Affairs, Vol. 17 No. 2, pp. 421–38.\n- Mishra, Anubhav A. (2015). \"Consumer innovativeness and consumer decision styles: A confirmatory and segmentation analysis\". The International Review of Retail, Distribution and Consumer Research. 25: 35–54. doi:10.1080/09593969.2014.911199. S2CID 219645290.\n- Jain, R. and Sharma, A., \"A Review on Sproles & Kendall's Consumer Style Inventory (CSI) for Analyzing Decision Making Styles of Consumers\", Indian Journal of Marketing, Vol. 43, no. 3, 2013\n- Sproles, G.B., & Kendall, E.L., \"A methodology for profiling consumers' decision-marking styles\", Journal of Consumer Affairs, Vol., 20 No. 2, 1986, pp. 267–79\n- Bauer, H.H., Sauer, N.E., and Becker, C., \"Investigating the relationship between product involvement and consumer decision-making styles\", Journal of Consumer Behaviour. Vol. 5, 2006 342–54.\n- Constantinides, E., \"The Marketing Mix Revisited: Towards the 21st Century Marketing\", Journal of Marketing Management, Vol. 22, 2006, p. 421\n- Ferrara, J. Susan. \"The World of Retail: Hardlines vs. Softlines\". Value Line. Archived from the original on 18 July 2014. Retrieved 22 May 2014.\n- Time, Forest. \"What is Soft Merchandising?\". Houston Chronicle. Archived from the original on 17 July 2014. Retrieved 22 May 2014.\n- \"hard goods\". Investor Words. Archived from the original on 4 January 2018. Retrieved 22 May 2014.\n- Wang, Cuimin (17 June 2021). \"Analyzing the Effects of Cross-Border E-Commerce Industry Transfer Using Big Data\". Mobile Information Systems. 2021: 1–12. doi:10.1155/2021/9916304. ISSN 1875-905X.\n- Kenton, Will; Rhinehart, Charlene (4 January 2011). \"Retail Inventory Method: Definition, Calculation, and Example\". Investopedia. Archived from the original on 28 July 2021. Retrieved 19 June 2024.\n- Jan, Irfanullah (16 March 2012). \"Retail Method of Inventory Estimation\". XPLAIND.com. Archived from the original on 9 August 2020. Retrieved 19 June 2024.\n- Jones, Brian D.G.; Shaw, Eric H. (2006). \"A History of Marketing Thought\", Handbook of Marketing. Weitz, Barton A.; Wensley, Robin (eds), Sage, p. 41, ISBN 1-4129-2120-1.\n- Thompson, D.B., An Ancient Shopping Center: The Athenian Agora, ASCSA, 1993 pp. 19–21\n- McGeough, K.M., The Romans: New Perspectives, ABC-CLIO, 2004, pp. 105–06\n- Coleman, P., Shopping Environments, Elsevier, Oxford, 2006, p. 28\n- Moore, Karl; Reid, Susan (2008). \"The Birth of Brand: 4000 Years of Branding History\". Business History. 50 (4): 419–432. doi:10.1080/00076790802106299 – via Munich Personal RePEc Archive.\n- Eckhardt, G.M. and Bengtsson. A. \"A Brief History of Branding in China\", Journal of Macromarketing, Vol, 30, no. 3, 2010, pp. 210–21\n- Eckhardt, G.M. and Bengtsson. A. \"A Brief History of Branding in China\", Journal of Macromarketing, Vol, 30, no. 3, 2010, p. 212\n- Thrupp, S.L., The Merchant Class of Medieval London, 1300–1500, pp. 7–8\n- Pevsner, N. and Hubbard, E., The Buildings of England: Cheshire Penguin, 1978, p. 170\n- \"Gazetteer of Markets and Fairs in England and Wales to 1516\". List and Index Society (32). 2003. Archived from the original on 13 January 2020 – via Institute of Historical Research.\n- Rebecca M. Seaman, ed. (2013). Conflict in the Early Americas: An Encyclopedia of the Spanish Empire's ... Abc-Clio. p. 375. ISBN 978-1-59884-777-2.\n- Cox, N.C. and Dannehl, K., Perceptions of Retailing in Early Modern England, Aldershot, Hampshire, Ashgate, 2007, p,. 129\n- Cox, N.C. and Dannehl, K., Perceptions of Retailing in Early Modern England, Aldershot, Hampshire, Ashgate, 2007, pp. 153–54\n- Conlin, J., Tales of Two Cities: Paris, London and the Birth of the Modern City, Atlantic Books, 2013, Chapter 2\n- Mill, J.S., Principles of a Political Economy with some of their Applications to Social Philosophy, 7th ed., London, Longman, 1909, Section IV.7.53\n- Reshaping Retail: Why Technology is Transforming the Industry and How to Win in the New Consumer Dr\n- Koot, G.M. (2011). \"Shops and Shopping in Britain: from market stalls to chain stores\" (PDF). University of Massachusetts, Dartmouth. Archived from the original (PDF) on 6 August 2019. Retrieved 29 May 2017.\n- Howard Moss, M., Shopping as an Entertainment Experience, Plymouth, Lexington Books, pp. 35–39\n- Goldstein. J., 101 Amazing Facts about Wales, Andrews, UK, 2013\n- Gladwell, Malcolm (7 March 2004). \"The Terrazzo Jungle\". The New Yorker. ISSN 0028-792X. Archived from the original on 22 October 2017. Retrieved 19 June 2024.\n- Byrne-Paquet, L., The Urge to Splurge: A Social History of Shopping, ECW Press, Toronto, Canada, p. 83\n- Johanson, Simon (2 June 2015). \"Bunnings Shifts Focus as it Upsizes Store Network\". The Age. Archived from the original on 20 December 2018. Retrieved 19 December 2018.\n- Wahba, Phil (15 June 2017). \"The Death of Retail is Greatly Exaggerated\". Fortune (Print magazine). p. 34.\n- Wetherell, Sam (8 April 2014). \"The Shopping Mall's Socialist Pre-History\". Jacobin. ISSN 2158-2602. Archived from the original on 25 June 2022. Retrieved 19 June 2024.\n- Townsend, Matt; Surane, Jenny; Orr, Emma; Cannon, Christopher (8 November 2017). \"America's 'Retail Apocalypse' Is Really Just Beginning\". Bloomberg. Archived from the original on 18 January 2018. Retrieved 15 January 2018.\n- \"Statistics on Mergers & Acquisitions (M&A) – M&A Courses | Company Valuation Courses | Mergers & Acquisitions Courses\". Institute for Mergers, Acquisitions and Alliances. Archived from the original on 6 January 2012. Retrieved 2 November 2012.\n- \"SuperValu-CVS group buys Albertson's for $17B\". Phoenix Business Journal. January 2006. Archived from the original on 12 July 2014. Retrieved 9 July 2014.\n- \"Federated and May Announce Merger; $17 billion transaction to create value for customers, shareholders\". Phx.corporate-ir.net. 28 February 2005. Archived from the original on 25 June 2017. Retrieved 2 November 2012.\n- \"Kmart Finalizes Transaction With Sears\". Searsholdings.com. 29 September 2004. Archived from the original on 10 June 2016. Retrieved 2 November 2012.\n- \"M&A by Industries\". Institute for Mergers, Acquisitions and Alliances. Archived from the original on 3 November 2020. Retrieved 28 February 2018.\n- \"China Eclipses the US to Become the World's Largest Retail Market – eMarketer\". www.emarketer.com. Archived from the original on 9 February 2022. Retrieved 25 April 2017.\n- \"Top 50 Global Retailers 2021\". NRF. Archived from the original on 15 April 2021. Retrieved 13 April 2021.\n- \"Top 100 Retailers 2020 List\". NRF. Archived from the original on 13 April 2021. Retrieved 13 April 2021.\n- \"Hot 100 Retailers 2020 List\". NRF. Archived from the original on 13 April 2021. Retrieved 13 April 2021.\n- \"US Census Bureau Monthly & Annual Retail Trade\". www.census.gov. 11 July 2011. Archived from the original on 14 December 2017. Retrieved 11 December 2017.\n- \"Estimated March imports at major U.S. retail container ports hit five-year low, declines expected to continue amid pandemic\". PortNews. 8 April 2020. Archived from the original on 23 May 2020. Retrieved 10 April 2020.\n- \"Grocery retail in Central Europe 2012\". PMR Ltd. Archived from the original on 2 November 2012. Retrieved 19 June 2024.\n- Millward, Steven (18 August 2016). \"Asia's ecommerce spending to hit record $1 trillion this year – but most of that is China\". Tech in Asia. Archived from the original on 19 August 2016. Retrieved 18 August 2016.\n- \"Fast Moving Consumer Goods\". 18 November 2022. Archived from the original on 7 December 2022. Retrieved 7 December 2022.\n-\nNicholson, Walter; Snyder, Christopher Mark (2014). \"Perfect Competition in a Single Market\". Intermediate Microeconomics and Its Application (12 ed.). Boston: Cengage Learning. p. 300. ISBN 9781133189022. Retrieved 25 September 2020.\nOne question raised by the growth of Internet selling is whether there will remain a separate role for retailers over the long term. If the Internet allows producers to reach customers directly, why would any role for retailing 'middlemen' remain?\n- Adburgham, A., Shopping in Style: London from the Restoration to Edwardian Elegance, London, Thames and Hudson, 1979\n- Alexander, A., \"The Study of British Retail History: Progress and Agenda\", in The Routledge Companion to Marketing History, D.G. Brian Jones and Mark Tadajewski (eds.), Oxon, Routledge, 2016, pp. 155–72\n- Feinberg, R.A. and Meoli, J., [Online: \"A A Brief History of the Mall Archived 4 October 2019 at the Wayback Machine Brief History of the Mall\"], in Advances in Consumer Research, Volume 18, Rebecca H. Holman and Michael R. Solomon (eds.), Provo, UT: Association for Consumer Research, 1991, pp. 426–27\n- Hollander, S. C., \"Who and What are Important in Retailing and Marketing History: A Basis for Discussion\", in S.C. Hollander and R. Savitt (eds.) First North American Workshop on Historical Research in Marketing, Lansing, MI: Michigan State University, 1983, pp. 35–40.\n- Jones, F., \"Retail Stores in the United States, 1800–1860\", Journal of Marketing, October 1936, pp. 135–40\n- Krafft, Manfred; Mantrala, Murali K., eds. (2006). Retailing in the 21st Century: Current and Future Trends. New York: Springer Verlag. ISBN 978-3-540-28399-7.\n- Kowinski, W. S., The Malling of America: An Inside Look at the Great Consumer Paradise, New York, William Morrow, 1985\n- Furnee, J. H., and Lesger, C. (eds), The Landscape of Consumption: Shopping Streets and Cultures in Western Europe, 1600–1900, Springer, 2014\n- MacKeith, M., The History and Conservation of Shopping Arcades, Mansell Publishing, 1986\n- Nystrom, P. H., \"Retailing in Retrospect and Prospect\", in H.G. Wales (ed.) Changing Perspectives in Marketing, Urbana: University of Illinois Press, 19951, pp. 117–38.\n- Stobard, J., Sugar and Spice: Grocers and Groceries in Provincial England, 1650–1830, Oxford University Press, 2016\n- Underhill, Paco, Call of the Mall: The Author of Why We Buy on the Geography of Shopping, Simon & Schuster, 2004",
    "risk assessment": "Risk assessment is a process for identifying hazards, potential (future) events which may negatively impact on individuals, assets, and/or the environment because of those hazards, their likelihood and consequences, and actions which can mitigate these effects. The output from such a process may also be called a risk assessment. Hazard analysis forms the first stage of a risk assessment process. Judgments \"on the tolerability of the risk on the basis of a risk analysis\" (i.e. risk evaluation) also form part of the process.[1][2] The results of a risk assessment process may be expressed in a quantitative or qualitative fashion.[3]\nRisk assessment forms a key part of a broader risk management strategy to help reduce any potential risk-related consequences.[1][2]\nRisk assessments can be undertaken in individual cases, including in patient and physician interactions.[4] In the narrow sense chemical risk assessment is the assessment of a health risk in response to environmental exposures.[5] The ways statistics are expressed and communicated to an individual, both through words and numbers impact his or her interpretation of benefit and harm. For example, a fatality rate may be interpreted as less benign than the corresponding survival rate.[4] A systematic review of patients and doctors from 2017 found that overstatement of benefits and understatement of risks occurred more often than the alternative.[4][6] A systematic review from the Cochrane collaboration suggested \"well-documented decision aids\" are helpful in reducing effects of such tendencies or biases.[4][7] Aids may help people come to a decision about their care based on evidence informed information that align with their values.[7] Decision aids may also help people understand the risks more clearly, and they empower people to take an active role when making medical decisions.[7] The systematic review did not find a difference in people who regretted their decisions between those who used decision aids and those who had the usual standard treatment.[7]\nAn individual's own risk perception may be affected by psychological, ideological, religious or otherwise subjective factors, which impact rationality of the process.[4] Individuals tend to be less rational when risks and exposures concern themselves as opposed to others.[4] There is also a tendency to underestimate risks that are voluntary or where the individual sees themselves as being in control, such as smoking.[4]\nRisk assessment can also be made on a much larger systems theory scale, for example assessing the risks of an ecosystem or an interactively complex mechanical, electronic, nuclear, and biological system or a hurricane (a complex meteorological and geographical system). Systems may be defined as linear and nonlinear (or complex), where linear systems are predictable and relatively easy to understand given a change in input, and non-linear systems unpredictable when inputs are changed.[8] As such, risk assessments of non-linear/complex systems tend to be more challenging.\nIn the engineering of complex systems, sophisticated risk assessments are often made within safety engineering and reliability engineering when it concerns threats to life, natural environment, or machine functioning. The agriculture, nuclear, aerospace, oil, chemical, railroad, and military industries have a long history of dealing with risk assessment.[9] Also, medical, hospital, social service,[10] and food industries control risks and perform risk assessments on a continual basis. Methods for assessment of risk may differ between industries and whether it pertains to general financial decisions or environmental, ecological, or public health risk assessment.[9]\nRapid technological change, increasing scale of industrial complexes, increased system integration, market competition, and other factors have been shown to increase societal risk in the past few decades.[1] As such, risk assessments become increasingly critical in mitigating accidents, improving safety, and improving outcomes. Risk assessment consists of an objective evaluation of risk in which assumptions and uncertainties are clearly considered and presented. This involves identification of risk (what can happen and why), the potential consequences, the probability of occurrence, the tolerability or acceptability of the risk, and ways to mitigate or reduce the probability of the risk.[2] Optimally, it also involves documentation of the risk assessment and its findings, implementation of mitigation methods, and review of the assessment (or risk management plan), coupled with updates when necessary.[1] Sometimes risks can be deemed acceptable, meaning the risk \"is understood and tolerated ... usually because the cost or difficulty of implementing an effective countermeasure for the associated vulnerability exceeds the expectation of loss.\"[11]\nBenoit Mandelbrot distinguished between \"mild\" and \"wild\" risk and argued that risk assessment and risk management must be fundamentally different for the two types of risk.[12] Mild risk follows normal or near-normal probability distributions, is subject to regression to the mean and the law of large numbers, and is therefore relatively predictable. Wild risk follows fat-tailed distributions, e.g., Pareto or power-law distributions, is subject to regression to the tail (infinite mean or variance, rendering the law of large numbers invalid or ineffective), and is therefore difficult or impossible to predict. A common error in risk assessment and management is to underestimate the wildness of risk, assuming risk to be mild when in fact it is wild, which must be avoided if risk assessment and management are to be valid and reliable, according to Mandelbrot.\nTo see the risk management process expressed mathematically, one can define expected risk as the sum over individual risks, , which can be computed as the product of potential losses, , and their probabilities, :\nEven though for some risks , we might have , if the probability is small compared to , its estimation might be based only on a smaller number of prior events, and hence, more uncertain. On the other hand, since , must be larger than , so decisions based on this uncertainty would be more consequential, and hence, warrant a different approach.\nThis becomes important when we consider the variance of risk\nas a large changes the value.\nFinancial decisions, such as insurance, express loss in terms of dollar amounts. When risk assessment is used for public health or environmental decisions, the loss can be quantified in a common metric such as a country's currency or some numerical measure of a location's quality of life. For public health and environmental decisions, the loss is simply a verbal description of the outcome, such as increased cancer incidence or incidence of birth defects. In that case, the \"risk\" is expressed as\nIf the risk estimate takes into account information on the number of individuals exposed, it is termed a \"population risk\" and is in units of expected increased cases per time period. If the risk estimate does not take into account the number of individuals exposed, it is termed an \"individual risk\" and is in units of incidence rate per time period. Population risks are of more use for cost/benefit analysis; individual risks are of more use for evaluating whether risks to individuals are \"acceptable\".\nIn quantitative risk assessment, an annualized loss expectancy (ALE) may be used to justify the cost of implementing countermeasures to protect an asset. This may be calculated by multiplying the single loss expectancy (SLE), which is the loss of value based on a single security incident, with the annualized rate of occurrence (ARO), which is an estimate of how often a threat would be successful in exploiting a vulnerability.\nThe usefulness of quantitative risk assessment has been questioned, however. Barry Commoner, Brian Wynne and other critics have expressed concerns that risk assessment tends to be overly quantitative and reductive. For example, they argue that risk assessments ignore qualitative differences among risks. Some charge that assessments may drop out important non-quantifiable or inaccessible information, such as variations among the classes of people exposed to hazards, or social amplification.[13] Furthermore, Commoner[14] and O'Brien[15] claim that quantitative approaches divert attention from precautionary or preventative measures.[16] Others, like Nassim Nicholas Taleb consider risk managers little more than \"blind users\" of statistical tools and methods.[17]\nRisk engineering is central to the assessment phase, where risks are not only identified but rigorously analyzed, quantified, and modeled. In the context of financial systems—particularly credit risk—risk engineering involves understanding the dynamic behavior of risk parameters such as probability of default, exposure at default, and loss given default.[18] These are not treated as isolated figures but as interconnected components that respond to systemic and idiosyncratic changes. As individual risks aggregate into portfolios or larger systems, risk engineers deploy statistical models and simulation techniques to uncover dependencies and potential cascade effects. This systems-level view enables the modeling of stress scenarios and rare, high-impact events—what some refer to as \"wild risk.\" It also supports the design of robust structures capable of absorbing shocks and preventing systemic collapse.[19] Regulatory frameworks add another layer to the assessment process, requiring that risk engineering efforts not only reflect real-world complexity but also align with institutional constraints.\nOlder textbooks distinguish between the term risk analysis and risk evaluation; a risk analysis includes the following 4 steps:[1]\n- establish the context, which restricts the range of hazards to be considered. It is also necessary to identify the potential parties or assets which may be affected by the threat, and the potential consequences to them if the hazard is activated.\n- hazard identification, an identification of visible and implied hazards and determining the qualitative nature of the potential adverse consequences of each hazard. Without a potential adverse consequence, there is no hazard.\n- frequency analysis If a consequence is dependent on dose, i.e. the amount of exposure, the relationship between dose and severity of consequence must be established, and the risk depends on the probable dose, which may depend on concentration or amplitude and duration or frequency of exposure. This is the general case for many health hazards where the mechanism of injury is toxicity or repetitive injury, particularly where the effect is cumulative.\n- consequence analysis. For other hazards, the consequences may either occur or not, and the severity may be extremely variable even when the triggering conditions are the same. This is typical of many biological hazards as well as a large range of safety hazards. Exposure to a pathogen may or may not result in actual infection, and the consequences of infection may also be variable. Similarly, a fall from the same place may result in minor injury or death, depending on unpredictable details. In these cases, estimates must be made of reasonably likely consequences and associated probability of occurrence.\nA risk evaluation means that judgements are made on the tolerability of the identified risks, leading to risk acceptance. When risk analysis and risk evaluation are made at the same time, it is called risk assessment.[1]\nAs of 2023, chemical risk assessment follows these 4 steps:[5]\n- hazard characterization\n- exposure assessment\n- dose-response modeling\n- risk characterization.\nThere is tremendous variability in the dose-response relationship between a chemical and human health outcome in particularly susceptible subgroups, such as pregnant women, developing fetuses, children up to adolescence, people with low socioeconomic status, those with preexisting diseases, disabilities, genetic susceptibility, and those with other environmental exposures.[5]\nThe process of risk assessment may be somewhat informal at the individual social level, assessing economic and household risks,[20][21] or a sophisticated process at the strategic corporate level. However, in both cases, ability to anticipate future events and create effective strategies for mitigating them when deemed unacceptable is vital.\nAt the individual level, identifying objectives and risks, weighing their importance, and creating plans, may be all that is necessary. At the strategic organisational level, more elaborate policies are necessary, specifying acceptable levels of risk, procedures to be followed within the organisation, priorities, and allocation of resources.[22]: 10\nAt the strategic corporate level, management involved with the project produce project level risk assessments with the assistance of the available expertise as part of the planning process and set up systems to ensure that required actions to manage the assessed risk are in place. At the dynamic level, the personnel directly involved may be required to deal with unforeseen problems in real time. The tactical decisions made at this level should be reviewed after the operation to provide feedback on the effectiveness of both the planned procedures and decisions made in response to the contingency.\n- Dose-Response Analysis, is determining the relationship between dose and the type of adverse response and/or probability or the incidence of effect (dose-response assessment). The complexity of this step in many contexts derives mainly from the need to extrapolate results from experimental animals (e.g. mouse, rat) to humans, and/or from high to lower doses, including from high acute occupational levels to low chronic environmental levels. In addition, the differences between individuals due to genetics or other factors mean that the hazard may be higher for particular groups, called susceptible populations. An alternative to dose-response estimation is to determine a concentration unlikely to yield observable effects, that is, a no effect concentration. In developing such a dose, to account for the largely unknown effects of animal to human extrapolations, increased variability in humans, or missing data, a prudent approach is often adopted by including safety or uncertainty factors in the estimate of the \"safe\" dose, typically a factor of 10 for each unknown step.\n- Exposure Quantification, aims to determine the amount of a contaminant (dose) that individuals and populations will receive, either as a contact level (e.g., concentration in ambient air) or as intake (e.g., daily dose ingested from drinking water). This is done by examining the results of the discipline of exposure assessment. As a different location, lifestyle, and other factors likely influence the amount of contaminant that is received, a range or distribution of possible values is generated in this step. Particular care is taken to determine the exposure of the susceptible population(s).\nThe results of these steps are combined to produce an estimate of risk. Because of the different susceptibilities and exposures, this risk will vary within a population. An uncertainty analysis is usually included in a health risk assessment.\nDuring an emergency response, the situation and hazards are often inherently less predictable than for planned activities (non-linear). In general, if the situation and hazards are predictable (linear), standard operating procedures should deal with them adequately. In some emergencies, this may also hold true, with the preparation and trained responses being adequate to manage the situation. In these situations, the operator can manage risk without outside assistance, or with the assistance of a backup team who are prepared and available to step in at short notice.\nOther emergencies occur where there is no previously planned protocol, or when an outsider group is brought in to handle the situation, and they are not specifically prepared for the scenario that exists but must deal with it without undue delay. Examples include police, fire department, disaster response, and other public service rescue teams. In these cases, ongoing risk assessment by the involved personnel can advise appropriate action to reduce risk.[22] HM Fire Services Inspectorate has defined dynamic risk assessment (DRA) as:\nThe continuous assessment of risk in the rapidly changing circumstances of an operational incident, in order to implement the control measures necessary to ensure an acceptable level of safety.[22]\nDynamic risk assessment is the final stage of an integrated safety management system that can provide an appropriate response during changing circumstances. It relies on experience, training and continuing education, including effective debriefing to analyse not only what went wrong, but also what went right, and why, and to share this with other members of the team and the personnel responsible for the planning level risk assessment.[22]\nThe application of risk assessment procedures is common in a wide range of fields, and these may have specific legal obligations, codes of practice, and standardised procedures. Some of these are listed here.\nThere are many resources that provide human health risk information:\nThe National Library of Medicine provides risk assessment and regulation information tools for a varied audience.[23] These include:\n- TOXNET (databases on hazardous chemicals, environmental health, and toxic releases),[24]\n- the Household Products Database (potential health effects of chemicals in over 10,000 common household products),[25]\n- TOXMAP (maps of the U.S. Environmental Protection Agency Superfund and Toxics Release Inventory data).\nThe United States Environmental Protection Agency provides basic information about environmental health risk assessments for the public for a wide variety of possible environmental exposures.[26]\nThe Environmental Protection Agency began actively using risk assessment methods to protect drinking water in the United States after the passage of the Safe Drinking Water Act of 1974. The law required the National Academy of Sciences to conduct a study on drinking water issues, and in its report, the NAS described some methodologies for doing risk assessments for chemicals that were suspected carcinogens, recommendations that top EPA officials have described as perhaps the study's most important part.[27]\nConsidering the increase in junk food and its toxicity, FDA required in 1973 that cancer-causing compounds must not be present in meat at concentrations that would cause a cancer risk greater than 1 in a million over a lifetime. The US Environmental Protection Agency provides extensive information about ecological and environmental risk assessments for the public via its risk assessment portal.[28] The Stockholm Convention on persistent organic pollutants (POPs) supports a qualitative risk framework for public health protection from chemicals that display environmental and biological persistence, bioaccumulation, toxicity (PBT) and long range transport; most global chemicals that meet this criterion have been previously assessed quantitatively by national and international health agencies.[29]\nFor non-cancer health effects, the terms reference dose (RfD) or reference concentration (RfC) are used to describe the safe level of exposure in a dichotomous fashion. Newer ways of communicating the risk is the probabilistic risk assessment.[30]\nWhen risks apply mainly to small sub-populations, it can be difficult to determine when intervention is necessary. For example, there may be a risk that is very low for everyone, other than 0.1% of the population. It is necessary to determine whether this 0.1% is represented by:\n- all infants younger than X days or\n- recreational users of a particular product.\nIf the risk is higher for a particular sub-population because of abnormal exposure rather than susceptibility, strategies to further reduce the exposure of that subgroup are considered. If an identifiable sub-population is more susceptible due to inherent genetic or other factors, public policy choices must be made. The choices are:\n- to set policies for protecting the general population that are protective of such groups, e.g. for children when data exists, the Clean Air Act for populations such as asthmatics or\n- not to set policies, because the group is too small, or the costs too high.\nAcceptable risk is a risk that is understood and tolerated usually because the cost or difficulty of implementing an effective countermeasure for the associated vulnerability exceeds the expectation of loss.[31]\nThe idea of not increasing lifetime risk by more than one in a million has become commonplace in public health discourse and policy.[32] It is a heuristic measure. It provides a numerical basis for establishing a negligible increase in risk.\nEnvironmental decision making allows some discretion for deeming individual risks potentially \"acceptable\" if less than one in ten thousand chance of increased lifetime risk. Low risk criteria such as these provide some protection for a case where individuals may be exposed to multiple chemicals e.g. pollutants, food additives, or other chemicals.[citation needed]\nIn practice, a true zero-risk is possible only with the suppression of the risk-causing activity.[citation needed]\nStringent requirements of 1 in a million may not be technologically feasible or may be so prohibitively expensive as to render the risk-causing activity unsustainable, resulting in the optimal degree of intervention being a balance between risks vs. benefit.[citation needed] For example, emissions from hospital incinerators result in a certain number of deaths per year. However, this risk must be balanced against the alternatives. There are public health risks, as well as economic costs, associated with all options. The risk associated with no incineration is the potential spread of infectious diseases or even no hospitals. Further investigation identifies options such as separating noninfectious from infectious wastes, or air pollution controls on a medical incinerator.\nIntelligent thought about a reasonably full set of options is essential. Thus, it is not unusual for there to be an iterative process between analysis, consideration of options, and follow up analysis.[citation needed]\nIn the context of public health, risk assessment is the process of characterizing the nature and likelihood of a harmful effect to individuals or populations from certain human activities. Health risk assessment can be mostly qualitative or can include statistical estimates of probabilities for specific populations. In most countries, the use of specific chemicals or the operations of specific facilities (e.g. power plants, manufacturing plants) is not allowed unless it can be shown that they do not increase the risk of death or illness above a specific threshold. For example, the American Food and Drug Administration (FDA) regulates food safety through risk assessment, while the EFSA does the same in EU.[33]\nAn occupational risk assessment is an evaluation of how much potential danger a hazard can have to a person in a workplace environment. The assessment takes into account possible scenarios in addition to the probability of their occurrence and the results.[34] The six types of hazards to be aware of are safety (those that can cause injury), chemicals, biological, physical, psychosocial (those that cause stress, harassment) and ergonomic (those that can cause musculoskeletal disorders).[35] To appropriately access hazards there are two parts that must occur. Firstly, there must be an \"exposure assessment\" which measures the likelihood of worker contact and the level of contact. Secondly, a \"risk characterization\" must be made which measures the probability and severity of the possible health risks.[36]\nThe importance of risk assessments to manage the consequences of climate change and variability is recalled in the global frameworks for disaster risk reduction, adopted by the member countries of the United Nations at the end of the World Conferences held in Kobe (2005) and Sendai (2015). The Sendai Framework for Disaster Risk Reduction brings attention to the local scale and encourages a holistic risk approach, which should consider all the hazards to which a community is exposed, the integration of technical-scientific knowledge with local knowledge, and the inclusion of the concept of risk in local plans to achieve a significant disaster reduction by 2030. Taking these principles into daily practice poses a challenge for many countries. The Sendai framework monitoring system highlights how little is known about the progress made from 2015 to 2019 in local disaster risk reduction.[37]\nAs of 2019, in the South of the Sahara, risk assessment is not yet an institutionalized practice. The exposure of human settlements to multiple hazards (hydrological and agricultural drought, pluvial, fluvial and coastal floods) is frequent and requires risk assessments on a regional, municipal, and sometimes individual human settlement scale. The multidisciplinary approach and the integration of local and technical-scientific knowledge are necessary from the first steps of the assessment. Local knowledge remains unavoidable to understand the hazards that threaten individual communities, the critical thresholds in which they turn into disasters, for the validation of hydraulic models, and in the decision-making process on risk reduction. On the other hand, local knowledge alone is not enough to understand the impacts of future changes and climatic variability and to know the areas exposed to infrequent hazards. The availability of new technologies and open access information (high resolution satellite images, daily rainfall data) allow assessment today with an accuracy that only 10 years ago was unimaginable. The images taken by unmanned vehicle technologies allow to produce very high resolution digital elevation models and to accurately identify the receptors.[38] Based on this information, the hydraulic models allow the identification of flood areas with precision even at the scale of small settlements.[39] The information on loss and damages and on cereal crop at individual settlement scale allow to determine the level of multi-hazard risk on a regional scale.The multi-temporal high-resolution satellite images allow to assess the hydrological drought and the dynamics of human settlements in the flood zone.[40] Risk assessment is more than an aid to informed decision making about risk reduction or acceptance.[41] It integrates early warning systems by highlighting the hot spots where disaster prevention and preparedness are most urgent.[42] When risk assessment considers the dynamics of exposure over time, it helps to identify risk reduction policies that are more appropriate to the local context. Despite these potentials, the risk assessment is not yet integrated into the local planning in the South of the Sahara which, in the best of cases, uses only the analysis of vulnerability to climate change and variability.[42]\nFor audits performed by an outside audit firm, risk assessment is a crucial stage before accepting an audit engagement. According to ISA315 Understanding the Entity and its Environment and Assessing the Risks of Material Misstatement, \"the auditor should perform risk assessment procedures to obtain an understanding of the entity and its environment, including its internal control\". Evidence relating to the auditor's risk assessment of a material misstatement in the client's financial statements. Then, the auditor obtains initial evidence regarding the classes of transactions at the client and the operating effectiveness of the client's internal controls. Audit risk is defined as the risk that the auditor will issue a clean unmodified opinion regarding the financial statements, when in fact the financial statements are materially misstated, and therefore do not qualify for a clean unmodified opinion. As a formula, audit risk is the product of two other risks: risk of material misstatement and detection risk. This formula can be further broken down as follows: inherent risk × control risk × detection risk.\nBanks and other financial institutions undertake risk assessments before lending money to consumers and businesses. The UK's Small Business, Enterprise and Employment Act 2015 recognised that many small businesses are refused bank loans because their business activities did not fit with the risk profiles of the larger financial institutions, and made legislative provision for credit information to be made available to other lenders to allow them also to conduct accurate risk assessments.[43]\nIn project management, risk assessment is an integral part of the risk management plan, studying the probability, the impact, and the effect of every known risk on the project, as well as the corrective action to take should an incident be implied by a risk occur.[44] Of special consideration in this area are the relevant codes of practice that are enforced in the specific jurisdiction. Understanding the regime of regulations that risk management must abide by is integral to formulating safe and compliant risk assessment practices.\nInformation technology risk assessment can be performed by a qualitative or quantitative approach, following different methodologies. One important difference[clarification needed] in risk assessments in information security is modifying the threat model to account for the fact that any adversarial system connected to the Internet has access to threaten any other connected system.[45] Risk assessments may therefore need to be modified to account for the threats from all adversaries, instead of just those with reasonable access as is done in other fields.\nNIST Definition: The process of identifying risks to organizational operations (including mission, functions, image, reputation), organizational assets, individuals, other organizations, and the Nation, resulting from the operation of an information system. Part of risk management incorporates threat and vulnerability analyses and considers mitigations provided by security controls planned or in place.[46]\nThere are various risk assessment methodologies and frameworks available which include NIST Risk Management Framework (RMF),[47] Control Objectives for Information and Related Technologies (COBIT),[48] Factor Analysis of Information Risk (FAIR),[49] Operationally Critical Threat, Asset, and Vulnerability Evaluation (OCTAVE),[50] The Center for Internet Security Risk Assessment Method (CIS RAM),[51] and The Duty of Care Risk Analysis (DoCRA) Standard,[52] which helps define 'reasonable' security.\nThe Threat and Risk Assessment (TRA) process is part of risk management referring to risks related to cyber threats. The TRA process will identify cyber risks, assess risks' severities, and may recommend activities to reduce risks to an acceptable level.\nThere are different methodologies for performing TRA (e.g., Harmonized TRA Methodology[53]), all utilize the following elements:[54][55][56] identifying of assets (what should be protected), identifying and assessing of the threats and vulnerabilities for the identified assets, determining the exploitability of the vulnerabilities, determining the levels of risk associated with the vulnerabilities (what are the implications if the assets were damaged or lost), and recommending a risk mitigation program.\nMegaprojects (sometimes also called \"major programs\") are extremely large-scale investment projects, typically costing more than US$1 billion per project. They include bridges, tunnels, highways, railways, airports, seaports, power plants, dams, wastewater projects, coastal flood protection, oil and natural gas extraction projects, public buildings, information technology systems, aerospace projects, and defence systems. Megaprojects have been shown to be particularly risky in terms of finance, safety, and social and environmental impacts.\nStudies have shown that early parts of the system development cycle such as requirements and design specifications are especially prone to error. This effect is particularly notorious in projects involving multiple stakeholders with different points of view. Evolutionary software processes offer an iterative approach to requirement engineering to alleviate the problems of uncertainty, ambiguity, and inconsistency inherent in software developments, including uncertainty, ambiguity, and inconsistency inherent in software developments.[clarification needed]\nIn July 2010, shipping companies agreed to use standardized procedures in order to assess risk in key shipboard operations. These procedures were implemented as part of the amended International Safety Management Code.[57]\nFormal risk assessment is a required component of most professional dive planning, but the format and methodology may vary. Consequences of an incident due to an identified hazard are generally chosen from a small number of standardised categories, and probability is estimated based on statistical data on the rare occasions when it is available, and on a best guess estimate based on personal experience and company policy in most cases. A simple risk matrix is often used to transform these inputs into a level of risk, generally expressed as unacceptable, marginal or acceptable. If unacceptable, measures must be taken to reduce the risk to an acceptable level, and the outcome of the risk assessment must be accepted by the affected parties before a dive commences. Higher levels of risk may be acceptable in special circumstances, such as military or search and rescue operations when there is a chance of recovering a survivor. Diving supervisors are trained in the procedures of hazard identification and risk assessment, and it is part of their planning and operational responsibility. Both health and safety hazards must be considered. Several stages may be identified. There is risk assessment done as part of the diving project planning, on site risk assessment which takes into account the specific conditions of the day, and dynamic risk assessment which is ongoing during the operation by the members of the dive team, particularly the supervisor and the working diver.[58][59]\nIn recreational scuba diving, the extent of risk assessment expected of the diver is relatively basic and is included in the pre-dive checks. Several mnemonics have been developed by diver certification agencies to remind the diver to pay some attention to risk, but the training is rudimentary. Diving service providers are expected to provide a higher level of care for their customers, and diving instructors and divemasters are expected to assess risk on behalf of their customers and warn them of site-specific hazards and the competence considered appropriate for the planned dive. Technical divers are expected to make a more thorough assessment of risk, but as they will be making an informed choice for a recreational activity, the level of acceptable risk may be considerably higher than that permitted for occupational divers under the direction of an employer.[60][61]\nIn outdoor activities including commercial outdoor education, wilderness expeditions, and outdoor recreation, risk assessment refers to the analysis of the probability and magnitude of unfavorable outcomes such as injury, illness, or property damage due to environmental and related causes, compared to the human development or other benefits of outdoor activity. This is of particular importance as school programs and others weigh the benefits of youth and adult participation in various outdoor learning activities against the inherent and other hazards present in those activities. Schools, corporate entities seeking team-building experiences, parents/guardians, and others considering outdoor experiences expect or require[62] organizations to assess the hazards and risks of different outdoor activities—such as sailing, target shooting, hunting, mountaineering, or camping—and select activities with acceptable risk profiles.\nOutdoor education, wilderness adventure, and other outdoor-related organizations should, and are in some jurisdictions required, to conduct risk assessments prior to offering programs for commercial purposes.[63][64][65]\nSuch organizations are given guidance on how to provide their risk assessments.[66]\nRisk assessments for led outdoor activities form only one component of a comprehensive risk management plan, as many risk assessments use a basic linear-style thinking that does not employ more modern risk management practice employing complex socio-technical systems theory.[67][68]\nEnvironmental Risk Assessment (ERA) aims to assess the effects of stressors, usually chemicals, on the local environment. A risk is an integrated assessment of the likelihood and severity of an undesired event. In ERA, the undesired event often depends on the chemical of interest and on the risk assessment scenario.[69] This undesired event is usually a detrimental effect on organisms, populations or ecosystems. Current ERAs usually compare an exposure to a no-effect level, such as the Predicted Environmental Concentration/Predicted No-Effect Concentration (PEC/PNEC) ratio in Europe. Although this type of ratio is useful and often used in regulation purposes, it is only an indication of an exceeded apparent threshold.[70] New approaches start to be developed in ERA in order to quantify this risk and to communicate effectively on it with both the managers and the general public.[69]\nEcological risk assessment is complicated by the fact that there are many nonchemical stressors that substantially influence ecosystems, communities, and individual plants and animals, as well as across landscapes and regions.[71][72] Defining the undesired (adverse) event is a political or policy judgment, further complicating applying traditional risk analysis tools to ecological systems. Much of the policy debate surrounding ecological risk assessment is over defining precisely what is an adverse event.[73]\nBiodiversity Risk Assessments evaluate risks to biological diversity, specially the risk of species extinction or the risk of ecosystem collapse. The units of assessments are the biological (species, subspecies or populations) or ecological entities (habitats, ecosystems, etc.), and the risk are often related to human actions and interventions (threats and pressures). Regional and national protocols have been proposed by multiple academic or governmental institutions and working groups,[74] but global standards such as the Red List of Threatened Species and the IUCN Red List of Ecosystems have been widely adopted, and are recognized or proposed as official indicators of progress toward international policy targets and goals, such as the Aichi targets and the Sustainable Development Goals.[75][76]\nRisk assessments are used in numerous stages during the legal process and are developed to measure a wide variety of items, such as recidivism rates, potential pretrial issues, probation/parole, and to identify potential interventions for defendants.[77] Clinical psychologists, forensic psychologists, and other practitioners are responsible for conducting risk assessments.[77][78][79] Depending on the risk assessment tool, practitioners are required to gather a variety of background information on the defendant or individual being assessed. This information includes their previous criminal history (if applicable) and other records (i.e. Demographics, Education, Job Status, Medical History), which can be accessed through direct interview with the defendant or on-file records.[77]\nIn the pre-trial stage, a widely used risk assessment tool is the Public Safety Assessment,[80] which predicts failure to appear in court, likelihood of a new criminal arrest while on pretrial release, and likelihood of a new violent criminal arrest while on pretrial release. Multiple items are observed and taken into account based on which aspect of the PSA is being focused, and like all other actuarial risk assessments, each item is assigned a weighted amount to produce a final score.[77] Detailed information such as transparency on the items the PSA factors and how scores are distributed are accessible online.[81]\nFor defendants who have been incarcerated, risk assessments are used to determine their likelihood of recidivism and inform sentence length decisions. Risk assessments also aid parole/probation officers in determining the level of supervision a probationer should be subjected to and what interventions could be implemented to improve offender risk status.[78] The Correctional Offender Management Profiling for Alternative Sanctions (COMPAS) is a risk assessment too designed to measure pretrial release risk, general recidivism risk, and violent recidivism risk. Detailed information on scoring and algorithms for COMPAS are not accessible to the general public.\n- Acceptable loss – Military euphemism\n- Benefit shortfall – When the actual benefits of a venture are less than the projected or estimated benefits\n- Control self-assessment – Technique to assess process effectiveness\n- Cost overrun – Unexpected incurred costs in excess of budgeted amounts\n- Digital continuity\n- Duty of care – Type of legal obligation\n- Edwards v National Coal Board\n- Extreme risk – Low-probability risk of very bad outcomes\n- Environmental impact assessment – Assessment of the environmental consequences of a decision before action\n- Flood risk assessment – Type of risk assessment with respect to floods\n- Form 696 – Metropolitan Police risk assessment\n- Global catastrophic risk – Hypothetical global-scale disaster risk\n- Hazard analysis – Method for assessing risk\n- Hazard analysis and critical control points (HACCP) – Systematic preventive approach to food safety risk assessment in food\n- Health impact assessment – Type of public health document\n- Horizon scanning – Methodology in futures studies\n- Information assurance – Multi-disciplinary methods for decision support systems security\n- Index of auditing-related articles\n- ISO 28000 – Management system standard\n- ISO 31000 – Set of international standards for risk management\n- ISSOW\n- Megaprojects and Risk – 2003 book by Bent Flyvbjerg, Nils Bruzelius and Werner Rothengatter\n- Network theory in risk assessment\n- Occupational exposure banding – Categorization process for chemical hazards\n- Optimism bias – Type of cognitive bias\n- PIMEX a video exposure monitoring method\n- Planning fallacy – Cognitive bias of underestimating time needed\n- Probabilistic risk assessment – Methodology for evaluating risks\n- Probit model – Statistical regression where the dependent variable can take only two values\n- Project risk management\n- Reference class forecasting – Method of predicting the future\n- Reliability engineering – Sub-discipline of systems engineering that emphasizes dependability\n- Risk assessment using qualifiers\n- Risk-based auditing\n- Risk management tools\n- Risk matrix – Risk assessment comparing the likelihood of a risk to its severity\n- Safety engineering – Engineering discipline\n- Security risk – Possibility of something bad happening\n- Statistical risk\n- Strategic misrepresentation – Cognitive bias of underestimating time needed\n- Gordon–Loeb model for cyber security investments\n- Rausand M (2013). \"Chapter 1: Introduction\". Risk Assessment: Theory, Methods, and Applications. John Wiley & Sons. pp. 1–28. ISBN 978-0-470-63764-7.\n- Manuele FA (2016). \"Chapter 1: Risk Assessments: Their Significance and the Role of the Safety Professional\". In Popov G, Lyon BK, Hollcraft B (eds.). Risk Assessment: A Practical Guide to Assessing Operational Risks. John Wiley & Sons. pp. 1–22. ISBN 978-1-118-91104-4.\n- Hodge, N. (2021), \"How to Address Low-Probability, High-Impact Risks\", Risk Management\n- Levi R (1 June 2018). \"Getting Real About Both Benefits and Risks\". Science & Practice, English Special 2018. Swedish Agency of Health Technology Assessment and Assessment of Social Services. ISSN 1104-1250. Retrieved 2018-06-14.\n- Varshavsky JR, Rayasam SD, Sass JB, Axelrad DA, Cranor CF, Hattis D, et al. (January 2023). \"Current practice and recommendations for advancing how human variability and susceptibility are considered in chemical risk assessment\". Environmental Health. 21 (Suppl 1) 133. Bibcode:2023EnvHe..21S.133V. doi:10.1186/s12940-022-00940-1. PMC 9835253. PMID 36635753.\n{{cite journal}}\n: CS1 maint: overridden setting (link) - Hoffmann TC, Del Mar C (February 2015). \"Patients' expectations of the benefits and harms of treatments, screening, and tests: a systematic review\" (PDF). JAMA Internal Medicine. 175 (2): 274–86. doi:10.1001/jamainternmed.2014.6016. PMID 25531451.\n- Stacey D, Lewis KB, Smith M, Carley M, Volk R, Douglas EE, et al. (January 2024). \"Decision aids for people facing health treatment or screening decisions\". The Cochrane Database of Systematic Reviews. 1 (1) CD001431. doi:10.1002/14651858.CD001431.pub6. PMC 10823577. PMID 38284415.\n{{cite journal}}\n: CS1 maint: overridden setting (link) - Rausand M (2013). \"Chapter 6: Accident Models\". Risk Assessment: Theory, Methods, and Applications. John Wiley & Sons. pp. 137–76. ISBN 978-0-470-63764-7.\n- Vamanu BI, Gheorghe AV, Kaina PF (2016). Critical Infrastructures: Risk and Vulnerability Assessment in Transportation of Dangerous Goods: Transportation by Road and Rail. Springer. p. 11. ISBN 978-3-319-30931-6.\n- Lacey P (2011). \"An Application of Fault Tree Analysis to the Identification and Management of Risks in Government Funded Human Service Delivery\". Proceedings of the 2nd International Conference on Public Policy and Social Sciences. SSRN 2171117.\n- Shirey R (August 2007). \"Internet Security Glossary, Version 2\". Network Working Group. The IETF Trust: 9. Retrieved 19 July 2018.\n- Mandelbrot B, Hudson RL (2008). The (mis)Behaviour of Markets: A Fractal View of Risk, Ruin and Reward. London: Profile Books. ISBN 978-1-84668-262-9.\n- Kasperson RE, Renn O, Slovic P, Brown HS, Emel J, Goble R, et al. (1988). \"The social amplification of risk: A conceptual framework\" (PDF). Risk Analysis. 8 (2): 177–187. Bibcode:1988RiskA...8..177K. doi:10.1111/j.1539-6924.1988.tb01168.x.\n- Commoner B. \"Comparing apples to oranges: Risk of cost/benefit analysis\". In Iannone AP (ed.). Contemporary moral controversies in technology. pp. 64–65.\n- O'Brien M (2002). Making better environmental decisions: an alternative to risk assessment. Cambridge, Massachusetts: MIT Press. ISBN 0-262-65053-3. Retrieved 27 September 2010.\n- Shrader-Frechette K, Westra L (October 1997). Technology and Values. Lanham, Md.: Rowman & Littlefield Publishers. ISBN 978-1-4616-4399-9.\n- Taleb NN (September 2008). The fourth quadrant: a map of the limits of statistics (PDF). An Edge original essay (Report).\n- Modern Financial Engineering | Topics in Systems Engineering. Vol. 02. 2022. doi:10.1142/12725. ISBN 978-981-12-5235-8.\n- B Chapman C (1 February 1990). \"A risk engineering approach to project risk management\". International Journal of Project Management. 8: 5–16. doi:10.1016/0263-7863(90)90003-T.\n- Holzmann R, Jørgensen S (2001). \"Social Risk Management: A New Conceptual Framework for Social Protection, and Beyond\". International Tax and Public Finance. 8 (4): 529–56. doi:10.1023/A:1011247814590. S2CID 14180040.\n- Nakaš N (21 November 2017). \"Three Lessons About Risk Management from Everyday Life\". Knowledge Hub. Center of Excellence in Finance. Retrieved 19 July 2018.\n- Lock G (June 2017). Phillips M (ed.). \"Public Safety Diving-Dynamic Risk Assessment\" (PDF). PS Diver Magazine (116): 9. Retrieved 20 June 2017.\n- \"Risk Assessment and Regulation Information from the NLM\". National Library of Medicine. Archived from the original on July 14, 2012. Retrieved 9 June 2013.\n- \"Databases on toxicology, hazardous chemicals, environmental health, and toxic releases\". TOXNET. NLM. May 2012. Retrieved 9 June 2013.\n- \"Household Products Database\". U.S. Dept. of Health & Human Services. January 2013. Archived from the original on August 3, 2003. Retrieved 9 June 2013.\n- \"Risk Assessment Portal\". EPA. 13 May 2013. Retrieved 9 June 2013.\n- EPA Alumni Association: Senior EPA officials discuss early implementation of the Safe Drinking Water Act of 1974, Video, Transcript (see pages 11,14).\n- \"Risk Assessment\". www.epa.gov. US Environmental Protection Agency. 2013-09-26. Retrieved 2016-04-07.\n- Szabo DT, Loccisano AE (March 30, 2012). \"POPs and Human Health Risk Assessment\". Dioxins and Persistent Organic Pollutants (3rd ed.). pp. 579–618. doi:10.1002/9781118184141.ch19. ISBN 978-1-118-18414-1.\n- Nielsen GH, Heiger-Bernays WJ, Levy JI, White RF, Axelrad DA, Lam J, et al. (January 2023). \"Application of probabilistic methods to address variability and uncertainty in estimating risks for non-cancer health effects\". Environmental Health. 21 (Suppl 1) 129. Bibcode:2023EnvHe..21S.129N. doi:10.1186/s12940-022-00918-z. PMC 9835218. PMID 36635712.\n{{cite journal}}\n: CS1 maint: overridden setting (link) - R. Shirey (August 2007). Internet Security Glossary, Version 2. Network Working Group. doi:10.17487/RFC4949. RFC 4949.Informational.\n- Hunter PR, Fewtrell L (2001). \"Acceptable Risk\" (PDF). World Health Organization.\n- Merrill RA (1997). \"Food safety regulation: reforming the Delaney Clause\". Annual Review of Public Health. 18: 313–40. doi:10.1146/annurev.publhealth.18.1.313. PMID 9143722.\n- Current intelligence bulletin 69: NIOSH practices in occupational risk assessment (Report). 2020-02-01. doi:10.26616/nioshpub2020106.\n- \"OSHA's 5 Workplace Hazards\". Grainger Industrial Supply.\n- Waters M, McKernan L, Maier A, Jayjock M, Schaeffer V, Brosseau L (2015-11-25). \"Exposure Estimation and Interpretation of Occupational Risk: Enhanced Information for the Occupational Risk Manager\". Journal of Occupational and Environmental Hygiene. 12 (Suppl 1): S99-111. Bibcode:2015JOEH...12S..99W. doi:10.1080/15459624.2015.1084421. PMC 4685553. PMID 26302336.\n- UNDRR (2019). Global Assessment Report on Disaster Risk Reduction. Geneva: UNDRR. p. 472. ISBN 978-92-1-004180-5. Retrieved 22 June 2020.\n- Tiepolo M (2019). \"Flood Assessment for Risk-Informed Planning along the Sirba River, Niger\". Sustainability. 11 (4003): 1018. Bibcode:2019Water..11.1018M. doi:10.3390/w11051018.\n- Massazza G (2019). \"Flood Hazard Scenarios of the Sirba River (Niger): Evaluation of the Hazard Thresholds and Flooding Areas\". Water. 11 (5): 1018. Bibcode:2019Water..11.1018M. doi:10.3390/w11051018.\n- Tiepolo M (2018). \"Multihazard Risk Assessment for Planning with Climate in the Dosso Region, Niger\". Climate. 6 (67): 67. Bibcode:2018Clim....6...67T. doi:10.3390/cli6030067.\n- International Organization for Standardization (8 November 2017). \"ISO Guide 73: 2009. Risk management – Vocabulary\". ISO. Retrieved 22 June 2020.\n- Tarchiani V (2020). \"Community and Impact Based Early Warning System for Flood Risk Preparedness: The Experience of the Sirba River in Niger\". Sustainability. 12 (2196). doi:10.3390/su12062196.\n- Department for Business, Innovation & Skills, Small Business, Enterprise and Employment Act: Provision of credit information on small and medium sized businesses, BIS/15/272, page 4, published in 2015, accessed on 27 October 2025\n- Managing Project Risks - Retrieved May 20th, 2010\n- Spring J, Kern S, Summers A (2015-05-01). \"Global adversarial capability modeling\". 2015 APWG Symposium on Electronic Crime Research (eCrime). pp. 1–21. doi:10.1109/ECRIME.2015.7120797. ISBN 978-1-4799-8909-6. S2CID 24580989.\n- \"Risk assessment\". NIST Computer Security Resource Center Glossary. National Institute of Standards and Technology (NIST).\n- \"NIST\". NIST. 30 November 2016.\n- \"ISACA COBIT\". ISACA.\n- \"FAIR\". FAIR.\n- \"Carnegie Mellon University\". Software Engineering Institute, Carnegie Mellon University. 31 August 1999.\n- \"Center for Internet Security\". Center for Internet Security (CIS).\n- \"DoCRA\". Duty of Care Risk Analysis (DoCRA).\n- Canadian Centre for Cyber Security (2018-08-15). \"Canadian Centre for Cyber Security\". Canadian Centre for Cyber Security. Retrieved 2021-08-09.\n- Baingo D (2021). \"Threat Risk Assessment (TRA) for Physical Security\". In Masys AJ (ed.). Sensemaking for Security. Advanced Sciences and Technologies for Security Applications. Cham: Springer International Publishing. pp. 243–270. doi:10.1007/978-3-030-71998-2_14. ISBN 978-3-030-71998-2. S2CID 236706551.\n- \"An Overview of Threat and Risk Assessment | SANS Institute\". www.sans.org. Retrieved 2021-08-09.\n- Treasury Board of Canada Secretariat (2006-03-06). \"Rescinded [2019-06-28] - Security Organization and Administration Standard\". www.tbs-sct.gc.ca. Retrieved 2021-08-09.\n- \"ISM CODE – Amendments from 1st July 2010 Risk Assessment\". Archived from the original on 27 April 2014.\n- \"Diving Regulations 2009\". Occupational Health and Safety Act 85 of 1993 – Regulations and Notices – Government Notice R41. Pretoria: Government Printer. Archived from the original on 4 November 2016. Retrieved 3 November 2016 – via Southern African Legal Information Institute.\n- Staff (August 2016). \"15 - General safety requirements\". Guidance for diving supervisors IMCA D 022 (Revision 1 ed.). London, UK: International Marine Contractors Association. pp. 15–5.\n- Staff (1977). \"The Diving at Work Regulations 1997\". Statutory Instruments 1997 No. 2776 Health and Safety. Kew, Richmond, Surrey: Her Majesty's Stationery Office (HMSO). Retrieved 6 November 2016.\n- Gurr K (August 2008). \"13: Operational Safety\". In Mount T, Dituri J (eds.). Exploration and Mixed Gas Diving Encyclopedia (1st ed.). Miami Shores, Florida: International Association of Nitrox Divers. pp. 165–180. ISBN 978-0-915539-10-9.\n- \"2018 Accreditation Rubric\" (PDF). Seattle, Washington: Northwest Association of Independent Schools.\n- \"Adventure Activities Regulations\". supportadventure.co.nz.\n- \"Health and Safety at Work (Adventure Activities) Regulations 2016 (LI 2016/19)\". New Zealand Legislation.\n- \"Adventure Activities Licensing\". The Health and Safety Executive (HSE). gov.uk.\n- \"Adventure activities\". Work Safe. New Zealand.\n- Dallat C, Salmon PM, Goode N (2015). \"All about the Teacher, the Rain and the Backpack: The Lack of a Systems Approach to Risk Assessment in School Outdoor Education Programs\". Procedia Manufacturing. 3: 1157–1164. doi:10.1016/j.promfg.2015.07.193.\n- Baierlein J (2019). Risk Management for Outdoor Programs: a Guide to Safety in Outdoor Education, Recreation and Adventure. Seattle, WA: Viristar LLC.\n- Goussen B, Price OR, Rendal C, Ashauer R (October 2016). \"Integrated presentation of ecological risk from multiple stressors\". Scientific Reports. 6 36004. Bibcode:2016NatSR...636004G. doi:10.1038/srep36004. PMC 5080554. PMID 27782171.\n- Jager T, Heugens EH, Kooijman SA (April 2006). \"Making sense of ecotoxicological test results: towards application of process-based models\". Ecotoxicology. 15 (3): 305–14. Bibcode:2006Ecotx..15..305J. CiteSeerX 10.1.1.453.1811. doi:10.1007/s10646-006-0060-x. PMID 16739032. S2CID 18825042.\n- Goussen B, Rendal C, Sheffield D, Butler E, Price OR, Ashauer R (December 2020). \"Bioenergetics modelling to analyse and predict the joint effects of multiple stressors: Meta-analysis and model corroboration\". The Science of the Total Environment. 749 141509. arXiv:2102.13107. Bibcode:2020ScTEn.74941509G. doi:10.1016/j.scitotenv.2020.141509. PMID 32827825.\n- Landis WG (2005). Regional scale ecological risk assessment: using the relative risk model. Boca Raton, FL: CRC Press. ISBN 1-56670-655-6. OCLC 74274833.\n- Lackey R (1997). \"If ecological risk assessment is the answer, what is the question\". Human and Ecological Risk Assessment. 3 (6): 921–928. Bibcode:1997HERA....3..921L. doi:10.1080/10807039709383735.\n- Nicholson E, Regan TJ, Auld TD, Burns EL, Chisholm LA, English V, et al. (2015). \"Towards consistency, rigour and compatibility of risk assessments for ecosystems and ecological communities\". Austral Ecology. 40 (4): 347–363. Bibcode:2015AusEc..40..347N. doi:10.1111/aec.12148. hdl:1885/66771. ISSN 1442-9985. S2CID 82412136.\n{{cite journal}}\n: CS1 maint: overridden setting (link) - Keith DA, Rodríguez JP, Brooks TM, Burgman MA, Barrow EG, Bland L, et al. (2015). \"The IUCN Red List of Ecosystems: Motivations, Challenges, and Applications\". Conservation Letters. 8 (3): 214–226. Bibcode:2015ConL....8..214K. doi:10.1111/conl.12167. hdl:10536/DRO/DU:30073631. ISSN 1755-263X.\n{{cite journal}}\n: CS1 maint: overridden setting (link) - Brooks TM, Butchart SH, Cox NA, Heath M, Hilton-Taylor C, Hoffmann M, et al. (2015). \"Harnessing biodiversity and conservation knowledge products to track the Aichi Targets and Sustainable Development Goals\". Biodiversity. 16 (2–3): 157–174. Bibcode:2015Biodi..16..157B. doi:10.1080/14888386.2015.1075903. ISSN 1488-8386.\n{{cite journal}}\n: CS1 maint: overridden setting (link) - \"What is Risk Assessment\". Bureau of Justice Assistance. U.S. Department of Justice.\n- Monahan J, Skeem JL (2016). \"Risk Assessment in Criminal Sentencing\". Annual Review of Clinical Psychology. 12: 489–513. doi:10.1146/annurev-clinpsy-021815-092945. PMID 26666966.\n- Heilbrun K (2009). \"Risk Assessment in Evidence-Based Sentencing: Context and Promising Sues\". Chapman Journal of Criminal Justice. 1: 127–142.\n- \"Advancing Pretrial Policy & Research: What is the PSA?\". Advancing Pretrial Policy and Research (APPR).\n- \"How the PSA Works\". Advancing Pretrial Policy & Research (APPR). Advancing Pretrial Policy and Research (APPR).\n- Dorne JC, Kass GE, Bordajandi LR, Amzal B, Bertelsen U, Castoldi AF, et al. (2011). \"Chapter 2. Human Risk Assessment of Heavy Metals: Principles and Applications\". In Sigel A, Sigel H, Sigel RK (eds.). Metal Ions in Toxicology. Metal Ions in Life Sciences. RSC Publishing. pp. 27–60. doi:10.1039/9781849732116-00027. ISBN 978-1-84973-091-4. S2CID 24530234.\n{{cite book}}\n: CS1 maint: overridden setting (link) - Mumtaz MM, Hansen H, Pohl HR (2011). \"Chapter 3. Mixtures and Their Risk Assessment in Toxicology\". In Sigel A, Sigel H, Sigel RK (eds.). Metal Ions in Toxicology. Metal Ions in Life Sciences. RSC Publishing. pp. 61–80. doi:10.1039/9781849732116-00061. ISBN 978-1-84973-091-4.\n- Committee on Risk Assessment of Hazardous Air Pollutants (1994), Science and judgment in risk assessment, Washington, D.C.: National Academy Press, ISBN 978-0-309-04894-1, retrieved 27 September 2010\n- Orlando G, Bufalo M, Penikas H, Zurlo C (2022). Modern financial engineering: counterparty, credit, portfolio and systemic risks. Hackensack, NJ: World Scientific Publishing Co. doi:10.1142/12725. ISBN 978-981-12-5235-8.\n- Hallenbeck WH (1986). Quantitative risk assessment for environmental and occupational health. Chelsea, Mich.: Lewis Publishers.\n- Harremoës P (ed.). Late lessons from early warnings: the precautionary principle 1896–2000.\n- Lachin JM. Biostatistical methods: the assessment of relative risks.\n- Lerche I, Glaesser W (2006). Environmental risk assessment: quantitative measures, anthropogenic influences, human impact. Berlin: Springer. ISBN 978-3-540-26249-7. Retrieved 27 September 2010.\n- Kluger J (November 26, 2006). \"How Americans Are Living Dangerously\". Time. Archived from the original on November 27, 2006. Retrieved 27 September 2010.\"Why We Worry About the Wrong Things: The Psychology of Risk\" |work=Time\n- A Review of risk assessment methodologies (Report). Washington: U.S: Congressional Research Service, Library of Congress, for the Subcommittee on Science, Research, and Technology. 1983.\n- Mayo DG (1997). \"Sociological versus metascientific views of technological risk assessment\". In Shrader-Frechette K, Westra L (eds.). Technology and values. Lanham, Maryland: Rowman & Littlefield. ISBN 978-0-8476-8631-5. Retrieved 27 September 2010.\n- Rozell DJ (2020). Dangerous Science: Science Policy and Risk Analysis for Scientists and Engineers. London: Ubiquity Press. doi:10.5334/bci. ISBN 978-1-911529-90-3. S2CID 213952232.",
    "semiconductor industry": "| Semiconductor device fabrication |\n|---|\n|\nMOSFET scaling (process nodes) |\nThe semiconductor industry is the aggregate of companies engaged in the design and fabrication of semiconductors and semiconductor devices, such as transistors and integrated circuits. Its roots can be traced to the invention of the transistor by Shockley, Brattain, and Bardeen at Bell Labs in 1948.[1][2] Bell Labs licensed the technology for $25,000,[3] and soon many companies, including Motorola (1952),[4] Shockley Semiconductor (1955), Sylvania, Centralab, Fairchild Semiconductor and Texas Instruments were making transistors. In 1958 Jack Kilby of Texas Instruments and Robert Noyce of Fairchild independently invented the Integrated Circuit, a method of producing multiple transistors on a single \"chip\" of Semiconductor material. This kicked off a number of rapid advances in fabrication technology leading to the exponential growth in semiconductor device production, known as Moore's law that has persisted over the past six or so decades. The industry's annual semiconductor sales revenue has since grown to over $481 billion, as of 2018.[5]\nIn 2010, the semiconductor industry had the highest intensity of Research & Development in the EU and ranked second after Biotechnology in the EU, United States and Japan combined.[6]\nThe semiconductor industry is in turn the driving force behind the wider electronics industry,[7] with annual power electronics sales of £135 billion ($216 billion) as of 2011,[8] annual consumer electronics sales expected to reach $2.9 trillion by 2020,[9] tech industry sales expected to reach $5 trillion in 2019,[10] and e-commerce with over $29 trillion in 2017.[11] In 2019, 32.4% of the semiconductor market segment was for networks and communications devices.[12]\nIn 2021, the sales of semiconductors reached a record $555.9 billion, up 26.2%, with sales in China reaching $192.5 billion, according to the Semiconductor Industry Association. A record 1.15 trillion semiconductor units were shipped in the calendar year.[13] The semiconductor industry is projected to reach $726.73 billion by 2027.[14]\nThe global semiconductor industry is dominated by companies from the United States, Taiwan, South Korea, Japan and the Netherlands, with Israel and Germany having significant presence in the field.[15]\nUnique features of the industry include continuous growth but in a cyclical pattern with high volatility.[16] While the current 20-year annual average growth of the semiconductor industry is on the order of 13%, this has been accompanied by equally above-average market volatility, which can lead to significant if not dramatic cyclical swings. This has required the need for high degrees of flexibility and innovation in order to constantly adjust to the rapid pace of change in the market as many products embedding semiconductor devices often have a very short life cycle.[citation needed]\nAt the same time, the rate of constant price-performance improvement in the semiconductor industry is staggering. As a consequence, changes in the semiconductor market not only occur extremely rapidly but also anticipate changes in industries evolving at a slower pace. The semiconductor industry is widely recognized as a key driver and technology enabler for the whole electronics value chain.[17]\nPrior to the 1980s, the semiconductor industry was vertically integrated. Semiconductor companies both designed and manufactured chips in their own facilities. In many cases, this included inventing new processes, refining and purifying source chemicals and silicon wafers, and even manufacturing equipment, like furnaces, lithography tools and etchers. These companies also carried out the assembly and testing of their chips. Over time, many of these functions were outsourced, such that today semiconductor manufacturers rely on a complex supply chain to provide wafers, high purity source chemicals, and processing equipment. Further, starting with LSI in 1969, the industry has seen the emergence of Fabless Semiconductor Companies that focus solely on chip design and rely on other companies to manufacture their designs. Initially, these other companies were integrated device manufacturers (IDMs), companies that also designed and manufactured their own products, and thus were often competitors of the Fabless companies. But, by the mid-1980's TSMC and UMC emerged as foundries, specializing solely in the manufacture of other companies' designs.\nToday, much of the industry is based on the foundry model, which consists of semiconductor fabrication plants (foundries) and integrated circuit design operations, each belonging to separate companies or subsidiaries. Some companies, known as integrated device manufacturers, both design and manufacture semiconductors. The foundry model has resulted in consolidation among foundries. As of 2021, only three firms are able to manufacture the most advanced semiconductors: TSMC of Taiwan, Samsung of South Korea, and Intel of the United States.[18] Part of this is due to the high capital costs of building foundries. TSMC's latest factory, capable of fabricating 3 nm process semiconductors and completed in 2020, cost $19.5 billion.[18]\nIntel is considering outsourcing some production to TSMC. It currently can only produce 10 nm semiconductors, while TSMC and Samsung can both produce 5 nm.[18] GlobalFoundries, an American-headquartered firm, uses a 12 nm process for its most advanced chips due to the rapidly increasing development costs of smaller process nodes.[19]\n|\n|\n| Industry sector | Market share |\n|---|---|\n| Computer and peripheral equipment | 32.3% |\n| Consumer electronics | 21.2% |\n| Telecommunications equipment | 16.5% |\n| Industrial electronics | 14.3% |\n| Defense and space industry | 11.5% |\n| Transportation technology | 4.2% |\nNotes:\n- Pure-play foundries – They specialize in foundry services. They may or may not offer design services to third parties, as well as mask (photomask) making, semiconductor packaging and testing services, which can also be outsourced to other companies. An example is TSMC, which offers design, testing and packaging services, TCE photomasks, which offers only mask making services, and ChipMOS, which offers only packaging and testing services.\n- IDMs (integrated device manufacturers) – They may or may not offer foundry services.\n- Fabless suppliers – They do not offer foundry services. They may or may not offer design services to third parties.\n| Year | Optoelectronics | Sensor / Actuator | MOSFET[38] |\n|---|---|---|---|\n| 1960–2001 | ? | ? | 2,900,000,000,000,000 |\n| 2002 | 23,164 | 1,654 | |\n| 2003 | 28,955 | 2,482 | |\n| 2004 | 38,056 | 3,310 | |\n| 2005 | 44,675 | 4,137 | |\n| 2006[39] | 55,429 | 4,137 | |\n| 2007[40] | 67,839 | 4,136 | |\n| 2008 | 76,939 | 4,964 | |\n| 2009 | 91,003 | 4,964 | |\n| 2010 | 97,622 | 6,619 | |\n| 2011 | 110,031 | 8,273 | |\n| 2012 | 129,886 | 11,583 | |\n| 2013 | 131,541 | 14,064 | |\n| 2014–2015 | ? | ? | 10,100,000,000,000,000 |\n| 2016[41][42] | 217,200 | 17,376 | |\n| 2017–2018 | ? | ? | |\n| 1960–2018 | 1,112,340+ | 87,699+ | 13,000,000,000,000,000 |\n| Year | MOS memory | MPU / MCU | Analog | Logic | ASIC | ASSP | Total |\n|---|---|---|---|---|---|---|---|\n| 1960–1991 | ? | 15,000[43] | ? | ? | ? | ? | 350,000[43] |\n| 1992[44] | 3,706 | ||||||\n| 1993[44] | 4,060 | ||||||\n| 1994[44] | 4,938 | ||||||\n| 1995[44] | 6,092 | ||||||\n| 1996[44] | 6,206 | ||||||\n| 1997 | 7,155[45] | ? | ? | ? | ? | ? | 60,100[40] |\n| 1998–1999 | ? | ? | ? | ? | ? | ? | ? |\n| 2000[46] | ? | ? | ? | ? | ? | ? | 89,100 |\n| 2001 | ? | ? | ? | ? | ? | ? | ? |\n| 2002 | 9,100 | 6,619 | 24,819 | 11,582 | 2,482 | 23,992 | 78,594 |\n| 2003 | 10,755 | 6,618 | 30,611 | 14,064 | 1,655 | 25,646 | 89,349 |\n| 2004 | 13,237 | 9,100 | 33,092 | 14,064 | 1,654 | 33,092 | 104,239 |\n| 2005 | 15,719 | 8,273 | 37,229 | 14,891 | 2,481 | 38,056 | 116,649 |\n| 2006[39] | 18,201 | 10,755 | 43,020 | 18,200 | 2,482 | 45,501 | 141,600 |\n| 2007[40] | 23,992 | 12,409 | 48,811 | 18,201 | 3,309 | 45,502 | 156,000 |\n| 2008 | 25,646 | 12,410 | 49,639 | 18,200 | 1,655 | 47,156 | 154,706 |\n| 2009 | 28,128 | 11,582 | 43,020 | 14,892 | 2,482 | 43,847 | 143,951 |\n| 2010[46] | 33,919 | 16,546 | 57,084 | 19,028 | 1,654 | 57,911 | 189,800 |\n| 2011 | 33,919 | 17,374 | 56,256 | 19,028 | 1,655 | 58,738 | 186,970 |\n| 2012 | 34,747 | 17,373 | 57,084 | 17,373 | 1,655 | 57,083 | 185,315 |\n| 2013 | 33,919 | 16,546 | 67,839 | 18,201 | 2,481 | 64,530 | 203,516 |\n| 2014 | ? | 18,600[47] | ? | ? | ? | ? | ? |\n| 2015 | ? | 22,058[48] | ? | ? | ? | ? | 235,600[46] |\n| 2016[41][42] | 43,440 | 21,174[48] | 130,320 | 52,128 | ? | ? | 342,416 |\n| 2017 | ? | 25,797[48] | ? | ? | ? | ? | 581,321[49] |\n| 2018 | ? | ? | ? | ? | ? | ? | 634,700[49] |\n| 1960–2018 | 356,879+ | 274,298+ | 635,804+ | 249,852+ | 25,645+ | 541,054+ | 4,043,926+ |\n| Year | Discrete transistors | Diode | Total | ||\n|---|---|---|---|---|---|\n| Power | Small-signal | Total | |||\n| 1954–1956[51] | ? | ? | 28 | ? | 28+ |\n| 1957[51] | ? | ? | 30 | ? | 30+ |\n| 1958–1962 | ? | ? | ? | ? | ? |\n| 1963[51] | ? | ? | 303 | ? | 303+ |\n| 1964–1965 | ? | ? | ? | ? | ? |\n| 1966[52] | ? | ? | 968 | ? | 968+ |\n| 1967[52] | ? | ? | 881 | ? | 881+ |\n| 1968[52] | ? | ? | 997 | ? | 997+ |\n| 1969[51] | ? | ? | 1,249 | ? | 1,249+ |\n| 1970[52] | ? | ? | 914 | ? | 914+ |\n| 1971[51] | ? | ? | 881 | ? | 881+ |\n| 1972–2001 | ? | ? | ? | ? | ? |\n| 2002 | ? | ? | ? | ? | 232,472 |\n| 2003 | ? | ? | ? | ? | 245,708 |\n| 2004 | ? | ? | ? | ? | 287,901 |\n| 2005 | ? | ? | ? | ? | 290,382 |\n| 2006[39] | ? | ? | ? | ? | 321,820 |\n| 2007[40] | ? | ? | ? | ? | 356,566 |\n| 2008 | ? | ? | ? | ? | 324,301 |\n| 2009 | ? | ? | ? | ? | 289,555 |\n| 2010 | 53,000[53] | ? | 53,000+ | ? | 371,458 |\n| 2011 | 45,000 | 110,000 | 155,000 | 143,000 | 356,000 |\n| 2012 | ? | ? | ? | ? | 345,812 |\n| 2013 | 44,000 | 103,000 | 147,000 | 146,000 | 358,000 |\n| 2014 | 48,000 | 109,000 | 157,000 | 154,000 | 380,000 |\n| 2015[46] | 52,000 | 107,000 | 159,000 | 150,000 | 372,000 |\n| 2016[41] | 53,300 | ? | 53,300+ | ? | 382,272 |\n| 2017 | 58,100 | ? | 58,100+ | ? | 58,100+ |\n| 2018 | 62,800 | ? | 62,800+ | ? | 62,800+ |\n| 1954–2018 | 416,200+ | 429,000+ | 851,451+ | 593,000+ | 5,041,398+ |\nManufacturers headquartered in the following places are the sales leaders in the pure-play foundry, IDM (integrated device manufacturing), fabless manufacturing and OSAT (outsourced semiconductor assembly and testing) sectors of the industry.[36]\nManufacturers headquartered in the United States have fabrication plants across the world, including over 50% in the Americas, 39% in the Asia-Pacific region (including 9% in Japan), and 9% in Europe.[36]\n- Electronic design automation\n- Electronics and semiconductor manufacturing industry in India\n- Electronics and semiconductor manufacturing industry in Japan\n- List of EDA companies\n- List of semiconductor fabrication plants\n- Semiconductor consolidation\n- Semiconductor device fabrication\n- Semiconductor fabrication plant\n- Semiconductor Industry Association\n- Semiconductor industry in India\n- Semiconductor industry in Japan\n- Semiconductor industry in Taiwan\n- Semiconductor industry in China\n- Semiconductor industry in South Korea\n- Transistor count\n- Bardeen, John; Brattain, Walter (19 February 1952). \"Oscillation Generator\" (PDF). U.S. Patent Office. 2586597. Retrieved 8 December 2024.\n- Shockley, William (13 October 1953). \"Bistable Circuits, Including Transistors\" (PDF). U.S. Patent Office. 2655609. Retrieved 8 December 2024.\n- Miller, Chris (October 2022). Chip War (1 ed.). New York, NY: Simon & Schuster, Inc. p. 13. ISBN 978-1-9821-7200-8.\n- \"Motorola History Milestones\". Motorola Solutions. Retrieved 8 December 2024.\n- \"Semiconductors – the Next Wave\" (PDF). Deloitte. April 2019. Archived from the original (PDF) on 20 October 2021. Retrieved 11 October 2019.\n- \"European semiconductor industry declared Europe's most R&D intensive industry sector\" (PDF). European Semiconductor Industry Association. Retrieved 2024-12-14.\n- \"Annual Semiconductor Sales Increase 21.6 Percent, Top $400 Billion for First Time\". Semiconductor Industry Association. 5 February 2018. Retrieved 11 October 2019.\n- \"Power Electronics: A Strategy for Success\" (PDF). Government of the United Kingdom. Department for Business, Innovation and Skills. October 2011. Retrieved 11 October 2019.\n- \"Global Consumer Electronics Market to Reach US$ 2.9 Trillion by 2020 - Persistence Market Research\". PR Newswire. Persistence Market Research. 3 January 2017. Retrieved 11 October 2019.\n- \"IT Industry Outlook 2019\". CompTIA. January 2019. Retrieved 11 October 2019.\n- \"Global e-Commerce sales surged to $29 trillion\". United Nations Conference on Trade and Development. 29 March 2019. Retrieved 13 October 2019.\n- Kamal, Kamal Y. (2022). \"The Silicon Age: Trends in Semiconductor Devices Industry\" (PDF). Journal of Engineering Science and Technology Review. 15 (1): 110–115. doi:10.25103/jestr.151.14. ISSN 1791-2377. S2CID 249074588. Retrieved 2022-05-26.\n- Kharpal, Arjun (2022-02-15). \"Global semiconductor sales top half a trillion dollars for first time as chip production gets boost\". CNBC. Retrieved 2022-02-15.\n- Kamal, Kamal Y. (2022). \"The Silicon Age: Trends in Semiconductor Devices Industry\" (PDF). Journal of Engineering Science and Technology Review. 15 (1): 110–115. doi:10.25103/jestr.151.14. ISSN 1791-2377. S2CID 249074588. Retrieved 2022-05-26.\n- \"Semiconductor Manufacturing by Country 2024\". worldpopulationreview.com. Retrieved 2024-07-08.\n- Strahl, Simon; Lundholm, Chester. \"Decoding Semiconductor Market Risks\" (PDF). Retrieved August 6, 2025.\n- Staff, ReportLinker. “Global Semiconductor Market Outlook 2022 Archived 2016-09-23 at the Wayback Machine.” January 13, 2016. February 19, 2016.\n- \"Chipmaking is being redesigned. Effects will be far-reaching\". The Economist. 2021-01-23. ISSN 0013-0613.\n- \"GlobalFoundries Stops All 7nm Development: Opts to Focus on Specialized Processes\". Archived from the original on August 27, 2018.\n- \"Gartner Says Worldwide Semiconductor Revenue Grew 1.1% in 2022\". Gartner. Retrieved 2023-08-10.\n- \"Gartner Says Worldwide Semiconductor Revenue Grew 10.4% in 2020\". Gartner. Retrieved 2023-08-10.\n- \"Semiconductor sales revenue worldwide from 1987 to 2020 (in billion U.S. dollars)\". Statista. July 4, 2019. Retrieved 11 October 2019.\n- \"Global Chip Sales Hit $255.6 Billion in 2007\". Semiconductor Industry Association. 1 February 2008. Retrieved 11 October 2019.\n- \"Annual Semiconductor Sales Increase 21.6 Percent, Top $400 Billion for First Time\". Semiconductor Industry Association. 5 February 2018. Retrieved 29 July 2019.\n- \"Global Power Semiconductor Market 2017-2018 to 2023: Analysis by Material, Component, Industry and Region\". Business Wire. Research and Markets. 2 October 2018. Retrieved 11 October 2019.\n- Woodall, Jerry M. (2010). \"Non-Silicon MOSFET Technology: A Long Time Coming\". Fundamentals of III-V Semiconductor MOSFETs. Springer Science & Business Media. p. 1. ISBN 9781441915474.\n- \"Power Transistors to Hit Another Sales Record After Growth Bubble Ends\". IC Insights. May 14, 2019. Retrieved 11 October 2019.\n- Asthana, Rajiv; Kumar, Ashok; Dahotre, Narendra B. (2022). Materials Processing and Manufacturing Science. Elsevier. p. 488. ISBN 9780080464886.\n- \"Samsung Takes Semiconductor Crown From Intel in 2021\". Counterpoint Research. 2022-01-28. Retrieved 2023-08-10.\n- \"ic insights\". www.icinsights.com. 2020-11-23. Retrieved 2021-02-24.\n- Manners, David (14 November 2018). \"Top Ten (+5) Semiconductor Companies 2018\". Electronics Weekly. Retrieved 15 June 2019.\n- \"Top 25 2011 Semiconductor Sales Ranking\". IC Insights. April 5, 2012. Retrieved 9 July 2019.\n- \"Tracking the Top 10 Semiconductor Sales Leaders Over 26 Years\". Semiconductor Market Research. IC Insights. December 12, 2011.\n- \"WORLDWIDE IC MANUFACTURERS\" (PDF). Smithsonian Institution. 1997. Retrieved 10 July 2019.\n- \"1980s Trends in the Semiconductor Industry\". Semiconductor History Museum of Japan. Retrieved 10 July 2019.\n- \"BEYOND BORDERS: THE GLOBAL SEMICONDUCTOR VALUE CHAIN\" (PDF). Semiconductor Industry Association. May 2016. Retrieved 10 July 2019.\n- Bahai, Ahmed (2015). \"Innovation in Power Electronics\" (PDF). SEMICON West. Texas Instruments. Retrieved 23 October 2019.[permanent dead link]\n- \"13 Sextillion & Counting: The Long & Winding Road to the Most Frequently Manufactured Human Artifact in History\". Computer History Museum. April 2, 2018. Retrieved 28 July 2019.\n- \"Semiconductor Unit Shipments To Exceed One Trillion Devices in 2016\". IC Insights. February 18, 2014. Retrieved 15 October 2019.\n- \"Semiconductor Unit Shipments To Exceed One Trillion Devices in 2017\". IC Insights. February 17, 2015. Retrieved 15 October 2019.\n- Manners, David (10 March 2017). \"Semi units to hit a trillion next year\". Electronics Weekly. Retrieved 15 October 2019.\n- \"Research Report on China Integrated Circuit Industry, 2018-2022: In 2017, Sales Value of Local IC Companies Reached Approximately USD 80.15 Billion\". GlobeNewswire. 8 May 2018. Retrieved 15 October 2019.\n- Port, Otis (9 December 1996). \"The Silicon Age? It's Just Dawning\". Bloomberg News. Retrieved 15 October 2019.\n- \"The MOS Memory Market\" (PDF). Integrated Circuit Engineering Corporation. Smithsonian Institution. 1997. pp. 1–7. Retrieved 16 October 2019.\n- \"MOS Memory Market Trends\" (PDF). Integrated Circuit Engineering Corporation. Smithsonian Institution. 1998. Retrieved 16 October 2019.\n- McGrath, Dylan (8 March 2016). \"Semiconductor Shipments to Top 1 Trillion Units in 2018\". EE Times. Retrieved 15 October 2019.\n- Roos, Gina (4 February 2015). \"Microcontroller Market Continues to Strengthen\". EPS News. Retrieved 26 October 2019.\n- \"Microcontroller sales set to soar, says IC Insights\". Electronic Specifier. 13 September 2018. Retrieved 29 October 2019.\n- \"Global and China $578 Bn Integrated Circuit Industries Markets, 2014-2018 & 2019-2023\". PR Newswire. Research and Markets. June 5, 2019. Retrieved 24 October 2019.\n- \"Global discrete semiconductor shipments by type 2011-2020\". Statista. Retrieved 15 October 2019.\n- Butrica, Andrew J. (2015). \"Chapter 3: NASA's Role in the Manufacture of Integrated Circuits\". In Dick, Steven J. (ed.). Historical Studies in the Societal Impact of Spaceflight (PDF). NASA. pp. 149–250. ISBN 978-1-62683-027-1.\n- Electronic receiving tubes and transistors production and maintenance workers at RCA Corporation plant. United States Tariff Commission. 1971. p. A-15.\n- Clarke, Peter (June 24, 2011). \"Power transistor market set to grow 9% in 2011\". EE Times. Retrieved 29 October 2019.",
    "software development": "| Part of a series on |\n| Software development |\n|---|\nSoftware development is the process of designing, creating, testing, and maintaining software applications to meet specific user needs or business objectives. The process is more encompassing than programming, writing code, in that it includes conceiving the goal, evaluating feasibility, analyzing requirements, design, testing and release. The process is part of software engineering which also includes organizational management, project management, configuration management and other aspects.[1]\nSoftware development involves many skills and job specializations including programming, testing, documentation, graphic design, user support, marketing, and fundraising.\nSoftware development involves many tools including: compiler, integrated development environment (IDE), version control, computer-aided software engineering, and word processor.\nThe details of the process used for a development effort vary. The process may be confined to a formal, documented standard, or it can be customized and emergent for the development effort. The process may be sequential, in which each major phase (i.e., design, implement, and test) is completed before the next begins, but an iterative approach – where small aspects are separately designed, implemented, and tested – can reduce risk and cost and increase quality.\nEach of the available methodologies is best suited to specific kinds of projects, based on various technical, organizational, project, and team considerations.[3]\n- The simplest methodology is the \"code and fix\", typically used by a single programmer working on a small project. After briefly considering the purpose of the program, the programmer codes it and runs it to see if it works. When they are done, the product is released. This methodology is useful for prototypes but cannot be used for more elaborate programs.[4]\n- In the top-down waterfall model, feasibility, analysis, design, development, quality assurance, and implementation occur sequentially in that order. This model requires one step to be complete before the next begins, causing delays, and makes it impossible to revise previous steps if necessary.[5][6][7]\n- With iterative processes these steps are interleaved with each other for improved flexibility, efficiency, and more realistic scheduling. Instead of completing the project all at once, one might go through most of the steps with one component at a time. Iterative development also lets developers prioritize the most important features, enabling lower priority ones to be dropped later on if necessary.[6][8] Agile is one popular method, originally intended for small or medium sized projects, that focuses on giving developers more control over the features that they work on to reduce the risk of time or cost overruns.[9] Derivatives of agile include extreme programming and Scrum.[9] Open-source software development typically uses agile methodology with concurrent design, coding, and testing, due to reliance on a distributed network of volunteer contributors.[10]\n- Beyond agile, some companies integrate information technology (IT) operations with software development, which is called DevOps or DevSecOps including computer security.[11] DevOps includes continuous development, testing, integration of new code in the version control system, deployment of the new code, and sometimes delivery of the code to clients.[12] The purpose of this integration is to deliver IT services more quickly and efficiently.[11]\nAnother focus in many programming methodologies is the idea of trying to catch issues such as security vulnerabilities and bugs as early as possible (shift-left testing) to reduce the cost of tracking and fixing them.[13]\nIn 2009, it was estimated that 32% of software projects were delivered on time and on budget, and with full functionality. An additional 44% were delivered, but were missing at least one of their features. The remaining 24% were cancelled before release.[14]\nSoftware development life cycle refers to the systematic process of developing applications.[15]\nThe sources of ideas for software products are plentiful. These ideas can come from market research, including the demographics of potential new customers, existing customers, sales prospects who rejected the product, other internal software development staff, or a creative third party. Ideas for software products are usually first evaluated by marketing personnel for economic feasibility, fit with existing channels of distribution, possible effects on existing product lines, required features, and fit with the company's marketing objectives. In the marketing evaluation phase, the cost and time assumptions are evaluated.[16] The feasibility analysis estimates the project's return on investment, its development cost and timeframe. Based on this analysis, the company can make a business decision to invest in further development.[17] After deciding to develop the software, the company is focused on delivering the product at or below the estimated cost and time, and with a high standard of quality (i.e., lack of bugs) and the desired functionality. Nevertheless, most software projects run late, and sometimes compromises are made in features or quality to meet a deadline.[18]\nSoftware analysis begins with a requirements analysis to capture the business needs of the software.[19] Challenges for the identification of needs are that current or potential users may have different and incompatible needs, may not understand their own needs, and change their needs during the process of software development.[20] Ultimately, the result of analysis is a detailed specification for the product that developers can work from. Software analysts often decompose the project into smaller objects, components that can be reused for increased cost-effectiveness, efficiency, and reliability.[19] Decomposing the project may enable a multi-threaded implementation that runs significantly faster on multiprocessor computers.[21]\nDuring the analysis and design phases of software development, structured analysis is often used to break down the customer's requirements into pieces that can be implemented by software programmers.[22] The underlying logic of the program may be represented in data-flow diagrams, data dictionaries, pseudocode, state transition diagrams, and/or entity relationship diagrams.[23] If the project incorporates a piece of legacy software that has not been modeled, this software may be modeled to help ensure it is correctly incorporated with the newer software.[24]\nDesign involves choices about the implementation of the software, such as which programming languages and database software to use, or how the hardware and network communications will be organized. Design may be iterative with users consulted about their needs in a process of trial and error. Design often involves people who are expert in aspects such as database design, screen architecture, and the performance of servers and other hardware.[19] Designers often attempt to find patterns in the software's functionality to spin off distinct modules that can be reused with object-oriented programming. An example of this is the model–view–controller, an interface between a graphical user interface and the backend.[25]\nThe central feature of software development is creating and understanding the software that implements the desired functionality.[26] There are various strategies for writing the code. Cohesive software has various components that are independent from each other.[19] Coupling is the interrelation of different software components, which is viewed as undesirable because it increases the difficulty of maintenance.[27] Often, software programmers do not follow industry best practices, resulting in code that is inefficient, difficult to understand, or lacking documentation on its functionality.[28] These standards are especially likely to break down in the presence of deadlines.[29] As a result, testing, debugging, and revising the code become much more difficult. Code refactoring, for example, adding more comments to the code, is a solution to improve the understandability of the code.[30]\nTesting is the process of ensuring that the code executes correctly and without errors. Debugging is performed by each software developer on their own code to confirm that the code does what it is intended to. In particular, it is crucial that the software executes on all inputs, even if the result is incorrect.[31] Code reviews by other developers are often used to scrutinize new code added to the project, and according to some estimates dramatically reduce the number of bugs persisting after testing is complete.[32] Once the code has been submitted, quality assurance – a separate department of non-programmers for most large companies – test the accuracy of the entire software product. Acceptance tests derived from the original software requirements are a popular tool for this.[31] Quality testing also often includes stress and load checking (whether the software is robust to heavy levels of input or usage), integration testing (to ensure that the software is adequately integrated with other software), and compatibility testing (measuring the software's performance across different operating systems or browsers).[31] When tests are written before the code, this is called test-driven development.[33]\nProduction is the phase in which software is deployed to the end user.[34] During production, the developer may create technical support resources for users[35][34] or a process for fixing bugs and errors that were not caught earlier. There might also be a return to earlier development phases if user needs changed or were misunderstood.[34]\nSoftware development is performed by software developers, usually working on a team. Efficient communications between team members is essential to success. This is more easily achieved if the team is small, used to working together, and located near each other.[36] Communications also help identify problems at an earlier stage of development and avoid duplicated effort. Many development projects avoid the risk of losing essential knowledge held by only one employee by ensuring that multiple workers are familiar with each component.[37] Software development involves professionals from various fields, not just software programmers but also product managers who set the strategy and roadmap for the product,[38] individuals specialized in testing, documentation writing, graphic design, user support, marketing, and fundraising. Although workers for proprietary software are paid, most contributors to open-source software are volunteers.[39] Alternately, they may be paid by companies whose business model does not involve selling the software, but something else – such as services and modifications to open source software.[40]\nComputer-aided software engineering (CASE) is tools for the partial automation of software development.[41] CASE enables designers to sketch out the logic of a program, whether one to be written, or an already existing one to help integrate it with new code or reverse engineer it (for example, to change the programming language).[42]\nDocumentation comes in two forms that are usually kept separate – one intended for software developers, and another made available to the end user to help them use the software.[43][44] Most developer documentation is in the form of code comments for each file, class, and method that cover the application programming interface (API)—how the piece of software can be accessed by another—and often implementation details.[45] This documentation is helpful for new developers to understand the project when they begin working on it.[46] In agile development, the documentation is often written at the same time as the code.[47] User documentation is more frequently written by technical writers.[48]\nAccurate estimation is crucial at the feasibility stage and in delivering the product on time and within budget. The process of generating estimations is often delegated by the project manager.[49] Because the effort estimation is directly related to the size of the complete application, it is strongly influenced by the addition of features in the requirements—the more requirements, the higher the development cost. Aspects not related to functionality, such as the experience of the software developers and code reusability, are also essential to consider in estimation.[50] As of 2019[update], most of the tools for estimating the amount of time and resources for software development were designed for conventional applications and are not applicable to web applications or mobile applications.[51]\nAn integrated development environment (IDE) supports software development with enhanced features compared to a simple text editor.[52] IDEs often include automated compiling, syntax highlighting of errors,[53] debugging assistance,[54] integration with version control, and semi-automation of tests.[52]\nVersion control is a popular way of managing changes made to the software. Whenever a new version is checked in, the software saves a backup of all modified files. If multiple programmers are working on the software simultaneously, it manages the merging of their code changes. The software highlights cases where there is a conflict between two sets of changes and allows programmers to fix the conflict.[55]\nA view model is a framework that provides the viewpoints on the system and its environment, to be used in the software development process. It is a graphical representation of the underlying semantics of a view.\nThe purpose of viewpoints and views is to enable human engineers to comprehend very complex systems and to organize the elements of the problem around domains of expertise. In the engineering of physically intensive systems, viewpoints often correspond to capabilities and responsibilities within the engineering organization.[56]\nFitness functions are automated and objective tests to ensure that the new developments do not deviate from the established constraints, checks and compliance controls.[57]\nIntellectual property can be an issue when developers integrate open-source code or libraries into a proprietary product, because most open-source licenses used for software require that modifications be released under the same license. As an alternative, developers may choose a proprietary alternative or write their own software module.[58]\n- Dooley 2017, p. 1.\n- Dooley 2017, p. 12.\n- System Development Methodologies for Web-Enabled E-Business: A Customization Framework Linda V. Knight (DePaul University, USA), Theresa A. Steinbach (DePaul University, USA), and Vince Kellen (Blue Wolf, USA)\n- Dooley 2017, pp. 8–9.\n- Dooley 2017, p. 9.\n- Langer 2016, pp. 2–3, 5–6.\n- Tucker, Morelli & de Silva 2011, p. 8.\n- Dooley 2017, p. 11.\n- Dooley 2017, p. 13.\n- Tucker, Morelli & de Silva 2011, pp. 41–42.\n- Vishnu 2019, pp. 1–2.\n- Laukkanen, Eero; Itkonen, Juha; Lassenius, Casper (2017). \"Problems, causes and solutions when adopting continuous delivery—A systematic literature review\". Information and Software Technology. 82: 55–79. doi:10.1016/j.infsof.2016.10.001.\n- Winters, Manshreck & Wright 2020, p. 17.\n- Tucker, Morelli & de Silva 2011, p. 6.\n- Saif 2019, pp. 46–47.\n- Morris 2001, p. 1.10.\n- Langer 2016, p. 7.\n- Dooley 2017, pp. 3, 8.\n- Langer 2016, p. 8.\n- Langer 2016, pp. 2–3.\n- Dooley 2017, pp. 193–194.\n- Langer 2016, pp. 103–104.\n- Langer 2016, pp. 117, 127, 131, 137, 141.\n- Langer 2016, p. 106.\n- Dooley 2017, p. 142.\n- Tucker, Morelli & de Silva 2011, p. 31.\n- Langer 2016, pp. 8–9.\n- Tucker, Morelli & de Silva 2011, pp. 31–32.\n- Tucker, Morelli & de Silva 2011, pp. 34–35.\n- Tucker, Morelli & de Silva 2011, pp. 31–32, 35.\n- Langer 2016, p. 9.\n- Dooley 2017, p. 272.\n- Tucker, Morelli & de Silva 2011, p. 9.\n- Langer 2016, p. 10.\n- Tucker, Morelli & de Silva 2011, p. 37.\n- Dooley 2017, p. 2.\n- Winters, Manshreck & Wright 2020, pp. 30–31.\n- \"What Does a Product Manager Do? And How to Become One\". Coursera. 21 January 2025. Retrieved 5 May 2025.\n- Tucker, Morelli & de Silva 2011, p. 7.\n- Tucker, Morelli & de Silva 2011, pp. 14–15.\n- Langer 2016, p. 22.\n- Langer 2016, pp. 108–110, 206.\n- Tucker, Morelli & de Silva 2011, p. 243.\n- Winters, Manshreck & Wright 2020, p. 192.\n- Winters, Manshreck & Wright 2020, pp. 193–195.\n- Tucker, Morelli & de Silva 2011, p. 143.\n- Tucker, Morelli & de Silva 2011, p. 144.\n- Winters, Manshreck & Wright 2020, p. 204.\n- Saif 2019, pp. 50–51.\n- Saif 2019, pp. 52–53.\n- Saif 2019, p. 45.\n- Tucker, Morelli & de Silva 2011, p. 68.\n- Dooley 2017, p. 236.\n- Dooley 2017, p. 239.\n- Dooley 2017, pp. 246–247.\n- Edward J. Barkmeyer ea (2003). Concepts for Automating Systems Integration Archived 25 January 2017 at the Wayback Machine NIST 2003.\n- Fundamentals of Software Architecture: An Engineering Approach. O'Reilly Media. 2020. ISBN 978-1492043454.\n- Langer 2016, pp. 44–45.\n- Conde, Dan (2002). Software Product Management: Managing Software Development from Idea to Product to Marketing to Sales. Aspatore Books. ISBN 1587622025.\n- Davis, A. M. (2005). Just enough requirements management: Where software development meets marketing. Dorset House Publishing Company, Incorporated. ISBN 0932633641.\n- Dooley, John F. (2017). Software Development, Design and Coding: With Patterns, Debugging, Unit Testing, and Refactoring. Apress. ISBN 978-1-4842-3153-1.\n- Kit, Edward (1992). Software Testing in The Real World. Addison-Wesley Professional. ISBN 0201877562.\n- Hasted, Edward (2005). Software That Sells: A Practical Guide to Developing and Marketing Your Software Project. Wiley Publishing. ISBN 0764597833.\n- Hohmann, Luke (2003). Beyond Software Architecture: Creating and Sustaining Winning Solutions. Addison-Wesley Professional. ISBN 0201775948.\n- Horch, John W. (March 1995). \"Two Orientations On How To Work With Objects\". IEEE Software. 12 (2): 117–118. ProQuest 215832531.\n- Langer, Arthur M. (2016). Guide to Software Development: Designing and Managing the Life Cycle. Springer. ISBN 978-1-4471-6799-0.\n- McCarthy, Jim (1995). Dynamics of Software Development. Microsoft Press. ISBN 1556158238.\n- Morris, Joseph M. (2001). Software industry accounting (2nd ed.). John Wiley & Sons. OCLC 53863959.\n- Rittinghouse, John (2003). Managing Software Deliverables: A Software Development Management Methodology. Digital Press. ISBN 155558313X.\n- Saif, Syed Mohsin (2019). \"Software Effort Estimation for Successful Software Application Development\". In Vishnu, Pendyala (ed.). Tools and Techniques for Software Development in Large Organizations: Emerging Research and Opportunities: Emerging Research and Opportunities. IGI Global. pp. 45–97. ISBN 978-1-7998-1865-6.\n- Tucker, Allen; Morelli, Ralph; de Silva, Chamindra (2011). Software Development: An Open Source Approach. CRC Press. ISBN 978-1-4398-8460-7.\n- Vishnu, Pendyala (2019). \"Evolution of Integration, Build, Test, and Release Engineering Into DevOps and to DevSecOps\". In Vishnu, Pendyala (ed.). Tools and Techniques for Software Development in Large Organizations: Emerging Research and Opportunities: Emerging Research and Opportunities. IGI Global. pp. 1–20. ISBN 978-1-7998-1865-6.\n- Wiegers, Karl E. (2005). More About Software Requirements: Thorny Issues and Practical Advice. Microsoft Press. ISBN 0735622671.\n- Winters, Titus; Manshreck, Tom; Wright, Hyrum (2020). Software Engineering at Google: Lessons Learned from Programming Over Time. O'Reilly Media, Inc. ISBN 978-1-4920-8276-7.\n- Wysocki, Robert K. (2006). Effective Software Project Management. Wiley. ISBN 0764596365.\n- Media related to Software development at Wikimedia Commons",
    "software industry": "The software industry includes businesses for development, maintenance and publication of software that are using different business models, mainly either \"license/maintenance based\" (on-premises) or \"Cloud based\" (such as SaaS, PaaS, IaaS, MBaaS, MSaaS, DCaaS etc.). The industry also includes software services, such as training, documentation, consulting and data recovery. The software and computer services industry spends more than 11% of its net sales for Research & Development which is in comparison with other industries the second highest share after pharmaceuticals & biotechnology.[1]\nThe first company founded to provide software products and services was Computer Usage Company in 1955.[2] Before that time, computers were programmed either by customers, or the few commercial computer vendors of the time, such as Sperry Rand and IBM.\nThe software industry expanded in the early 1960s, shortly after computers became widely available. Demand for software was created by universities, the government, and businesses. Many of these programs were developed by full-time staff programmers in-house. Some were distributed free of charge among users of a particular machine. Others were done on a commercial basis, and other firms such as Computer Sciences Corporation (founded in 1959) started to grow. Other influential or typical software companies begun in the early 1960s included Advanced Computer Techniques, Automatic Data Processing, Applied Data Research, and Informatics General.[3][4] The computer/hardware makers started bundling operating systems, systems software and programming environments with their machines.\nWhen Digital Equipment Corporation (DEC) brought a relatively low-priced microcomputer to market, it brought computing within the reach of many more companies and universities worldwide, and it spawned great innovation in terms of new, powerful programming languages and methodologies. New software was built for microcomputers, so other manufacturers including IBM, followed DEC's example quickly, resulting in the IBM AS/400 amongst others.\nThe industry expanded greatly with the rise of the personal computer in the latter half of the 1970s, with the TRS-80, Apple II, and Commodore PET all introduced in 1977. The affordability of computers for home use created a growing market for games, applications, and utilities. The IBM PC, introduced in 1981, became a standard for office use.\nIn the early years of the 21st century, another successful business model has arisen for hosted software, called software-as-a-service, or SaaS; this was at least the third time[citation needed] this model had been attempted. From the point of view of producers of some proprietary software, SaaS reduces the concerns about unauthorized copying, since it can only be accessed through the Web, and by definition no client software is loaded onto the end user's PC.\nMarket research firm Gartner estimates the global market for IT spending in 2024 at $3.73 trillion. If telecoms services are included, this will rise to $5.26 trillion.[5] Major companies include Microsoft, HP, Oracle, Dell and IBM.[6]\nThe software industry has been subject to a high degree of consolidation over the past couple of decades. Between 1995 and 2018 around 37,039 mergers and acquisitions have been announced with a total known value of US$1,166 billion.[7] The highest number and value of deals was set in 2000 during the high times of the dot-com bubble with 2,674 transactions valued at US$105 billion. In 2017, 2,547 deals were announced valued at US$111 billion. Approaches to successfully acquire and integrate software companies are available.[8]\nSoftware industry business models include SaaS (subscription-based), PaaS (platform services), IaaS (infrastructure services), and freemium (free with premium features). Others are perpetual licenses (one-time fee), ad-supported (free with ads), open source (free with paid support), pay-per-use (usage-based), and consulting/customization services. Hybrid models combine multiple approaches.\nBusiness models of software companies have been widely discussed.[9][10] Network effects in software ecosystems, networks of companies, and their customers are an important element in the strategy of software companies.[11]\n- Software engineering\n- World's largest software companies\n- Function point\n- Software development effort estimation\n- Comparison of development estimation software\n- \"The Pharmaceutical Industry in Figures Key Data 2021\" (PDF). European Federation of Pharmaceutical Industries and Associations. Retrieved 28 June 2022.\n- Kubie, Elmer C. (Summer 1994). \"Recollections of the first software company\". Annals of the History of Computing. 16 (2). IEEE Computer Society: 65–71. doi:10.1109/85.279238. S2CID 5733812.\n- Campbell-Kelly, Martin (2003). From Airline Reservations to Sonic the Hedgehog: A History of the Software Industry. Cambridge, Massachusetts: MIT Press. p. 57. ISBN 978-0-262-03303-9.\n- Fishman, Katharine Davis (1981). The Computer Establishment (paperback 1982). New York: McGraw-Hill Book Company. p. 268.\n- \"Gartner Forecasts Worldwide IT Spending to Grow 7.5% in 2024\". Gartner. 2024-07-16. Retrieved 2024-12-14.\n- \"Software Products Global Market Report 2021: COVID-19 Impact and Recovery to 2030\". ResearchAndMarkets.com. September 9, 2021. Retrieved June 28, 2022.\n- \"M&A by Industries - Institute for Mergers, Acquisitions and Alliances (IMAA)\". Institute for Mergers, Acquisitions and Alliances (IMAA). Retrieved 2018-02-28.\n- Popp, Karl Michael (2013). Mergers and Acquisitions in the Software Industry - foundations of due diligence. Norderstedt: Books on demand. ISBN 978-3-7322-4381-5.\n- Karl M. Popp and Ralf Meyer (2010). Profit from Software Ecosystems: Business Models, Ecosystems and Partnerships in the Software Industry. Norderstedt, Germany: BOD. ISBN 978-3-8391-6983-4.\n- Cusumano M. (2003) Finding Your balance in the Products and Service Debate, Communications of the ACM. Vol. 46:3\n- Software Ecosystem: Understanding an Indispensable Technology and Industry. Cambridge, MA: MIT Press. 2003. ISBN 0-262-13432-2.\n- \"Software Industry\". Words to Avoid (or Use with Care) Because They Are Loaded or Confusing. Free Software Foundation. 2012-11-20. Retrieved 2013-01-31.",
    "streaming media": "| E-commerce |\n|---|\n| Digital content |\n| Retail goods and services |\n| Online shopping |\n| Mobile commerce |\n| Customer service |\n| E-procurement |\n| Purchase-to-pay |\n| Super-apps |\nStreaming media is multimedia delivered through a network for playback using a media player. Media is transferred in a stream of packets from a server to a client and is rendered in real-time or near real-time;[1] this contrasts with file downloading, a process in which the end-user obtains an entire media file before consuming the content. Streaming is more commonly used for video on demand, streaming television, and music streaming services over the Internet.\nWhile streaming is most commonly associated with multimedia from a remote server over the Internet, it also includes offline multimedia between devices on a local area network. For example, using DLNA[2] and a home server, or in a personal area network between two devices using Bluetooth (which uses radio waves rather than IP).[3] Online streaming was initially popularized by RealNetworks and Microsoft in the 1990s[4] and has since grown to become the globally most popular method for consuming music and videos,[5] with numerous competing subscription services being offered since the 2010s.[6] Audio streaming to wireless speakers, often using Bluetooth, is another use that has become prevalent during that decade.[7] Live streaming is the real-time delivery of content during production, much as live television broadcasts content via television channels.[8]\nDistinguishing delivery methods from the media applies specifically to, as most of the traditional media delivery systems are either inherently streaming (e.g., radio, television) or inherently non-streaming (e.g., books, videotapes, audio CDs). The term \"streaming media\" can apply to media other than video and audio, such as live closed captioning, ticker tape, and real-time text, which are all considered \"streaming text\".\nThe term \"streaming\" was first used for tape drives manufactured by Data Electronics Inc. that were meant to slowly ramp up and run for the entire track; slower ramp times lowered drive costs. \"Streaming\" was applied in the early 1990s as a better description for video on demand and later live video on IP networks. It was first done by Starlight Networks for video streaming and Real Networks for audio streaming. Such video had previously been referred to by the misnomer \"store and forward video.\"[9]\nBeginning in 1881, Théâtrophone enabled subscribers to listen to opera and theatre performances over telephone lines. This operated until 1932. The concept of media streaming eventually came to America.[10]\nIn the early 1920s, George Owen Squier was granted patents for a system for the transmission and distribution of signals over electrical lines,[11] which was the technical basis for what later became Muzak, a technology for streaming continuous music to commercial customers without the use of radio.\nThe Telephone Music Service, a live jukebox service, began in 1929 and continued until 1997.[12][13] The clientele eventually included 120 bars and restaurants in the Pittsburgh area. A tavern customer would deposit money in the jukebox, use a telephone on top of the jukebox, and ask the operator to play a song. The operator would find the record in the studio library of more than 100,000 records, put it on a turntable, and the music would be piped over the telephone line to play in the tavern. The music media began as 78s, 33s and 45s, played on the six turntables they monitored. CDs and tapes were incorporated in later years.\nThe business had a succession of owners, notably Bill Purse, his daughter Helen Reutzel, and finally Dotti White. The revenue stream for each quarter was split between 60% for the music service and 40% for the tavern owner.[14] This business model eventually became unsustainable due to city permits and the cost of setting up these telephone lines.[13]\nAttempts to display media on computers date back to the earliest days of computing in the mid-20th century. However, little progress was made for several decades, primarily due to the high cost and limited capabilities of computer hardware. From the late 1980s through the 1990s, consumer-grade personal computers became powerful enough to display various media. The primary technical issues related to streaming were having enough CPU and bus bandwidth to support the required data rates and achieving the real-time computing performance required to prevent buffer underruns and enable smooth streaming of the content. However, computer networks were still limited in the mid-1990s, and audio and video media were usually delivered over non-streaming channels, such as playback from a local hard disk drive or CD-ROMs on the end user's computer.\nTerminology in the 1970s was at best confusing for applications such as telemetered aircraft or missile test data. By then PCM [Pulse Code Modulation] was the dominant transmission type. This PCM transmission was bit-serial and not packetized so the 'streaming' terminology was often a confusion factor. In 1969 Grumman acquired one of the first telemetry ground stations [Automated Telemetry Station, 'ATS'] which had the capability for reconstructing serial telemetered data which had been recorded on digital computer peripheral tapes. Computer peripheral tapes were inherently recorded in blocks. Reconstruction was required for continuous display purposes without time-base distortion. The Navy implemented similar capability in DoD for the first time in 1973. These implementations are the only known examples of true 'streaming' in the sense of reconstructing distortion-free serial data from packetized or blocked recordings.[15] 'Real-time' terminology has also been confusing in streaming context. The most accepted definition of 'real-time' requires that all associated processing or formatting of the data must take place prior to availability of the next sample of each measurement. In the 1970s the most powerful mainframe computers were not fast enough for this task at significant overall data rates in the range of 50,000 samples per second. For that reason both the Grumman ATS and the Navy Real-time Telemetry Processing System [RTPS] employed unique special purpose digital computers dedicated to real-time processing of raw data samples.\nIn 1990, the first commercial Ethernet switch was introduced by Kalpana, which enabled the more powerful computer networks that led to the first streaming video solutions used by schools and corporations.\nPractical streaming media was only made possible with advances in data compression due to the impractically high bandwidth requirements of uncompressed media. Raw digital audio encoded with pulse-code modulation (PCM) requires a bandwidth of 1.4 Mbit/s for uncompressed CD audio, while raw digital video requires a bandwidth of 168 Mbit/s for SD video and over 1000 Mbit/s for FHD video.[16]\nDuring the late 1990s and early 2000s, users had increased access to computer networks, especially the Internet. During the early 2000s, users had access to increased network bandwidth, especially in the last mile. These technological improvements facilitated the streaming of audio and video content to computer users in their homes and workplaces. There was also an increasing use of standard protocols and formats, such as TCP/IP, HTTP, and HTML, as the Internet became increasingly commercialized, which led to an infusion of investment into the sector.\nThe band Severe Tire Damage was the first group to perform live on the Internet. On 24 June 1993, the band was playing a gig at Xerox PARC, while elsewhere in the building, scientists were discussing new technology (the Mbone) for broadcasting on the Internet using multicasting. As proof of PARC's technology, the band's performance was broadcast and could be seen live in Australia and elsewhere. In a March 2017 interview, band member Russ Haines stated that the band had used approximately \"half of the total bandwidth of the internet\" to stream the performance, which was a 152 × 76 pixel video, updated eight to twelve times per second, with audio quality that was, \"at best, a bad telephone connection.\"[17] In October 1994, a school music festival was webcast from the Michael Fowler Centre in Wellington, New Zealand. The technician who arranged the webcast, local council employee Richard Naylor, later commented: \"We had 16 viewers in 12 countries.\"[18]\nRealNetworks pioneered the broadcast of a baseball game between the New York Yankees and the Seattle Mariners over the Internet in 1995.[19] The first symphonic concert on the Internet—a collaboration between the Seattle Symphony and guest musicians Slash, Matt Cameron, and Barrett Martin—took place at the Paramount Theater in Seattle, Washington, on 10 November 1995.[20]\nIn 1996, Marc Scarpa produced the first large-scale, online, live broadcast, the Adam Yauch–led Tibetan Freedom Concert, an event that would define the format of social change broadcasts. Scarpa continued to pioneer in the streaming media world with projects such as Woodstock '99, Townhall with President Clinton, and more recently Covered CA's campaign \"Tell a Friend Get Covered\", which was livestreamed on YouTube.\nXing Technology was founded in 1989 and developed a JPEG streaming product called \"StreamWorks\". Another streaming product appeared in late 1992 and was named StarWorks.[21] StarWorks enabled on-demand MPEG-1 full-motion videos to be randomly accessed on corporate Ethernet networks. Starworks was from Starlight Networks, which also pioneered live video streaming on Ethernet and via Internet Protocol over satellites with Hughes Network Systems.[22] Other early companies that created streaming media technology include Progressive Networks and Protocomm prior to widespread World Wide Web usage. After the Netscape IPO in 1995 (and the release of Windows 95 with built-in TCP/IP support), usage of the Internet expanded, and many companies \"went public\", including Progressive Networks (which was renamed \"RealNetworks\", and listed on Nasdaq as \"RNWK\"). As the web became even more popular in the late 90s, streaming video on the internet blossomed from startups such as Vivo Software (later acquired by RealNetworks), VDOnet (acquired by RealNetworks), Precept (acquired by Cisco), and Xing (acquired by RealNetworks).[23]\nMicrosoft developed a media player known as ActiveMovie in 1995 that supported streaming media and included a proprietary streaming format, which was the precursor to the streaming feature later in Windows Media Player 6.4 in 1999. In June 1999, Apple also introduced a streaming media format in its QuickTime 4 application. It was later also widely adopted on websites, along with RealPlayer and Windows Media streaming formats. The competing formats on websites required each user to download the respective applications for streaming, which resulted in many users having to have all three applications on their computer for general compatibility.\nIn 2000, Industryview.com launched its \"world's largest streaming video archive\" website to help businesses promote themselves.[24] Webcasting became an emerging tool for business marketing and advertising that combined the immersive nature of television with the interactivity of the Web. The ability to collect data and feedback from potential customers caused this technology to gain momentum quickly.[25]\nAround 2002, the interest in a single, unified, streaming format and the widespread adoption of Adobe Flash prompted the development of a video streaming format through Flash, which was the format used in Flash-based players on video hosting sites. The first popular video streaming site, YouTube, was founded by Steve Chen, Chad Hurley, and Jawed Karim in 2005. It initially used a Flash-based player, which played MPEG-4 AVC video and AAC audio, but now defaults to HTML video.[26] Increasing consumer demand for live streaming prompted YouTube to implement a new live streaming service for users.[27] The company currently also offers a (secure) link that returns the available connection speed of the user.[28]\nThe Recording Industry Association of America (RIAA) revealed through its 2015, earnings report that streaming services were responsible for 34.3 percent of the year's total music industry's revenue, growing 29 percent from the previous year and becoming the largest source of income, pulling in around $2.4 billion.[29][30] US streaming revenue grew 57 percent to $1.6 billion in the first half of 2016 and accounted for almost half of industry sales.[31]\n| History of television in the United States |\n|---|\n| Eras |\n|\n| Histories |\nThe term streaming wars was coined to describe the new era (starting in the late 2010s) of competition between video streaming services such as Netflix, Amazon Prime Video, Hulu, HBO Max, Disney+, Paramount+, Apple TV+, Peacock, and many more.[6][32]\nThe competition between increasingly popular online platforms, such as Netflix and Amazon, and legacy broadcasters and studios moving online, like Disney and NBC, has driven each service to find ways to differentiate from one another. A key differentiator has been offering exclusive content, often self-produced and created for a specific market segment.\nWhen Netflix first launched in 2007, it became one of the more dominant streaming platforms even though it initially offered no original content. It would be nearly six years before Netflix began offering its own shows, such as House of Cards, Orange Is the New Black, and Hemlock Grove. The legacy services also began producing original digital-only content, but they also began restricting their back catalog of shows and movies to their platforms, one of the most notable examples being Disney+. Disney took advantage of owning popular movies and shows like Frozen, Snow White, and the Star Wars and Marvel franchises, which could draw in more subscribers and make it a more serious competitor to Netflix and Amazon.[33] Research suggests that this approach to streaming competition can be disadvantageous for consumers by increasing spending across platforms, and for the industry as a whole by dilution of subscriber base. Once specific content is made available on a streaming service, piracy searches for the same content decrease; competition or legal availability across multiple platforms appears to deter online piracy. Exclusive content produced for subscription services such as Netflix tends to have a higher production budget than content produced exclusively for pay-per-view services, such as Amazon Prime Video.[34]\nThis competition increased during the first two years of the COVID-19 pandemic as more people stayed home and watched TV. \"The COVID-19 pandemic has led to a seismic shift in the film & TV industry in terms of how films are made, distributed, and screened. Many industries have been hit by the economic effects of the pandemic\" (Totaro Donato).[9] In August 2022, a CNN headline declared that \"The streaming wars are over\" as pandemic-era restrictions had largely ended and audience growth had stalled. This led services to focus on profit over market share by cutting production budgets, cracking down on password sharing, and introducing ad-supported tiers.[35] A December 2022 article in The Verge echoed this, declaring an end to the \"golden age of the streaming wars\".[36]\nIn September 2023, several streaming services formed a trade association named the Streaming Innovation Alliance (SIA), spearheaded by Charles Rivkin of the Motion Picture Association (MPA). Former U.S. representative Fred Upton and former Federal Communications Commission (FCC) acting chair Mignon Clyburn serve as senior advisors. Founding members include AfroLandTV, America Nu Network, BET+, The Africa Channel, Discovery+, FedNet, For Us By Us Network, In the Black Network, Max, Motion Picture Association, MotorTrend+, Netflix, Paramount+, Peacock, Pluto TV, Radiant, SkinsPlex, Telemundo, TelevisaUnivision, TVEI, Vault TV, Vix, and The Walt Disney Company. Notably absent were Apple, Amazon, Roku, and Tubi.[37][38]\nAdvances in computer networking, combined with powerful home computers and operating systems, have made streaming media affordable and easy for the public. Stand-alone Internet radio devices emerged to offer listeners a non-technical option for listening to audio streams. These audio-streaming services became increasingly popular; music streaming reached 4 trillion streams globally in 2023—a significant increase from 2022—jumping 34% over the year.[39]\nIn general, multimedia content is data-intensive, so media storage and transmission costs are still significant. Media is generally compressed for transport and storage. Increasing consumer demand for streaming high-definition (HD) content has led the industry to develop technologies such as WirelessHD and G.hn, which are optimized for streaming HD content. Many developers have introduced HD streaming apps that work on smaller devices, such as tablets and smartphones, for everyday purposes.\n\"Streaming creates the illusion—greatly magnified by headphone use, which is another matter—that music is a utility you can turn on and off; the water metaphor is intrinsic to how it works. It dematerializes music, denies it a crucial measure of autonomy, reality, and power. It makes music seem disposable, impermanent. Hence it intensifies the ebb and flow of pop fashion, the way musical 'memes' rise up for a week or a month and are then forgotten. And it renders our experience of individual artists/groups shallower.\"\nA media stream can be streamed either live or on demand. Live streams are generally provided by a method called true streaming. True streaming sends the information straight to the computer or device without saving it to a local file. On-demand streaming is provided by a method called progressive download. Progressive download saves the received information to a local file and then plays it from that location. On-demand streams are often saved to files for extended period of time, while live streams are available at one time only (e.g., during a football game).[41]\nStreaming media is increasingly being coupled with the use of social media. For example, sites such as YouTube encourage social interaction in webcasts through features such as live chat, online surveys, user posting of comments online, and more. Furthermore, streaming media is increasingly being used for social business and e-learning.[42]\nThe Horowitz Research State of Pay TV, OTT, and SVOD 2017 report said that 70 percent of those viewing content did so through a streaming service and that 40 percent of TV viewing was done this way, twice the number from five years earlier. Millennials, the report said, streamed 60 percent of the content.[43]\nOne of the movie streaming industry's largest impacts was on the DVD industry, which drastically dropped in popularity and profitability with the mass popularization of online content.[44] The rise of media streaming caused the downfall of many DVD rental companies, such as Blockbuster. In July 2015, The New York Times published an article about Netflix's DVD services. It stated that Netflix was continuing their DVD services with 5.3 million subscribers, which was a significant drop from the previous year. On the other hand, their streaming service had 65 million members.[45] The shift to streaming platforms also led to the decline of DVD rental services. In July 2024, NBC News reported that RedBox, a DVD rental service that had operated for 22 years, would shut down due to the rapid incline of streaming platforms. As the rental services has been rapidly declining since 2010, the business had to file for bankruptcy, with 99% of households now subscribing to streaming services. Further reflecting the shift away from physical media, BestBuy has ceased selling DVDs.[46]\nMusic streaming is one of the most popular ways in which consumers interact with streaming media. In the age of digitization, the private consumption of music has transformed into a public good, largely due to one player in the market: Napster.\nNapster, a peer-to-peer (P2P) file-sharing network where users could upload and download MP3 files freely, broke all music industry conventions when it launched in early 1999 in Hull, Massachusetts. The platform was developed by Shawn and John Fanning as well as Sean Parker.[47] In an interview from 2009, Shawn Fanning explained that Napster \"was something that came to me as a result of seeing a sort of unmet need and the passion people had for being able to find all this music, particularly a lot of the obscure stuff, which wouldn't be something you go to a record store and purchase, so it felt like a problem worth solving.\"[48]\nNot only did this development disrupt the music industry by making songs that previously required payment to be freely accessible to any Napster user, but it also demonstrated the power of P2P networks in turning any digital file into a public, shareable good. For the brief period of time that Napster existed, mp3 files fundamentally changed as a type of good. Songs were no longer financially excludable, barring access to a computer with internet access, and they were not rivals, meaning if one person downloaded a song, it did not diminish another user from doing the same. Napster, like most other providers of public goods, faced the free-rider problem. Every user benefits when an individual uploads an mp3 file, but there is no requirement or mechanism that forces all users to share their music. Generally, the platform encouraged sharing; users who downloaded files from others often had their own files available for upload as well. However, not everyone chose to share their files. There was no a built-in incentive specifically discouraging users from sharing their own files.[49]\nThis structure revolutionized the consumer's perception of ownership over digital goods; it made music freely replicable. Napster quickly garnered millions of users, growing faster than any other business in history. At the peak of its existence, Napster boasted about 80 million users globally. The site gained so much traffic that many college campuses had to block access to Napster because it created network congestion from so many students sharing music files.[50]\nThe advent of Napster sparked the creation of numerous other P2P sites, including LimeWire (2000), BitTorrent (2001), and the Pirate Bay (2003). The reign of P2P networks was short-lived. The first to fall was Napster in 2001. Numerous lawsuits were filed against Napster by various record labels, all of which were subsidiaries of Universal Music Group, Sony Music Entertainment, Warner Music Group, or EMI. In addition to this, the Recording Industry Association of America (RIAA) also filed a lawsuit against Napster on the grounds of unauthorized distribution of copyrighted material, which ultimately led Napster to shut down in 2001.[50] In an interview with the New York Times, Gary Stiffelman, who represents Eminem, Aerosmith, and TLC, explained, \"I'm not an opponent of artists' music being included in these services, I'm just an opponent of their revenue not being shared.\"[51]\nThe lawsuit A&M Records, Inc. v. Napster, Inc. fundamentally changed the way consumers interact with music streaming. It was argued on 2 October 2000, and was decided on 12 February 2001. The Court of Appeals for the Ninth Circuit ruled that a P2P file-sharing service could be held liable for contributory and vicarious infringement of copyright, serving as a landmark decision for Intellectual property law.[52]\nThe first issue that the Court addressed was fair use, which says that otherwise infringing activities are permissible so long as they are for purposes \"such as criticism, comment, news reporting, teaching [...] scholarship, or research.\"[53] Judge Beezer, the judge for this case, noted that Napster claimed that its services fit \"three specific alleged fair uses: sampling, where users make temporary copies of a work before purchasing; space-shifting, where users access a sound recording through the Napster system that they already own in audio CD format; and permissive distribution of recordings by both new and established artists.\"[53] Judge Beezer found that Napster did not fit these criteria, instead enabling their users to repeatedly copy music, which would affect the market value of the copyrighted good.\nThe second claim by the plaintiffs was that Napster was actively contributing to copyright infringement since it had knowledge of widespread file sharing on its platform. Since Napster took no action to reduce infringement and financially benefited from repeated use, the court ruled against the P2P site. The court found that \"as much as eighty-seven percent of the files available on Napster may be copyrighted and more than seventy percent may be owned or administered by plaintiffs.\"[53]\nThe injunction ordered against Napster ended the brief period in which music streaming was a public good – non-rival and non-excludable in nature. Other P2P networks had some success at sharing MP3s, though they all met a similar fate in court. The ruling set the precedent that copyrighted digital content cannot be freely replicated and shared unless given consent by the owner, thereby strengthening the property rights of artists and record labels alike.[52]\nAlthough music streaming is no longer a freely replicable public good, streaming platforms such as Spotify, Deezer, Apple Music, SoundCloud, YouTube Music, and Amazon Music have shifted music streaming to a club-type good. While some platforms, most notably Spotify, give customers access to a freemium service that enables the use of limited features for exposure to advertisements, most companies operate under a premium subscription model.[55] Under such circumstances, music streaming is financially excludable, requiring that customers pay a monthly fee for access to a music library, but non-rival, since one customer's use does not impair another's.\nAn article written by the New York Times in 2021 states that \"streaming saved music.\" This is because it provided monthly revenue. Especially Spotify offers its free platform, but you can pay for their premium to get music ad-free.[56] This allows access for people to stream music anywhere from their devices not having to rely on CDs anymore.\nThere is competition between services similar but lesser to the streaming wars for video media. As of 2019[update], Spotify has over 207 million users in 78 countries,[57] As of 2018[update], Apple Music has about 60 million, and SoundCloud has 175 million.[58] All platforms provide varying degrees of accessibility. Apple Music and Prime Music only offer their services for paid subscribers, whereas Spotify and SoundCloud offer freemium and premium services. Napster, owned by Rhapsody since 2011, has resurfaced as a music streaming platform offering subscription-based services to over 4.5 million users as of January 2017[update].[59]\nIn the evolving music streaming landscape, competition among platforms is shaped by various factors, including royalty rates, exclusive content, and market expansion strategies. A notable development occurred in January 2025, when Universal Music Group (UMG) and Spotify announced a new multi-year agreement. This partnership aims to enhance opportunities for artists and consumers through innovative subscription tiers and an enriched audio-visual catalog.[60]\nThe music industry's response to music streaming was initially negative. Along with music piracy, streaming services disrupted the market and contributed to the fall in US revenue from $14.6 billion in 1999 to $6.3 billion in 2009. CDs and single-track downloads were not selling because content was freely available on the Internet. By 2018, however, music streaming revenue exceeded that of traditional revenue streams (e.g. record sales, album sales, downloads).[61] Streaming revenue is now one of the largest driving forces behind the growth in the music industry.\nBy August 2020, the COVID-19 pandemic had streaming services busier than ever. The pandemic contributed to a surge in subscriptions, in the UK alone, 12 million people joined a new streaming service that they had not previously had.[63] Global subscriptions skyrocketed passing 1 billion.[64] Within the first 3 months, back in 2020, nearly 15.7 million people signed up for Netflix.[65]\nAn impact analysis of 2020 data by the International Confederation of Societies of Authors and Composers (CISAC) indicated that remuneration from digital streaming of music increased with a strong rise in digital royalty collection (up 16.6% to EUR 2.4 billion), but it would not compensate the overall loss of income of authors from concerts, public performance and broadcast.[66] The International Federation of the Phonographic Industry (IFPI) recompiled the music industry initiatives around the world related to the COVID-19. In its State of the Industry report, it recorded that the global recorded music market grew by 7.4% in 2022, the 6th consecutive year of growth. This growth was driven by streaming, mostly from paid subscription streaming revenues which increased by 18.5%, fueled by 443 million users of subscription accounts by the end of 2020.[67]\nThe COVID-19 pandemic has also driven an increase in misinformation and disinformation, particularly on streaming platforms like YouTube and podcasts.[68]\nStreaming also refers to the offline streaming of multimedia at home. This is made possible by technologies such as DLNA, which allow devices on the same local network to connect to each other and share media.[69][70] Such capabilities are heightened using network-attached storage (NAS) devices at home, or using specialized software like Plex Media Server, Jellyfin or TwonkyMedia.[71]\nA broadband speed of 2 Mbit/s or more is recommended for streaming standard-definition video,[72] for example to a Roku, Apple TV, Google TV or a Sony TV Blu-ray Disc Player. 5 Mbit/s is recommended for high-definition content and 25 Mbit/s for ultra-high-definition content.[73] Streaming media storage size is calculated from the streaming bandwidth and length of the media using the following formula (for a single user and file): storage size in megabytes is equal to length (in seconds) × bit rate (in bit/s) / (8 × 1024 × 1024). For example, one hour of digital video encoded at 300 kbit/s (this was a typical broadband video in 2005 and it was usually encoded in 320 × 240 resolution) will be: (3,600 s × 300,000 bit/s) / (8 × 1024 × 1024) requires around 128 MB of storage.\nIf the file is stored on a server for on-demand streaming and this stream is viewed by 1,000 people at the same time using a Unicast protocol, the requirement is 300 kbit/s × 1,000 = 300,000 kbit/s = 300 Mbit/s of bandwidth. This is equivalent to around 135 GB per hour. Using a multicast protocol the server sends out only a single stream that is common to all users. Therefore, such a stream would only use 300 kbit/s of server bandwidth.\nIn 2018 video was more than 60% of data traffic worldwide and accounted for 80% of growth in data usage.[74][75]\nVideo and audio streams are compressed to make the file size smaller. Audio coding formats include MP3, Vorbis, AAC and Opus. Video coding formats include H.264, HEVC, VP8, VP9 and AV1. Encoded audio and video streams are assembled in a container bitstream such as MP4, FLV, WebM, ASF or ISMA. The bitstream is delivered from a streaming server to a streaming client (e.g., the computer user with their Internet-connected laptop) using a transport protocol, such as Adobe's RTMP or RTP.\nIn the 2010s, technologies such as Apple's HLS, Microsoft's Smooth Streaming, Adobe's HDS and non-proprietary formats such as MPEG-DASH emerged to enable adaptive bitrate streaming over HTTP as an alternative to using proprietary transport protocols. Often, a streaming transport protocol is used to send video from an event venue to a cloud transcoding service and content delivery network, which then uses HTTP-based transport protocols to distribute the video to individual homes and users.[76] The streaming client (the end user) may interact with the streaming server using a control protocol, such as MMS or RTSP.\nThe quality of the interaction between servers and users is based on the workload of the streaming service; as more users attempt to access a service the quality may be affected by resource constraints in the service.[77] Deploying clusters of streaming servers is one such method where there are regional servers spread across the network, managed by a singular, central server containing copies of all the media files as well as the IP addresses of the regional servers. This central server then uses load balancing and scheduling algorithms to redirect users to nearby regional servers capable of accommodating them. This approach also allows the central server to provide streaming data to both users as well as regional servers using FFmpeg libraries if required, thus demanding the central server to have powerful data processing and immense storage capabilities. In return, workloads on the streaming backbone network are balanced and alleviated, allowing for optimal streaming quality.[78][needs update]\nDesigning a network protocol to support streaming media raises many problems. Datagram protocols, such as the User Datagram Protocol (UDP), send the media stream as a series of small packets. This is simple and efficient; however, there is no mechanism within the protocol to guarantee delivery. It is up to the receiving application to detect loss or corruption and recover data using error correction techniques. If data is lost, the stream may suffer a dropout. The Real-Time Streaming Protocol (RTSP), Real-time Transport Protocol (RTP) and the Real-time Transport Control Protocol (RTCP) were specifically designed to stream media over networks. RTSP runs over a variety of transport protocols,[79] while the latter two are built on top of UDP.\nHTTP adaptive bitrate streaming is based on HTTP progressive download, but contrary to the previous approach, here the files are very small, so that they can be compared to the streaming of packets, much like the case of using RTSP and RTP.[80] Reliable protocols, such as the Transmission Control Protocol (TCP), guarantee correct delivery of each bit in the media stream. It means, however, that when there is data loss on the network, the media stream stalls while the protocol handlers detect the loss and retransmit the missing data. Clients can minimize this effect by buffering data for display. While delay due to buffering is acceptable in video-on-demand scenarios, users of interactive applications such as video conferencing will experience a loss of fidelity if the delay caused by buffering exceeds 200 ms.[81]\nUnicast protocols send a separate copy of the media stream from the server to each recipient. Unicast is the norm for most Internet connections but does not scale well when many users want to view the same television program concurrently. Multicast protocols were developed to reduce server and network loads resulting from duplicate data streams that occur when many recipients receive unicast content streams independently. These protocols send a single stream from the source to a group of recipients. Depending on the network infrastructure and type, multicast transmission may or may not be feasible. One potential disadvantage of multicasting is the loss of video on demand functionality. Continuous streaming of radio or television material usually precludes the recipient's ability to control playback. However, this problem can be mitigated by elements such as caching servers, digital set-top boxes, and buffered media players.\nIP multicast provides a means to send a single media stream to a group of recipients on a computer network. A connection management protocol, usually Internet Group Management Protocol, is used to manage the delivery of multicast streams to the groups of recipients on a LAN. One of the challenges in deploying IP multicast is that routers and firewalls between LANs must allow the passage of packets destined to multicast groups. If the organization that is serving the content has control over the network between server and recipients (i.e., educational, government, and corporate intranets), then routing protocols such as Protocol Independent Multicast can be used to deliver stream content to multiple local area network segments.\nPeer-to-peer (P2P) protocols arrange for prerecorded streams to be sent between computers. This prevents the server and its network connections from becoming a bottleneck. However, it raises technical, performance, security, quality, and business issues.\nContent delivery networks (CDNs) use intermediate servers to distribute the load. Internet-compatible unicast delivery is used between CDN nodes and streaming destinations.\nMedia that is livestreamed can be recorded through certain media players, such as VLC player, or through the use of a screen recorder. Live-streaming platforms such as Twitch may also incorporate a video on demand system that allows automatic recording of live broadcasts so that they can be watched later.[82] YouTube also has recordings of live broadcasts, including television shows aired on major networks. These streams have the potential to be recorded by anyone who has access to them, whether legally or otherwise.[83]\nRecordings can happen through any device that allows people to watch movies they do not have access to or be at a music festival they could not get tickets to. These live streaming platforms have revolutionized entertainment, creating new ways for people to interact with content. Many celebrities started live streaming during COVID-19 through platforms like Instagram, YouTube, and TikTok offering an alternate form of entertainment when concerts were postponed. Live streaming and recording allow for fans to communicate with these artists through chats and likes.\nMost streaming services feature a recommender system for viewing based on each user's view history in conjunction with all viewers' aggregated view histories. Rather than focusing on subjective categorization of content by content curators, there is an assumption that, with the immensity of data collected on viewing habits, the choices of those who are first to view content can be algorithmically extrapolated to the totality of the user base, with increasing probabilistic accuracy as to the likelihood of their choosing and enjoying the recommended content as more data is collected.[84]\nUseful and typical applications of streaming are, for example, long video lectures performed online.[85] An advantage of this presentation is that these lectures can be very long, although they can always be interrupted or repeated at arbitrary places. Streaming enables new content marketing concepts. For example, the Berlin Philharmonic Orchestra sells Internet live streams of whole concerts instead of several CDs or similar fixed media in their Digital Concert Hall[86] using YouTube for trailers. These online concerts are also spread over a lot of different places, including cinemas at various places on the globe. A similar concept is used by the Metropolitan Opera in New York. There is also a livestream from the International Space Station.[87][88] In video entertainment, video streaming platforms like Netflix, Hulu, and Disney+ are mainstream elements of the media industry.[89]\nMarketers have found many opportunities offered by streaming media and the platforms that offer them, especially in light of the significant increase in the use of streaming media during COVID lockdowns from 2020 onwards. While revenue and placement of traditional advertising continued to decrease, digital marketing increased by 15% in 2021,[90] with digital media and search representing 65% of the expenditures.\nA case study commissioned by the WIPO[91] indicates that streaming services attract advertising budgets with the opportunities provided by interactivity and the use of data from users, resulting in personalization on a mass scale with content marketing.[92] Targeted marketing is expanding with the use of artificial intelligence, in particular programmatic advertisement, a tool that helps advertisers decide their campaign parameters and whether they are interested in buying advertising space online or not. One example of advertising space acquisition is Real-Time Bidding (RTB).[93]\nFor over-the-top media service (OTT) platforms, the original content captures additional subscribers.[94] This presents copyright issues and the potential for international exploitation through streaming,[95] widespread use of standards, and metadata in digital files.[96] The WIPO has indicated several basic copyright issues arising for those pursuing work in the film[97] and music industries[98] in the era of streaming.\nStreaming copyrighted content can involve making infringing copies of the works in question. The recording and distribution of streamed content is also an issue for many companies that rely on revenue based on views or attendance.[99]\nThe net greenhouse gas emissions from streaming music were estimated at between 0.2 and 0.35 million metric tons CO2eq (between 200,000 and 340,000 long tons; 220,000 and 390,000 short tons) per year in the United States, by a 2019 study.[100] This was an increase from emissions in the pre-digital music period, which were estimated at \"0.14 million metric tons (140,000 long tons; 150,000 short tons) in 1977, 0.136 million (134,000 long tons; 150,000 short tons) in 1988, and 0.157 million (155,000 long tons; 173,000 short tons) in 2000.\"[101] However, this is far less than other everyday activities such as eating. For example greenhouse gas emissions in the United States from beef cattle (burping of ruminants only - not including their manure) were 129 million metric tons (127 million long tons; 142 million short tons) in 2019.[102]\nA 2021 study claimed that, based on the amount of data transmitted, one hour of streaming or videoconferencing \"emits 150–1,000 grams (5–35 oz) of carbon dioxide ... requires 2–12 liters (0.4–2.6 imp gal; 0.5–3.2 U.S. gal) of water and demands a land area adding up to about the size of an iPad Mini.\" The study suggests that turning the camera off during video calls can reduce the greenhouse gas and water use footprints by 96%, and that an 86% reduction is possible by using standard definition rather than high definition when streaming content with apps such as Netflix or Hulu.[103][104] However, another study estimated a relatively low amount of 36 grams per hour (1.3 ounces per hour), and concluded that watching a Netflix video for half an hour emitted only the same amount as driving a gasoline-fuelled car for about 100 meters (330 ft), so not a significant amount.[105]\nOne way to decrease greenhouse gas emissions associated with streaming music is to make data centers carbon neutral by converting to electricity produced from renewable sources. On an individual level, the purchase of a physical CD may be more environmentally friendly if it is to be played more than 27 times.[106][dubious – discuss] Another option for reducing energy use is downloading the music for offline listening to reduce the need for streaming over distance.[106] The Spotify service has a built-in local cache to reduce the necessity of repeating song streams.[107]\n- Comparison of music streaming services\n- Comparison of streaming media software\n- Comparison of video hosting services\n- Content delivery platform\n- Digital television\n- Directive on Copyright in the Digital Single Market\n- Internet Protocol television\n- Geo-blocking\n- List of streaming media services\n- List of streaming media systems\n- M3U playlists\n- National Streaming Day\n- Over-the-top media service\n- P2PTV\n- Protection of Broadcasts and Broadcasting Organizations Treaty\n- Smart TV\n- Stream ripping\n- Video over cellular\n- Patrikakis, Charalampos; Papaoulakis, Nikos; Stefanoudaki, Chryssanthi; Nunes, Mário (2010), Daras, Petros; Ibarra, Oscar Mayora (eds.), \"Streaming Content Wars: Download and Play Strikes Back\", User Centric Media, vol. 40, Berlin, Heidelberg: Springer Berlin Heidelberg, pp. 218–226, doi:10.1007/978-3-642-12630-7_26, ISBN 978-3-642-12629-1, retrieved 5 May 2024\n- \"DLNA Network Guide\" (PDF). Retrieved 21 August 2024.\n- Fayyoumi, Ebaa; Idwan, Sahar; Muhared, Hiba; Matar, Izzeddin; Rawashdeh, Obaidah (November 2014). \"L2CAP-based prototype media streaming via Bluetooth technology\". International Journal of Networking and Virtual Organisations. 14 (3): 221. doi:10.1504/IJNVO.2014.065785.\n- The history of streaming media - PC Plus (PDF). 2012.\n- \"Music consumption at all time high powered by streaming and video apps | Complete Music Update\". Retrieved 5 May 2024.\n- \"Streaming Wars\". The Verge. Archived from the original on 6 December 2019. Retrieved 1 December 2019.\n- Bonnington, Christina (12 April 2018). \"Even Ikea Has a Connected Speaker Now\". Slate. ISSN 1091-2339. Retrieved 5 May 2024.\n- \"What is live streaming?\". Cloudflare.\n- Gelman, A.D.; Halfin, S.; Willinger, W. (1991). \"On buffer requirements for store-and-forward video on demand service circuits\". IEEE Global Telecommunications Conference GLOBECOM '91: Countdown to the New Millennium. Conference Record. IEEE. pp. 976–980. doi:10.1109/GLOCOM.1991.188525. ISBN 0-87942-697-7. S2CID 61767197.\n- Reason, Samuel (6 November 2020). \"Music Streaming Actually Existed Back In 1890\". blitzlift.com. Archived from the original on 1 December 2020. Retrieved 27 December 2020.\n- US 1,641,608, \"Electrical signaling\"\n- Greene, Bob (8 February 1987). \"GETTING PERSONAL WITH THE JUKEBOX\". Chicago Tribune. Archived from the original on 8 November 2020. Retrieved 27 December 2020.\n- Furness, Zack (17 October 2019). \"Did You Know Music Streaming Has Roots in Pittsburgh?\". pittsburghmagazine.com. Archived from the original on 4 February 2021. Retrieved 27 December 2020.\n- Bradley-Steck, Tara (4 September 1988). \"Complex Link-Up of Phone Lines, Old Phonograph Records: 'Human Jukebox' Spins Sounds for the Heart\". Los Angeles Times. Archived from the original on 25 January 2021. Retrieved 27 December 2020.\n- IEEE Aero & AES Magazine, May 2022 ISSN 0885-8985, Vol 37, No.5 pp. 40\n- Lee, Jack (2005). Scalable Continuous Media Streaming Systems: Architecture, Design, Analysis and Implementation. John Wiley & Sons. p. 25. ISBN 978-0-470-85764-9.\n- \"History of the Internet Pt. 1 – The First Live Stream\" Archived 29 January 2019 at the Wayback Machine. Via YouTube. Internet Archive – Stream Division. 5 April 2017. Retrieved 13 January 2018.\n- Newman, Keith (2008). Connecting the Clouds: The Internet in New Zealand. Auckland: Activity Press. p. 90. ISBN 978-0-9582634-4-3.\n- \"RealNetworks Inc\". Funding Universe. Archived from the original on 11 July 2011. Retrieved 23 July 2011.\n- \"Cyberian Rhapsody\". Billboard. United States: Lynne Segall. 17 February 1996.\n- Tobagi, F.A.; Pang, J. (1993). \"StarWorks-a video applications server\". Digest of Papers. Compcon Spring. pp. 4–11. doi:10.1109/CMPCON.1993.289623. ISBN 0-8186-3400-6. S2CID 61039780.\n- \"Starlight Networks and Hughes Network Systems\". Archived from the original on 2 April 2019. Retrieved 10 May 2017.\n- Sullivan, Jennifer. \"Revived RealNetworks Buys Xing\". Wired. ISSN 1059-1028. Retrieved 5 October 2022.\n- Hebert, Steve (November 2000). \"Streaming Video Opens New Doors\". Videography. p. 164.\n- Reinstein, Bill (25 June 2001). \"Webcasts Mature as Marketing Tool\". DM News. p. 24.\n- \"YouTube now defaults to HTML5 <video>\". YouTube Engineering and Developers Blog. Archived from the original on 10 September 2018. Retrieved 20 February 2018.\n- Lowensohn, Josh (2008). \"YouTube to Offer Live Streaming This Year\". Archived from the original on 10 August 2011. Retrieved 23 July 2011.\n- \"YouTube Video Speed History\". Archived from the original on 26 April 2012. Retrieved 30 April 2012 – via YouTube.\n- \"News and Notes on 2015 RIAA Shipment and Revenue Statistics\" (PDF). Recording Industry Association of America. Archived (PDF) from the original on 6 June 2019. Retrieved 5 January 2017.\n- \"Streaming made more revenue for music industry in 2015 than digital downloads, physical sales\". The Washington Times. Archived from the original on 5 January 2017. Retrieved 5 January 2017.\n- Shaw, Lucas (20 September 2016). \"The Music Industry Is Finally Making Money on Streaming\". Bloomberg.com. Bloomberg L.P. Archived from the original on 22 May 2019. Retrieved 5 January 2017.\n- Chalaby, Jean K (2024). \"The streaming industry and the platform economy: An analysis\". Media, Culture & Society. 46 (3): 552–571. doi:10.1177/01634437231210439.\n- \"Why the Streaming Wars Will Change the TV Industry Forever | Paramount\". www.paramount.com. Retrieved 9 December 2024.\n- \"Streaming wars (Creative Economy Notes Series)\". wipo.int. Retrieved 29 December 2021.\n- Pallotta, Frank (11 August 2022). \"The streaming wars are over\". CNN. Archived from the original on 19 August 2022. Retrieved 19 August 2022.\n- Cranz, Alex (14 December 2022). \"The golden age of the streaming wars has ended\". The Verge. Archived from the original on 29 December 2022. Retrieved 29 December 2022.\n- Huston, Caitlin (26 September 2023). \"Netflix, Max, Disney and More Form Streaming Industry Trade Alliance\". The Hollywood Reporter. Archived from the original on 26 September 2023. Retrieved 26 September 2023.\n- Davis, Wes (26 September 2023). \"Streaming giants have banded together for lobbying power\". The Verge. Archived from the original on 26 September 2023. Retrieved 26 September 2023.\n- Sherman, Maria (10 January 2024). \"Music streams hit 4 trillion in 2023. Country and global acts — and Taylor Swift — fueled the growth\". AP News. Retrieved 21 November 2024.\n- Christgau, Robert (20 November 2018). \"Xgau Sez\". robertchristgau.com. Archived from the original on 26 July 2018. Retrieved 21 November 2018.\n- Grant and Meadows. (2009). Communication Technology Update and Fundamentals 11th Edition. pp.114\n- Kellner, Scott (28 February 2013). \"The Future of Webcasting\". INXPO. Archived from the original on 3 July 2013. Retrieved 15 May 2013.\n- Umstead, R. Thomas (5 June 2017). \"Horowitz: Streaming Is the New Normal\". Broadcasting & Cable: 4.\n- Durrani, Ana (27 March 2023). \"Top Streaming Statistics In 2024\". Forbes Home. Retrieved 28 September 2024.\n- Steel, Emily (26 July 2015). \"Netflix Refines Its DVD Business, Even as Streaming Unit Booms\". The New York Times. Archived from the original on 21 June 2017. Retrieved 4 November 2019.\n- \"Redbox set to close as DVD market withers in streaming's shadow\". NBC News. 11 July 2024. Retrieved 9 December 2024.\n- \"Ashes to ashes, peer to peer: An oral history of Napster\". Fortune. Archived from the original on 9 March 2019. Retrieved 11 March 2019.\n- Evangelista, Benny (31 May 2009). \"An interview with Napster's Shawn Fanning\". The Technology Chronicles. Archived from the original on 21 May 2021. Retrieved 11 March 2019.\n- \"The Ethics of Anonymous Computing: Napster\". cs.stanford.edu. Retrieved 21 September 2023.\n- Harris, Mark. \"The History of Napster: Yes, It's Still Around\". Lifewire. Archived from the original on 15 March 2019. Retrieved 11 March 2019.\n- Strauss, Neil (18 February 2002). \"Record Labels' Answer to Napster Still Has Artists Feeling Bypassed\". The New York Times. ISSN 0362-4331. Archived from the original on 23 March 2019. Retrieved 11 March 2019.\n- \"Case Study: A&M Records, Inc. v. Napster, Inc. – Blog | @WashULaw\". onlinelaw.wustl.edu. 1 August 2013. Archived from the original on 31 May 2020. Retrieved 11 March 2019.\n- \"A&M RECORDS, INC. v. NAPSTER, INC., 239 F.3d 1004 (9th Cir. 2001)\". law.cornell.edu. Archived from the original on 12 April 2019. Retrieved 11 March 2019.\n- \"Digital Media Association Annual Report\" (PDF). March 2018. Archived (PDF) from the original on 10 December 2018. Retrieved 11 March 2019.\n- \"Battle of the Streaming Services: Which Is the Best Premium Video Service?\". NDTV Gadgets 360. Archived from the original on 17 June 2022. Retrieved 11 May 2020.\n- Ovide, Shira (22 March 2021). \"Streaming Saved Music. Artists Hate It. (Published 2021)\". The New York Times. Retrieved 9 December 2024.\n- \"Decoding Artist Compensation: Streaming 2024\". 7 February 2024.\n- McIntyre, Hugh. \"The Top 10 Streaming Music Services By Number Of Users\". Forbes. Archived from the original on 8 November 2019. Retrieved 11 March 2019.\n- \"Napster Proves That Streaming Music Can Be Profitable\". Digital Music News. 22 August 2018. Archived from the original on 1 March 2020. Retrieved 11 March 2019.\n- Oganesyan, Natalie (26 January 2025). \"Spotify, Universal Music Group Strike Multi-Year Deal\". Deadline. Retrieved 27 January 2025.\n- \"Global Music Report 2018: Annual State of the Industry\" (PDF). GMR. 2017. Archived from the original (PDF) on 9 July 2020. Retrieved 12 March 2019.\n- Zhang, Christine; Barnes, Brooks (3 September 2025). \"Behind the Numbers: How Hollywood Missed Its Mark This Summer\". The New York Times. Archived from the original on 3 September 2025.\nSource: Box Office Mojo. Notes: Summer is the first Friday in May through Labor Day weekend. Amounts are adjusted for inflation.\n- Rajan, Amol (5 August 2020). \"TV watching and online streaming surge during lockdown\". BBC News. Archived from the original on 24 November 2021. Retrieved 24 November 2021.\n- Faughnder, Ryan (18 March 2021). \"Streaming milestone: Global subscriptions passed 1 billion last year\". Los Angeles Times. Retrieved 9 December 2024.\n- Lee, Edmund (21 April 2020). \"Everyone You Know Just Signed Up for Netflix\". New York Times.\n- CISAC (27 October 2021). \"CISAC Global Collections Report 2021 (for 2020 Data)\". CISAC. Archived from the original on 30 December 2021. Retrieved 30 December 2021.\n- \"IFPI issues Global Music Report 2021: Global recorded music revenues grow 7.4%\". IFPI.org. 23 March 2021. Archived from the original on 25 March 2021. Retrieved 30 December 2021.\n- Hsu, Tiffany; Tracy, Marc (12 November 2021). \"On Podcasts and Radio, Misleading Covid-19 Talk Goes Unchecked\". The New York Times. ISSN 0362-4331. Archived from the original on 28 December 2021. Retrieved 24 November 2021.\n- \"Enabling and configuring DLNA media server\". docs.qnap.com. Retrieved 27 October 2023.\n- \"Connected Digital Home\". manifest-tech.com. Retrieved 27 October 2023.\n- Brookes, Tim (30 March 2023). \"No Plex App, No Problem: Using Plex as a DLNA/UPnP Server\". How-To Geek. Retrieved 5 May 2024.\n- Staples, Kim (20 May 2016). \"How to watch live TV online: The complete guide\". broadbandchoices. Archived from the original on 16 May 2016. Retrieved 1 October 2016.\n- Anthony, Spadafora (18 October 2022). \"How Much Internet Speed Should You Really Pay For?\". Tom's Guide.\n- Rizk, Shirley (21 June 2019). \"The myth of the green cloud\". European Investment Bank. Archived from the original on 14 April 2021. Retrieved 17 September 2020.\n- \"Cisco Annual Internet Report (2018–2023) White Paper\". Cisco. Archived from the original on 7 February 2014. Retrieved 17 September 2020.\n- \"Streaming the London Olympic Games with the 'Go Live Package' from iStreamPlanet and Haivision\". iStreamPlanet. Archived from the original on 1 January 2016. Retrieved 11 November 2015.\n- Sripanidkulchai, Kunwadee; Maggs, Bruce; Zhang, Hui (2004). \"An analysis of live streaming workloads on the internet\". Proceedings of the 4th ACM SIGCOMM conference on Internet measurement. IMC '04. New York, NY, US: ACM. pp. 41–54. doi:10.1145/1028788.1028795. ISBN 978-1-58113-821-4. S2CID 1742312.\n- Zhao, Hong; Chun-long, Zhou; Bao-zhao, Jin (3 February 2015). \"Design and Implementation of Streaming Media Server Cluster Based on FFMpeg\". The Scientific World Journal. 2015 963083. doi:10.1155/2015/963083. PMC 4334929. PMID 25734187.\n- \"RTSP: The Real-Time Streaming Protocol. What is RTSP and How Does It Work?\". antmedia.io. 8 July 2021. Retrieved 6 January 2025.\n- Ch. Z. Patrikakis, N. Papaoulakis, Ch. Stefanoudaki, M. S. Nunes, \"Streaming content wars: Download and play strikes back\" presented at the Personalization in Media Delivery Platforms Workshop, [218 – 226], Venice, Italy, 2009.\n- Krasic, C. and Li, K. and Walpole, J., The case for streaming multimedia with TCP, Lecture Notes in Computer Science, pages 213–218, Springer, 2001\n- \"Videos On Demand\". Archived from the original on 15 December 2018. Retrieved 8 May 2017.\n- Burroughs, Benjamin; Rugg, Adam (3 July 2014). \"Extending the Broadcast: Streaming Culture and the Problems of Digital Geographies\". Journal of Broadcasting & Electronic Media. 58 (3): 365–380. doi:10.1080/08838151.2014.935854. ISSN 0883-8151. S2CID 144577408.\n- Buijsman, Stefan (2018). Pluses and Minuses: How Math Solves Our Problems (in Dutch) (English ed.). Amsterdam: Penguin Books. pp. 12–16. ISBN 978-0-14-313458-9.\n- A typical one-hour video lecture is the following live stream from an international conference on financial crises: Stanley, Eugene (2008). \"Applications of Statistical Physics to Understanding Complex Systems\". Videolectures. Archived from the original on 28 May 2019.\n- \"The Berliner Philharmoniker's Digital Concert Hall\". digitalconcerthall.com. Archived from the original on 3 May 2012. Retrieved 3 May 2012.\n- \"ISS High Definition Live Streaming Video of the Earth (HDEV)\". Earth Science & Remote Sensing Unit. NASA. Archived from the original on 8 December 2016. Retrieved 26 December 2016.\n- \"ISS HD Earth Viewing Experiment\". IBM Video Streaming. Archived from the original on 29 December 2016. Retrieved 26 December 2016.\n- Forrester (27 April 2020). \"Q1 2020 Proves Streaming Is Essential To Consumers And To The Future Of Media Companies\". Forbes. Archived from the original on 1 November 2020. Retrieved 2 October 2020.\n- \"Deloitte study: digital marketing spending is expected to increase by almost 15% until the end of 2021, while traditional advertising will slightly decrease\". Deloitte Romania. 29 October 2021. Archived from the original on 4 February 2022. Retrieved 4 February 2022.\n- Pozza, Leticia Ange; Sifuentes, Ana Paola. \"Case Study VI: Data in the Audiovisual business: Trends and Opportunities\" (PDF). dacatalogue.wipo.int. Retrieved 15 May 2025.\n- \"Revised Proposal for a Pilot Project on Copyright and the Distribution of Content in the Digital Environment Submitted by Brazil\". WIPO. 23 November 2018. Archived from the original on 4 February 2022. Retrieved 4 February 2022.\n- \"What is programmatic video advertising? (And why it's smart to use it)\". Biteable. 17 May 2018. Archived from the original on 4 February 2022. Retrieved 4 February 2022.\n- Katz, Raul (October 2021). Study on the copyright legal framework and licensing practices of audiovisual content in the digital environment, Part 1: Audiovisual OTT business models in Latin America: Recent trends and future evolution. Archived 5 November 2022 at the Wayback Machine World Intellectual Property Organization\n- Moullier, B; Galvis, Alexandra (October 2021). Study on the copyright legal framework and licensing practices of audiovisual content in the digital environment, Part 4: contractual practices in the Latin American audiovisual sector in the digital environment. World Intellectual Property Organization\n- Schotz, Gustavo (October 2021). Study on the copyright legal framework and licensing practices of audiovisual content in the digital environment, Part 5: The Identification and Use of Metadata in Audiovisual Works https://www.wipo.int/ip-development/en/agenda/work_undertaken.html#pilot_project_cdcde. World Intellectual Property Organization\n- Bertrand, Moullier (2022). \"Rights, Camera, Action! Intellectual property rights and the filmmaking process\". www.wipo.int. doi:10.34667/tind.46316. Retrieved 15 May 2025.\n- David, Stopps. \"How to Make a Living from Music\". www.wipo.int. doi:10.34667/tind.45019. Retrieved 15 May 2025.\n- Maeda, Mari (17 March 2001). \"OFC'01 Invited Talk the Internet of the Future\". Optical Fiber Communication Conference and International Conference on Quantum Information. Optical Society of America. pp. TuK1. doi:10.1364/OFC.2001.TuK1. ISBN 1-55752-654-0. Archived from the original on 18 February 2020. Retrieved 28 July 2019.\n- Blistein, Jon (23 May 2019). \"Is Streaming Music Dangerous to the Environment? One Researcher Is Sounding the Alarm\". Rolling Stone. Retrieved 3 August 2019.\n- \"Music consumption has unintended economic and environmental costs\". The University of Glasgow. 8 April 2019. Archived from the original on 3 August 2019. Retrieved 3 August 2019.\n- \"Greenhouse Gas Inventory Data Explorer | US EPA\". cfpub.epa.gov. Archived from the original on 9 March 2022. Retrieved 9 March 2022.\n- \"Turn off that camera during virtual meetings, environmental study says: Simple tips to go green with your internet use during a pandemic\". ScienceDaily. Archived from the original on 17 January 2021. Retrieved 16 January 2021.\n- Obringer, Renee; Rachunok, Benjamin; Maia-Silva, Debora; Arbabzadeh, Maryam; Nateghi, Roshanak; Madani, Kaveh (April 2021). \"The overlooked environmental footprint of increasing Internet use\". Resources, Conservation and Recycling. 167 105389. Bibcode:2021RCR...16705389O. doi:10.1016/j.resconrec.2020.105389. S2CID 233072553.\n- \"The carbon footprint of streaming video: fact-checking the headlines – Analysis\". IEA. 11 December 2020. Archived from the original on 21 March 2022. Retrieved 9 March 2022.\n- McKay, Deirdre; George, Sharon (10 January 2019). \"The environmental impact of music: digital, records, CDs analysed\". The Conversation. Archived from the original on 3 August 2019. Retrieved 3 August 2019.\n- Andrews, Robert (12 September 2012). \"Streaming media could have larger carbon footprint than plastic discs\". gigaom.com. Archived from the original on 3 August 2019. Retrieved 3 August 2019.\n- Hagen, Anja Nylund (2020). Music in Streams: Communicating Music in the Streaming Paradigm, In Michael Filimowicz & Veronika Tzankova (ed.), Reimagining Communication: Mediation (1st Edition). Routledge.\n- Preston, J. (11 December 2011). \"Occupy Video Showcases Live Streaming\". The New York Times.\n- Sherman, Alex (27 October 2019). \"AT&T, Disney and Comcast have very different plans for the streaming wars – here's what they're doing and why\". CNBC.",
    "technology industry": "A technology company (or tech company) is a company that focuses primarily on the manufacturing, support, research and development of—most commonly computing, telecommunication and consumer electronics–based—technology-intensive products and services, which include businesses relating to digital electronics, software, optics, new energy, and Internet-related services such as cloud storage and e-commerce services. Big Tech refers to the 6[a] largest companies, both in the United States and globally, symbolized by the metonym 'Silicon Valley', where 4[b] of them are based.\nAccording to Fortune, as of 2020[update], the ten largest technology companies by revenue are: Apple Inc., Samsung, Foxconn, Alphabet Inc., Microsoft, Huawei, Dell Technologies, Hitachi, IBM, and Sony.[1] Amazon has higher revenue than Apple, but is classified by Fortune in the retail sector.[2] The most profitable listed in 2020 are Apple Inc., Microsoft, Alphabet Inc., Intel, Meta Platforms, Samsung, and Tencent.[1]\nApple Inc., Alphabet Inc. (owner of Google), Meta Platforms (owner of Facebook), Microsoft, and Amazon.com, Inc. are often referred to as the Big Five multinational technology companies based in the United States. These five technology companies dominate major functions, e-commerce channels, and information of the entire Internet ecosystem. As of 2017, the Big Five had a combined valuation of over $3.3 trillion and make up more than 40 percent of the value of the Nasdaq-100 index.[3]\nMany large tech companies have a reputation for innovation, spending large sums of money annually on research and development. According to PwC's 2017 Global Innovation 1000 ranking, tech companies made up nine of the 20 most innovative companies in the world, with the top R&D spender (as measured by expenditure) being Amazon, followed by Alphabet Inc., and then Intel.[4]\nAs a result of numerous influential tech companies and tech startups opening offices in proximity to one another, a number of technology districts have developed in various areas across the globe.[5] These include: Silicon Valley in the San Francisco Bay Area, Silicon Wadi in Israel, Silicon Docks in Dublin, Silicon Hills in Austin, Tech City in London; Digital Media City in Seoul, Zhongguancun in Beijing, Cyberjaya in Malaysia and Cyberabad in Hyderabad, India.\n- List of largest technology companies by revenue\n- Big Tech, a grouping of the largest IT companies in the world\n- Deep tech\n- Dot-com company\n- Outline of technology\n- Nvidia, Microsoft, Apple, Alphabet, Amazon, and Meta\n- Nvidia, Apple, Alphabet, and Meta\n- \"Global 500\". Fortune. Retrieved 31 October 2020.\n- \"Amazon.com | 2020 Global 500\". Fortune. Retrieved 31 October 2020.\n- \"The 'Big Five' Could Destroy the Tech Ecosystem\". Bloomberg. 15 November 2017.\n- \"Tech companies dominate as the most innovative in the world\". BusinessTech. 28 October 2017. Retrieved 9 July 2018.\n- Kit Eaton (24 July 2012). \"The Silicon Valleys Of The World: The European Edition\". Fast Company. Retrieved 9 July 2018.",
    "telecommunications": "Telecommunication, often used in its plural form or abbreviated as telecom, is the transmission of information over a distance using electrical or electronic means, typically through cables, radio waves, or other communication technologies. These means of transmission may be divided into communication channels for multiplexing, allowing for a single medium to transmit several concurrent communication sessions. Long-distance technologies invented during the 20th and 21st centuries generally use electric power, and include the electrical telegraph, telephone, television, and radio.\nEarly telecommunication networks used metal wires as the medium for transmitting signals. These networks were used for telegraphy and telephony for many decades. In the first decade of the 20th century, a revolution in wireless communication began with breakthroughs including those made in radio communications by Guglielmo Marconi, who won the 1909 Nobel Prize in Physics. Other early pioneers in electrical and electronic telecommunications include co-inventors of the telegraph Charles Wheatstone and Samuel Morse, numerous inventors and developers of the telephone including Antonio Meucci, Philipp Reis, Elisha Gray and Alexander Graham Bell, inventors of radio Edwin Armstrong and Lee de Forest, as well as inventors of television like Vladimir K. Zworykin, John Logie Baird and Philo Farnsworth.\nSince the 1960s, the proliferation of digital technologies has meant that voice communications have gradually been supplemented by data. The physical limitations of metallic media prompted the development of optical fibre.[1][2][3] The Internet, a technology independent of any given medium, has provided global access to services for individual users and further reduced location and time limitations on communications.\nAt the 1932 Plenipotentiary Telegraph Conference and the International Radiotelegraph Conference in Madrid, the two organizations merged to form the International Telecommunication Union (ITU).[4] They defined telecommunication as \"any telegraphic or telephonic communication of signs, signals, writing, facsimiles and sounds of any kind, by wire, wireless or other systems or processes of electric signaling or visual signaling (semaphores).\"\nThe definition was later reconfirmed, according to Article 1.3 of the ITU Radio Regulations, which defined it as \"Any transmission, emission or reception of signs, signals, writings, images and sounds or intelligence of any nature by wire, radio, optical, or other electromagnetic systems\".\nAs such, slow communications technologies like postal mail and pneumatic tubes are excluded from the telecommunication's definition.[5][6]\nThe term telecommunication was coined in 1904 by the French engineer and novelist Édouard Estaunié, who defined it as \"remote transmission of thought through electricity\".[7] Telecommunication is a compound noun formed from the Greek prefix tele- (τῆλε), meaning distant, far off, or afar,[8] and the Latin verb communicare, meaning to share.[9][10] Communication was first used as an English word in the late 14th century. It comes from Old French comunicacion (14c., Modern French communication), from Latin communicationem (nominative communication), noun of action from past participle stem of communicare, \"to share, divide out; communicate, impart, inform; join, unite, participate in,\" literally, \"to make common\", from communis.[11]\nMany transmission media have been used for long-distance communication throughout history, from smoke signals, beacons, semaphore telegraphs, signal flags, and optical heliographs to wires and empty space made to carry electromagnetic signals.\nLong distance communication was used long before the discovery of electricity and electromagnetism enabled the invention of telecommunications. A few of the many ingenious methods for communicating over distances prior to that are described here.\nHoming pigeons have been used throughout history by different cultures. Pigeon post had Persian roots and was later used by the Romans to aid their military. Frontinus claimed Julius Caesar used pigeons as messengers in his conquest of Gaul.[12] The Greeks also conveyed the names of the victors at the Olympic Games to various cities using homing pigeons.[13] In the early 19th century, the Dutch government used the system in Java and Sumatra. And in 1849, Paul Julius Reuter started a pigeon service to fly stock prices between Aachen and Brussels, a service that operated for a year until the gap in the telegraph link was closed.[14]\nIn the Middle Ages, chains of beacons were commonly used on hilltops as a means of relaying a signal. Beacon chains suffered the drawback that they could only pass a single bit of information, so the meaning of the message such as \"the enemy has been sighted\" had to be agreed upon in advance. One notable instance of their use was during the Spanish Armada, when a beacon chain relayed a signal from Plymouth to London.[15]\nIn 1792, Claude Chappe, a French engineer, built the first fixed visual telegraphy system (or semaphore line) between Lille and Paris.[16] However semaphore suffered from the need for skilled operators and expensive towers at intervals of ten to thirty kilometres (six to nineteen miles). As a result of competition from the electrical telegraph, the last commercial line was abandoned in 1880.[17]\nOn July 25, 1837, the first commercial electrical telegraph was demonstrated by English inventor Sir William Fothergill Cooke and English scientist Sir Charles Wheatstone.[18][19] Both inventors viewed their device as \"an improvement to the [existing] electromagnetic telegraph\" and not as a new device.[20]\nSamuel Morse independently developed a version of the electrical telegraph that he unsuccessfully demonstrated on September 2, 1837. His code was an important advance over Wheatstone's signaling method. The first transatlantic telegraph cable was successfully completed on July 27, 1866, allowing transatlantic telecommunication for the first time.[21]\nAfter early attempts to develop a talking telegraph by Antonio Meucci and a telefon by Johann Philipp Reis, a patent for the conventional telephone was filed by Alexander Bell in February 1876 (just a few hours before Elisha Gray filed a patent caveat for a similar device).[22][23] The first commercial telephone services were set up by the Bell Telephone Company in 1878 and 1879 on both sides of the Atlantic in the cities of New Haven and London.[24][25]\nIn 1894, Italian inventor Guglielmo Marconi began developing a wireless communication using the then-newly discovered phenomenon of radio waves, demonstrating, by 1901, that they could be transmitted across the Atlantic Ocean.[26] This was the start of wireless telegraphy by radio. On 17 December 1902, a transmission from the Marconi station in Glace Bay, Nova Scotia, Canada, became the world's first radio message to cross the Atlantic from North America. In 1904, a commercial service was established to transmit nightly news summaries to subscribing ships, which incorporated them into their onboard newspapers.[27]\nWorld War I accelerated the development of radio for military communications. After the war, commercial radio AM broadcasting began in the 1920s and became an important mass medium for entertainment and news. World War II again accelerated the development of radio for the wartime purposes of aircraft and land communication, radio navigation, and radar.[28] Development of stereo FM broadcasting of radio began in the 1930s in the United States and the 1940s in the United Kingdom,[29] displacing AM as the dominant commercial standard in the 1970s.[30]\nOn March 25, 1925, John Logie Baird demonstrated the transmission of moving pictures at the London department store Selfridges. Baird's device relied upon the Nipkow disk by Paul Nipkow and thus became known as the mechanical television. It formed the basis of experimental broadcasts done by the British Broadcasting Corporation beginning on 30 September 1929.[31]\nVacuum tubes use thermionic emission of electrons from a heated cathode for a number of fundamental electronic functions such as signal amplification and current rectification.\nThe simplest vacuum tube, the diode invented in 1904 by John Ambrose Fleming, contains only a heated electron-emitting cathode and an anode. Electrons can only flow in one direction through the device—from the cathode to the anode. Adding one or more control grids within the tube enables the current between the cathode and anode to be controlled by the voltage on the grid or grids.[32] These devices became a key component of electronic circuits for the first half of the 20th century and were crucial to the development of radio, television, radar, sound recording and reproduction, long-distance telephone networks, and analogue and early digital computers. While some applications had used earlier technologies such as the spark gap transmitter for radio or mechanical computers for computing, it was the invention of the thermionic vacuum tube that made these technologies widespread and practical, leading to the creation of electronics.[33]\nFor most of the 20th century, televisions depended on a kind of vacuum tube — the cathode ray tube — invented by Karl Ferdinand Braun. The first version of such a television to show promise was produced by Philo Farnsworth and demonstrated to his family on 7 September 1927.[34] After World War II, interrupted experiments resumed and television became an important home entertainment broadcast medium.\nAlso in the 1940s, the invention of semiconductor devices made it possible to produce solid-state devices, which are smaller, cheaper, and more efficient, reliable, and durable than vacuum tubes. Starting in the mid-1960s, vacuum tubes were replaced with the transistor. Vacuum tubes still have some applications for certain high-frequency amplifiers.\nOn 11 September 1940, George Stibitz transmitted problems for his Complex Number Calculator in New York using a teletype and received the computed results back at Dartmouth College in New Hampshire.[35] This configuration of a centralized computer (mainframe) with remote dumb terminals remained popular well into the 1970s. In the 1960s, Paul Baran and, independently, Donald Davies started to investigate packet switching, a technology that sends a message in portions to its destination asynchronously without passing it through a centralized mainframe. A four-node network emerged on 5 December 1969, constituting the beginnings of the ARPANET, which by 1981 had grown to 213 nodes.[36] ARPANET eventually merged with other networks to form the Internet. While Internet development was a focus of the Internet Engineering Task Force (IETF) who published a series of Request for Comments documents, other networking advancements occurred in industrial laboratories, such as the local area network (LAN) developments of Ethernet (1983), Token Ring (1984)[citation needed] and Star network topology.\nThe effective capacity to exchange information worldwide through two-way telecommunication networks grew from 281 petabytes (PB) of optimally compressed information in 1986 to 471 PB in 1993 to 2.2 exabytes (EB) in 2000 to 65 EB in 2007.[37] This is the informational equivalent of two newspaper pages per person per day in 1986, and six entire newspapers per person per day by 2007.[38] Given this growth, telecommunications play an increasingly important role in the world economy and the global telecommunications industry was about a $4.7 trillion sector in 2012.[39][40] The service revenue of the global telecommunications industry was estimated to be $1.5 trillion in 2010, corresponding to 2.4% of the world's gross domestic product (GDP).[39]\nModern telecommunication is founded on a series of key concepts that experienced progressive development and refinement in a period of well over a century:\nTelecommunication technologies may primarily be divided into wired and wireless methods. Overall, a basic telecommunication system consists of three main parts that are always present in some form or another:\n- A transmitter that takes information and converts it to a signal\n- A transmission medium, also called the physical channel, that carries the signal (e.g., the \"free space channel\")\n- A receiver that takes the signal from the channel and converts it back into usable information for the recipient\nIn a radio broadcasting station, the station's large power amplifier is the transmitter and the broadcasting antenna is the interface between the power amplifier and the free space channel. The free space channel is the transmission medium and the receiver's antenna is the interface between the free space channel and the receiver. Next, the radio receiver is the destination of the radio signal, where it is converted from electricity to sound.\nTelecommunication systems are occasionally \"duplex\" (two-way systems) with a single box of electronics working as both the transmitter and a receiver, or a transceiver (e.g., a mobile phone).[41] The transmission electronics and the receiver electronics within a transceiver are quite independent of one another. This can be explained by the fact that radio transmitters contain power amplifiers that operate with electrical powers measured in watts or kilowatts, but radio receivers deal with radio powers measured in microwatts or nanowatts. Hence, transceivers have to be carefully designed and built to isolate their high-power circuitry and their low-power circuitry from each other to avoid interference.\nTelecommunication over fixed lines is called point-to-point communication because it occurs between a transmitter and a receiver. Telecommunication through radio broadcasts is called broadcast communication because it occurs between a powerful transmitter and numerous low-power but sensitive radio receivers.[41]\nTelecommunications in which multiple transmitters and multiple receivers have been designed to cooperate and share the same physical channel are called multiplex systems. The sharing of physical channels using multiplexing often results in significant cost reduction. Multiplexed systems are laid out in telecommunication networks and multiplexed signals are switched at nodes through to the correct destination terminal receiver.\nCommunications can be encoded as analogue or digital signals, which may in turn be carried by analogue or digital communication systems. Analogue signals vary continuously with respect to the information, while digital signals encode information as a set of discrete values (e.g., a set of ones and zeroes).[42] During propagation and reception, information contained in analogue signals is degraded by undesirable noise. Commonly, the noise in a communication system can be expressed as adding or subtracting from the desirable signal via a random process. This form of noise is called additive noise, with the understanding that the noise can be negative or positive at different instances.\nUnless the additive noise disturbance exceeds a certain threshold, the information contained in digital signals will remain intact. Their resistance to noise represents a key advantage of digital signals over analogue signals. However, digital systems fail catastrophically when noise exceeds the system's ability to autocorrect. On the other hand, analogue systems fail gracefully: as noise increases, the signal becomes progressively more degraded but still usable. Also, digital transmission of continuous data unavoidably adds quantization noise to the output. This can be reduced, but not eliminated, only at the expense of increasing the channel bandwidth requirement.\nThe term channel has two different meanings. In one meaning, a channel is the physical medium that carries a signal between the transmitter and the receiver. Examples of this include the atmosphere for sound communications, glass optical fibres for some kinds of optical communications, coaxial cables for communications by way of the voltages and electric currents in them, and free space for communications using visible light, infrared waves, ultraviolet light, and radio waves. Coaxial cable types are classified by RG type or radio guide, terminology derived from World War II. The various RG designations are used to classify the specific signal transmission applications.[43] This last channel is called the free space channel. The sending of radio waves from one place to another has nothing to do with the presence or absence of an atmosphere between the two. Radio waves travel through a perfect vacuum just as easily as they travel through air, fog, clouds, or any other kind of gas.\nThe other meaning of the term channel in telecommunications is seen in the phrase communications channel, which is a subdivision of a transmission medium so that it can be used to send multiple streams of information simultaneously. For example, one radio station can broadcast radio waves into free space at frequencies in the neighbourhood of 94.5 MHz (megahertz) while another radio station can simultaneously broadcast radio waves at frequencies in the neighbourhood of 96.1 MHz. Each radio station would transmit radio waves over a frequency bandwidth of about 180 kHz (kilohertz), centred at frequencies such as the above, which are called the \"carrier frequencies\". Each station in this example is separated from its adjacent stations by 200 kHz, and the difference between 200 kHz and 180 kHz (20 kHz) is an engineering allowance for the imperfections in the communication system.\nIn the example above, the free space channel has been divided into communications channels according to frequencies, and each channel is assigned a separate frequency bandwidth in which to broadcast radio waves. This system of dividing the medium into channels according to frequency is called frequency-division multiplexing. Another term for the same concept is wavelength-division multiplexing, which is more commonly used in optical communications when multiple transmitters share the same physical medium.\nAnother way of dividing a communications medium into channels is to allocate each sender a recurring segment of time (a time slot, for example, 20 milliseconds out of each second), and to allow each sender to send messages only within its own time slot. This method of dividing the medium into communication channels is called time-division multiplexing (TDM), and is used in optical fibre communication. Some radio communication systems use TDM within an allocated FDM channel. Hence, these systems use a hybrid of TDM and FDM.\nThe shaping of a signal to convey information is known as modulation. Modulation can be used to represent a digital message as an analogue waveform. This is commonly called \"keying\"—a term derived from the older use of Morse Code in telecommunications—and several keying techniques exist (these include phase-shift keying, frequency-shift keying, and amplitude-shift keying). The Bluetooth system, for example, uses phase-shift keying to exchange information between various devices.[44][45] In addition, there are combinations of phase-shift keying and amplitude-shift keying which is called (in the jargon of the field) quadrature amplitude modulation (QAM) that are used in high-capacity digital radio communication systems.\nModulation can also be used to transmit the information of low-frequency analogue signals at higher frequencies. This is helpful because low-frequency analogue signals cannot be effectively transmitted over free space. Hence the information from a low-frequency analogue signal must be impressed into a higher-frequency signal (known as the carrier wave) before transmission. There are several different modulation schemes available to achieve this [two of the most basic being amplitude modulation (AM) and frequency modulation (FM)]. An example of this process is a disc jockey's voice being impressed into a 96 MHz carrier wave using frequency modulation (the voice would then be received on a radio as the channel 96 FM).[46] In addition, modulation has the advantage that it may use frequency division multiplexing (FDM).\nA telecommunications network is a collection of transmitters, receivers, and communications channels that send messages to one another. Some digital communications networks contain one or more routers that work together to transmit information to the correct user. An analogue communications network consists of one or more switches that establish a connection between two or more users. For both types of networks, repeaters may be necessary to amplify or recreate the signal when it is being transmitted over long distances. This is to combat attenuation that can render the signal indistinguishable from the noise.[47] Another advantage of digital systems over analogue is that their output is easier to store in memory, i.e., two voltage states (high and low) are easier to store than a continuous range of states.\nTelecommunication has a significant social, cultural and economic impact on modern society. In 2008, estimates placed the telecommunication industry's revenue at US$4.7 trillion or just under three per cent of the gross world product (official exchange rate).[39] Several following sections discuss the impact of telecommunication on society.\nOn the microeconomic scale, companies have used telecommunications to help build global business empires. This is self-evident in the case of online retailer Amazon.com but, according to academic Edward Lenert, even the conventional retailer Walmart has benefited from better telecommunication infrastructure compared to its competitors.[48] In cities throughout the world, home owners use their telephones to order and arrange a variety of home services ranging from pizza deliveries to electricians. Even relatively poor communities have been noted to use telecommunication to their advantage. In Bangladesh's Narsingdi District, isolated villagers use cellular phones to speak directly to wholesalers and arrange a better price for their goods. In Côte d'Ivoire, coffee growers share mobile phones to follow hourly variations in coffee prices and sell at the best price.[49]\nOn the macroeconomic scale, Lars-Hendrik Röller and Leonard Waverman suggested a causal link between good telecommunication infrastructure and economic growth.[50][51] Few dispute the existence of a correlation although some argue it is wrong to view the relationship as causal.[52]\nBecause of the economic benefits of good telecommunication infrastructure, there is increasing worry about the inequitable access to telecommunication services amongst various countries of the world—this is known as the digital divide. A 2003 survey by the International Telecommunication Union (ITU) revealed that roughly a third of countries have fewer than one mobile subscription for every 20 people and one-third of countries have fewer than one land-line telephone subscription for every 20 people. In terms of Internet access, roughly half of all countries have fewer than one out of 20 people with Internet access. From this information, as well as educational data, the ITU was able to compile an index that measures the overall ability of citizens to access and use information and communication technologies.[53] Using this measure, Sweden, Denmark and Iceland received the highest ranking while the African countries Niger, Burkina Faso and Mali received the lowest.[54]\nTelecommunication has played a significant role in social relationships. Nevertheless, devices like the telephone system were originally advertised with an emphasis on the practical dimensions of the device (such as the ability to conduct business or order home services) as opposed to the social dimensions. It was not until the late 1920s and 1930s that the social dimensions of the device became a prominent theme in telephone advertisements. New promotions started appealing to consumers' emotions, stressing the importance of social conversations and staying connected to family and friends.[55]\nSince then the role that telecommunications has played in social relations has become increasingly important. In recent years,[when?] the popularity of social networking sites has increased dramatically. These sites allow users to communicate with each other as well as post photographs, events and profiles for others to see. The profiles can list a person's age, interests, sexual preference and relationship status. In this way, these sites can play important role in everything from organising social engagements to courtship.[56]\nPrior to social networking sites, technologies like short message service (SMS) and the telephone also had a significant impact on social interactions. In 2000, market research group Ipsos MORI reported that 81% of 15- to 24-year-old SMS users in the United Kingdom had used the service to coordinate social arrangements and 42% to flirt.[57]\n| Local TV | 59% |\n| National TV | 47% |\n| Radio | 44% |\n| Local paper | 38% |\n| Internet | 23% |\n| National paper | 12% |\n| Survey permitted multiple answers |\nIn cultural terms, telecommunication has increased the public's ability to access music and film. With television, people can watch films they have not seen before in their own home without having to travel to the video store or cinema. With radio and the Internet, people can listen to music they have not heard before without having to travel to the music store.\nTelecommunication has also transformed the way people receive their news. A 2006 survey (right table) of slightly more than 3,000 Americans by the non-profit Pew Internet and American Life Project in the United States the majority specified television or radio over newspapers.\nTelecommunication has had an equally significant impact on advertising. TNS Media Intelligence reported that in 2007, 58% of advertising expenditure in the United States was spent on media that depend upon telecommunication.[59]\n| Medium | Spending | |\n|---|---|---|\n| Internet | 7.6% | $11.31 billion |\n| Radio | 7.2% | $10.69 billion |\n| Cable TV | 12.1% | $18.02 billion |\n| Syndicated TV | 2.8% | $4.17 billion |\n| Spot TV | 11.3% | $16.82 billion |\n| Network TV | 17.1% | $25.42 billion |\n| Newspaper | 18.9% | $28.22 billion |\n| Magazine | 20.4% | $30.33 billion |\n| Outdoor | 2.7% | $4.02 billion |\n| Total | 100% | $149 billion |\nMany countries have enacted legislation which conforms to the International Telecommunication Regulations established by the International Telecommunication Union (ITU), which is the \"leading UN agency for information and communication technology issues\".[60] In 1947, at the Atlantic City Conference, the ITU decided to \"afford international protection to all frequencies registered in a new international frequency list and used in conformity with the Radio Regulation\". According to the ITU's Radio Regulations adopted in Atlantic City, all frequencies referenced in the International Frequency Registration Board, examined by the board and registered on the International Frequency List \"shall have the right to international protection from harmful interference\".[61]\nFrom a global perspective, there have been political debates and legislation regarding the management of telecommunication and broadcasting. The history of broadcasting discusses some debates in relation to balancing conventional communication such as printing and telecommunication such as radio broadcasting.[62] The onset of World War II brought on the first explosion of international broadcasting propaganda.[62] Countries, their governments, insurgents, terrorists, and militiamen have all used telecommunication and broadcasting techniques to promote propaganda.[62][63] Patriotic propaganda for political movements and colonization started the mid-1930s. In 1936, the BBC broadcast propaganda to the Arab World to partly counter similar broadcasts from Italy, which also had colonial interests in North Africa.[62] Modern political debates in telecommunication include the reclassification of broadband Internet service as a telecommunications service (also called net neutrality),[64][65] regulation of phone spam,[66][67] and expanding affordable broadband access.[68]\nAccording to data collected by Gartner[69][70] and Ars Technica[71] sales of main consumer's telecommunication equipment worldwide in millions of units was:\n| Equipment / year | 1975 | 1980 | 1985 | 1990 | 1994 | 1996 | 1998 | 2000 | 2002 | 2004 | 2006 | 2008 |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| Computers | 0 | 1 | 8 | 20 | 40 | 75 | 100 | 135 | 130 | 175 | 230 | 280 |\n| Cell phones | N/A | N/A | N/A | N/A | N/A | N/A | 180 | 400 | 420 | 660 | 830 | 1000 |\nIn a telephone network, the caller is connected to the person to whom they wish to talk by switches at various telephone exchanges. The switches form an electrical connection between the two users and the setting of these switches is determined electronically when the caller dials the number. Once the connection is made, the caller's voice is transformed to an electrical signal using a small microphone in the caller's handset. This electrical signal is then sent through the network to the user at the other end where it is transformed back into sound by a small speaker in that person's handset.\nAs of 2015[update], the landline telephones in most residential homes are analogue—that is, the speaker's voice directly determines the signal's voltage.[72] Although short-distance calls may be handled from end-to-end as analogue signals, increasingly telephone service providers are transparently converting the signals to digital signals for transmission. The advantage of this is that digitized voice data can travel side by side with data from the Internet and can be perfectly reproduced in long-distance communication (as opposed to analogue signals that are inevitably impacted by noise).\nMobile phones have had a significant impact on telephone networks. Mobile phone subscriptions now outnumber fixed-line subscriptions in many markets. Sales of mobile phones in 2005 totalled 816.6 million with that figure being almost equally shared amongst the markets of Asia/Pacific (204 m), Western Europe (164 m), CEMEA (Central Europe, the Middle East and Africa) (153.5 m), North America (148 m) and Latin America (102 m).[73] In terms of new subscriptions over the five years from 1999, Africa has outpaced other markets with 58.2% growth.[74] Increasingly these phones are being serviced by systems where the voice content is transmitted digitally such as GSM or W-CDMA with many markets choosing to deprecate analog systems such as AMPS.[75]\nThere have also been dramatic changes in telephone communication behind the scenes. Starting with the operation of TAT-8 in 1988, the 1990s saw the widespread adoption of systems based on optical fibres. The benefit of communicating with optical fibres is that they offer a drastic increase in data capacity. TAT-8 itself was able to carry 10 times as many telephone calls as the last copper cable laid at that time and today's optical fibre cables are able to carry 25 times as many telephone calls as TAT-8.[76] This increase in data capacity is due to several factors: First, optical fibres are physically much smaller than competing technologies. Second, they do not suffer from crosstalk which means several hundred of them can be easily bundled together in a single cable.[77] Lastly, improvements in multiplexing have led to an exponential growth in the data capacity of a single fibre.[78][79]\nAssisting communication across many modern optical fibre networks is a protocol known as Asynchronous Transfer Mode (ATM). The ATM protocol allows for the side-by-side data transmission mentioned in the second paragraph. It is suitable for public telephone networks because it establishes a pathway for data through the network and associates a traffic contract with that pathway. The traffic contract is essentially an agreement between the client and the network about how the network is to handle the data; if the network cannot meet the conditions of the traffic contract it does not accept the connection. This is important because telephone calls can negotiate a contract so as to guarantee themselves a constant bit rate, something that will ensure a caller's voice is not delayed in parts or cut off completely.[80] There are competitors to ATM, such as Multiprotocol Label Switching (MPLS), that perform a similar task and are expected to supplant ATM in the future.[81][82]\nIn a broadcast system, the central high-powered broadcast tower transmits a high-frequency electromagnetic wave to numerous low-powered receivers. The high-frequency wave sent by the tower is modulated with a signal containing visual or audio information. The receiver is then tuned so as to pick up the high-frequency wave and a demodulator is used to retrieve the signal containing the visual or audio information. The broadcast signal can be either analogue (signal is varied continuously with respect to the information) or digital (information is encoded as a set of discrete values).[41][83]\nThe broadcast media industry is at a critical turning point in its development, with many countries moving from analogue to digital broadcasts. This move is made possible by the production of cheaper, faster and more capable integrated circuits. The chief advantage of digital broadcasts is that they prevent a number of complaints common to traditional analogue broadcasts. For television, this includes the elimination of problems such as snowy pictures, ghosting and other distortion. These occur because of the nature of analogue transmission, which means that perturbations due to noise will be evident in the final output. Digital transmission overcomes this problem because digital signals are reduced to discrete values upon reception and hence small perturbations do not affect the final output. In a simplified example, if a binary message 1011 was transmitted with signal amplitudes [1.0 0.0 1.0 1.0] and received with signal amplitudes [0.9 0.2 1.1 0.9] it would still decode to the binary message 1011— a perfect reproduction of what was sent. From this example, a problem with digital transmissions can also be seen in that if the noise is great enough it can significantly alter the decoded message. Using forward error correction a receiver can correct a handful of bit errors in the resulting message but too much noise will lead to incomprehensible output and hence a breakdown of the transmission.[84][85]\nIn digital television broadcasting, there are three competing standards that are likely to be adopted worldwide. These are the ATSC, DVB and ISDB standards; the adoption of these standards thus far is presented in the captioned map. All three standards use MPEG-2 for video compression. ATSC uses Dolby Digital AC-3 for audio compression, ISDB uses Advanced Audio Coding (MPEG-2 Part 7) and DVB has no standard for audio compression but typically uses MPEG-1 Part 3 Layer 2.[86][87] The choice of modulation also varies between the schemes. In digital audio broadcasting, standards are much more unified with practically all countries choosing to adopt the Digital Audio Broadcasting standard (also known as the Eureka 147 standard). The exception is the United States which has chosen to adopt HD Radio. HD Radio, unlike Eureka 147, is based upon a transmission method known as in-band on-channel transmission that allows digital information to piggyback on normal AM or FM analog transmissions.[88]\nHowever, despite the pending switch to digital, analog television remains being transmitted in most countries. An exception is the United States that ended analog television transmission (by all but the very low-power TV stations) on 12 June 2009[89] after twice delaying the switchover deadline. Kenya also ended analog television transmission in December 2014 after multiple delays. For analogue television, there were three standards in use for broadcasting colour TV (see a map on adoption here). These are known as PAL (German designed), NTSC (American designed), and SECAM (French designed). For analogue radio, the switch to digital radio is made more difficult by the higher cost of digital receivers.[90] The choice of modulation for analogue radio is typically between amplitude (AM) or frequency modulation (FM). To achieve stereo playback, an amplitude modulated subcarrier is used for stereo FM, and quadrature amplitude modulation is used for stereo AM or C-QUAM.\nThe Internet is a worldwide network of computers and computer networks that communicate with each other using the Internet Protocol (IP).[91] Any computer on the Internet has a unique IP address that can be used by other computers to route information to it. Hence, any computer on the Internet can send a message to any other computer using its IP address. These messages carry with them the originating computer's IP address allowing for two-way communication. The Internet is thus an exchange of messages between computers.[92]\nIt is estimated that 51% of the information flowing through two-way telecommunications networks in the year 2000 were flowing through the Internet (most of the rest (42%) through the landline telephone). By 2007 the Internet clearly dominated and captured 97% of all the information in telecommunication networks (most of the rest (2%) through mobile phones).[37] As of 2008[update], an estimated 21.9% of the world population has access to the Internet with the highest access rates (measured as a percentage of the population) in North America (73.6%), Oceania/Australia (59.5%) and Europe (48.1%).[93] In terms of broadband access, Iceland (26.7%), South Korea (25.4%) and the Netherlands (25.3%) led the world.[94]\nThe Internet works in part because of protocols that govern how the computers and routers communicate with each other. The nature of computer network communication lends itself to a layered approach where individual protocols in the protocol stack run more-or-less independently of other protocols. This allows lower-level protocols to be customized for the network situation while not changing the way higher-level protocols operate. A practical example of why this is important is because it allows a web browser to run the same code regardless of whether the computer it is running on is connected to the Internet through an Ethernet or Wi-Fi connection. Protocols are often talked about in terms of their place in the OSI reference model (pictured on the right), which emerged in 1983 as the first step in an unsuccessful attempt to build a universally adopted networking protocol suite.[95]\nFor the Internet, the physical medium and data link protocol can vary several times as packets traverse the globe. This is because the Internet places no constraints on what physical medium or data link protocol is used. This leads to the adoption of media and protocols that best suit the local network situation. In practice, most intercontinental communication will use the Asynchronous Transfer Mode (ATM) protocol (or a modern equivalent) on top of optic fibre. This is because for most intercontinental communication the Internet shares the same infrastructure as the public switched telephone network.\nAt the network layer, things become standardized with the Internet Protocol (IP) being adopted for logical addressing. For the World Wide Web, these IP addresses are derived from the human-readable form using the Domain Name System (e.g., 72.14.207.99 is derived from Google). At the moment, the most widely used version of the Internet Protocol is version four but a move to version six is imminent.[96]\nAt the transport layer, most communication adopts either the Transmission Control Protocol (TCP) or the User Datagram Protocol (UDP). TCP is used when it is essential every message sent is received by the other computer whereas UDP is used when it is merely desirable. With TCP, packets are retransmitted if they are lost and placed in order before they are presented to higher layers. With UDP, packets are not ordered nor retransmitted if lost. Both TCP and UDP packets carry port numbers with them to specify what application or process the packet should be handled by.[97] Because certain application-level protocols use certain ports, network administrators can manipulate traffic to suit particular requirements. Examples are to restrict Internet access by blocking the traffic destined for a particular port or to affect the performance of certain applications by assigning priority.\nAbove the transport layer, there are certain protocols that are sometimes used and loosely fit in the session and presentation layers, most notably the Secure Sockets Layer (SSL) and Transport Layer Security (TLS) protocols. These protocols ensure that data transferred between two parties remains completely confidential.[98] Finally, at the application layer, are many of the protocols Internet users would be familiar with such as HTTP (web browsing), POP3 (e-mail), FTP (file transfer), IRC (Internet chat), BitTorrent (file sharing) and XMPP (instant messaging).\nVoice over Internet Protocol (VoIP) allows data packets to be used for synchronous voice communications. The data packets are marked as voice-type packets and can be prioritized by the network administrators so that the real-time, synchronous conversation is less subject to contention with other types of data traffic which can be delayed (i.e., file transfer or email) or buffered in advance (i.e., audio and video) without detriment. That prioritization is fine when the network has sufficient capacity for all the VoIP calls taking place at the same time and the network is enabled for prioritization, i.e., a private corporate-style network, but the Internet is not generally managed in this way and so there can be a big difference in the quality of VoIP calls over a private network and over the public Internet.[99]\nDespite the growth of the Internet, the characteristics of local area networks (LANs)—computer networks that do not extend beyond a few kilometres—remain distinct. This is because networks on this scale do not require all the features associated with larger networks and are often more cost-effective and efficient without them. When they are not connected with the Internet, they also have the advantages of privacy and security. However, purposefully lacking a direct connection to the Internet does not provide assured protection from hackers, military forces, or economic powers. These threats exist if there are any methods for connecting remotely to the LAN.\nWide area networks (WANs) are private computer networks that may extend for thousands of kilometres. Once again, some of their advantages include privacy and security. Prime users of private LANs and WANs include armed forces and intelligence agencies that must keep their information secure and secret.\nIn the mid-1980s, several sets of communication protocols emerged to fill the gaps between the data-link layer and the application layer of the OSI reference model. These included AppleTalk, IPX, and NetBIOS with the dominant protocol set during the early 1990s being IPX due to its popularity with MS-DOS users. TCP/IP existed at this point, but it was typically only used by large government and research facilities.[100]\nAs the Internet grew in popularity and its traffic was required to be routed into private networks, the TCP/IP protocols replaced existing local area network technologies. Additional technologies, such as DHCP, allowed TCP/IP-based computers to self-configure in the network. Such functions also existed in the AppleTalk/ IPX/ NetBIOS protocol sets.[101]\nWhereas Asynchronous Transfer Mode (ATM) or Multiprotocol Label Switching (MPLS) are typical data-link protocols for larger networks such as WANs; Ethernet and Token Ring are typical data-link protocols for LANs. These protocols differ from the former protocols in that they are simpler, e.g., they omit features such as quality of service guarantees, and offer medium access control. Both of these differences allow for more economical systems.[102]\nDespite the modest popularity of Token Ring in the 1980s and 1990s, virtually all LANs now use either wired or wireless Ethernet facilities. At the physical layer, most wired Ethernet implementations use copper twisted-pair cables (including the common 10BASE-T networks). However, some early implementations used heavier coaxial cables and some recent implementations (especially high-speed ones) use optical fibres.[103] When optic fibres are used, the distinction must be made between multimode fibres and single-mode fibres. Multimode fibres can be thought of as thicker optical fibres that are cheaper to manufacture devices for, but that suffer from less usable bandwidth and worse attenuation—implying poorer long-distance performance.[104]\n- Active networking\n- Cell site\n- Control communications\n- Digital Revolution\n- Information Age\n- Institute of Telecommunications Professionals\n- International Teletraffic Congress\n- List of telecommunications encryption terms\n- Military communication\n- Nanonetwork\n- New media\n- Outline of telecommunication\n- Telecommunications engineering\n- Telecommunications Industry Association\n- Telecoms resilience\n- Telemetry\n- Underwater acoustic communication\n- Wavelength-division multiplexing\n- Wired communication\n- \"How does a Gigabit Passive Optical Network (GPON) work?\". European Investment Bank. Archived from the original on 7 June 2021. Retrieved 7 June 2021.\n- Renewing U.S. Telecommunications Research. 2006. doi:10.17226/11711. ISBN 978-0-309-10265-0. Archived from the original on 23 June 2021. Retrieved 25 June 2021.\n- Cyphers, Bennett (16 October 2019). \"The Case for Fiber to the Home, Today: Why Fiber is a Superior Medium for 21st Century Broadband\". Electronic Frontier Foundation. Archived from the original on 3 June 2021. Retrieved 7 June 2021.\n- \"International Telegraph Conference (Madrid, 1932)\". ITU. Archived from the original on 8 January 2023. Retrieved 8 January 2023.\n- \"Article 1.3\" (PDF), ITU Radio Regulations, International Telecommunication Union, 2012, archived from the original (PDF) on 19 March 2015\n- Constitution and Convention of the International Telecommunication Union, Annex (Geneva, 1992)\n- Dilhac, Jean-Marie (2004). \"From tele-communicare to Telecommunications\" (PDF). Institute of Electrical and Electronics Engineers (IEEE). Archived from the original (PDF) on 2 December 2010.\n- \"Online Etymology Dictionary\". Archived from the original on 25 December 2016. Retrieved 19 August 2016.\n- \"Telecommunication\". Oxford Dictionaries. Oxford University Press. Archived from the original on 30 April 2013. Retrieved 28 February 2013.\n- Telecommunication, tele- and communication, New Oxford American Dictionary (2nd edition), 2005.\n- \"communication\". Online Etymology Dictionary. Archived from the original on 14 September 2016. Retrieved 19 August 2016.\n- Levi, Wendell (1977). The Pigeon. Sumter, SC: Levi Publishing Co, Inc. ISBN 978-0-85390-013-9.\n- Blechman, Andrew (2007). Pigeons-The fascinating saga of the world's most revered and reviled bird. St Lucia, Queensland: University of Queensland Press. ISBN 978-0-7022-3641-9. Archived from the original on 14 May 2008.\n- \"Chronology: Reuters, from pigeons to multimedia merger\" (Web article). Reuters. 19 February 2008. Archived from the original on 26 March 2008. Retrieved 21 February 2008.\n- Ross, David. \"The Spanish Armada\". Britain Express. Archived from the original on 4 January 2020. Retrieved 1 October 2007.\n- \"Les Télégraphes Chappe\". Cédrick Chatenet. l'Ecole Centrale de Lyon. 2003. Archived from the original on 9 April 2004.\n- \"CCIT/ITU-T 50 Years of Excellence\" (PDF). International Telecommunication Union. 2006. Archived from the original (PDF) on 12 February 2020.\n- Brockedone, William (11 March 2013). Cooke and Wheatstone and the Invention of the Electric Telegraph. Routledge. ISBN 9780415846783.\n- \"Who made the first electric telegraph communications?\". The Telegraph. Archived from the original on 8 August 2017. Retrieved 7 August 2017.\n- Calvert, J. B. (19 May 2004). \"The Electromagnetic Telegraph\". Archived from the original on 16 June 2001.\n- \"The Atlantic Cable\". Bern Dibner. Burndy Library Inc. 1959. Archived from the original on 1 July 2017.\n- Who is credited with inventing the telephone? loc.gov, published: 02/22/2022. updated 9/12/2024. Author: Science Reference Section, Library of Congress\n- \"Elisha Gray\". Oberlin College Archives. Electronic Oberlin Group. 2006. Archived from the original on 28 June 2017.\n- \"Connected Earth: The telephone\". BT. 2006. Archived from the original on 22 August 2006.\n- \"History of AT&T\". AT&T. Archived from the original on 14 January 2003.\n- Vujovic, Ljubo (1998). \"Tesla Biography\". Tesla Memorial Society of New York. Archived from the original on 14 January 2016.\n- \"TR Center - Talking Across the Ocean\". www.theodorerooseveltcenter.org. Archived from the original on 17 April 2021. Retrieved 12 March 2021.\n- Thompson, R.J. Jr. (2011). Crystal Clear: The Struggle for Reliable Communications Technology in World War II. Hoboken, NJ: Wiley. ISBN 9781118104644.\n- \"Report 1946-04 – Frequency Modulation\". BBC Research & Development. January 1946. Archived from the original on 3 January 2020. Retrieved 3 January 2020.\n- Théberge, P.; Devine, K.; Everrett, T (2015). Living Stereo: Histories and Cultures of Multichannel Sound. New York: Bloomsbury Publishing. ISBN 9781623566654.\n- \"The Pioneers\". MZTV Museum of Television. 2006. Archived from the original on 14 May 2013.\n- Hoddeson, L. \"The Vacuum Tube\". PBS. Archived from the original on 15 April 2012. Retrieved 6 May 2012.\n- Macksey, Kenneth; Woodhouse, William (1991). \"Electronics\". The Penguin Encyclopedia of Modern Warfare: 1850 to the present day. Viking. p. 110. ISBN 978-0-670-82698-8.\nThe electronics age may be said to have been ushered in with the invention of the vacuum diode valve in 1902 by the Briton John Fleming (himself coining the word 'electronics'), the immediate application being in the field of radio.\n- Postman, Neil (29 March 1999). \"Philo Farnsworth\". TIME Magazine. Archived from the original on 30 September 2009.\n- \"George Stibitz (1904–1995)\". www.kerryr.net. Kerry Redshaw. Archived from the original on 15 August 2017. Retrieved 6 June 2023.\n- Hafner, Katie (1998). Where Wizards Stay Up Late: The Origins Of The Internet. Simon & Schuster. ISBN 978-0-684-83267-8.\n- Hilbert, Martin; López, Priscila (2011). \"The World's Technological Capacity to Store, Communicate, and Compute Information\". Science. 332 (6025): 60–65. Bibcode:2011Sci...332...60H. doi:10.1126/science.1200970. PMID 21310967. S2CID 206531385.\n- \"video animation\". The Economist. Archived from the original on 18 January 2012.\n- \"Worldwide Telecommunications Industry Revenues\". Plunkett's Telecommunications Industry Almanac 2010. 1 June 2010. Archived from the original on 28 March 2010.\n- \"Introduction to the Telecommunications Industry\". Plunkett Research. Archived from the original on 22 October 2012.\n- Haykin, Simon (2001). Communication Systems (4th ed.). John Wiley & Sons. pp. 1–3. ISBN 978-0-471-17869-9.\n- Ambardar, Ashok (1999). Analog and Digital Signal Processing (2nd ed.). Brooks. pp. 1–2. ISBN 978-0-534-95409-3.\n- \"Coax Cable FAQ Series: What is RG Cable? – Conwire\". Conwire. 12 January 2016. Archived from the original on 8 August 2017. Retrieved 7 August 2017.\n- Haykin, pp. 344–403.\n- Bluetooth Specification Version 2.0 + EDR Archived 14 August 2014 at the Wayback Machine (p. 27), Bluetooth, 2004.\n- Haykin, pp. 88–126.\n- \"ATIS Telecom Glossary 2000\". ATIS Committee T1A1 Performance and Signal Processing (approved by the American National Standards Institute). 28 February 2001. Archived from the original on 2 March 2008.\n- Lenert, Edward (December 1998). \"A Communication Theory Perspective on Telecommunications Policy\". Journal of Communication. 48 (4): 3–23. doi:10.1111/j.1460-2466.1998.tb02767.x.\n- Mireille Samaan (April 2003). The Effect of Income Inequality on Mobile Phone Penetration (Honors thesis). Boston University. Archived from the original (PDF) on 14 February 2007. Retrieved 8 June 2007.\n- Röller, Lars-Hendrik; Leonard Waverman (2001). \"Telecommunications Infrastructure and Economic Development: A Simultaneous Approach\". American Economic Review. 91 (4): 909–23. CiteSeerX 10.1.1.202.9393. doi:10.1257/aer.91.4.909. ISSN 0002-8282.\n- Christine Zhen-Wei Qiang and Carlo M. Rossotto with Kaoru Kimura. \"Economic Impacts of Broadband\" (PDF). siteresources.worldbank.org. Archived from the original on 12 August 2020. Retrieved 31 March 2016.\n- Riaz, Ali (1997). \"The role of telecommunications in economic growth: proposal for an alternative framework of analysis\". Media, Culture & Society. 19 (4): 557–83. doi:10.1177/016344397019004004. S2CID 154398428.\n- \"Digital Access Index (DAI)\". itu.int. Archived from the original on 2 January 2019. Retrieved 6 March 2008.\n- \"World Telecommunication Development Report 2003: Access Indicators for the Information Society: Executive Summary\" (PDF). International Telecommunication Union (ITU). December 2003. p. 22. Archived (PDF) from the original on 6 June 2023. Retrieved 6 June 2023.\n- Fischer, Claude S. (January 1988). \"Touch Someone: The Telephone Industry Discovers Sociability\". Technology and Culture. 29 (1): 32–61. doi:10.2307/3105226. JSTOR 3105226. S2CID 146820965.\n- \"How do you know your love is real? Check Facebook\". CNN. 4 April 2008. Archived from the original on 6 November 2017. Retrieved 8 February 2009.\n- \"I Just Text To Say I Love You\". Ipsos MORI. September 2005. Archived from the original on 27 December 2016.\n- \"Online News: For many home broadband users, the internet is a primary news source\" (PDF). Pew Internet Project. 22 March 2006. Archived from the original (PDF) on 21 October 2013.\n- \"100 Leading National Advertisers\" (PDF). Advertising Age. 23 June 2008. Archived (PDF) from the original on 27 July 2011. Retrieved 21 June 2009.\n- \"International Telecommunication Union : About ITU\". ITU. Archived from the original on 15 July 2009. Retrieved 21 July 2009.PDF) Archived 7 June 2011 at the Wayback Machine of regulation)\n- Codding, George A. (1955). \"Jamming and the Protection of Frequency Assignments\". American Journal of International Law. 49 (3): 384–388. doi:10.1017/S0002930000170046. JSTOR 2194872.\n- Wood, James (1992). History of international broadcasting. P. Peregrinus Limited. p. 2. ISBN 9780863413025.\n- Garfield, Andrew (Fall 2007). \"The U.S. Counter-propaganda Failure in Iraq\". Middle East Quarterly. 14 (4): 23–32. Archived from the original on 2 March 2009 – via Middle East Forum.\n- Wyatt, Edward (10 November 2014). \"Obama Asks F.C.C. to Adopt Tough Net Neutrality Rules\". New York Times. Archived from the original on 27 April 2019. Retrieved 15 November 2014.\n- \"Why the F.C.C. Should Heed President Obama on Internet Regulation\". New York Times. 14 November 2014. Archived from the original on 9 July 2018. Retrieved 15 November 2014.\n- McGill, Margaret Harding (26 September 2022). \"FCC takes long-delayed step against spam text surge\". Axios. Archived from the original on 8 February 2023. Retrieved 8 February 2023.\n- Hall, Madison. \"Robocallers are preying on the elderly with fake Medicare calls. It's a no-brainer to stop it, but nobody has\". Business Insider. Archived from the original on 7 February 2023. Retrieved 8 February 2023.\n- \"Affordable Broadband: FCC Could Improve Performance Goals and Measures, Consumer Outreach, and Fraud Risk Management\". www.gao.gov. February 2023. Archived from the original on 8 February 2023. Retrieved 8 February 2023.\n- Arthur, Charles (4 March 2009). \"Why falling PC sales means Windows 7 is on the way\". The Guardian. ISSN 0261-3077. Archived from the original on 19 May 2017. Retrieved 6 June 2023.\n- \"Mobile Phone Sales To Exceed One Billion in 2009\". Palm Infocenter. 21 July 2005. Archived from the original on 8 March 2018. Retrieved 6 June 2023.\n- Reimer, Jeremy (15 December 2005). \"Total share: 30 years of personal computer market share figures\". Ars Technica. Archived from the original on 12 May 2015. Retrieved 6 June 2023.\n- Hacker, Michael; Burghardt, David; Fletcher, Linnea; Gordon, Anthony; Peruzzi, William (3 April 2015). Engineering and Technology. Cengage Learning. p. 433. ISBN 978-1305855779.\n- \"Gartner Says Top Six Vendors Drive Worldwide Mobile Phone Sales to 21% Growth in 2005\" (Press release). Gartner. 28 February 2006. Archived from the original on 10 May 2012.\n- Mbarika, V.W.A.; Mbarika, I. (2006). \"Africa calling [African wireless connection]\". IEEE Spectrum. 43 (5): 56–60. doi:10.1109/MSPEC.2006.1628825. S2CID 30385268.\n- \"Ten Years of GSM in Australia\". Australia Telecommunications Association. 2003. Archived from the original on 20 July 2008.\n- \"Milestones in AT&T History\". AT&T Knowledge Ventures. 2006. Archived from the original on 6 September 2008.\n- Bhatti, Saleem (1995). \"Optical fibre waveguide\". Archived from the original on 24 May 2006.\n- \"Fundamentals of DWDM Technology\" (PDF). Cisco Systems. 2006. Archived from the original (PDF) on 9 August 2012.\n- Jander, Mary (15 April 2003). \"Report: DWDM No Match for Sonet\". Light Reading. Archived from the original on 24 July 2012.\n- Stallings, William (2004). Data and Computer Communications (7th intl ed.). Pearson Prentice Hall. pp. 337–66. ISBN 978-0-13-183311-1.\n- Dix, John (2002). \"MPLS is the future, but ATM hangs on\". Network World. Archived from the original on 6 July 2007.\n- Lazar, Irwin (22 February 2011). \"The WAN Road Ahead: Ethernet or Bust?\". Telecom Industry Updates. Archived from the original on 2 April 2015. Retrieved 22 February 2011.\n- \"How Radio Works\". HowStuffWorks. 7 December 2000. Archived from the original on 2 January 2016. Retrieved 12 February 2023.\n- \"Digital Television in Australia\". Digital Television News Australia. Archived from the original on 12 March 2018. Retrieved 6 June 2023.\n- Stallings, William (2004). Data and Computer Communications (7th intl ed.). Pearson Prentice Hall. ISBN 978-0-13-183311-1.\n- \"HDV Technology Handbook\" (PDF). Sony. 2004. Archived from the original (PDF) on 23 June 2006.\n- \"Audio\". Digital Video Broadcasting Project. 2003. Archived from the original on 27 September 2006.\n- \"Status of DAB (US)\". World DAB Forum. March 2005. Archived from the original on 21 July 2006.\n- Brian Stelter (13 June 2009). \"Changeover to Digital TV Off to a Smooth Start\". New York Times. Archived from the original on 14 December 2017. Retrieved 25 February 2017.\n- \"DAB Products\". World DAB Forum. 2006. Archived from the original on 21 June 2006.\n- Kahn, Robert; Cerf, Vinton G. (December 1999). \"What Is The Internet (And What Makes It Work)\". Corporation for National Research Initiatives (CNRI). Archived from the original on 15 July 2017. Retrieved 6 June 2023.\n- Jeff Tyson (2007). \"How Internet Infrastructure Works\". Computer.HowStuffWorks.com. Archived from the original on 10 April 2010. Retrieved 22 May 2007.\n- \"World Internet Users and Population Stats\". Internet World Stats. 30 June 2008. Archived from the original on 2 February 2009.\n- \"OECD Broadband Statistics, December 2005\". OECD. Archived from the original on 6 January 2009.\n- Kozierok, Charles M. (2005). \"The TCP/IP Guide - History of the OSI Reference Model\". The TCP/IP Guide. Archived from the original on 4 September 2017. Retrieved 6 June 2023.\n- \"Introduction to IPv6\". Microsoft Corporation. February 2006. Archived from the original on 13 October 2008.\n- Stallings, pp. 683–702.\n- T. Dierks and C. Allen, The TLS Protocol Version 1.0, RFC 2246, 1999.\n- Multimedia, Crucible (7 May 2011). \"VoIP, Voice over Internet Protocol and Internet telephone calls\". Archived from the original on 24 January 2018. Retrieved 30 June 2011.\n- Martin, Michael (2000). \"Understanding the Network\". The Networker's Guide to AppleTalk, IPX, and NetBIOS (PDF). SAMS Publishing. ISBN 0-7357-0977-7. Archived from the original (PDF) on 29 March 2009.\n- Droms, Ralph (November 2003). \"Resources for DHCP\". Archived from the original on 4 July 2007.\n- Stallings, pp. 500–26.\n- Stallings, pp. 514–16.\n- \"Fiber Optic Cable single-mode multi-mode Tutorial\". ARC Electronics. Archived from the original on 23 October 2018. Retrieved 6 June 2023.\n- Goggin, Gerard, Global Mobile Media (New York: Routledge, 2011), p. 176. ISBN 978-0-415-46918-0.\n- OECD, Universal Service and Rate Restructuring in Telecommunications, Organisation for Economic Co-operation and Development (OECD) Publishing, 1991. ISBN 92-64-13497-2.\n- Wheen, Andrew. Dot-Dash to Dot.Com: How Modern Telecommunications Evolved from the Telegraph to the Internet (Springer, 2011).\n- International Teletraffic Congress\n- International Telecommunication Union (ITU)\n- ATIS Telecom Glossary\n- Federal Communications Commission\n- IEEE Communications Society\n- International Telecommunication Union\n- Ericsson's Understanding Telecommunications at the Wayback Machine (archived 13 April 2004) (Ericsson removed the book from their site in September 2005)",
    "television production": "A television show, TV program (British English: programme), or simply a TV show, is the general reference to any content produced for viewing on a television set that is transmitted via over-the-air, satellite, and cable, or distributed digitally on streaming platforms.[1][2] This generally excludes breaking news or advertisements that are aired between shows or between segments of a show. A regularly recurring show is called a television series, and an individual segment of such a series is called an episode. Content is produced either in-house on a television stage with multiple cameras or produced by contract with film production companies. Episodes are usually broadcast in annual sets, which are called seasons in North America and series in other regions. A one-off television show may be called a television special, while a show with a limited number of episodes is a miniseries.[a] A television film, or telefilm, is a feature film produced for broadcast by a terrestrial or cable network.\nTelevision shows by terrestrial and cable networks are most often scheduled for broadcast ahead of time and appear on electronic guides or other TV listings. The rise of streaming television, however, has made television schedules less relevant than in earlier decades. Some programming may be aired live—that is, events are broadcast at the time they happen rather than at a later time or date—but the vast majority of programming is produced ahead of time. Originally, viewers had no practical way to record a show for later viewing; this changed with the advent of home video, first in the form of videotape recorded on VCRs and later in the form of digital video recorders. Cable television providers began offering certain programming \"pay-per-view\" or on-demand, with viewers paying a one-time fee to watch a program at a time of their own choosing. Streaming television allows viewers to watch programming at any time with a subscription to the OTT platform service.\nHistory\nThe first television shows were experimental, sporadic broadcasts viewable only within a very short range from the broadcast tower starting in the 1930s. Televised events such as the 1936 Summer Olympics in Germany, the 1937 coronation of King George VI in the United Kingdom, and David Sarnoff's famous introduction at the 1939 New York World's Fair in the United States spurred growth in the medium, but World War II put a halt to development until after the war. The 1947 World Series inspired many Americans to buy their first television set, and then in 1948, the popular radio show Texaco Star Theater made the move and became the first weekly televised variety show, earning host Milton Berle the name \"Mr. Television\", and demonstrating that the medium was a stable, modern form of entertainment that could attract advertisers. The first national live television broadcast in the US took place on September 4, 1951, when President Harry Truman's speech at the Japanese Peace Treaty Conference in San Francisco was transmitted over AT&T's transcontinental cable and microwave radio relay system to broadcast stations in local markets.[5][6][7]\nThe first national color broadcast (the 1954 Tournament of Roses Parade) in the US occurred on January 1, 1954. During the following ten years, most network broadcasts, and nearly all local programming, continued to be in black-and-white. The color transition was announced for the fall of 1965, during which over half of all network prime-time programming would be broadcast in color. The first all-color prime-time season came just one year later. In 1972, the last holdout among daytime network shows converted to color, resulting in the first completely all-color network season.\nFormats and genres\nTelevision shows are more varied than most other forms of media due to the wide variety of formats and genres that can be presented. A show may be fictional (as in comedies and dramas), or non-fictional (as in documentary, news, and reality television). It may be topical (as in the case of a local newscast and some made-for-television films), or historical (as in the case of many documentaries and fictional series). They could be primarily instructional, educational, or entertaining, as is the case in situation comedy and game shows.[citation needed]\nA drama program usually features a set of actors playing characters in a historical or contemporary setting. The program follows their lives and adventures. Before the 1980s, shows (except for soap opera-type serials) typically remained static without story arcs, and the main characters and premise changed little.[citation needed] If some change happened to the characters' lives during the episode, it was usually undone by the end. Due to this, the episodes could be broadcast in any order.[citation needed] Since the 1980s, many series feature progressive change in the plot, the characters, or both. For instance, Hill Street Blues and St. Elsewhere were two of the first US prime time drama television series to have this kind of dramatic structure,[8][better source needed] while the later series Babylon 5 further exemplifies such structure in that it had a predetermined story running over its intended five-season run.[citation needed]\nIn 2012, it was reported that television was growing into a larger component of major media companies' revenues than film.[9] Some also noted the increase in quality of some television programs. In 2012, Academy Award-winning film director Steven Soderbergh, commenting on ambiguity and complexity of character and narrative, stated: \"I think those qualities are now being seen on television, and that people who want to see stories that have those kinds of qualities are watching television.\"[10]\nProduction\nDevelopment\nUnited States\nWhen a person or company decides to create new content for television broadcast, they develop the show's elements, consisting of the concept, the characters, the crew, and the cast. Then they often \"pitch\" it to the various networks in an attempt to find one interested enough to order a prototype for the first episode of the series, known as a pilot.[11] Eric Coleman, an animation executive at Disney, told an interviewer, \"One misconception is that it's very difficult to get in and pitch your show, when the truth is that development executives at networks want very much to hear ideas. They want very much to get the word out on what types of shows they're looking for.\"[12]\nTo create the pilot, the structure and team of the whole series must be put together. If audiences respond well to the pilot, the network will pick up the show to air it the next season.[citation needed] Sometimes they save it for mid-season or request rewrites and additional review.[citation needed] Other times, they pass entirely, forcing the show's creator to \"shop it around\" to other networks. Many shows never make it past the pilot stage.[13]\nUnited Kingdom\nThe method of \"team writing\" is employed on some longer dramatic series (usually running up to a maximum of around 13 episodes). The idea for such a program may be generated \"in-house\" by one of the networks; it could originate from an independent production company (sometimes a product of both). For instance, the BBC's long-running soap opera EastEnders is wholly a BBC production, whereas its popular drama Life on Mars was developed by Kudos in association with the broadcaster.\nThere are still a significant number of programs (usually sitcoms) that are built by just one or two writers and a small, close-knit production team. These are \"pitched\" in the traditional way, but since the creators handle all the writing requirements, there is a run of six or seven episodes per series once approval has been given. Many of the most popular British comedies have been made this way, including Monty Python's Flying Circus (albeit with an exclusive team of six writer-performers), Fawlty Towers, Blackadder and The Office.\nOther nations\nThe production company is often separate from the broadcaster. The executive producer, often the show's creator, is in charge of running the show. They pick the crew and help cast the actors, approve and sometimes write series plots—some even write or direct major episodes—while various other producers help to ensure that the show runs smoothly. Very occasionally, the executive producer will cast themselves in the show. As with filmmaking or other electronic media production, producing of an individual episode can be divided into three parts: pre-production, principal photography, and post-production.\nPre-production\nPre-production begins when a script is approved. A director is chosen to plan the episode's final look. Pre-production tasks include storyboarding; construction of sets, props, and costumes; casting guest stars; budgeting; acquiring resources like lighting, special effects, stunts, etc. Once the show is planned, it must then be scheduled: scenes are often filmed out of sequence, and guest actors or even regulars may only be available at certain times. Sometimes the principal photography of different episodes must be done at the same time, complicating the schedule (a guest star might shoot scenes from two episodes on the same afternoon). Complex scenes are translated from storyboard to animatics to further clarify the action. Scripts are adjusted to meet altering requirements.\nSome shows have a small stable of directors, but also usually rely on outside directors. Given the time constraints of broadcasting, a single show might have two or three episodes in pre-production, one or two episodes in principal photography, and a few more in various stages of post-production. The task of directing is complex enough that a single director can usually not work on more than one episode or show at a time, hence the need for multiple directors.\nPrincipal photography\nPrincipal photography is the actual filming of the episode. Director, actors, and crew gather at a television studio or on location for filming or videoing a scene. A scene is further divided into shots, which should be planned during pre-production. Depending on scheduling, a scene may be shot in non-sequential order of the story. Conversations may be filmed twice from different camera angles, often using stand-ins, so one actor might perform all their lines in one set of shots, and then the other side of the conversation is filmed from the opposite perspective. To complete a production on time, a second unit may be filming a different scene on another set or location at the same time, using a different set of actors, an assistant director, and a second unit crew. A director of photography supervises the lighting of each shot to ensure consistency.\nLive events are usually covered by Outside Broadcast crews using mobile television studios, known as scanners or OB trucks. Although varying greatly depending on the era and subject covered, these trucks were normally crewed by up to 15 skilled operators and production personnel. In the UK for most of the 20th century, the BBC was the preeminent provider of outside broadcast coverage. BBC crews worked on almost every major event, including Royal weddings and funerals, major political and sporting events, and even drama programs.[14]\nPost-production\nOnce principal photography is complete, producers coordinate tasks to begin the video editing. Visual and digital video effects are added to the film; this is often outsourced to companies specializing in these areas. Often music is performed with the conductor using the film as a time reference (other musical elements may be previously recorded). An editor cuts the various pieces of film together, adds the musical score and effects, determines scene transitions, and assembles the completed show.\nBudgets and revenues\nMost television networks throughout the world are 'commercial', dependent on selling advertising time or acquiring sponsors.[citation needed] Broadcasting executives' main concern over their programming is audience size.[citation needed] In the past, the number of 'free to air' stations was restricted by the availability of channel frequencies, but cable TV (outside the United States, satellite television) technology has allowed an expansion in the number of channels available to viewers (sometimes at premium rates) in a much more competitive environment.[citation needed]\nIn the United States, the average broadcast network drama costs $3 million an episode to produce, while cable dramas cost $2 million on average.[15] The pilot episode may be more expensive than a regular episode.[citation needed] In 2004, Lost's two-hour pilot cost $10 to $14 million, in 2008, Fringe's two-hour pilot cost $10 million, and in 2010, Boardwalk Empire was $18 million for the first episode. In 2011, Game of Thrones was $5 to $10 million, Pan Am cost an estimated $10 million, while Terra Nova's two-hour pilot was between $10 and $20 million.[16][17]\nMany scripted network television shows in the United States are financed through deficit financing: a studio finances the production cost of a show and a network pays a license fee to the studio for the right to air the show. This license fee does not cover the show's production costs, leading to the deficit. Although the studio does not make its money back in the original airing of the show, it retains ownership of the show. This allows the studio to make its money back and earn a profit through syndication and sales of DVDs and Blu-rays. This system places most of the financial risk on the studios; however, a hit show in the syndication and home video markets can more than make up for the misses. Although deficit financing places minimal financial risk on the networks, they lose out on the future profits of big hits since they are only licensing the shows.[18]\nCosts are recouped mainly by advertising revenues for broadcast networks and some cable channels, while other cable channels depend on subscriptions. In general, advertisers, and consequently networks that depend on advertising, are more interested in the number of viewers within the 18–49 age range than in the total number of viewers.[19][20] Advertisers are willing to pay more to advertise on shows successful with young adults because they watch less television and are harder to reach.[21] According to Advertising Age, during the 2007–08 season, Grey's Anatomy was able to charge $419,000 per commercial, compared to only $248,000 for a commercial during CSI, despite CSI having almost five million more viewers on average.[22] Due to its strength with younger viewers, Friends was able to charge almost three times as much for a commercial as Murder, She Wrote, even though the two series had similar total viewer numbers at that time.[19] Glee and The Office drew fewer total viewers than NCIS during the 2009–10 season, but earned an average of $272,694 and $213,617 respectively, compared to $150,708 for NCIS.[23]\nDistribution\nAfter production, the show is handed over to the television network, which sends it out to its affiliate stations, which broadcast it in the specified broadcast programming time slot. If the Nielsen ratings are good, the show is kept alive as long as possible. If not, the show is usually canceled. The show's creators are then left to shop around for remaining episodes, and the possibility of future episodes, on other networks. On especially successful series, the producers sometimes call a halt to a series on their own like Seinfeld, The Cosby Show, Corner Gas, and M*A*S*H and end it with a concluding episode, which sometimes is a big series finale.\nOn rare occasions, a series that has not attracted particularly high ratings and has been canceled can be given a reprieve if home video viewership has been particularly strong. This has happened in the cases of Family Guy in the US and Peep Show in the UK.\nIn the United States, if the show is popular or lucrative, and a minimum number of episodes (usually 100) have been made, it can go into broadcast syndication, where rights to broadcast the program are then resold for cash or put into a barter exchange (offered to an outlet for free in exchange for airing additional commercials elsewhere in the station's broadcast day).\nThe terminology used to define a set of episodes produced for a television series varies from country to country.\nNorth American usage\nIn North American television, a series is a connected set of television program episodes that run under the same title, possibly spanning many seasons. During the 1950s, it was common for television seasons to consist of more than 30 episodes—however, the average length has been declining since.[24]\nUntil the 1980s, most new programs for the US broadcast networks debuted in the \"fall season\", which ran from September through March and nominally contained 24 to 26 episodes. These episodes were rebroadcast during the spring (or summer) season, from April through August. Because of cable television and the Nielsen sweeps, the \"fall\" season now normally extends to May. Thus, a \"full season\" on a broadcast network now usually runs from September through May for at least 22 episodes.[25]\nJericho on CBS. When this split occurs, the last half of the episodes are sometimes referred to with the letter B as in \"The last nine episodes (of The Sopranos) will be part of what is being called either 'Season 6, Part 2' or 'Season 6B'\",[26] or \"Futurama is splitting its seasons similar to how South Park does, doing half a season at a time, so this is season 6B for them.\"[27] Since the 1990s, these shorter seasons also have been referred to as \"split\" or \"half\" seasons, which is done to increase profits, as seen with shows such as The Witcher.[28]\nSince at least the 2000s, new broadcast television series are often ordered (funded) for just the first 10 to 13 episodes, to gauge audience interest. If a series is popular, the network places a \"back nine order\" and the season is completed to the regular 20 to 26 episodes. An established series that is already popular, however, will typically receive an immediate full-season order at the outset of the season. A midseason replacement is a less-expensive short-run show of generally 10 to 13 episodes designed to take the place of an original series that failed to garner an audience and has not been picked up. A \"series finale\" is the last show of the series before the show is no longer produced. (In the UK, it means the end of a season, what is known in the United States as a \"season finale\".) Streaming services time finales to the next quarter to induce consumers to renew at least one more quarter.[29]\nA standard television season in the United States runs predominantly during autumn.[30] During the summer months of June through roughly mid-September, network schedules typically feature reruns of their flagship programs, first-run series with lower rating expectations, and other specials. First-run scripted series are typically shorter and of a lower profile than those aired during the main season and can also include limited series events. Reality and game shows have also been fixtures of the schedule.[30]\nIn Canada, the commercial networks air most US programming in tandem with the US television season, but their original Canadian shows follow a model closer to British than US television production. Due to the smaller production budgets available in Canada, a Canadian show's season normally runs to a maximum of 13 episodes rather than 20 or more, although an exceptionally popular series such as Corner Gas or Murdoch Mysteries might receive 20-episode orders in later seasons. Canadian shows do not normally receive \"back nine\" extensions within the same season, however; even a popular series simply ends for the year when the original production order has finished airing, and an expanded order of more than 13 episodes is applied to the next season's renewal order rather than an extension of the current season. Only the public CBC Television normally schedules Canadian-produced programming throughout the year; the commercial networks typically now avoid scheduling Canadian productions to air in the fall, as such shows commonly get lost amid the publicity onslaught of the US fall season. Instead, Canadian-produced shows on the commercial networks typically air either in the winter as mid-season replacements for canceled US shows or in the summer (which may also improve their chances of being picked up by a US network for a summer run).[31]\nWhile network orders for 13- or 22-episode seasons are still pervasive in the television industry, several shows have deviated from this traditional trend. Written to be closed-ended and of shorter length than other shows, they are marketed with a variety of terms.\n- Miniseries: A very short, closed-ended series, typically six or more hours in two or more parts (nights), similar to an extended television movie. Many early miniseries were adaptations of popular novels of the day, such as The National Dream (1974), Roots (1977), and North and South (1985). In recent years, as described by several television executives interviewed by The Hollywood Reporter, the term miniseries has grown to have negative connotations within the industry, having become associated with melodrama-heavy works that were commonly produced under the format, while limited series or event series receive higher respect.[32]\n- Limited series: Distinct from miniseries in that the production is seen to have potential to be renewed, but without the requirement of it having as many episodes as a typical order per season. Under the Dome, Killer Women, and Luther were marketed as limited series. Individual season-length stories of anthology series such as American Horror Story, Fargo, and True Detective are also described as \"limited series\". The Primetime Emmys have had to make numerous changes to their miniseries/limited series category to accommodate anthology and other limited series.[33]\n- Event series: Largely considered a marketing term, falling under the general category of event television. The term can be applied to almost any new, short-run series, such as 24: Live Another Day. It has also been used to describe game shows like The Million Second Quiz which aired for just two weeks.[32]\nIn the United Kingdom and other countries, these sets of episodes are referred to as a \"series\". In Australia, the broadcasting may be different from North American usage. The terms series and season are both used and are the same. For example, Battlestar Galactica has an original series as well as a remake, both are considered a different series, each with their own number of individual seasons.\nAustralian television does not follow \"seasons\" in the way that US television does; for example, there is no \"fall season\" or \"fall schedule\". For many years, popular night-time dramas in Australia would run for much of the year, and would only go into recess during the summer period (December to February, as Australia is in the Southern Hemisphere), when ratings are not taken. Therefore, popular dramas would usually run from February through November each year. This schedule was used in the 1970s for popular dramas, including Number 96. Many drama series, such as McLeod's Daughters, have received between 22 and 32 episodes per season.\nTypically, soap operas, which have always run in season format in Australia, such as Home and Away, would usually begin a new season in late January, while the season finale would air in late November, as the show is off air for two months, or sometimes longer, depending on the schedule. In recent years,[when?] a new season would begin in early February, and the season finale would broadcast in early December. Since Home and Away's inception, it normally receives 230 episodes per season. Some seasons have seen between 205 and 235 episodes commissioned. During the Olympics, Home and Away would often go on hiatus, which was referred to as an \"Olympic cliffhanger\". Therefore, the number of episodes would decrease. Australian situation comedy series' seasons are approximately 13 episodes long and premiere any time between February and November.\nBritish television programmes have tended toward shorter series in recent years. For example, the first series of long-running science fiction show Doctor Who in 1963 featured forty-two 25‑minute episodes, and continued with a similar number each year until it was reduced to twenty-five for 1970 to accommodate changes in production and significantly reducing the actors' workload) and continued to 1984. For 1985 fewer but longer episodes were shown, but even after a return to shorter episodes in 1986, lack of support within the BBC meant fewer episodes were commissioned leading to only fourteen 25‑minute episodes up to those in 1989 after which it was cancelled. The revival of Doctor Who from 2005 has comprised thirteen 45‑minute installments.\nThere are some series in the UK that have a larger number of episodes, for example Waterloo Road started with 8 to 12 episodes, but from series three onward it increased to twenty episodes and series seven will contain 30 episodes. Recently, US non-cable networks have also begun to experiment with shorter series for some programs, particularly reality shows, such as Survivor. They often air two series per year, resulting in roughly the same number of episodes per year as a drama.\nThis is a reduction from the 1950s, in which many US shows (e.g. Gunsmoke) had between 29 and 39 episodes per season. Actual storytelling time within a commercial television hour has also gradually reduced over the years, from 50 minutes out of every 60 to the current 44 (and even less on some networks), beginning in the early 21st century.\nThe usage of \"season\" and \"series\" differ for DVD and Blu-ray releases in both Australia and the UK. In Australia, many locally produced shows are termed differently on home video releases. For example, a set of the television drama series Packed to the Rafters or Wentworth is referred to as \"season\" (\"The Complete First Season\", etc.), whereas drama series such as Tangle are known as a \"series\" (\"Series 1\", etc.). British-produced programmes such as Mrs. Brown's Boys are referred to as \"season\" in Australia for the DVD and Blu-ray releases.\nIn the UK and Ireland, most programmes are referred to as 'series' while 'season' is starting to be used for some US and international releases.\nEgypt\nThe 1980s and 1990s was the golden age of television miniseries attracting millions of Egyptians. For example, The Family of Mr Shalash miniseries, starring Salah Zulfikar and Laila Taher, was the highest rated at the time.[34]\nRunning time\nIn the United States, dramas produced for hour-long time slots typically are 37–42 minutes in length (excluding advertisements), while sitcoms produced for 30-minute time slots typically are 18–21 minutes long. There are exceptions: subscription-based cable TV channels, such as HBO, Starz, Cinemax, and Showtime, have episodes that are 45–48 minutes long, similar to the UK. Audience opinions of length have varied due to factors such as content overload.[35]\nIn Britain, dramas typically run from 46–48 minutes on commercial channels, and 57–59 minutes on the BBC. Half-hour programs are around 22 minutes on commercial channels and around 28 minutes on the BBC. The longer duration on the BBC is due to the lack of advertising breaks.\nIn France, most television shows (whether dramas, game shows or documentaries) have a duration of 52 minutes. This is the same on nearly all French networks (TF1, France 2, France 5, M6, Canal+, etc.).[36]\nThe episode runtime of television shows produced for streaming platforms, such as Netflix and Hulu, can vary from just under 30 minutes to over one hour long.[37][38] Internet-based series with episode runtimes of less than 25 minutes are considered web series.[37]\nSee also\n- Radio program\n- Lists of actors by television series\n- Lists of television programs\n- List of American public access television programs\nNotes\nReferences\n- Willcox, James K. (June 27, 2017). \"The Many Ways to Watch Television\". Consumer Reports. Archived from the original on August 17, 2020.\n- Pedersen, Erik (June 27, 2025). \"2025 Premiere Dates For New & Returning Series On Broadcast, Cable & Streaming\". Deadline Hollywood. Archived from the original on June 27, 2025. Retrieved 28 June 2025.\n- Mitra, Mallika (July 24, 2019). \"Miniseries may be the competitive edge streamers are looking for\". CNBC.\n- \"Miniseries - Definition, Usage & Quiz\". Ultimate Lexicon. September 17, 2024.\n- \"Truman to Be Televised In First National Hook-Up\", The New York Times, September 4, 1951, p. 2.\n- \"Television Highlights\", The Washington Post, September 4, 1951, p. B13.\n- \"Coast to Coast Television\" (CBS advertisement), The Wall Street Journal, September 4, 1951, p. 9.\n- Arneson, Erik. \"Hill Street Blues: A Cop TV Turning Point\". Mysterynet. Archived from the original on June 27, 2009.\n- Lang, Brent (June 6, 2012). \"Why Television Is Trouncing Film at Major Media Companies\". TheWrap.com. Archived from the original on April 2, 2019. Retrieved June 30, 2012.\n- Zakarin, Jordan (June 29, 2012). \"Steven Soderbergh Hints at Switch to Television\". The Hollywood Reporter.\n- Basile, Nancy (April 15, 2019). \"What Is a Pilot Episode?\". LiveAbout.\n- Heintjies, Tom (September 21, 2012). \"The Oral History of SpongeBob SquarePants\". No. #17. Hogan's Alley. Retrieved November 14, 2017.\n- \"The Whole Crazy Process Of Creating A TV Show, From Pitch To Pilot\". Gizmodo. January 23, 2015. Retrieved January 28, 2022.\n- Ellis, John; Hall, Nick (2017): ADAPT. figshare. Collection.https://doi.org/10.17637/rh.c.3925603.v1\n- Carter, Bill (April 4, 2010). \"Weighty Dramas Flourish on Cable\". The New York Times. Retrieved October 18, 2011.\n- Fernandez, Sofia M. (September 26, 2011). \". The Hollywood Reporter. Retrieved October 19, 2011.\n- Barnes, Brooks (August 28, 2011). \"Prime Time Ambitions\". The New York Times. Retrieved October 19, 2011.\n- Lotz, Amanda (2007). The Television will be Revolutionized. New York and London: New York University Press. pp. 82–85.\n- Storey, Michael (April 23, 2009). \"THE TV COLUMN: Not in 18–49 age group? TV execs write you off\". Arkansas Democrat Gazette. Retrieved May 2, 2008.\n- Carter, Bill (April 6, 2010). \"An 'Idol' Ratings Loss, but Not in Its Pocketbook\". The New York Times. Retrieved April 8, 2010.\n- \"ABC, \"Dancing with the Stars\" Again Top Monday Television Ratings\". City News Service. Beverly Hills Courier. Archived from the original on October 24, 2011. Retrieved October 19, 2011.\n- Santiago, Rosario (October 3, 2007). \"For Advertising Purposes, 'Grey's Anatomy' May Well be Colored Green\". BuddyTV. Retrieved May 3, 2009.\n- Steinberg, Brian (October 18, 2010). \"Simon Who? 'Idol' Spots Still Priciest in Prime Time\". Advertising Age. Retrieved October 28, 2010.\n- Lindbergh, Ben (August 4, 2017). \"Mourning the Loss of the Long TV Season\". The Ringer. Retrieved January 22, 2024.\n- Schneider, Michael (July 8, 2015). \"Networks Put in Short Orders for Next Season\". TV Guide. Retrieved August 14, 2012.\n- \"Vacation's Over; 'The Sopranos' Returning for One Last Shot\". Milwaukee Journal. March 28, 2007. Archived from the original on November 4, 2015. Retrieved November 14, 2017.\n- Bozeman, Bobby (June 24, 2011). \"Pop Cultured: When summer and the Braves get you down, just flip around\". Anniston Star. Archived from the original on October 6, 2013. Retrieved November 14, 2017.\n- Gaughan, Liam (January 29, 2023). \"Splitting Seasons in Half Should Be the New Normal for Netflix Releases\". Collider. Retrieved January 22, 2024.\n- Dolye, John (May 11, 2021). \"Thank you, technology: It's been a long time since TV was 'a vast wasteland'. The Globe and Mail. Retrieved May 11, 2021.\n- Alexander, Brian. \"Where are my TV shows? Frustrated viewers' guide to strike-hit, reality-filled fall season\". USA TODAY. Retrieved January 22, 2024.\n- \"For Canadian TV, summer is the new growing season\". The Globe and Mail, June 8, 2011.\n- Rose, Lacey; Goldberg, Lesley (February 28, 2014). \"Heroes, 24: What's the Difference Between a 'Miniseries,' 'Limited' or 'Event' Series?\". The Hollywood Reporter. Retrieved November 30, 2017.\n- Turitz, Neil (June 11, 2015). \"From 'American Crime' to 'Wayward Pines,' Limited Series Invade Network TV\". Variety. Retrieved November 30, 2017.\n- Kijamii. \"15 Timeless Egyptian Series You Should Watch Over And Over Again\". NileFM. Archived from the original on September 15, 2021. Retrieved January 22, 2022.\n- Nguyen, Hanh (April 23, 2019). \"During Peak TV, Are Shorter Episode Runtimes Better? – IndieWire Critics Survey\". IndieWire. Retrieved January 22, 2024.\n- Morin, Fabien (March 9, 2015). \"Pourquoi les programmes durent-ils 52 minutes à la télévision ?\". TV Magazine (in French). Retrieved July 24, 2017.\n- Volpe, Allie (October 16, 2017). \"The One Thing That Isn't Evolving With Netflix & Hulu's Takeover of TV\". Thrillist. Retrieved 29 January 2025.\n- Schneider, Michael (February 24, 2022). \"Streaming Has Supersized TV Episodes, But How Long Is Too Long?\". Variety. Retrieved 29 January 2025.",
    "tourism industry": "Tourism is travel for pleasure, and the commercial activity of providing and supporting such travel.[1] UN Tourism defines tourism more generally, in terms which go \"beyond the common perception of tourism as being limited to holiday activity only\", as people \"travelling to and staying in places outside their usual environment for not more than one consecutive year for leisure and not less than 24 hours, business and other purposes\".[2] Tourism can be domestic (within the traveller's own country) or international. International tourism has both incoming and outgoing implications on a country's balance of payments.\nBetween the second half of 2008 and the end of 2009, tourism numbers declined due to a severe economic slowdown (see Great Recession) and the outbreak of the 2009 H1N1 influenza virus.[3][4] These numbers, however, recovered until the COVID-19 pandemic put an abrupt end to the growth.[5] The United Nations World Tourism Organization has estimated that global international tourist arrivals might have decreased by 58% to 78% in 2020, leading to a potential loss of US$0.9–1.2 trillion in international tourism receipts.[6]\nGlobally, international tourism receipts (the travel item in the balance of payments) grew to US$1.03 trillion (€740 billion) in 2005, corresponding to an increase in real terms of 3.8% from 2010.[7] International tourist arrivals surpassed the milestone of 1 billion tourists globally for the first time in 2012.[8] Emerging source markets such as China, Russia, and Brazil had significantly increased their spending over the previous decade.[9]\nGlobal tourism accounts for c. 8% of global greenhouse-gas emissions.[10] Emissions as well as other significant environmental and social impacts are not always beneficial to local communities and their economies. Many tourist development organizations are shifting focus to sustainable tourism to minimize the negative effects of growing tourism. This approach aims to balance economic benefits with environmental and social responsibility. The United Nations World Tourism Organization emphasized these practices by promoting tourism as part of the Sustainable Development Goals, through programs such as the International Year for Sustainable Tourism for Development in 2017.[11]\nThe English-language word tourist was used in 1772[12] and tourism in 1811.[13][14] These words derive from the word tour, which comes from Old English turian, from Old French torner, from Latin tornare, \"to turn on a lathe\", which is itself from Ancient Greek tornos (τόρνος), \"lathe\".[15]\nIn 1936, the League of Nations defined a foreign tourist as \"someone traveling abroad for at least twenty-four hours\". Its successor, the United Nations, amended this definition in 1945, by including a maximum stay of six months.[16]\nIn 1941, Hunziker and Kraft defined tourism as \"the sum of the phenomena and relationships arising from the travel and stay of non-residents, insofar as they do not lead to permanent residence and are not connected with any earning activity.\"[17][18] In 1976, the Tourism Society of England's definition was: \"Tourism is the temporary, short-term movement of people to destinations outside the places where they normally live and work and their activities during the stay at each destination. It includes movements for all purposes.\"[19] In 1981, the International Association of Scientific Experts in Tourism defined tourism in terms of particular activities chosen and undertaken outside the home.[20]\nIn 1994, the United Nations identified three forms of tourism in its Recommendations on Tourism Statistics:[21]\n- Domestic tourism, involving residents of the given country traveling only within this country\n- Inbound tourism,[22] involving non-residents traveling into the given country\n- Outbound tourism, involving residents traveling to another country\nOther groupings derived from the above grouping:[23]\n- National tourism, a combination of domestic and outbound tourism\n- Regional tourism, a combination of domestic and inbound tourism\n- International tourism, a combination of inbound and outbound tourism\nTourism has reached new dimensions with the emerging industry of space tourism, as well as the transoceanic cruise ship industry.\nThe terms tourism and travel are sometimes used interchangeably. In this context, travel has a similar definition to tourism but implies a more purposeful journey. The terms tourism and tourist are sometimes used pejoratively, to imply a shallow interest in the cultures or locations visited. By contrast, traveller is often used as a sign of distinction. The sociology of tourism has studied the cultural values underpinning these distinctions and their implications for class relations.[24]\nThere are many varieties of tourism. Of those types, there are multiple forms of outdoor-oriented tourism. Outdoor tourism is generally categorized into nature, eco, and adventure tourism (NEAT). These categories share many similarities but also possess definite and unique characteristics. Nature tourism generally encompasses tourism activities that would take place outside. Nature tourism appeals to a large audience of tourists and many may not know they are participating in this form of tourism. This type of tourism has a low barrier to entry and is accessible to a large population. Ecotourism focuses on education, maintaining a social responsibility for the community and the environment, as well as centering economic growth around the local economy. Weaver describes ecotourism as sustainable nature-based tourism.[25] Ecotourism is more specific than nature tourism and works toward accomplishing a specific goal through the outdoors. Finally, we have adventure tourism. Adventure tourism is the most extreme of the categories and includes participation in activities and sports that require a level of skill or experience, risk, and physical exertion.[25] Adventure tourism often appeals less to the general public than nature and ecotourism and tends to draw in individuals who partake in such activities with limited marketing.\nIt is important to understand that these definitions may vary. Perceived risk in adventure tourism is subjective and may change for each individual.\nExamples of these tourism types include...\nNature tourism\nEcotourism\n- Guided tours focusing on educating, summer camps, outdoor classes\nAdventure tourism\nAccording to the World Tourism Organization, a tourism product is:[26]\n\"a combination of tangible and intangible elements, such as natural, cultural, and man-made resources, attractions, facilities, services and activities around a specific center of interest which represents the core of the destination marketing mix and creates an overall visitor experience including emotional aspects for the potential customers. A tourism product is priced and sold through distribution channels and it has a life-cycle.\"\nA tourist map shows the functional zones of a city.[27] Tourism products cover a wide variety of services including:[28]\n- Accommodation services from low-cost homestays to five-star hotels\n- Hospitality services including food and beverage serving centers\n- Health care services like massages\n- All modes of transport, its booking and rental\n- Travel agencies, guided tours and tourist guides\n- Cultural services such as religious monuments, museums, and historical places\n- Shopping\n- Additional travel services like airport parking, airport hotels and travel insurance\nInternational tourism is tourism that crosses national borders. Globalization has made tourism a popular global leisure activity. The World Tourism Organization defines tourists as people \"traveling to and staying in places outside their usual environment for not more than one consecutive year for leisure, business and other purposes\".[29] The World Health Organization (WHO) estimates that up to 500,000 people are in flight at any one time.[30]\nIn 2010, international tourism reached US$919B, growing 6.5% over 2009, corresponding to an increase in real terms of 4.7%.[31] In 2010, there were over 940 million international tourist arrivals worldwide.[32] By 2016 that number had risen to 1,235 million, producing $1.22 trillion USD in destination spending.[33] The COVID-19 crisis had significant negative effects on international tourism significantly slowing the overall increasing trend.\nInternational tourism has significant impacts on the environment, exacerbated in part by the problems created by air travel but also by other issues, including wealthy tourists bringing lifestyles that stress local infrastructure, water and trash systems among others. In many countries, there have been protests against Air bnb tourism raising rents.\nTourism typically requires the tourist to feel engaged in a genuine experience of the location they are visiting. According to Dean MacCannell, tourism requires that the tourist can view the toured area as both authentic and different from their own lived experience.[34][35]: 113 [better source needed] By viewing the \"exotic,\" tourists learn what they themselves are not: that is, they are \"un-exotic,\" or normal.[35][better source needed]\nAccording to MacCannell, all modern tourism experiences the \"authentic\" and \"exotic\" as \"developmentally inferior\" to the modern—that is, to the lived experience of the tourist.[35]: 114 [better source needed]\nTravel outside a person's local area for leisure was largely confined to wealthy classes, who at times travelled to distant parts of the world, to see great buildings and works of art, learn new languages, experience new cultures, enjoy pristine nature and to taste different cuisines. As early as Shulgi, however, kings praised themselves for protecting roads and building way stations for travellers. Travelling for pleasure can be seen in Egypt as early on as 1500 BC. Ancient Roman tourists during the Republic would visit spas and coastal resorts such as Baiae. The Roman upper class used to spend their free time on land or at sea and travelled to their villa urbana or villa maritima. Numerous villas were located in Campania, around Rome and in the northern part of the Adriatic as in Barcola near Trieste. Pausanias wrote his Description of Greece in the second century AD. In ancient China, nobles sometimes made a point of visiting Mount Tai and, on occasion, all five Sacred Mountains.\nBy the post-classical era, many religions, including Christianity, Buddhism, and Islam had developed traditions of pilgrimage. The Canterbury Tales (c. 1390s), which uses a pilgrimage as a framing device, remains a classic of English literature, and Journey to the West (c. 1592), which holds a seminal place in Chinese literature, has a Buddhist pilgrimage at the center of its narrative.\nIn medieval Italy, Petrarch wrote an allegorical account of his 1336 ascent of Mont Ventoux that praised the act of travelling and criticized frigida incuriositas (a 'cold lack of curiosity'); this account is regarded as one of the first known instances of travel being undertaken for its own sake.[36][37] The Burgundian poet Michault Taillevent later composed his own horrified recollections of a 1430 trip through the Jura Mountains.[38]\nIn China, 'travel record literature' (遊記文學; yóujì wénxué) became popular during the Song Dynasty (960–1279).[39] Travel writers such as Fan Chengda (1126–1193) and Xu Xiake (1587–1641) incorporated a wealth of geographical and topographical information into their writing, while the 'daytrip essay' Record of Stone Bell Mountain by the noted poet and statesman Su Shi (1037–1101) presented a philosophical and moral argument as its central purpose. [40]\nModern tourism can be traced to what was known as the Grand Tour, which was a traditional trip around Europe (especially Germany and Italy), undertaken by mainly upper-class European young men of means, mainly from Western and Northern European countries. In 1624, the young Prince of Poland, Ladislaus Sigismund Vasa, the eldest son of Sigismund III, embarked on a journey across Europe, as was in custom among Polish nobility.[41] He travelled through territories of today's Germany, Belgium, the Netherlands, where he admired the siege of Breda by Spanish forces, France, Switzerland to Italy, Austria, and the Czech Republic.[41] It was an educational journey[42] and one of the outcomes was introduction of Italian opera in the Polish–Lithuanian Commonwealth.[43]\nThe custom flourished from about 1660 until the advent of large-scale rail transit in the 1840s and generally followed a standard itinerary. It was an educational opportunity and rite of passage. Though primarily associated with the British nobility and wealthy landed gentry, similar trips were made by wealthy young men of Protestant Northern European nations on the Continent, and from the second half of the 18th century some South American, US, and other overseas youth joined in. The tradition was extended to include more of the middle class after rail and steamship travel made the journey easier, and Thomas Cook made the \"Cook's Tour\" a byword.\nThe Grand Tour became a status symbol for upper-class students in the 18th and 19th centuries. In this period, Johann Joachim Winckelmann's theories about the supremacy of classic culture became very popular and appreciated in the European academic world. Artists, writers, and travellers (such as Goethe) affirmed the supremacy of classic art of which Italy, France, and Greece provide excellent examples. For these reasons, the Grand Tour's main destinations were to those centers, where upper-class students could find rare examples of classic art and history.\nThe New York Times recently described the Grand Tour in this way:\nThree hundred years ago, wealthy young Englishmen began taking a post-Oxbridge trek through France and Italy in search of art, culture and the roots of Western civilization. With nearly unlimited funds, aristocratic connections and months (or years) to roam, they commissioned paintings, perfected their language skills and mingled with the upper crust of the Continent.\nThe primary value of the Grand Tour, it was believed, laid in the exposure both to the cultural legacy of classical antiquity and the Renaissance, and to the aristocratic and fashionably polite society of the European continent.\nLeisure travel was associated with the Industrial Revolution in the United Kingdom – the first European country to promote leisure time to the increasing industrial population.[44] Initially, this applied to the owners of the machinery of production, the economic oligarchy, factory owners and traders. These comprised the new middle class.[44] Cox & Kings was the first official travel company to be formed in 1758.[45]\nThe British origin of this new industry is reflected in many place names. In Nice, France, one of the first and best-established holiday resorts on the French Riviera, the long esplanade along the seafront is known to this day as the Promenade des Anglais; in many other historic resorts in continental Europe, old, well-established palace hotels have names like the Hotel Bristol, Hotel Carlton, or Hotel Majestic – reflecting the dominance of English customers.\nA pioneer of the travel agency business, Thomas Cook's idea to offer excursions came to him while waiting for the stagecoach on the London Road at Kibworth. With the opening of the extended Midland Counties Railway, he arranged to take a group of 540 temperance campaigners from Leicester Campbell Street station to a rally in Loughborough, eleven miles (18 km) away. On 5 July 1841, Thomas Cook arranged for the rail company to charge one shilling per person; this included rail tickets and food for the journey. Cook was paid a share of the fares charged to the passengers, as the railway tickets, being legal contracts between company and passenger, could not have been issued at his own price.[clarification needed] This was the first privately chartered excursion train to be advertised to the general public; Cook himself acknowledged that there had been previous, unadvertised, private excursion trains.[46] During the following three summers he planned and conducted outings for temperance societies and Sunday school children. In 1844, the Midland Counties Railway Company agreed to make a permanent arrangement with him, provided he found the passengers. This success led him to start his own business running rail excursions for pleasure, taking a percentage of the railway fares.[47]\nIn 1855, he planned his first excursion abroad, when he took a group from Leicester to Calais to coincide with the Paris Exhibition. The following year he started his \"grand circular tours\" of Europe.[48] During the 1860s he took parties to Switzerland, Italy, Egypt, and the United States. Cook established \"inclusive independent travel\", whereby the traveller went independently but his agency charged for travel, food, and accommodation for a fixed period over any chosen route. Such was his success that the Scottish railway companies withdrew their support between 1862 and 1863 to try the excursion business for themselves.\nAlthough tourism is more often associated with cultural appreciation and leisure, it is also directly connected with power dynamics, cultural representations, and conflicts.[49] As a matter of fact, tourism developed alongside violent colonial domination in many regions of the world.[50] Colonial authorities often developed transportation infrastructure that facilitated the growth of tourism, while simultaneously promoting racialized and demeaning representations of native populations.[51]\nThe violence of the colonial powers was justified by labelling European culture as superior and civilized, while labeling others as inferior, uncivilized and in-need of domestication.[52] European people often depicted non-European peoples and cultures as fundamentally different and inferior, establishing hierarchical representations of societies in various kinds of media such as academic books, travel journals, and travel guidebooks.[53] [54] [55] By portraying colonized societies as inferior on the hierarchy of cultural value, they \"othered\" these populations.[55] The concept of \"othering\" refers to the representation of individuals and cultures in a way that simultaneously romanticizes and devalues them, with the goal of establishing dominance.[55] \"Othering\" also refers to representing peoples while ignoring their own self-representations.[55]\nIn the 19th century, in order to foster the development of tourism in the colonies, touristic enterprises used tourist media to present them as attractive destinations for European travelers.[54] Consequently, tourism media not only promoted the colonies as touristic destinations and helped shape popular conceptions about them, but also helped consolidate ideas of Western cultural superiority.[56][57] One notable example is Thomas Cook's travel enterprise established in the United Kingdom in 1841 and his travel newspaper called “The Excursionist”.[58][59] Thomas Cook enterprise promoted touristic excursions and package tours all over the world. In the case of the tour to Egypt, Thomas Cook & Son’s promotional materials aimed to portray it as an “out-of-the-ordinary”, wild, yet safe and domesticated destination, appealing to European tourists’ desire for both familiarity and adventure.[60] Thomas Cook & Son collaboration with the British Empire during the occupation of Egypt facilitated European access to the Middle East through the construction of transportation networks such as steamships on the River Nile.[61][50] At the same time, it reinforced Eurocentric and imperial politics.[62][50]\nThese narratives, as reflected in travel guidebooks present in the Orientalist collection, often reveal more about the symbolic authority of European powers over colonized regions than they do about the actual cultures depicted.[63] The process of othering and categorizing societies into simplistic binary oppositions—such as civilized/primitive and superior/inferior — contributes to the perpetuation of imperialist ideologies because it silences the voices of local communities and obscures their cultural complexity.[64]\nIn the period following World War II, an increasing number of individuals from diverse backgrounds were able to participate in tourism.[65]\nPrior to the Civil Rights Act, Black travellers encountered specific challenges when travelling within the United States.[66] Jim Crow legislation enforced racial segregation in numerous public spaces, including public transport, accommodation, and tourist sites in general.[67][66]\nThe Negro Motorist Green Book was a travel guide published from 1936 to 1967 by Victor and Alma Duke Green. It was aimed at Black travellers in the United States during the era of segregation and listed places where Black travellers were welcome.[68] Several major companies collaborated with the Green Book. For instance, the Esso Standard Oil Company placed advertisements in the Green Book and sold it at their nationwide gas stations.[68]\nCultural and natural heritage are in many cases the absolute basis for worldwide tourism. Cultural tourism is one of the mega-trends that is reflected in massive numbers of overnight stays and sales. As UNESCO is increasingly observing, the cultural heritage is needed for tourism, but also endangered by it. The \"ICOMOS - International Cultural Tourism Charter\" from 1999 is already dealing with all of these problems. As a result of the tourist hazard, for example, the Lascaux cave was rebuilt for tourists. Overtourism is an important buzzword in this area. Furthermore, the focus of UNESCO in war zones is to ensure the protection of cultural heritage in order to maintain this future important economic basis for the local population. And there is intensive cooperation between UNESCO, the United Nations, the United Nations peacekeeping and Blue Shield International. There are extensive international and national considerations, studies and programs to protect cultural assets from the effects of tourism and those from war. In particular, it is also about training civilian and military personnel. But the involvement of the locals is particularly important. The founding president of Blue Shield International Karl von Habsburg summed it up with the words: \"Without the local community and without the local participants, that would be completely impossible'.[69][70][71][72]\nMass tourism and its tourist attractions have emerged as among the most iconic demonstration of western consumer societies.[73] Academics have defined mass tourism as travel by groups on pre-scheduled tours, usually under the organization of tourism professionals. This form of tourism developed during the second half of the 19th century in the United Kingdom and was pioneered by Thomas Cook. Cook took advantage of Europe's rapidly expanding railway network and established a company that offered affordable day trip excursions to the masses, in addition to longer holidays to Continental Europe, India, Asia and the Western Hemisphere which attracted wealthier customers. By the 1890s over 20,000 tourists per year used Thomas Cook & Son.\nThe relationship between tourism companies, transportation operators and hotels is a central feature of mass tourism. Cook was able to offer prices that were below the publicly advertised price because his company purchased large numbers of tickets from railroads. One contemporary form of mass tourism, package tourism, still incorporates the partnership between these three groups.\nTravel developed during the early 20th century and was facilitated by the development of the automobiles and later by airplanes. Improvements in transport allowed many people to travel quickly to places of leisure interest so that more people could begin to enjoy the benefits of leisure time.\nIn Continental Europe, early seaside resorts included: Heiligendamm, founded in 1793 at the Baltic Sea, being the first seaside resort; Ostend, popularized by the people of Brussels; Boulogne-sur-Mer and Deauville for the Parisians; Taormina in Sicily. In the United States, the first seaside resorts in the European style were at Atlantic City, New Jersey and Long Island, New York.\nBy the mid-20th century, the Mediterranean Coast became the principal mass tourism destination. The 1960s and 1970s saw mass tourism play a major role in the Spanish economic \"miracle\".[74]\nIn the 1960s and 1970s, scientists discussed negative socio-cultural impacts of tourism on host communities. Since the 1980s the positive aspects of tourism began to be recognized as well.[75]\nIn more recent times, mass tourism is something which has become a negative experience for local residents of cities and destinations that experience heavy tourism, especially in summer months. In July 2024 for example, protests by local residents in Barcelona, Spain were held in the city, where ″thousands of people joined an anti-tourism protest amid rising housing costs.″[76]\nNiche tourism refers to the specialty forms of tourism that have emerged over the years, each with its own adjective. Many of these terms have come into common use by the tourism industry and academics.[77] Others are emerging concepts that may or may not gain popular usage. Examples of the more common niche tourism markets are:\n- Agritourism\n- Birth tourism\n- Coastal island tourism\n- Culinary tourism\n- Cultural tourism\n- Dark tourism (also called \"black tourism\" or \"grief tourism\")\n- Eco tourism\n- Extreme tourism\n- Film tourism\n- Geotourism\n- Heritage tourism\n- LGBT tourism\n- Medical tourism\n- Nautical tourism\n- Pop-culture tourism\n- Religious tourism\n- Sex tourism\n- Slum tourism\n- Sports tourism\n- Tallest buildings tourism\n- Trains tourism (e.g., steam and model railways)\n- Virtual tourism\n- War tourism\n- Wellness tourism\n- Wildlife tourism\nOther terms used for niche or specialty travel forms include the term \"destination\" in the descriptions, such as destination weddings, and terms such as location vacation.\nThere has been a limited amount of orbital space tourism, with only the Russian Space Agency providing transport to date. A 2010 report into space tourism anticipated that it could become a billion-dollar market by 2030.[78][79] The space market has been around since 1979, however, there has been a limited amount of orbital space tourism, with only the Russian Space Agency providing transport on its Soyuz and the Chinese Shenzhou being the only two spacecrafts suitable for human travel . In April 2001, Dennis Tito, a customer of the Russian Soyuz became the first tourist to visit space. In May 2011, Virgin Galactic launched its SpaceShipTwo plane that allows people to travel 2 hours space at the advertised price of $200,000 per seat. A challenge that the commercial space tourism industry faces is to be able to have fundings from private investments needed to lower the cost of access to space in addition to being able to encourage both private and public sector support to increase capacity to allow commercial passengers. With space tourism still being new concept, there are many factors that needs to be considered for the industry. From its actual demand to its risk factor to its liabilities and insurance issues, there are still a lot of research that needs to be conducted. A 2010 report into space tourism anticipated that the industry is expected to grow by 18% - 26% per year during 2020 to 2030.\nSports tourism that attracts spectators is associated with negative impacts such as traffic congestion, vandalism, and anti-social behaviour. Sports tourist destinations may therefore be subject public displays of resentment and antagonism even though the host community benefits substantially. Sports tourism growth and decline can be subject to international commercial sporting events. For example, the irreversible environmental damage caused by the 1992 Winter Olympics is cited as a reason for stagnating ski tourism.[80]\nCruising is a popular form of water tourism. Leisure cruise ships were introduced by the P&O in 1844, sailing from Southampton to destinations such as Gibraltar, Malta and Athens.[81] In 1891, German businessman Albert Ballin sailed the ship Augusta Victoria from Hamburg into the Mediterranean Sea. 29 June 1900 saw the launching of the first purpose-built cruise ship was Prinzessin Victoria Luise, built in Hamburg for the Hamburg America Line.[82][83]\nSt. Moritz, Switzerland became the cradle of the developing winter tourism in the 1860s: hotel manager Johannes Badrutt invited some summer guests from England to return in the winter to see the snowy landscape, thereby inaugurating a popular trend.[85][86] It was, however, only in the 1970s when winter tourism took over the lead from summer tourism in many of the Swiss ski resorts. Even in winter, up to one third of all guests (depending on the location) consist of non-skiers.[87]\nMajor ski resorts are located mostly in the various European countries (e.g. Andorra, Austria, Bulgaria, Bosnia and Herzegovina, Croatia, Czech Republic, Cyprus, Finland, France, Germany, Greece, Iceland, Italy, Norway, Latvia, Lithuania, Poland, Romania, Serbia, Sweden, Slovakia, Slovenia, Spain, Switzerland, Turkey), Canada, the United States (e.g. Montana, Utah, Colorado, California, Wyoming, Vermont, New Hampshire, New York) Argentina, New Zealand, Japan, South Korea, Chile, and Lebanon.\nThere has been an up-trend in tourism over the last few decades,[vague] especially in Europe, where international travel for short breaks is common. Tourists have a wide range of budgets and tastes, and a wide variety of resorts and hotels have developed to cater for them. For example, some people prefer simple beach vacations, while others want more specialized holidays, quieter resorts, family-oriented holidays, or niche market-targeted destination hotels.\nThe developments in air transport infrastructure, such as jumbo jets, low-cost airlines, and more accessible airports have made many types of tourism more affordable. A major factor in the relatively low cost of air travel is the tax exemption for aviation fuels. The WHO estimated in 2009 that there are around half a million people on board aircraft at any given time.[30] There have also been changes in lifestyle, for example, some retirement-age people sustain year-round tourism. This is facilitated by internet sales of tourist services. Some sites have now started to offer dynamic packaging, in which an inclusive price is quoted for a tailor-made package requested by the customer upon impulse.\nThere have been a few setbacks in tourism, such as the September 11 attacks and terrorist threats to tourist destinations, such as in Bali and several European cities. Also, on 26 December 2004, a tsunami, caused by the 2004 Indian Ocean earthquake, hit the Asian countries on the Indian Ocean, including the Maldives. Thousands of people died including many tourists. This, together with the vast clean-up operations, stopped or severely hampered tourism in the area for a time.[88]\nIndividual low-price or even zero-price overnight stays have become more popular in the 2000s, especially with a strong growth in the hostel market and services like CouchSurfing and airbnb being established.[89] There has also been examples of jurisdictions wherein a significant portion of GDP is being spent on altering the primary sources of revenue towards tourism, as has occurred for instance in Dubai.[90]\nSustainable tourism is a concept that covers the complete tourism experience, including concern for economic, social, and environmental issues as well as attention to improving tourists' experiences and addressing the needs of host communities.[91] Sustainable tourism should embrace concerns for environmental protection, social equity, and the quality of life, cultural diversity, and a dynamic, viable economy delivering jobs and prosperity for all.[92] It has its roots in sustainable development and there can be some confusion as to what \"sustainable tourism\" means.[93]: 23 There is now broad consensus that tourism should be sustainable.[94][95] In fact, all forms of tourism have the potential to be sustainable if planned, developed and managed properly.[93] Tourist development organizations are promoting sustainable tourism practices in order to mitigate negative effects caused by the growing impact of tourism, for example its environmental impacts.\nThe United Nations World Tourism Organization emphasized these practices by promoting sustainable tourism as part of the Sustainable Development Goals, through programs like the International Year for Sustainable Tourism for Development in 2017.[96] There is a direct link between sustainable tourism and several of the 17 Sustainable Development Goals (SDGs).[93]: 26 Tourism for SDGs focuses on how SDG 8 (\"decent work and economic growth\"), SDG 12 (\"responsible consumption and production\") and SDG 14 (\"life below water\") implicate tourism in creating a sustainable economy.[97]Ecotourism, also known as ecological tourism, is responsible travel to fragile, pristine, and usually protected areas that strives to be low-impact and (often) small-scale. It helps educate the traveller; provides funds for conservation; directly benefits the economic development and political empowerment of local communities, and fosters respect for different cultures and for human rights. Take only memories and leave only footprints is a very common slogan in protected areas.[98] Tourist destinations are shifting to low carbon emissions following the trend of visitors more focused in being environmentally responsible adopting a sustainable behavior.[99]\nVolunteer tourism (or voluntourism) is growing as a largely Western phenomenon, with volunteers travelling to aid those less fortunate than themselves to counter global inequalities. Volunteer tourism is defined as applying \"to those tourists who, for various reasons, volunteer in an organised way to undertake holidays that might involve aiding or alleviating the material poverty of some groups in society\" (Wearing 2001). VSO founded in 1958 in the UK and the US Peace Corps founded in 1958 were the first large-scale voluntary organisations sending groups, initially arising to modernise less economically developed countries, which it was hoped would curb the influence of communism.\nThis form of tourism is largely praised for being a more sustainable approach to travel, with tourists attempting to assimilate into local cultures and avoiding the criticism of consumptive, exploitative mass tourism. However, increasingly, voluntourism is being criticised by scholars who suggest that volunteer tourism may have negative effects as it begins to undermine local labour and force unwilling host communities to adopt Western initiatives. While host communities without a strong heritage fail to retain volunteers who become dissatisfied with their experiences, volunteer shortages persist. Increasingly, organisations such as VSO have been concerned with community-centric volunteer programmes where power to control the future of the community is in the hands of local people.\nPro-poor tourism, which seeks to help the poorest people in developing countries, has been receiving increasing attention by those involved in development; the issue has been addressed through small-scale projects in local communities and through attempts by Ministries of Tourism to attract large numbers of tourists.[100] Research by the Overseas Development Institute suggests that neither is the best way to encourage tourists' money to reach the poorest as only 25% or less (far less in some cases) ever reaches the poor; successful examples of money reaching the poor include mountain-climbing in Tanzania and cultural tourism in Luang Prabang, Laos.[101] There is also the possibility of pro-poor tourism principles being adopted in centre sites of regeneration in the developed world.[102]\nRecession tourism is a travel trend which evolved by way of the world economic crisis. Recession tourism is defined by low-cost and high-value experiences taking place at once-popular generic retreats. Various recession tourism hotspots have seen business boom during the recession thanks to comparatively low costs of living and a slow world job market suggesting travellers are elongating trips where their money travels further. This concept is not widely used in tourism research. It is related to the short-lived phenomenon that is more widely known as staycation. In general, studies have primarily focused on the short-term effects of the crisis on tourism demand, often overlooking the long-term implications for the competitive positioning of the impacted destinations.[103]\nWhen there is a significant price difference between countries for a given medical procedure, particularly in Southeast Asia, India, Sri Lanka, Eastern Europe, Cuba[104] and Canada[105] where there are different regulatory regimes, in relation to particular medical procedures (e.g. dentistry), travelling to take advantage of the price or regulatory differences is often referred to as \"medical tourism\".\nEducational tourism is developed because of the growing popularity of teaching and learning of knowledge and the enhancing of technical competency outside of the classroom environment. Brent W. Ritchie, publisher of Managing Educational Tourism, created a study of a geographic subdivision to demonstrate how tourism educated high school students participating in foreign exchange programs over the last 15 years.[106] In educational tourism, the main focus of the tour or leisure activity includes visiting another country to learn about the culture, study tours, or to work and apply skills learned inside the classroom in a different environment, such as in the International Practicum Training Program.[107] In 2018, one impact was many exchange students traveled to America to assist students financially in order to maintain their secondary education.[108]\nThis type of tourism is focused on tourists coming into a region to either participate in an event or to see an organized event put on by the city/region.[109] This type of tourism can also fall under sustainable tourism as well and companies that create a sustainable event to attend open up a chance to not only the consumer but their workers to learn and develop from the experience. Creating a sustainable atmosphere creates a chance to inform and encourage sustainable practices. An example of event tourism would be the music festival South by Southwest that is hosted in Austin, Texas annually. Every year people from all over the world flock to the city for one week to sit in on technology talks and see bands perform. People are drawn here to experience something that they are not able to experience in their hometown, which defines event tourism.\nCreative tourism has existed as a form of cultural tourism, since the early beginnings of tourism itself. Its European roots date back to the time of the Grand Tour, which saw the sons of aristocratic families travelling for the purpose of mostly interactive, educational experiences. More recently, creative tourism has been given its own name by Crispin Raymond and Greg Richards,[110] who as members of the Association for Tourism and Leisure Education (ATLAS), have directed a number of projects for the European Commission, including cultural and crafts tourism, known as sustainable tourism. They have defined \"creative tourism\" as tourism related to the active participation of travellers in the culture of the host community, through interactive workshops and informal learning experiences.[110]\nMeanwhile, the concept of creative tourism has been picked up by high-profile organizations such as UNESCO, who through the Creative Cities Network, have endorsed creative tourism as an engaged, authentic experience that promotes an active understanding of the specific cultural features of a place. UNESCO wrote in one of its documents: \"'Creative Tourism' involves more interaction, in which the visitor has an educational, emotional, social, and participative interaction with the place, its living culture, and the people who live there. They feel like a citizen.\"[111] Saying so, the tourist will have the opportunity to take part in workshops, classes and activities related to the culture of the destination.\nMore recently, creative tourism has gained popularity as a form of cultural tourism, drawing on active participation by travellers in the culture of the host communities they visit. Several countries offer examples of this type of tourism development, including the United Kingdom, Austria, France, the Bahamas, Jamaica, Spain, Italy, New Zealand and South Korea.[112][113]\nThe growing interest of tourists[114] in this new way to discover a culture regards particularly the operators and branding managers, attentive to the possibility of attracting a quality tourism, highlighting the intangible heritage (craft workshops, cooking classes, etc.) and optimizing the use of existing infrastructure (for example, through the rent of halls and auditoriums).\nExperiential travel (or \"immersion travel\") is one of the major market trends in the modern tourism industry. It is an approach to travelling which focuses on experiencing a country, city or particular place by connecting to its history, people, food and culture.[115]\nThe term \"experiential travel\" has been mentioned in publications since 1985,[116] but it was not discovered as a meaningful market trend until much later.\nOne emerging area of special interest has been identified by Lennon and Foley (2000)[117][118] as \"dark\" tourism. This type of tourism involves visits to \"dark\" sites, such as battlegrounds, scenes of horrific crimes or acts of genocide, for example concentration camps. Its origins are rooted in fairgrounds and medieval fairs.[119]\nSocial tourism is making tourism available to poor people who otherwise could not afford to travel for their education or recreation. It includes youth hostels and low-priced holiday accommodation run by church and voluntary organisations, trade unions, or in Communist times publicly owned enterprises. In May 1959, at the second Congress of Social Tourism in Austria, Walter Hunziker proposed the following definition: \"Social tourism is a type of tourism practiced by low-income groups, and which is rendered possible and facilitated by entirely separate and therefore easily recognizable services\".[120]\nAlso known as \"tourism of doom,\" or \"last chance tourism\", involves travelling to places that are environmentally or otherwise threatened (such as the ice caps of Mount Kilimanjaro, the melting glaciers of Patagonia, or the coral of the Great Barrier Reef) before it is too late. The trend emerged in the 21st century, identified in 2007 by travel trade magazine in 2007[121] and explored in The New York Times,[122] This type of tourism has been on the rise. Some see the trend as related to sustainable tourism or ecotourism due to the fact that a number of these tourist destinations are considered threatened by environmental factors such as global warming, overpopulation or climate change. Others worry that travel to many of these threatened locations increases an individual's carbon footprint and only hastens problems threatened locations are already facing.[123][124][125] As of 2024, climate change has been making Last Chance Tourism more popular, and riskier. In August 2024, an American was killed visiting an ice cave at the foot of the Breidamerkurjokull glacier.[126]\nReligious tourism, in particular pilgrimage, can serve to strengthen faith and to demonstrate devotion.[127] Religious tourists may seek destinations whose image encourages them to believe that they can strengthen the religious elements of their self-identity in a positive manner. Given this, the perceived image of a destination may be positively influenced by whether it conforms to the requirements of their religious self-identity or not.[128]\nDNA tourism, also called \"ancestry tourism\" or \"heritage travel\", is tourism based on DNA testing. These tourists visit their remote relatives or places where their ancestors came from, or where their relatives reside, based on the results of DNA tests. DNA tourism became a growing trend in 2019.[129][130]\nSleep tourism focuses on medical treatments or other approaches, and may focus on people who have difficulty falling asleep, people who experience interrupted sleep, people who don't feel rested after sleeping, snoring, breathing difficulties, and dreaming.[131]\nTourism has a significant impact on destinations, influencing their economy, culture, environment, and communities. Tourism positively affects many parties in society but can also be detrimental in certain situations.\nIn general, tourism positively affects the economy of its destination. The purchasing of commodities, and the usage of hotels and transport by tourists all contribute to economic activity within the country.\nThe sociocultural impacts of tourism are less straightforward, bringing both benefits and challenges to the destination. The interactions between tourists and locals foster a cultural exchange, particularly exposing tourists to a different culture through direct interactions and overall immersion. However, differing expectations in the societal and moral values of the tourists and those from the host location can cause friction between the two parties.\nWhile tourism may have positive impacts environmentally, through an increase in awareness of certain environmental issues, tourism overall negatively impacts the environment. Tourist destinations and attractions located in the wild may neglect environmental concerns to satisfy the demands of tourists, creating issues such as pollution and deforestation.\nTourism also has positive and negative health outcomes for local people.[132] The short-term negative impacts of tourism on residents' health are related to the density of tourist arrivals, the risk of disease transmission, road accidents, higher crime levels, as well as traffic congestion, crowding, and other stressful factors.[133] In addition, residents can experience anxiety and depression related to their risk perceptions about mortality rates, food insecurity, contact with infected tourists, etc.[134] At the same time, there are positive long-term impacts of tourism on residents' health and well-being outcomes through improving healthcare access, positive emotions, novelty, and social interactions.The tourism industry, as part of the service sector,[135] has become an important source of income for many regions and even for entire countries. The Manila Declaration on World Tourism of 1980 recognized its importance as \"an activity essential to the life of nations because of its direct effects on the social, cultural, educational, and economic sectors of national societies, and on their international relations.\"[2][136]\nTourism brings large amounts of income into a local economy in the form of payment for goods and services needed by tourists, accounting as of 2011[update] for 30% of the world's trade in services, and, as an invisible export, for 6% of overall exports of goods and services.[7] It also generates opportunities for employment in the service sector of the economy associated with tourism.[137] It is also claimed that travel broadens the mind.[138][139]\nThe hospitality industries which benefit from tourism include transportation services (such as airlines, cruise ships, transits, trains and taxicabs); lodging (including hotels, hostels, homestays, resorts and renting out rooms); and entertainment venues (such as amusement parks, restaurants, casinos, festivals, shopping malls, music venues, and theatres). This is in addition to goods bought by tourists, including souvenirs.\nOn the flip-side, tourism can degrade people[140] and sour relationships between host and guest.[141] Tourism frequently also puts additional pressure on the local environment.[142]\nThe economic foundations of tourism are essentially the cultural assets, the cultural property and the nature of the travel location. The World Heritage Sites are particularly worth mentioning today because they are real tourism magnets. But even a country's current or former form of government can be decisive for tourism. For example, the fascination of the British royal family brings millions of tourists to Great Britain every year and thus the economy around £550 million a year. The Habsburg family can be mentioned in Central Europe. According to estimates, the Habsburg brand should generate tourism sales of 60 million euros per year for Vienna alone. The tourist principle \"Habsburg sells\" applies.[143][144]\nIn 2004 the World Tourism Organization (UNWTO) forecasts that international tourism will continue growing at the average annual rate of 4 percent.[145] With the advent of e-commerce, tourism products have become prominent traded items on the internet.[146][147] Tourism products and services have been made available through intermediaries, although tourism providers (hotels, airlines, etc.), including small-scale operators, can sell their services directly.[148][149]\nAs a result of the late-2000s recession, international arrivals experienced a strong slowdown beginning in June 2008. Growth from 2007 to 2008 was only 3.7 percent during the first eight months of 2008. This slowdown on international tourism demand was also reflected in the air transport industry, with negative growth in September 2008 and a 3.3% growth in passenger traffic through September. The hotel industry also reported a slowdown, with room occupancy declining. In 2009 worldwide tourism arrivals decreased by 3.8 percent.[150] By the first quarter of 2009, real travel demand in the United States had fallen 6 percent over six quarters. While this was considerably milder than what occurred after the September 11 attacks, the decline was at twice the rate, as real GDP has fallen.[151][152] However, evidence suggests that tourism as a global phenomenon shows no signs of substantially abating in the long term.[153] The UNWTO has noted, that tourists increasingly view vacations and travel as a necessity rather than a luxury, and that this shift in attitudes may explain tourist numbers recovering globally in 2009.[150]\nIt has been suggested there is a strong correlation between tourism expenditure per capita and the degree to which countries play in the global context.[154] Not only as a result of the important economic contribution of the tourism industry, but also as an indicator of the degree of confidence with which global citizens leverage the resources of the globe for the benefit of their local economies. This is why any projections of growth in tourism may serve as an indication of the relative influence that each country will exercise in the future.\nAfter the September 11 attacks the tourism industry operators had to consider the health and safety of tourists because it became increasingly difficult to obtain liability insurance. The organisations willing to provide insurance to tourism industry operators required, that operators put in place best practice risk management structures. This included, that whatever was promised in the contract about the holiday was really delivered by the operator.[155]\nSecurity in Tourism is a sub-discipline of tourist studies that explores the factors that affect the ontological security of tourists. Risks are evaluated by their impact and nature.[156] Tourism security includes methodologies, theories and techniques oriented to protect the organic image of tourist destinations.[157] Three academic waves are significant in tourism security: risk perception theory, disaster management, and post-disaster consumption.[158]\nAndrew Spencer & Peter Tarlow argue that tourism security is not an easy concept to define. It includes a set of sub-disciplines, and global risks different in nature which cause different effects in the tourism industry. The rise of tourism security and safety as a consolidated discipline coincides with the globalization and ultimate maturation of the industry worldwide. Some threats include, for example, terrorist groups looking to destabilize governments affecting not only the local economies but killing foreign tourists to cause geopolitical tensions between delivery-country and receiving-tourist countries. Today, island destinations are more affected by terrorism and other global risks than other continent destinations [159][160]\nIn 2020 the COVID-19 pandemic travel bans and a substantial reduction in passenger travel by air and sea contributed to a sharp decline in tourism activity.[161] The World Tourism Organization (WTO) reported a 70% decrease in international travel in 2020, where 165 of 217 worldwide destinations completely stopped international tourism by April 2020. Since every country imposes different travel restrictions, it makes traveling plans complicated and often too difficult to figure out, thus the willingness to travel for the general population decreases. It is estimated that the United States lost 147 billion U.S. dollars in revenue from tourism between January and October 2020. Spain had the next highest loss of revenue at around 46.7 billion U.S dollars, and countries in Africa collectively lost about 55 billion dollars during April and June 2020.[citation needed]\n- Business tourism – Type of tourism\n- Cultural travel – Style of tourism\n- Environmental effects of aviation – Effect of emissions from aircraft engines\n- International tourism advertising\n- Medical tourism – People traveling abroad to obtain medical treatment\n- Noctourism\n- Outline of tourism – Overview and topical guide of tourism\n- Overtourism – Excessive number of tourists\n- Science tourism – Travel to notable science locations\n- Scuba diving tourism – Industry based on recreational diver travel\n- Sex tourism – Travel to engage in sexual activity\n- Snorkeling – Swimming while inhaling through a snorkel\n- Terminal tourism\n- Tombstone tourist – Person who visits grave sites\n- Tour guide – Person who provides cultural heritage interpretation to tourists\n- Tourist attraction – Place of interest where tourists visit\n- Touron – Pejorative for irresponsible tourists\n- Travel agency – Retailer that provides tourism-related services\n- Travel visa – Authority to enter, stay in, or exit a territory\n- World Tourism rankings – List compiled by the UN World Tourism Organization\n- Tourismphobia – Negative attitudes towards tourists\n- \"tourism\". Oxford English Dictionary (Online ed.). Oxford University Press.(Subscription or participating institution membership required.)\n- \"UNWTO technical manual: Collection of Tourism Expenditure Statistics\" (PDF). World Tourism Organization. 1995. p. 10. Archived from the original (PDF) on 22 September 2010. Retrieved 26 March 2009.\n- \"International tourism challenged by deteriorating global economy\" (PDF). UNWTO World Tourism Barometer. 7 (1). January 2009. Archived from the original (PDF) on 17 October 2013. Retrieved 17 November 2011.\n- \"UNWTO World Tourism Barometer Interim Update\" (PDF). UNWTO World Tourism Barometer. August 2010. Archived from the original (PDF) on 17 October 2013. Retrieved 17 November 2011.\n- \"International Tourist Arrivals Reach 1.4 billion Two Years Ahead of Forecasts | UN Tourism\". www.unwto.org. Retrieved 1 May 2025.\n- \"International Tourist Numbers Could Fall 60-80% in 2020\". www.unwto.org. Retrieved 16 September 2020.\n- Magalhães, Bianca dos Santos (1 July 2017). UNWTO Tourism Highlights: 2017 Edition. World Tourism Organization (UNWTO). doi:10.18111/9789284419029. ISBN 978-92-844-1902-9.\n- \"UNWTO World Tourism Barometer\" (PDF). UNWTO World Tourism Barometer. 11 (1). January 2013. Archived from the original (PDF) on 28 February 2013. Retrieved 9 April 2013.\n- \"China – the new number one tourism source market in the world\". World Tourism Organization. 4 April 2013. Archived from the original on 8 April 2013. Retrieved 9 April 2013.\n-\nLenzen, Manfred; Sun, Ya-Yen; Faturay, Futu; Ting, Yuan-Peng; Geschke, Arne; Malik, Arunima (7 May 2018). \"The carbon footprint of global tourism\". Nature Climate Change. 8 (6). Springer Nature Limited: 522–528. Bibcode:2018NatCC...8..522L. doi:10.1038/s41558-018-0141-x. ISSN 1758-6798. S2CID 90810502.\n[...] between 2009 and 2013, tourism's global carbon footprint has increased from 3.9 to 4.5 GtCO2e, four times more than previously estimated, accounting for about 8% of global greenhouse gas emissions. Transport, shopping and food are significant contributors. The majority of this footprint is exerted by and in high-income countries.\n- Tourism and the Sustainable Development Goals – Journey to 2030, Highlights. World Tourism Organization (UNWTO). 18 December 2017. doi:10.18111/9789284419340. ISBN 978-92-844-1934-0.\n- Griffiths, Ralph; Griffiths, G.E. (1772). \"Pennant's Tour in Scotland in 1769\". The Monthly Review, Or, Literary Journal. 46: 150. Retrieved 23 December 2011.\n- Harper, Douglas. \"tour (n.)\". Online Etymology Dictionary. Retrieved 23 December 2011.\n- \"tourism\". Oxford English Dictionary (Online ed.). Oxford University Press.(Subscription or participating institution membership required.)\n- \"Online Etymology Dictionary\". etymonline.com. Retrieved 3 June 2016.\n- Theobald, William F. (1998). Global Tourism (2nd ed.). Oxford [England]: Butterworth–Heinemann. pp. 6–7. ISBN 978-0-7506-4022-0. OCLC 40330075.\n- Hunziker, W; Krapf, K (1942). Grundriß Der Allgemeinen Fremdenverkehrslehre (in German). Zurich: Polygr. Verl. OCLC 180109383.\n- Spode, Hasso (1998). \"Geschichte der Tourismuswissenschaft\". In Haedrich, Günther (ed.). Tourismus-management: Tourismus-marketing Und Fremdenverkehrsplanung (in German). Berlin: [u.a.] de Gruyter. ISBN 978-3-11-015185-5. OCLC 243881885.\n- Beaver, Allan (2002). A Dictionary of Travel and Tourism Terminology. Wallingford: CAB International. p. 313. ISBN 978-0-85199-582-3. OCLC 301675778.\n- International Association of Scientific Experts in Tourism. \"The AIEST, its character and aims\". Archived from the original on 26 November 2011. Retrieved 29 March 2008.\n- \"Recommendations on Tourism Statistics\" (PDF). Statistical Papers (83): 5. 1994. Retrieved 12 July 2010.\n- \"ww.oicstatcom.org\" (PDF). Archived from the original (PDF) on 12 December 2019. Retrieved 19 June 2019.\n- \"Glossary:Tourism - Statistics Explained\". ec.europa.eu. 30 October 2020. Archived from the original on 30 October 2020. Retrieved 17 December 2020.\n- Edensor, Tim (1998). Tourists at the Taj: Performance and Meaning at a Symbolic Site. Psychology Press. ISBN 978-0-415-16712-3.\n- Weaver, David B. (2008). Ecotourism. Wiley Australia tourism series (2nd ed.). Milton, Qld: Wiley. ISBN 978-0-470-81304-1.\n- \"Product Development\". unwto.org. 21 November 2020. Archived from the original on 21 November 2020.\n- Erin H. Fouberg; Alexander B. Murphy (2020). Human Geography: People, Place, and Culture. Wiley. p. 268. ISBN 9781119577607.\n- \"Introduction to tourism\". visitbritain.org. 11 April 2020. Archived from the original on 11 April 2020.\n- \"UNWTO technical manual: Collection of Tourism Expenditure Statistics\" (PDF). World Tourism Organization. 1995. p. 14. Archived from the original (PDF) on 22 September 2010. Retrieved 26 March 2009.\n- Swine flu prompts EU warning on travel to US. The Guardian. 28 April 2009.\n- \"UNWTO World Tourism Barometer June 2009\" (PDF). UNWTO World Tourism Barometer. 7 (2). World Tourism Organization. June 2011. Archived from the original (PDF) on 19 November 2011. Retrieved 3 August 2009.\n- \"2011 Highlights\" (PDF). UNWTO World Tourism Highlights. UNWTO. June 2011. Archived from the original (PDF) on 13 January 2012. Retrieved 9 January 2012.\n- World Tourism Organization (UNWTO) (1 July 2017). UNWTO Tourism Highlights: 2017 Edition. World Tourism Organization (UNWTO). doi:10.18111/9789284419029. ISBN 978-92-844-1902-9.\n- Maccannell, Dean (1999). The Tourist: A New Theory of the Leisure Class (2nd ed.). University of California Press. p. 12. ISBN 9780520218925.\n- Nolt, Steven (2016). The Amish and the Media | Johns Hopkins University Press Books. jhupbooks.press.jhu.edu. doi:10.1353/book.44948. ISBN 9781421419572. Retrieved 30 November 2021.\n- Cassirer, Ernst (January 1943). \"Some Remarks on the Question of the Originality of the Renaissance\". Journal of the History of Ideas. 4 (1). University of Pennsylvania Press: 49–74. doi:10.2307/2707236. ISSN 0022-5037. JSTOR 2707236.\n- Halsall, Paul (August 1998). \"Petrarch: The Ascent of Mount Ventoux\". fordham.edu. Fordham University. Retrieved 5 March 2014.\n- Deschaux, Robert; Taillevent, Michault (1975). Un poète bourguignon du XVe siècle, Michault Taillevent: édition et étude. Librairie Droz. pp. 31–32. ISBN 978-2-600-02831-8.\n- Hargett 1985, p. 67.\n- Hargett, James M. (1985). \"Some Preliminary Remarks on the Travel Records of the Song Dynasty (960-1279)\". Chinese Literature: Essays, Articles, Reviews. 7 (1/2): 67–93. doi:10.2307/495194. JSTOR 495194.\n- Tomasz Bohun, Podróże po Europie, Władysław IV Wasa, Władcy Polski, p. 12\n- Adam Kucharski. \"Dyplomacja i turystyka – królewicz Władysław Waza w posiadłościach hiszpańskich (1624–1625)\". Silva Rerum. Archived from the original on 14 August 2019. Retrieved 7 June 2017.\n- The Oxford Illustrated History of Opera, ed. Roger Parker (1994): a chapter on Central and Eastern European opera by John Warrack, p. 240; The Viking Opera Guide, ed. Amanda Holden (1993): articles on Polish composers, p. 174\n- Singh, L.K. (2008). \"Issues in Tourism Industry\". Fundamental of Tourism and Travel. Delhi: Isha Books. p. 189. ISBN 978-81-8205-478-3.\n- \"History: Centuries of Experience\". Cox & Kings. Archived from the original on 25 May 2011. Retrieved 23 December 2011.\n- Ingle, R., 1991 Thomas Cook of Leicester, Bangor, Headstart History\n- \"Thomas Cook History\". Thomas Cook. Archived from the original on 19 September 2018. Retrieved 12 May 2017.\n- \"Key Dates 1841–2014\". Thomas Cook. Archived from the original on 5 August 2017. Retrieved 12 May 2017.\n- Hunter, F. Robert (2004). \"Tourism and Empire: The Thomas Cook & Son Enterprise on the Nile, 1868–1914\". Middle Eastern Studies. 40 (5): 28. doi:10.1080/0026320042000265666.\n- Baranowski, Shelley; Endy, Christopher; Hazbun, Waleed; Hom, Stephanie M.; Pirie, Gordon; Simmons, Tony; Zuelow, Eric G. E. (2015). \"Tourism and Empire\". Journal of Tourism History. 7 (1–2): 101. doi:10.1080/1755182X.2015.1063709.\n- Hunter, F. Robert (2004). \"Tourism and Empire: The Thomas Cook & Son Enterprise on the Nile, 1868–1914\". Middle Eastern Studies. 40 (5): 28–29. doi:10.1080/0026320042000265666.\n- Hunter, F. Robert (2004). \"Tourism and Empire: The Thomas Cook & Son Enterprise on the Nile, 1868–1914\". Middle Eastern Studies. 40 (5): 29. doi:10.1080/0026320042000265666.\n- Zuelow, Eric G. E. (2016). \"Chapter 5. Guidebooks and the importance of seeing the sights\". A History of Modern Tourism. London: Palgrave Macmillan. pp. 76–90. ISBN 9780230369641.\n- MacKenzie, John M. (2005). \"Chapter 1. Empires of Travel: British Guide Books and Cultural Imperialism in the 19th and 20th Centuries\". In John K. Walton (ed.). Histories of Tourism: Representation, Identity and Conflict. Bristol, Blue Ridge Summit: Channel View Publications. p. 31. doi:10.21832/9781845410339-003. ISBN 978-1-84541-033-9.\n- Said, Edward W. (1979). Orientalism. New York: Vintage Books. p. 20. ISBN 9780394740676.\n- Hunter, F. Robert (2004). \"Tourism and Empire: The Thomas Cook & Son Enterprise on the Nile, 1868–1914\". Middle Eastern Studies. 40 (5): 28–29. doi:10.1080/0026320042000265666.\n- MacKenzie, John M. (2005). \"Chapter 1. Empires of Travel: British Guide Books and Cultural Imperialism in the 19th and 20th Centuries\". In John K. Walton (ed.). Histories of Tourism: Representation, Identity and Conflict. Bristol, Blue Ridge Summit: Channel View Publications. p. 21. doi:10.21832/9781845410339-003. ISBN 978-1-84541-033-9.\n- Hunter, F. Robert (2004). \"Tourism and Empire: The Thomas Cook & Son Enterprise on the Nile, 1868–1914\". Middle Eastern Studies. 40 (5): 30. doi:10.1080/0026320042000265666.\n- Zuelow, Eric G. E. (2016). \"Chapter 5\". A History of Modern Tourism. London: Palgrave Macmillan. pp. 76–90. ISBN 9780230369641.\n- MacKenzie, John M. (2005). \"Chapter 1. Empires of Travel: British Guide Books and Cultural Imperialism in the 19th and 20th Centuries\". In John K. Walton (ed.). Histories of Tourism: Representation, Identity and Conflict. Bristol, Blue Ridge Summit: Channel View Publications. p. 20. doi:10.21832/9781845410339-003. ISBN 978-1-84541-033-9.\n- Hunter, F. Robert (2004). \"Tourism and Empire: The Thomas Cook & Son Enterprise on the Nile, 1868–1914\". Middle Eastern Studies. 40 (5): 31–32. doi:10.1080/0026320042000265666.\n- MacKenzie, John M. (2005). \"Chapter 1. Empires of Travel: British Guide Books and Cultural Imperialism in the 19th and 20th Centuries\". In John K. Walton (ed.). Histories of Tourism: Representation, Identity and Conflict. Bristol, Blue Ridge Summit: Channel View Publications. p. 25. doi:10.21832/9781845410339-003. ISBN 978-1-84541-033-9.\n- Said, Edward W. (1979). Orientalism. New York: Vintage Books. p. 6. ISBN 9780394740676.\n- Said, Edward W. (1979). Orientalism. New York: Vintage Books. p. 33. ISBN 9780394740676.\n- Zuelow, Eric (2016). A History of Modern Tourism. Palgrave. pp. 149–164. ISBN 978-0-230-36965-8.\n- Zuelow, Eric (2016). A History of Modern Tourism. Palgrave. p. 171. ISBN 978-0-230-36965-8.\n- Jackson, Antoinette T. (2020). Heritage, Tourism, and Race: The Other Side of Leisure. Taylor & Francis. p. 12. ISBN 978-1-00-004806-3.\n- Jackson, Antoinette T. (2020). Heritage, Tourism, and Race: The Other Side of Leisure. Taylor & Francis. p. 13. ISBN 978-1-00-004806-3. Retrieved 2 May 2025.\n- Rick Szostak: The Causes of Economic Growth: Interdisciplinary Perspectives. Springer Science & Business Media, 2009, ISBN 9783540922827; Markus Tauschek \"Kulturerbe\" (2013), p 166; Laurajane Smith \"Uses of Heritage\" (2006).\n- \"UNESCO Legal Instruments: Second Protocol to the Hague Convention of 1954 for the Protection of Cultural Property in the Event of Armed Conflict 1999\".Action plan to preserve heritage sites during conflict - UNITED NATIONS, 12 Apr 2019\n- \"Austrian Armed Forces Mission in Lebanon\" (in German). 28 April 2019.Culture: at the heart of SDGs. UNESCO-Kurier, April-Juni 2017.\n- Simon Osborne (27 September 2016). \"Don't look now, Venice tourists – the locals are sick of you\". The Guardian. Retrieved 10 May 2018.\n- Pau Obrador Pons; Mike Crang; Penny Travlou, eds. (2016). Cultures of Mass Tourism: Doing the Mediterranean in the Age of Banal Mobilities. Taylor & Francis. p. 2. ISBN 9781317155652.\n- S. Pack (2006). Tourism and Dictatorship Europe's Peaceful Invasion of Franco's Spain. Palgrave Macmillan US. p. 141. ISBN 9780230601161.\n- Putova, Barbora (2018). \"Anthropology of Tourism: Researching Interactions between Hosts and Guests\" (PDF). Czech Journal of Tourism. 7 (1): 71–92. doi:10.1515/cjot-2018-0004. S2CID 159280794. Archived from the original (PDF) on 10 July 2023. Retrieved 25 September 2022.\n- Al Jazeera Staff. \". Al Jazeera. Retrieved 10 July 2024.\n- Lew, Alan A. (2008). \"Long Tail Tourism: New geographies for marketing niche tourism products\" (PDF). Journal of Travel & Tourism Marketing. 25 (3–4): 409–19. CiteSeerX 10.1.1.467.6320. doi:10.1080/10548400802508515. S2CID 16085592. Archived from the original (PDF) on 14 June 2010. Retrieved 22 December 2011.\n- \"The Economic Impact of Commercial Space Transportation on the U. S Economy in 2009\" (PDF). Federal Aviation Administration. September 2010. p. 11. Retrieved 5 May 2012.\n- Cohen, E. (2017). The paradoxes of space tourism. Tourism Recreation Research, 42(1), 22-31.\n- James Higham (2007). Sport Tourism Destinations. Taylor & Francis. p. 225. ISBN 9781136364617.\n- \"Cruise News\". June 2012. Retrieved 17 December 2012.\n- \"The Prinzessin Victoria Luise – world's first cruise ship\". Cruising the Past. Retrieved 12 August 2018.\n- Russell, Mark A. (2020). Steamship nationalism: ocean liners and national identity in Imperial Germany and Atlantic world. Routledge studies in modern European history. Abingdon, Oxon; New York, NY: Routledge. ISBN 978-0-429-02771-0.\n- \"Rovaniemi Lapland Holidays – Discovering Finland\".\n- \"Birthplace of winter tourism\". Archived from the original on 17 October 2013.\n- \"Early Winter Tourism\". Tradition & History. St. Moritz: Kulm Hotel. Archived from the original on 19 December 2011. Retrieved 23 December 2011.\n- \"Winter hiking in Switzerland-Graubünden\". graubuenden.ch. Archived from the original on 29 January 2012. Retrieved 23 December 2011.\n- \"India Top Tourist Destinations & Attractions\". TravelCupio. Archived from the original on 8 June 2017. Retrieved 9 April 2017.\n- Marx, Patricia. \"Couch-surfing the globe\". The New Yorker. Retrieved 15 March 2014.\n- Cadene, Philippe (2013). Atlas of the Gulf States. p. 29.\n- \"Sustainable development | UNWTO\". www.unwto.org. Retrieved 25 September 2020.\n- Zeng, L. Economic Development and Mountain Tourism Research from 2010 to 2020: Bibliometric Analysis and Science Mapping Approach. Sustainability 2022, 14, 562. https://doi.org/10.3390/su14010562.\n- Fennell, David A.; Cooper, Chris (2020). Sustainable Tourism: Principles, Contexts and Practices. Bristol, Blue Ridge Summit: Multilingual Matters. pp. 198, 234. doi:10.21832/9781845417673. ISBN 978-1-84541-767-3. S2CID 228913882.\n- Peeters P., Gössling S., Ceron J.P., Dubois G., Patterson T., Richardson R.B., Studies E. (2004). The Eco-efficiency of Tourism.\n- Bramwell, B., & Lane, B. (1993). Sustainable tourism: An evolving global approach. Journal of sustainable tourism, 1(1), 1-5.\n- Tourism and the Sustainable Development Goals – Journey to 2030, Highlights. World Tourism Organization. 18 December 2017. doi:10.18111/9789284419340. ISBN 978-92-844-1934-0.\n- \"Tourism & Sustainable Development Goals – Tourism for SDGs\". Retrieved 10 January 2021.\n- \"Morgan Gamble\". Pinterest. Retrieved 9 June 2015.\n- Entrepreneuring Sustainable Tourism, Jack Soifer Editor, Lisboa, 2008, ISBN 978-989-95976-0-0\n- Freire-Medeiros, B. (2014). Touring poverty. Routledge.\n- Jonathan Mitchel (2009). \"Value chain analysis and poverty reduction at scale\". Overseas Development Institute. Archived from the original on 26 August 2010. Retrieved 3 October 2010.\n- Butler, Richard; Curran, Ross; O'Gorman, Kevin D. (1 September 2013). \"Pro-Poor Tourism in a First World Urban Setting: Case Study of Glasgow Govan\". International Journal of Tourism Research. 15 (5): 443–57. doi:10.1002/jtr.1888. ISSN 1522-1970.\n- Ramón, Ana (1 January 2014). \"The effects of economic crises on tourism success: an integrated model\". Tourism Economics.\n- Neuman, William (17 February 2015). \"Americans May See Appeal of Medical Tourism in Cuba\". The New York Times. ISSN 0362-4331. Retrieved 12 September 2016.\n- \"Evolving medical tourism in Canada | Deloitte Canada\". Deloitte Canada. Retrieved 12 September 2016.\n- McGladdery, Christine A.; Lubbe, Berendien A. (1 January 2017). \"Rethinking educational tourism: proposing a new model and future directions\". Tourism Review. 72 (3): 319–329. doi:10.1108/TR-03-2017-0055. hdl:2263/62536. ISSN 1660-5373.\n- Seraphin, H., Bah, M., Fyall, A., & Gowreesunkar, V. (2021). Tourism education in France and sustainable development goal 4 (quality education). Worldwide Hospitality and Tourism Themes.\n- Shulman, Robyn D. \"5 Ways Student Exchange Programs Affect The American Economy\". Forbes. Retrieved 17 February 2022.\n- Clare., Inkson (2012). Tourism management : an introduction. Minnaert, Lynn. Los Angeles: Sage. ISBN 978-1-84860-869-6. OCLC 760291882.\n- Wurzburger, Rebecca; et al. (2009). Creative Tourism: A Global Conversation: How to Provide Unique Creative Experiences for Travelers Worldwide: As Presented at the 2008 Santa Fe & UNESCO International Conference on Creative Tourism in Santa Fe, New Mexico, USA. Santa Fe: Sunstone Press. ISBN 978-0-86534-724-3. OCLC 370387178.\n- \"Towards Sustainable Strategies for Creative Tourism: discussion report of the planning meeting for the 2008 International Conference on Creative Tourism\". UNESCO Digital Library. 2006.\n- Lau, Samantha (14 November 2016). \"Creative tourism\". Legislative Council of the Hong Kong Special Administrative Region. Archived from the original on 5 March 2024.\n- \"Creative Friendly Destinations\". Creative Tourism Network. Retrieved 20 February 2022.\n- Charlie Mansfield Lecturer in Tourism Management and French. \"JTCaP Tourism Consumption Online Journal\". Tourismconsumption.org. Archived from the original on 15 April 2013. Retrieved 10 August 2013.\n- Bellafante, Ginia (6 July 2012). \"Your Home, the New Frontier for Tourists in New York City\". The New York Times.\n- Gattorna, John (1985). Insights in Strategic Retail Management. MCB University Press. ISBN 9780861762378. Retrieved 9 June 2015.\n- Quinion, Michael (26 November 2005). \"Dark Tourism\". World Wide Words. Retrieved 9 April 2010.\n- Lennon, J. John; Foley, Malcolm (2000). Dark Tourism. London: Continuum. ISBN 978-0-8264-5063-0. OCLC 44603703.\n- Cooper, Chris; et al. (2005). Tourism: Principles and Practice (3rd ed.). Harlow: Pearson Education. ISBN 978-0-273-68406-0. OCLC 466952897.\n- R., Goeldner, Charles (2009). Tourism : principles, practices, philosophies. Ritchie, J.R. Brent. (Eleventh ed.). Hoboken, N.J.: John Wiley. ISBN 978-0-470-38213-4. OCLC 261135450.\n{{cite book}}\n: CS1 maint: multiple names: authors list (link) - Shapiro, Kenneth (11 May 2007). \"The Tourism of Doom\". TravelAge West.\n- Salkin, Allen (16 December 2007). \". The New York Times. Retrieved 30 October 2012.\n- Lemelin, H., Dawson, J., & Stewart, E.J. (Eds.). (2013). Last chance tourism: adapting tourism opportunities in a changing world. Routledge.\n- Frew, E. (2008). Climate change and doom tourism: Advertising destinations 'before they disappear'. In J. Fountain & K. Moore (Chair), Symposium conducted at the meeting of the New Zealand Tourism & Hospitality Research Conference.\n- Hall, C.M. (2010). Crisis events in tourism: subjects of crisis in tourism. Current Issues in Tourism, 13(5), 401–17.\n- \"Climate Change Is Making 'Last Chance Tourism' More Popular, and Riskier\". NYT. 4 September 2024.\n- Jafari, Jafar; Scott, Noel (1 January 2014). \"Muslim world and its tourisms\" (PDF). Annals of Tourism Research. 44: 1–19. doi:10.1016/j.annals.2013.08.011. hdl:10072/63617.\n- Compare:\nGannon, Martin Joseph; Baxter, Ian W.F.; Collinson, Elaine; Curran, Ross; Farrington, Thomas; Glasgow, Steven; Godsman, Elliot M.; Gori, Keith; Jack, Gordon R.A. (11 June 2017). \"Travelling for Umrah: destination attributes, destination image, and post-travel intentions\" (PDF). The Service Industries Journal. 37 (7–8): 448–65. doi:10.1080/02642069.2017.1333601. ISSN 0264-2069. S2CID 54745153.\nThe result from the structural model suggests that destination attributes influence perceived destination image. Further, such tourists are likely to revisit or recommend Islamic destinations if their experience matches their perceived image of the destination. This implies that, while the religious characteristics of the destination remain important, destination managers cannot disregard the tangential, non-religious attributes of a destination which are crucial in order to satisfy more conventional tourist desires.\n- \"Why DNA tourism may be the big travel trend of 2019\". NBC News. Retrieved 7 October 2019.\n- Okona, Nneka M. (18 September 2019). \". Vox. Retrieved 7 October 2019.\n- Bennett, Elizabeth (15 March 2025). \"What is sleep tourism and why is it on the rise?\". National Geographic. Retrieved 15 March 2025.\n- Godovykh, Maksim; Ridderstaat, Jorge (1 September 2020). \"Health outcomes of tourism development: A longitudinal study of the impact of tourism arrivals on residents' health\". Journal of Destination Marketing & Management. 17 100462. doi:10.1016/j.jdmm.2020.100462. ISSN 2212-571X. PMC 7376339. S2CID 220688162.\n- Gursoy, Dogan; Ouyang, Zhe; Nunkoo, Robin; Wei, Wei (17 September 2018). \"Residents' impact perceptions of and attitudes towards tourism development: a meta-analysis\". Journal of Hospitality Marketing & Management. 28 (3): 306–333. doi:10.1080/19368623.2018.1516589. ISSN 1936-8623. S2CID 149483878.\n- Zhang, Yingfei; Ma, Zheng Feei (20 August 2020). \"Psychological responses and lifestyle changes among pregnant women with respect to the early stages of COVID-19 pandemic\". International Journal of Social Psychiatry. 67 (4): 344–350. doi:10.1177/0020764020952116. ISSN 0020-7640. PMC 8191160. PMID 32815434.\n- Tassiopoulos, Dimitri (2008). Tassiopoulos, Dimitri (ed.). New Tourism Ventures: An Entrepreneurial and Managerial Approach. Cape Town: Juta and Company Ltd. p. 10. ISBN 9780702177262.\n- Manila Declaration on World Tourism (PDF). World Tourism Conference. Manila, Philippines. 10 October 1980. pp. 1–4. Archived from the original (PDF) on 20 November 2012.\n- \"2012 Tourism Highlights\" (PDF). UNWTO. June 2012. Archived from the original (PDF) on 9 July 2012. Retrieved 17 June 2012.\n- \"Travel broadens the mind, but can it alter the brain?\". theguardian.com. 18 January 2016.\n- Rebanks, James (2019). \"James Rebanks: One shepherd and his beloved Herdwick sheep\". bbc.co.uk.\n-\nO'Grady, Alison, ed. (1990). The Challenge of Tourism: Learning Resources for Study and Action. Ecumenical Coalition on Third World Tourism. p. 19. ISBN 9789748555706. Retrieved 20 September 2019.\n[...] the products to be sold to international tourists are not only natural resources such as sea, sand and sun, but also the subservience of people in receiving countries.\n-\nSmith, Melanie K. (2003). Issues in Cultural Tourism Studies. Tourism / Routledge. London: Routledge. p. 50. ISBN 978-0-415-25638-4. Retrieved 30 May 2018.\nThe globalisation of tourism has partially exacerbated the relationships of inequality and subservience that are so commonplace in host-guest encounters. It is not simply enough for local people to accept their role as servants, guides or companions to a range of ever-changing tourists. They are also confronted increasingly by the luxurious global products of Western indulgence which remain far from their reach, rather like the thirsty Tantalus in his elusive pool of water.\n- Gössling, Stefan; Hansson, Carina Borgström; Hörstmeier, Oliver; Saggel, Stefan (1 December 2002). \"Ecological footprint analysis as a tool to assess tourism sustainability\". Ecological Economics. 43 (2): 199–211. Bibcode:2002EcoEc..43..199G. doi:10.1016/S0921-8009(02)00211-2. ISSN 0921-8009.\n- Laurajane Smith \"Uses of Heritage\" (2006); Regina Bendix, Vladimir Hafstein \"Culture and Property. An Introduction\" (2009) in Ethnologia Europaea 39/2\n- Gerhard Bitzan, Christine Imlinger \"Die Millionen-Marke Habsburg\" (German), in Die Presse, 15 July 2011.\n- \"Long-term Prospects: Tourism 2020 Vision\". World Tourism. 2004. Archived from the original on 19 June 2004.\n- Lock, S. (3 July 2018). \"Online travel market - Statistics & Facts\". Statista.\n- Statista Research Department (23 July 2019). \"Digital travel sales worldwide from 2014 to 2020\". Statista.\n- Lu, Jie; Lu, Zi (1 July 2004). \"Development, Distribution and Evaluation of Online Tourism Services in China\". Electronic Commerce Research. 4 (3): 221–39. doi:10.1023/B:ELEC.0000027981.81945.2a. ISSN 1389-5753. S2CID 6473875.\n- Karanasios, Stan; Burgess, Stephen (1 March 2008). \"Tourism and internet adoption: a developing world perspective\". International Journal of Tourism Research. 10 (2): 169–82. doi:10.1002/jtr.649. ISSN 1522-1970.\n- UNWTO. \"UNWTO Tourism Highlights\" (PDF). UNWTO. Archived from the original (PDF) on 5 January 2012. Retrieved 2 May 2012.\n- \"Impacts of the World Recession and Economic Crisis on Tourism: North America\".\n- Ritchie, J.R. Brent; Amaya Molinar, Carlos Mario; Frechtling, Douglas C. (2011). \"Impacts of the World Recession and Economic Crisis on Tourism: North America\". Journal of Travel Research. 49 (1): 5–15. doi:10.1177/0047287509353193. S2CID 154854770.\n- Spencer, A., Tarlow, P. E., Gowreesunkar, V. G., Maingi, S. W., Roy, H., Micera, R., ... & Lane, W. (2021). Tourism Destination Management in a Post-Pandemic Context, New York, Emerald.\n- \"airports & tourists\". Global Culture. 2007. Archived from the original on 5 June 2009. Retrieved 1 May 2007.\n- Jeff Wilks; Stephen J Stephen, eds. (2013). Managing Tourist Health and Safety in the New Millennium. Taylor & Francis. ISBN 9781136381348.\n- Mansfeld, Y., & Pizam, A. (Eds.). (2006). Tourism, security and safety. Routledge.\n- Tarlow, P. (2014). Tourism security: strategies for effectively managing travel risk and safety. Elsevier.\n- Vanessa GB Gowreesunkar et al. 2020. Tourism Destination Management in a Post-Pandemic Context: Global Issues and Destination Management Solutions, Emerald\n- Tourism Security. 2014. doi:10.1016/c2012-0-06812-3. ISBN 9780124115705.\n- Spencer, Andrew; Tarlow, Peter (22 February 2021), \"Introduction\", Tourism Safety and Security for the Caribbean, Emerald Publishing Limited, pp. 1–14, doi:10.1108/978-1-80071-318-520211003, ISBN 978-1-80071-319-2, S2CID 240831742, retrieved 30 November 2021\n- Tate, Curtis. \"International tourism won't come back until late 2021, UN panel predicts\". USA TODAY. Retrieved 24 November 2020.\n- Costa, P (1991). \"Managing tourism carrying capacity of art cities\". The Tourist Review. 46 (4): 8–11. doi:10.1108/eb058076.\n- Garlick, S (2002). \"Revealing the unseen: Tourism, art and photography\". Cultural Studies. 16 (2): 289–305. doi:10.1080/09502380110107599. S2CID 143902911.\n- Gartner, W.C. (1993). \"Image formation process\". Journal of Travel & Tourism Marketing. 2 (2–3): 191–216. doi:10.1300/j073v02n02_12.\n- Hughes, H.L. (1989). \"Tourism and the arts\". Tourism Management. 10 (2): 97–99. doi:10.1016/0261-5177(89)90050-2.\n- Phelps, A (1986). \"Holiday destination image: The problem of assessment—an example developed in Minorca\". Tourism Management. 7 (3): 168–80. doi:10.1016/0261-5177(86)90003-8.\n- Richardson, S.; Crompton, J. (1988). \"Cultural variations in perceptions of vacation attributes\". Tourism Management. 9 (2): 128–36. doi:10.1016/0261-5177(88)90022-2.\n- Holder IV, Floyd William (2009). An Empirical Analysis of the State's Monopolization of the Legitimate Means of Movement: Evaluating the Effects of Required Passport use on International Travel (M.P.A. thesis). Texas State University-San Marcos. OCLC 564144593. Docket Applied Research Projects. Paper 308.\n- Wilkerson, Chad (2003). \"Travel and Tourism: An Overlooked Industry in the U.S. and Tenth District\" (PDF). Economic Review. 88 (Third Quarter): 45–72. ISSN 0161-2387. OCLC 295437935. Archived from the original (PDF) on 9 January 2011. Retrieved 31 October 2007.\n- Antje Monshausen, Sustainable and development friendly In: D+C Vol.42.2015:4",
    "transmission and distribution": "Electric power transmission is the bulk movement of electrical energy from a generating site, such as a power plant, to an electrical substation. The interconnected lines that facilitate this movement form a transmission network. This is distinct from the local wiring between high-voltage substations and customers, which is typically referred to as electric power distribution. The combined transmission and distribution network is part of electricity delivery, known as the electrical grid.\nEfficient long-distance transmission of electric power requires high voltages. This reduces the losses produced by strong currents. Transmission lines use either alternating current (AC) or direct current (DC). The voltage level is changed with transformers. The voltage is stepped up for transmission, then reduced for local distribution.\nA wide area synchronous grid, known as an interconnection in North America, directly connects generators delivering AC power with the same relative frequency to many consumers. North America has four major interconnections: Western, Eastern, Quebec and Texas. One grid connects most of continental Europe.\nHistorically, transmission and distribution lines were often owned by the same company, but starting in the 1990s, many countries liberalized the regulation of the electricity market in ways that led to separate companies handling transmission and distribution.[2]\nMost North American transmission lines are high-voltage three-phase AC, although single phase AC is sometimes used in railway electrification systems. DC technology is used for greater efficiency over longer distances, typically hundreds of miles. High-voltage direct current (HVDC) technology is also used in submarine power cables (typically longer than 30 miles (50 km)), and in the interchange of power between grids that are not mutually synchronized. HVDC links stabilize power distribution networks where sudden new loads, or blackouts, in one part of a network might otherwise result in synchronization problems and cascading failures.\nElectricity is transmitted at high voltages to reduce the energy loss due to resistance that occurs over long distances. Power is usually transmitted through overhead power lines. Underground power transmission has a significantly higher installation cost and greater operational limitations, but lowers maintenance costs. Underground transmission is more common in urban areas or environmentally sensitive locations.\nElectrical energy must typically be generated at the same rate at which it is consumed. A sophisticated control system is required to ensure that power generation closely matches demand. If demand exceeds supply, the imbalance can cause generation plant(s) and transmission equipment to automatically disconnect or shut down to prevent damage. In the worst case, this may lead to a cascading series of shutdowns and a major regional blackout.\nThe US Northeast faced blackouts in 1965, 1977, 2003, and major blackouts in other US regions in 1996 and 2011. Electric transmission networks are interconnected into regional, national, and even continent-wide networks to reduce the risk of such a failure by providing multiple redundant, alternative routes for power to flow should such shutdowns occur. Transmission companies determine the maximum reliable capacity of each line (ordinarily less than its physical or thermal limit) to ensure that spare capacity is available in the event of a failure in another part of the network.\nHigh-voltage overhead conductors are not covered by insulation. The conductor material is nearly always an aluminium alloy, formed of several strands and possibly reinforced with steel strands. Copper was sometimes used for overhead transmission, but aluminum is lighter, reduces yields only marginally and costs much less. Overhead conductors are supplied by several companies. Conductor material and shapes are regularly improved to increase capacity.\nConductor sizes range from 12 mm2 (#6 American wire gauge) to 1,092 mm2 (2,156,000 circular mils area), with varying resistance and current-carrying capacity. For large conductors (more than a few centimetres in diameter), much of the current flow is concentrated near the surface due to the skin effect. The center of the conductor carries little current but contributes weight and cost. Thus, multiple parallel cables (called bundle conductors) are used for higher capacity. Bundle conductors are used at high voltages to reduce energy loss caused by corona discharge.\nToday, transmission-level voltages are usually considered to be 110 kV and above.[3] Lower voltages, such as 66 kV and 33 kV, are usually considered subtransmission voltages, but are occasionally used on long lines with light loads. Voltages less than 33 kV are usually used for distribution. Voltages above 765 kV are considered extra high voltage and require different designs.\nOverhead transmission wires depend on air for insulation, requiring that lines maintain minimum clearances. Adverse weather conditions, such as high winds and low temperatures, interrupt transmission. Wind speeds as low as 23 knots (43 km/h) can permit conductors to encroach operating clearances, resulting in a flashover and loss of supply.[4] Oscillatory motion of the physical line is termed conductor gallop or flutter depending on the frequency and amplitude of oscillation.\n-\nA five-hundred kilovolt (500 kV) three-phase transmission tower in Washington State, the line is bundled 3-ways\n-\nThree abreast electrical pylons in Webster, Texas\nElectric power can be transmitted by underground power cables. Underground cables take up no right-of-way, have lower visibility, and are less affected by weather. However, cables must be insulated. Cable and excavation costs are much higher than overhead construction. Faults in buried transmission lines take longer to locate and repair.\nIn some metropolitan areas, cables are enclosed by metal pipe and insulated with dielectric fluid (usually an oil) that is either static or circulated via pumps. If an electric fault damages the pipe and leaks dielectric, liquid nitrogen is used to freeze portions of the pipe to enable draining and repair. This extends the repair period and increases costs. The temperature of the pipe and surroundings are monitored throughout the repair period.[5][6][7]\nUnderground lines are limited by their thermal capacity, which permits less overload or re-rating lines. Long underground AC cables have significant capacitance, which reduces their ability to provide useful power beyond 50 miles (80 kilometres). DC cables are not limited in length by their capacitance.\nCommercial electric power was initially transmitted at the same voltage used by lighting and mechanical loads. This restricted the distance between generating plant and loads. In 1882, DC voltage could not easily be increased for long-distance transmission. Different classes of loads (for example, lighting, fixed motors, and traction/railway systems) required different voltages, and so used different generators and circuits.[8][9]\nThus, generators were sited near their loads, a practice that later became known as distributed generation using large numbers of small generators.[10]\nTransmission of alternating current (AC) became possible after Lucien Gaulard and John Dixon Gibbs built what they called the secondary generator, an early transformer provided with 1:1 turn ratio and open magnetic circuit, in 1881.\nThe first long distance AC line was 34 kilometres (21 miles) long, built for the 1884 International Exhibition of Electricity in Turin, Italy. It was powered by a 2 kV, 130 Hz Siemens & Halske alternator and featured several Gaulard transformers with primary windings connected in series, which fed incandescent lamps. The system proved the feasibility of AC electric power transmission over long distances.[9]\nThe first commercial AC distribution system entered service in 1885 in via dei Cerchi, Rome, Italy, for public lighting. It was powered by two Siemens & Halske alternators rated 30 hp (22 kW), 2 kV at 120 Hz and used 19 km of cables and 200 parallel-connected 2 kV to 20 V step-down transformers provided with a closed magnetic circuit, one for each lamp. A few months later it was followed by the first British AC system, serving Grosvenor Gallery. It also featured Siemens alternators and 2.4 kV to 100 V step-down transformers – one per user – with shunt-connected primaries.[11]\nWorking to improve what he considered an impractical Gaulard-Gibbs design, electrical engineer William Stanley, Jr. developed the first practical series AC transformer in 1885.[12] Working with the support of George Westinghouse, in 1886 he demonstrated a transformer-based AC lighting system in Great Barrington, Massachusetts. It was powered by a steam engine-driven 500 V Siemens generator. Voltage was stepped down to 100 volts using the Stanley transformer to power incandescent lamps at 23 businesses over 4,000 feet (1,200 m).[13] This practical demonstration of a transformer and alternating current lighting system led Westinghouse to begin installing AC systems later that year.[12]\nIn 1888 the first designs for an AC motor appeared. These were induction motors running on polyphase current, independently invented by Galileo Ferraris and Nikola Tesla. Westinghouse licensed Tesla's design. Practical three-phase motors were designed by Mikhail Dolivo-Dobrovolsky and Charles Eugene Lancelot Brown.[14] Widespread use of such motors were delayed many years by development problems and the scarcity of polyphase power systems needed to power them.[15][16]\nIn the late 1880s and early 1890s smaller electric companies merged into larger corporations such as Ganz and AEG in Europe and General Electric and Westinghouse Electric in the US. These companies developed AC systems, but the technical difference between direct and alternating current systems required a much longer technical merger.[17] Alternating current's economies of scale with large generating plants and long-distance transmission slowly added the ability to link all the loads. These included single phase AC systems, poly-phase AC systems, low voltage incandescent lighting, high-voltage arc lighting, and existing DC motors in factories and street cars. In what became a universal system, these technological differences were temporarily bridged via the rotary converters and motor-generators that allowed the legacy systems to connect to the AC grid.[17][18] These stopgaps were slowly replaced as older systems were retired or upgraded.\nThe first transmission of single-phase alternating current using high voltage came in Oregon in 1890 when power was delivered from a hydroelectric plant at Willamette Falls to the city of Portland 14 miles (23 km) down river.[19] The first three-phase alternating current using high voltage took place in 1891 during the international electricity exhibition in Frankfurt. A 15 kV transmission line, approximately 175 km long, connected Lauffen on the Neckar and Frankfurt.[11][20]\nTransmission voltages increased throughout the 20th century. By 1914, fifty-five transmission systems operating at more than 70 kV were in service. The highest voltage then used was 150 kV.[21] Interconnecting multiple generating plants over a wide area reduced costs. The most efficient plants could be used to supply varying loads during the day. Reliability was improved and capital costs were reduced, because stand-by generating capacity could be shared over many more customers and a wider area. Remote and low-cost sources of energy, such as hydroelectric power or mine-mouth coal, could be exploited to further lower costs.[8][11]\nThe 20th century's rapid industrialization made electrical transmission lines and grids critical infrastructure. Interconnection of local generation plants and small distribution networks was spurred by World War I, when large electrical generating plants were built by governments to power munitions factories.[22]\nThese networks use components such as power lines, cables, circuit breakers, switches and transformers. The transmission network is usually administered on a regional basis by an entity such as a regional transmission organization or transmission system operator.[23]\nTransmission efficiency is improved at higher voltage and lower current. The reduced current reduces heating losses. Joule's first law states that energy losses are proportional to the square of the current. Thus, reducing the current by a factor of two lowers the energy lost to conductor resistance by a factor of four for any given size of conductor.\nThe optimum size of a conductor for a given voltage and current can be estimated by Kelvin's law for conductor size, which states that size is optimal when the annual cost of energy wasted in resistance is equal to the annual capital charges of providing the conductor. At times of lower interest rates and low commodity costs, Kelvin's law indicates that thicker wires are optimal. Otherwise, thinner conductors are indicated. Since power lines are designed for long-term use, Kelvin's law is used in conjunction with long-term estimates of the price of copper and aluminum as well as interest rates.\nHigher voltage is achieved in AC circuits by using a step-up transformer. High-voltage direct current (HVDC) systems require relatively costly conversion equipment that may be economically justified for particular projects such as submarine cables and longer distance high capacity point-to-point transmission. HVDC is necessary for sending energy between unsynchronized grids.\nA transmission grid is a network of power stations, transmission lines, and substations. Energy is usually transmitted within a grid with three-phase AC. Single-phase AC is used only for distribution to end users since it is not usable for large polyphase induction motors. In the 19th century, two-phase transmission was used but required either four wires or three wires with unequal currents. Higher order phase systems require more than three wires, but deliver little or no benefit.\nWhile the price of generating capacity is high, energy demand is variable, making it often cheaper to import needed power than to generate it locally. Because loads often rise and fall together across large areas, power often comes from distant sources. Because of the economic benefits of load sharing, wide area transmission grids may span countries and even continents. Interconnections between producers and consumers enables power to flow even if some links are inoperative.\nThe slowly varying portion of demand is known as the base load and is generally served by large facilities with constant operating costs, termed firm power. Such facilities are nuclear, coal or hydroelectric, while other energy sources such as concentrated solar thermal and geothermal power have the potential to provide firm power. Renewable energy sources, such as solar photovoltaics, wind, wave, and tidal, are, due to their intermittency, not considered to be firm. The remaining or peak power demand, is supplied by peaking power plants, which are typically smaller, faster-responding, and higher cost sources, such as combined cycle or combustion turbine plants typically fueled by natural gas.\nLong-distance transmission (hundreds of kilometers) is cheap and efficient, with costs of US$0.005–0.02 per kWh, compared to annual averaged large producer costs of US$0.01–0.025 per kWh, retail rates upwards of US$0.10 per kWh, and multiples of retail for instantaneous suppliers at unpredicted high demand moments.[24] New York often buys over 1000 MW of low-cost hydropower from Canada.[25] Local sources (even if more expensive and infrequently used) can protect the power supply from weather and other disasters that can disconnect distant suppliers.\nHydro and wind sources cannot be moved closer to big cities, and solar costs are lowest in remote areas where local power needs are nominal. Connection costs can determine whether any particular renewable alternative is economically realistic. Costs can be prohibitive for transmission lines, but high capacity, long distance super grid transmission network costs could be recovered with modest usage fees.\nAt power stations, power is produced at a relatively low voltage between about 2.3 kV and 30 kV, depending on the size of the unit. The voltage is then stepped up by the power station transformer to a higher voltage (115 kV to 765 kV AC) for transmission.\nIn the United States, power transmission is, variously, 230 kV to 500 kV, with less than 230 kV or more than 500 kV as exceptions.\nThe Western Interconnection has two primary interchange voltages: 500 kV AC at 60 Hz, and ±500 kV (1,000 kV net) DC from North to South (Columbia River to Southern California) and Northeast to Southwest (Utah to Southern California). The 287.5 kV (Hoover Dam to Los Angeles line, via Victorville) and 345 kV (Arizona Public Service (APS) line) are local standards, both of which were implemented before 500 kV became practical.\nTransmitting electricity at high voltage reduces the fraction of energy lost to Joule heating, which varies by conductor type, the current, and the transmission distance. For example, a 100 miles (160 km) span at 765 kV carrying 1000 MW of power can have losses of 0.5% to 1.1%. A 345 kV line carrying the same load across the same distance has losses of 4.2%.[26] For a given amount of power, a higher voltage reduces the current and thus the resistive losses. For example, raising the voltage by a factor of 10 reduces the current by a corresponding factor of 10 and therefore the losses by a factor of 100, provided the same sized conductors are used in both cases. Even if the conductor size (cross-sectional area) is decreased ten-fold to match the lower current, the losses are still reduced ten-fold using the higher voltage.\nWhile power loss can also be reduced by increasing the wire's conductance (by increasing its cross-sectional area), larger conductors are heavier and more expensive. And since conductance is proportional to cross-sectional area, resistive power loss is only reduced proportionally with increasing cross-sectional area, providing a much smaller benefit than the squared reduction provided by multiplying the voltage.\nLong-distance transmission is typically done with overhead lines at voltages of 115 to 1,200 kV. At higher voltages, where more than 2,000 kV exists between conductor and ground, corona discharge losses are so large that they can offset the lower resistive losses in the line conductors. Measures to reduce corona losses include larger conductor diameter, hollow cores[27] or conductor bundles.\nFactors that affect resistance and thus loss include temperature, spiraling, and the skin effect. Resistance increases with temperature. Spiraling, which refers to the way stranded conductors spiral about the center, also contributes to increases in conductor resistance. The skin effect causes the effective resistance to increase at higher AC frequencies. Corona and resistive losses can be estimated using a mathematical model.[28]\nUS transmission and distribution losses were estimated at 6.6% in 1997,[29] 6.5% in 2007[29] and 5% from 2013 to 2019.[30] In general, losses are estimated from the discrepancy between power produced (as reported by power plants) and power sold; the difference constitutes transmission and distribution losses, assuming no utility theft occurs.\nAs of 1980, the longest cost-effective distance for DC transmission was 7,000 kilometres (4,300 miles). For AC it was 4,000 kilometres (2,500 miles), though US transmission lines are substantially shorter.[24]\nIn any AC line, conductor inductance and capacitance can be significant. Currents that flow solely in reaction to these properties, (which together with the resistance define the impedance) constitute reactive power flow, which transmits no power to the load. These reactive currents, however, cause extra heating losses. The ratio of real power transmitted to the load to apparent power (the product of a circuit's voltage and current, without reference to phase angle) is the power factor. As reactive current increases, reactive power increases and power factor decreases.\nFor transmission systems with low power factor, losses are higher than for systems with high power factor. Utilities add capacitor banks, reactors and other components (such as phase-shifters; static VAR compensators; and flexible AC transmission systems, FACTS) throughout the system help to compensate for the reactive power flow, reduce the losses in power transmission and stabilize system voltages. These measures are collectively called 'reactive support'.\nCurrent flowing through transmission lines induces a magnetic field that surrounds the lines of each phase and affects the inductance of the surrounding conductors of other phases. The conductors' mutual inductance is partially dependent on the physical orientation of the lines with respect to each other. Three-phase lines are conventionally strung with phases separated vertically. The mutual inductance seen by a conductor of the phase in the middle of the other two phases is different from the inductance seen on the top/bottom.\nUnbalanced inductance among the three conductors is problematic because it may force the middle line to carry a disproportionate amount of the total power transmitted. Similarly, an unbalanced load may occur if one line is consistently closest to the ground and operates at a lower impedance. Because of this phenomenon, conductors must be periodically transposed along the line so that each phase sees equal time in each relative position to balance out the mutual inductance seen by all three phases. To accomplish this, line position is swapped at specially designed transposition towers at regular intervals along the line using various transposition schemes.\nSubtransmission runs at relatively lower voltages. It is uneconomical to connect all distribution substations to the high main transmission voltage, because that equipment is larger and more expensive. Typically, only larger substations connect with this high voltage. Voltage is stepped down before the current is sent to smaller substations. Subtransmission circuits are usually arranged in loops so that a single line failure does not stop service to many customers for more than a short time.\nLoops can be normally closed, where loss of one circuit should result in no interruption, or normally open where substations can switch to a backup supply. While subtransmission circuits are usually carried on overhead lines, in urban areas buried cable may be used. The lower-voltage subtransmission lines use less right-of-way and simpler structures; undergrounding is less difficult.\nNo fixed cutoff separates subtransmission and transmission, or subtransmission and distribution. Their voltage ranges overlap. Voltages of 69 kV, 115 kV, and 138 kV are often used for subtransmission in North America. As power systems evolved, voltages formerly used for transmission were used for subtransmission, and subtransmission voltages became distribution voltages. Like transmission, subtransmission moves relatively large amounts of power, and like distribution, subtransmission covers an area instead of just point-to-point.[31]\nSubstation transformers reduce the voltage to a lower level for distribution to customers. This distribution is accomplished with a combination of sub-transmission (33 to 138 kV) and distribution (3.3 to 25 kV). Finally, at the point of use, the energy is transformed to end-user voltage (100 to 4160 volts).\nHigh-voltage power transmission allows for lesser resistive losses over long distances. This efficiency delivers a larger proportion of the generated power to the loads.\nIn a simplified model, the grid delivers electricity from an ideal voltage source with voltage , delivering a power ) to a single point of consumption, modelled by a resistance , when the wires are long enough to have a significant resistance .\nIf the resistances are in series with no intervening transformer, the circuit acts as a voltage divider, because the same current runs through the wire resistance and the powered device. As a consequence, the useful power (at the point of consumption) is:\nShould an ideal transformer convert high-voltage, low-current electricity into low-voltage, high-current electricity with a voltage ratio of (i.e., the voltage is divided by and the current is multiplied by in the secondary branch, compared to the primary branch), then the circuit is again equivalent to a voltage divider, but the wires now have apparent resistance of only . The useful power is then:\nFor (i.e. conversion of high voltage to low voltage near the consumption point), a larger fraction of the generator's power is transmitted to the consumption point and a lesser fraction is lost to Joule heating.\nThe terminal characteristics of the transmission line are the voltage and current at the sending (S) and receiving (R) ends. The transmission line can be modeled as a black box and a 2 by 2 transmission matrix is used to model its behavior, as follows:\nThe line is assumed to be a reciprocal, symmetrical network, meaning that the receiving and sending labels can be switched with no consequence. The transmission matrix T has the properties:\nThe parameters A, B, C, and D differ depending on how the desired model handles the line's resistance (R), inductance (L), capacitance (C), and shunt (parallel, leak) conductance G.\nThe four main models are the short line approximation, the medium line approximation, the long line approximation (with distributed parameters), and the lossless line. In such models, a capital letter such as R refers to the total quantity summed over the line and a lowercase letter such as c refers to the per-unit-length quantity.\nThe lossless line approximation is the least accurate; it is typically used on short lines where the inductance is much greater than the resistance. For this approximation, the voltage and current are identical at the sending and receiving ends.\nThe characteristic impedance is pure real, which means resistive for that impedance, and it is often called surge impedance. When a lossless line is terminated by surge impedance, the voltage does not drop. Though the phase angles of voltage and current are rotated, the magnitudes of voltage and current remain constant along the line. For load > SIL, the voltage drops from sending end and the line consumes VARs. For load < SIL, the voltage increases from the sending end, and the line generates VARs.\nThe short line approximation is normally used for lines shorter than 80 km (50 mi). There, only a series impedance Z is considered, while C and G are ignored. The final result is that A = D = 1 per unit, B = Z Ohms, and C = 0. The associated transition matrix for this approximation is therefore:\nThe medium line approximation is used for lines running between 80 and 250 km (50 and 155 mi). The series impedance and the shunt (current leak) conductance are considered, placing half of the shunt conductance at each end of the line. This circuit is often referred to as a nominal π (pi) circuit because of the shape (π) that is taken on when leak conductance is placed on both sides of the circuit diagram. The analysis of the medium line produces:\nCounterintuitive behaviors of medium-length transmission lines:\n- voltage rise at no load or small current (Ferranti effect)\n- receiving-end current can exceed sending-end current\nThe long line model is used when a higher degree of accuracy is needed or when the line under consideration is more than 250 km (160 mi) long. Series resistance and shunt conductance are considered to be distributed parameters, such that each differential length of the line has a corresponding differential series impedance and shunt admittance. The following result can be applied at any point along the transmission line, where is the propagation constant.\nTo find the voltage and current at the end of the long line, should be replaced with (the line length) in all parameters of the transmission matrix. This model applies the Telegrapher's equations.\nHigh-voltage direct current (HVDC) is used to transmit large amounts of power over long distances or for interconnections between asynchronous grids. When electrical energy is transmitted over very long distances, the power lost in AC transmission becomes appreciable and it is less expensive to use direct current instead. For a long transmission line, these lower losses (and reduced construction cost of a DC line) can offset the cost of the required converter stations at each end.\nHVDC is used for long submarine cables where AC cannot be used because of cable capacitance.[32] In these cases special high-voltage cables are used. Submarine HVDC systems are often used to interconnect the electricity grids of islands, for example, between Great Britain and continental Europe, between Great Britain and Ireland, between Tasmania and the Australian mainland, between the North and South Islands of New Zealand, between New Jersey and New York City, and between New Jersey and Long Island. Submarine connections up to 600 kilometres (370 mi) in length have been deployed.[33]\nHVDC links can be used to control grid problems. The power transmitted by an AC line increases as the phase angle between source end voltage and destination ends increases, but too large a phase angle allows the systems at either end to fall out of step. Since the power flow in a DC link is controlled independently of the phases of the AC networks that it connects, this phase angle limit does not exist, and a DC link is always able to transfer its full rated power. A DC link therefore stabilizes the AC grid at either end, since power flow and phase angle can then be controlled independently.\nAs an example, to adjust the flow of AC power on a hypothetical line between Seattle and Boston would require adjustment of the relative phase of the two regional electrical grids. This is an everyday occurrence in AC systems, but one that can become disrupted when AC system components fail and place unexpected loads on the grid. With an HVDC line instead, such an interconnection would:\n- Convert AC in Seattle into HVDC;\n- Use HVDC for the 3,000 miles (4,800 km) of cross-country transmission; and\n- Convert the HVDC to locally synchronized AC in Boston,\n(and possibly in other cooperating cities along the transmission route). Such a system could be less prone to failure if parts of it were suddenly shut down. One example of a long DC transmission line is the Pacific DC Intertie located in the Western United States.\nThe amount of power that can be sent over a transmission line varies with the length of the line. The heating of short line conductors due to line losses sets a thermal limit. If too much current is drawn, conductors may sag too close to the ground, or conductors and equipment may overheat. For intermediate-length lines on the order of 100 kilometres (62 miles), the limit is set by the voltage drop in the line. For longer AC lines, system stability becomes the limiting factor. Approximately, the power flowing over an AC line is proportional to the cosine of the phase angle of the voltage and current at the ends.\nThis angle varies depending on system loading. It is undesirable for the angle to approach 90 degrees, as the power flowing decreases while resistive losses remain. The product of line length and maximum load is approximately proportional to the square of the system voltage. Series capacitors or phase-shifting transformers are used on long lines to improve stability. HVDC lines are restricted only by thermal and voltage drop limits, since the phase angle is not material.\nUnderstanding the temperature distribution along the cable route became possible with the introduction of distributed temperature sensing (DTS) systems that measure temperatures all along the cable. Without them maximum current was typically set as a compromise between understanding of operation conditions and risk minimization. This monitoring solution uses passive optical fibers as temperature sensors, either inside a high-voltage cable or externally mounted on the cable insulation.\nFor overhead cables the fiber is integrated into the core of a phase wire. The integrated Dynamic Cable Rating (DCR)/Real Time Thermal Rating (RTTR) solution makes it possible to run the network to its maximum. It allows the operator to predict the behavior of the transmission system to reflect major changes to its initial operating conditions.\nSome utilities have embraced reconductoring to handle the increase in electricity production. Reconductoring is the replacement-in-place of existing transmission lines with higher-capacity lines. Adding transmission lines is difficult due to cost, permit intervals, and local opposition. Reconductoring has the potential to double the amount of electricity that can travel across a transmission line.[34] A 2024 report found the United States behind countries like Belgium and the Netherlands in adoption of this technique to accommodate electrification and renewable energy.[35] In April 2022, the Biden Administration streamlined environmental reviews for such projects, and in May 2022 announced competitive grants for them funded by the 2021 Bipartisan Infrastructure Law and 2022 Inflation Reduction Act.[36]\nThe rate of transmission expansion needs to double to support ongoing electrification and reach emission reduction targets. As of 2022, more than 10,000 power plant and energy storage projects were awaiting permission to connect to the US grid — 95% were zero-carbon resources. New power lines can take 10 years to plan, permit, and build.[34]\nTraditional power lines use a steel core surrounded by aluminum strands (Aluminium-conductor steel-reinforced cable). Replacing the steel with a lighter, stronger composite material such as carbon fiber (ACCC conductor) allows lines to operate at higher temperatures, with less sag, and doubled transmission capacity. Lowering line sag at high temperatures can prevent wildfires from starting when power lines touch dry vegetation.[35] Although advanced lines can cost 2-4x more than steel, total reconductoring costs are less than half of a new line, given savings in time, land acquisition, permitting, and construction.[34]\nA reconductoring project in southeastern Texas upgraded 240 miles of transmission lines at a cost of $900,000 per mile, versus a 3,600-mile greenfield project that averaged $1.9 million per mile.[34]\nTo ensure safe and predictable operation, system components are controlled with generators, switches, circuit breakers and loads. The voltage, power, frequency, load factor, and reliability capabilities of the transmission system are designed to provide cost effective performance.\nThe transmission system provides for base load and peak load capability, with margins for safety and fault tolerance. Peak load times vary by region largely due to the industry mix. In hot and cold climates home air conditioning and heating loads affect the overall load. They are typically highest in the late afternoon in the hottest part of the year and in mid-mornings and mid-evenings in the coldest part of the year. Power requirements vary by season and time of day. Distribution system designs always take the base load and the peak load into consideration.\nThe transmission system usually does not have a large buffering capability to match loads with generation. Thus generation has to be kept matched to the load, to prevent overloading generation equipment.\nMultiple sources and loads can be connected to the transmission system and they must be controlled to provide orderly transfer of power. In centralized power generation, only local control of generation is necessary. This involves synchronization of the generation units.\nIn distributed power generation the generators are geographically distributed and the process to bring them online and offline must be carefully controlled. The load control signals can either be sent on separate lines or on the power lines themselves. Voltage and frequency can be used as signaling mechanisms to balance the loads.\nIn voltage signaling, voltage is varied to increase generation. The power added by any system increases as the line voltage decreases. This arrangement is stable in principle. Voltage-based regulation is complex to use in mesh networks, since the individual components and setpoints would need to be reconfigured every time a new generator is added to the mesh.\nIn frequency signaling, the generating units match the frequency of the power transmission system. In droop speed control, if the frequency decreases, the power is increased. (The drop in line frequency is an indication that the increased load is causing the generators to slow down.)\nWind turbines, vehicle-to-grid, virtual power plants, and other locally distributed storage and generation systems can interact with the grid to improve system operation. Internationally[where?], a slow move from a centralized to decentralized power systems have taken place. The main draw of locally distributed generation systems is that they reduce transmission losses by leading to consumption of electricity closer to where it was produced.[37]\nUnder excess load conditions, the system can be designed to fail incrementally rather than all at once. Brownouts occur when power supplied drops below the demand. Blackouts occur when the grid fails completely.\nRolling blackouts (also called load shedding) are intentionally engineered electrical power outages, used to distribute insufficient power to various loads in turn.\nGrid operators require reliable communications to manage the grid and associated generation and distribution facilities. Fault-sensing protective relays at each end of the line must communicate to monitor the flow of power so that faulted conductors or equipment can be quickly de-energized and the balance of the system restored. Protection of the transmission line from short circuits and other faults is usually so critical that common carrier telecommunications are insufficiently reliable, while in some remote areas no common carrier is available. Communication systems associated with a transmission project may use:\nRarely, and for short distances, pilot-wires are strung along the transmission line path. Leased circuits from common carriers are not preferred since availability is not under control of the operator.\nTransmission lines can be used to carry data: this is called power-line carrier, or power-line communication (PLC). PLC signals can be easily received with a radio in the long wave range.\nOptical fibers can be included in the stranded conductors of a transmission line, in the overhead shield wires. These cables are known as optical ground wire (OPGW). Sometimes a standalone cable is used, all-dielectric self-supporting (ADSS) cable, attached to the transmission line cross arms.\nSome jurisdictions, such as Minnesota, prohibit energy transmission companies from selling surplus communication bandwidth or acting as a telecommunications common carrier. Where the regulatory structure permits, the utility can sell capacity in extra dark fibers to a common carrier.\nElectricity transmission is generally considered to be a natural monopoly, but one that is not inherently linked to generation.[38][39][40] Many countries regulate transmission separately from generation.\nSpain was the first country to establish a regional transmission organization. In that country, transmission operations and electricity markets are separate. The transmission system operator is Red Eléctrica de España (REE) and the wholesale electricity market operator is Operador del Mercado Ibérico de Energía – Polo Español, S.A. (OMEL) OMEL Holding | Omel Holding. Spain's transmission system is interconnected with those of France, Portugal, and Morocco.\nThe establishment of RTOs in the United States was spurred by the FERC's Order 888, Promoting Wholesale Competition Through Open Access Non-discriminatory Transmission Services by Public Utilities; Recovery of Stranded Costs by Public Utilities and Transmitting Utilities, issued in 1996.[41] In the United States and parts of Canada, electric transmission companies operate independently of generation companies, but in the Southern United States vertical integration is intact. In regions of separation, transmission owners and generation owners continue to interact with each other as market participants with voting rights within their RTO. RTOs in the United States are regulated by the Federal Energy Regulatory Commission.\nMerchant transmission projects in the United States include the Cross Sound Cable from Shoreham, New York to New Haven, Connecticut, Neptune RTS Transmission Line from Sayreville, New Jersey, to New Bridge, New York, and Path 15 in California. Additional projects are in development or have been proposed throughout the United States, including the Lake Erie Connector, an underwater transmission line proposed by ITC Holdings Corp., connecting Ontario to load serving entities in the PJM Interconnection region.[42]\nAustralia has one unregulated or market interconnector – Basslink – between Tasmania and Victoria. Two DC links originally implemented as market interconnectors, Directlink and Murraylink, were converted to regulated interconnectors.[43]\nA major barrier to wider adoption of merchant transmission is the difficulty in identifying who benefits from the facility so that the beneficiaries pay the toll. Also, it is difficult for a merchant transmission line to compete when the alternative transmission lines are subsidized by utilities with a monopolized and regulated rate base.[44] In the United States, the FERC's Order 1000, issued in 2010, attempted to reduce barriers to third party investment and creation of merchant transmission lines where a public policy need is found.[45]\nThe cost of high voltage transmission is comparatively low, compared to all other costs constituting consumer electricity bills. In the UK, transmission costs are about 0.2 p per kWh compared to a delivered domestic price of around 10 p per kWh.[46]\nThe level of capital expenditure in the electric power T&D equipment market was estimated to be $128.9 bn in 2011.[47]\nMainstream scientific evidence suggests that low-power, low-frequency, electromagnetic radiation associated with household currents and high transmission power lines does not constitute a short- or long-term health hazard.\nSome studies failed to find any link between living near power lines and developing any sickness or diseases, such as cancer. A 1997 study reported no increased risk of cancer or illness from living near a transmission line.[48] Other studies, however, reported statistical correlations between various diseases and living or working near power lines. No adverse health effects have been substantiated for people not living close to power lines.[49]\nThe New York State Public Service Commission conducted a study[50] to evaluate potential health effects of electric fields. The study measured the electric field strength at the edge of an existing right-of-way on a 765 kV transmission line. The field strength was 1.6 kV/m, and became the interim maximum strength standard for new transmission lines in New York State. The opinion also limited the voltage of new transmission lines built in New York to 345 kV. On September 11, 1990, after a similar study of magnetic field strengths, the NYSPSC issued their Interim Policy Statement on Magnetic Fields. This policy established a magnetic field standard of 200 mG at the edge of the right-of-way using the winter-normal conductor rating. As a comparison with everyday items, a hair dryer or electric blanket produces a 100 mG – 500 mG magnetic field.[51][52]\nApplications for a new transmission line typically include an analysis of electric and magnetic field levels at the edge of rights-of-way. Public utility commissions typically do not comment on health impacts.\nBiological effects have been established for acute high level exposure to magnetic fields above 100 μT (1 G) (1,000 mG). In a residential setting, one study reported \"limited evidence of carcinogenicity in humans and less than sufficient evidence for carcinogenicity in experimental animals\", in particular, childhood leukemia, associated with average exposure to residential power-frequency magnetic field above 0.3 μT (3 mG) to 0.4 μT (4 mG). These levels exceed average residential power-frequency magnetic fields in homes, which are about 0.07 μT (0.7 mG) in Europe and 0.11 μT (1.1 mG) in North America.[53][54]\nThe Earth's natural geomagnetic field strength varies over the surface of the planet between 0.035 mT and 0.07 mT (35 μT – 70 μT or 350 mG – 700 mG) while the international standard for continuous exposure is set at 40 mT (400,000 mG or 400 G) for the general public.[53]\nTree growth regulators and herbicides may be used in transmission line right of ways,[55] which may have health effects.\nIn some countries where electric locomotives or electric multiple units run on low frequency AC power, separate single phase traction power networks are operated by the railways. Prime examples are countries such as Austria, Germany and Switzerland that utilize AC technology based on 16 2/3 Hz. Norway and Sweden also use this frequency but use conversion from the 50 Hz public supply; Sweden has a 16 2/3 Hz traction grid but only for part of the system.\nHigh-temperature superconductors (HTS) promise to revolutionize power distribution by providing lossless transmission. The development of superconductors with transition temperatures higher than the boiling point of liquid nitrogen has made the concept of superconducting power lines commercially feasible, at least for high-load applications.[56] It has been estimated that waste would be halved using this method, since the necessary refrigeration equipment would consume about half the power saved by the elimination of resistive losses. Companies such as Consolidated Edison and American Superconductor began commercial production of such systems in 2007.[57]\nSuperconducting cables are particularly suited to high load density areas such as the business district of large cities, where purchase of an easement for cables is costly.[58]\n| Location | Length (km) | Voltage (kV) | Capacity (GW) | Date |\n|---|---|---|---|---|\n| Carrollton, Georgia | 2000 | |||\n| Albany, New York[60] | 0.35 | 34.5 | 0.048 | 2006 |\n| Holbrook, Long Island[61] | 0.6 | 138 | 0.574 | 2008 |\n| Tres Amigas | 5 | Proposed 2013 | ||\n| Manhattan: Project Hydra | Proposed 2014 | |||\n| Essen, Germany[62][63] | 1 | 10 | 0.04 | 2014 |\nSingle-wire earth return (SWER) or single-wire ground return is a single-wire transmission line for supplying single-phase electrical power to remote areas at low cost. It is principally used for rural electrification, but also finds use for larger isolated loads such as water pumps. Single-wire earth return is also used for HVDC over submarine power cables.\nBoth Nikola Tesla and Hidetsugu Yagi attempted to devise systems for large scale wireless power transmission in the late 1800s and early 1900s, without commercial success.\nIn November 2009, LaserMotive won the NASA 2009 Power Beaming Challenge by powering a cable climber 1 km vertically using a ground-based laser transmitter. The system produced up to 1 kW of power at the receiver end. In August 2010, NASA contracted with private companies to pursue the design of laser power beaming systems to power low earth orbit satellites and to launch rockets using laser power beams.\nWireless power transmission has been studied for transmission of power from solar power satellites to the earth. A high power array of microwave or laser transmitters would beam power to a rectenna. Major engineering and economic challenges face any solar power satellite project.\nThe federal government of the United States stated that the American power grid was susceptible to cyber-warfare.[64][65] The United States Department of Homeland Security works with industry to identify vulnerabilities and to help industry enhance the security of control system networks.[66]\nIn June 2019, Russia conceded that it was \"possible\" its electrical grid is under cyber-attack by the United States.[67] The New York Times reported that American hackers from the United States Cyber Command planted malware potentially capable of disrupting the Russian electrical grid.[68]\n- Highest capacity system: 12 GW Zhundong–Wannan (准东-皖南)±1100 kV HVDC.[69][70]\n- Highest transmission voltage (AC):\n- planned: 1.20 MV (Ultra-High Voltage) on Wardha-Aurangabad line (India), planned to initially operate at 400 kV.[71]\n- worldwide: 1.15 MV (Ultra-High Voltage) on Ekibastuz-Kokshetau line (Kazakhstan) (operating at 500kv)\n- Largest double-circuit transmission, Kita-Iwaki Powerline (Japan).\n- Highest towers: Yangtze River Crossing (China) (height: 345 m or 1,132 ft)\n- Longest power line: Inga-Shaba (Democratic Republic of Congo) (length: 1,700 kilometres or 1,056 miles)\n- Longest span of power line: 5,376 m (17,638 ft) at Ameralik Span (Greenland, Denmark)\n- Longest submarine cables:\n- As of 29 December 2023, the longest operational land-and-subsea HVDC interconnector is Viking Link between the UK and Denmark at 765 km, surpassing North Sea Link at 720 km.\n- North Sea Link, (Norway/United Kingdom) – (length of submarine cable: 720 kilometres or 447 miles)\n- NorNed, North Sea (Norway/Netherlands) – (length of submarine cable: 580 kilometres or 360 miles)\n- Basslink, Bass Strait, (Australia) – (length of submarine cable: 290 kilometres or 180 miles, total length: 370.1 kilometres or 230 miles)\n- Baltic Cable, Baltic Sea (Germany/Sweden) – (length of submarine cable: 238 kilometres or 148 miles, HVDC length: 250 kilometres or 155 miles, total length: 262 kilometres or 163 miles)\n- Longest underground cables:\n- Murraylink, Riverland/Sunraysia (Australia) – (length of underground cable: 170 kilometres or 106 miles)\n- Dynamic demand (electric power)\n- Demand response\n- List of energy storage power plants\n- Traction power network\n- Backfeeding\n- Conductor marking lights\n- Double-circuit transmission line\n- Electromagnetic Transients Program (EMTP)\n- Flexible AC transmission system (FACTS)\n- Geomagnetically induced current, (GIC)\n- Graphene-clad wire\n- Grid-tied electrical system\n- List of high-voltage underground and submarine cables\n- Load profile\n- National Grid (disambiguation)\n- Power-line communications (PLC)\n- Power system simulation\n- Radio frequency power transmission\n- Wheeling (electric power transmission)\n- \"Grand Coulee Powerplant\". U.S. Bureau of Reclamation. Archived from the original on April 29, 2014. Retrieved March 11, 2015.\n- \"A Primer on Electric Utilities, Deregulation, and Restructuring of U.S. Electricity Markets\" (PDF). United States Department of Energy Federal Energy Management Program (FEMP). May 2002. Archived (PDF) from the original on October 9, 2022. Retrieved October 30, 2018.\n- \"Electric Power Generation, Transmission, and Distribution eTool\". OSHA. Retrieved September 4, 2025.\n- Hans Dieter Betz, Ulrich Schumann, Pierre Laroche (2009). Lightning: Principles, Instruments and Applications. Springer, pp. 202–203. ISBN 978-1-4020-9078-3. Retrieved on 13 May 2009.\n- Banerjee, Neela (September 16, 2001). \"After the Attacks: The Workers; Con Edison Crews Improvise as They Rewire a Truncated System\". The New York Times.\n- \"Investigation of the September 2013 Electric Outage of a Portion of Metro-North Railroad's New Haven Line\". documents.dps.ny.gov. 2014. Retrieved December 29, 2019.\n- NYSPSC case no. 13-E-0529\n- Thomas P. Hughes (1993). Networks of Power: Electrification in Western Society, 1880–1930. Baltimore: Johns Hopkins University Press. pp. 119–122. ISBN 0-8018-4614-5.\n- Guarnieri, M. (2013). \"The Beginning of Electric Energy Transmission: Part One\". IEEE Industrial Electronics Magazine. 7 (1): 57–60. doi:10.1109/MIE.2012.2236484. S2CID 45909123.\n- \"Electricity Transmission: A primer\" (PDF). National Council on Electricity Policy. Archived (PDF) from the original on October 9, 2022. Retrieved September 17, 2019.\n- Guarnieri, M. (2013). \"The Beginning of Electric Energy Transmission: Part Two\". IEEE Industrial Electronics Magazine. 7 (2): 52–59. doi:10.1109/MIE.2013.2256297. S2CID 42790906.\n- \"Great Barrington Experiment\". edisontechcenter.org.\n- \"William Stanley – Engineering and Technology History Wiki\". ethw.org. August 8, 2017.\n- Arnold Heertje, Mark Perlman Evolving Technology and Market Structure: Studies in Schumpeterian Economics, p. 138\n- Carlson, W. Bernard (2013). Tesla: Inventor of the Electrical Age. Princeton University Press. ISBN 1-4008-4655-2, p. 130\n- Jonnes, Jill (2004). Empires of Light: Edison, Tesla, Westinghouse, and the Race to Electrify the World. Random House Trade Paperbacks. ISBN 978-0-375-75884-3, p. 161.\n- Parke Hughes, Thomas (1993). Networks of Power: Electrification in Western Society, 1880–1930. JHU Press. pp. 120–121.\n- Garud, Raghu; Kumaraswamy, Arun; Langlois, Richard (2009). Managing in the Modular Age: Architectures, Networks, and Organizations. John Wiley & Sons. p. 249. ISBN 9781405141949.\n- Argersinger, R.E. (1915). \"Electric Transmission of Power\". General Electric Review. XVIII: 454.\n- Kiessling F, Nefzger P, Nolasco JF, Kaintzyk U. (2003). Overhead power lines. Springer, Berlin, Heidelberg, New York, p. 5\n- Bureau of Census data reprinted in Hughes, pp. 282–283\n- Hughes, pp. 293–295\n- \"Distribution Substations - Michigan Technological University\" (PDF). Archived (PDF) from the original on October 9, 2022. Retrieved April 20, 2019.\n- Paris, L.; Zini, G.; Valtorta, M.; Manzoni, G.; Invernizzi, A.; De Franco, N.; Vian, A. (1984). \"Present Limits of Very Long Distance Transmission Systems\" (PDF). CIGRE International Conference on Large High Voltage Electric Systems, 1984 Session, 29 August – 6 September. Global Energy Network Institute. Retrieved March 29, 2011.\n- \"NYISO Zone Maps\". New York Independent System Operator. Archived from the original on December 2, 2018. Retrieved January 10, 2014.\n- \"Transmission Facts, p. 4\" (PDF). American Electric Power. Archived from the original (PDF) on June 4, 2011.\n- California Public Utilities Commission Archived March 4, 2016, at the Wayback Machine Corona and induced currents\n- Curt Harting (October 24, 2010). \"AC Transmission Line Losses\". Stanford University. Retrieved June 10, 2019.\n- \"Where can I find data on electricity transmission and distribution losses?\". Frequently Asked Questions – Electricity. U.S. Energy Information Administration. November 19, 2009. Archived from the original on December 12, 2012. Retrieved March 29, 2011.\n- \"How much electricity is lost in electricity transmission and distribution in the United States?\". Frequently Asked Questions – Electricity. U.S. Energy Information Administration. January 9, 2019. Retrieved February 27, 2019.\n- Donald G. Fink and H. Wayne Beaty. (2007), Standard Handbook for Electrical Engineers (15th ed.). McGraw-Hill. ISBN 978-0-07-144146-9 section 18.5\n- Donald G. Fink, H. Wayne Beatty, Standard Handbook for Electrical Engineers 11th Edition, McGraw Hill, 1978, ISBN 0-07-020974-X, pages 15–57 and 15–58\n- Guarnieri, M. (2013). \"The Alternating Evolution of DC Power Transmission\". IEEE Industrial Electronics Magazine. 7 (3): 60–63. doi:10.1109/MIE.2013.2272238. S2CID 23610440.\n- Pontecorvo, Emily (February 20, 2024). \"There Is a Stupidly Easy Way To Expand the Grid - Heatmap News\". heatmap.news. Retrieved March 6, 2024.\n- Brad Plumer (April 14, 2024). \"The U.S. Urgently Needs a Bigger Grid. Here's a Fast Solution\". The New York Times.\n- \"Fact Sheet: Biden-Harris Administration Launches Federal-State Initiative to Bolster America's Power Grid\". The White House. May 28, 2024.\n- \"The Bumpy Road to Energy Deregulation\". EnPowered. March 28, 2016. Archived from the original on April 7, 2017. Retrieved April 6, 2017.\n- Schmalensee, Richard (2021). \"Strengths and weaknesses of traditional arrangements for electricity supply\". Handbook on Electricity Markets. Edward Elgar Publishing. p. 16. doi:10.4337/9781788979955.00008. ISBN 9781788979955. S2CID 244796440.\n- Raghuvir Srinivasan (August 15, 2004). \"Power transmission business is a natural monopoly\". The Hindu Business Line. The Hindu. Retrieved January 31, 2008.\n- Lynne Kiesling (August 18, 2003). \"Rethink the Natural Monopoly Justification of Electricity Regulation\". Reason Foundation. Archived from the original on February 13, 2008. Retrieved January 31, 2008.\n- \"FERC: Landmark Orders – Order No. 888\". www.ferc.gov. Archived from the original on December 19, 2016. Retrieved December 7, 2016.\n- \"How ITC Holdings plans to connect PJM demand with Ontario's rich renewables\". Utility Dive. December 8, 2014.\n- \"NEMMCO Power System Planning\". July 18, 2008. Archived from the original on July 18, 2008. Retrieved November 14, 2022.\n- Fiona Woolf (2003). Global Transmission Expansion. Pennwell Books. pp. 226, 247. ISBN 0-87814-862-0.\n- \"FERC: Industries – Order No. 1000 – Transmission Planning and Cost Allocation\". www.ferc.gov. Archived from the original on October 30, 2018. Retrieved October 30, 2018.\n- What is the cost per kWh of bulk transmission / National Grid in the UK (note this excludes distribution costs)\n- \"The Electric Power Transmission & Distribution (T&D) Equipment Market 2011–2021\". Archived from the original on June 18, 2011. Retrieved June 4, 2011.\n- Power Lines and Cancer Archived April 17, 2011, at the Wayback Machine, The Health Report / ABC Science - Broadcast on 7 June 1997 (Australian Broadcasting Corporation)\n- \"WHO | Electromagnetic fields and public health\". December 24, 2007. Archived from the original on December 24, 2007. Retrieved November 14, 2022.\n- Opinion No. 78-13 (issued June 19, 1978)\n- \"EMF Report for the CHPE\". TRC. March 2010. pp. 1–4. Retrieved November 9, 2018.\n- \"Electric and Magnetic Field Strengths\" (PDF). Transpower New Zealand Ltd. p. 2. Archived (PDF) from the original on October 9, 2022. Retrieved November 9, 2018.\n- \"Electromagnetic fields and public health\". Fact sheet No. 322. World Health Organization. June 2007. Archived from the original on July 1, 2007. Retrieved January 23, 2008.\n- \"Electric and Magnetic Fields Associated with the Use of Power\" (PDF). National Institute of Environmental Health Sciences. June 2002. Archived from the original (PDF) on October 9, 2022. Retrieved January 29, 2008.\n- \"Transmission Vegetation Management NERC Standard FAC-003-2 Technical Reference Page 14/50\" (PDF). nerc.com. Archived (PDF) from the original on October 9, 2022.\n- Jacob Oestergaard; et al. (2001). \"Energy losses of superconducting power transmission cables in the grid\" (PDF). IEEE Transactions on Applied Superconductivity. 11 (1): 2375. Bibcode:2001ITAS...11.2375O. doi:10.1109/77.920339. S2CID 55086502. Archived (PDF) from the original on October 9, 2022.\n- New Scientist and Reuters (May 22, 2007). \"Superconducting power line to shore up New York grid\". New Scientist.\n- \"Superconducting cables will be used to supply electricity to consumers\". Archived from the original on July 14, 2014. Retrieved June 12, 2014.\n- \"Superconductivity's First Century\". Archived from the original on August 12, 2012. Retrieved August 9, 2012.\n- \"HTS Transmission Cable\". www.superpower-inc.com.\n- \"IBM100 - High-Temperature Superconductors\". www-03.ibm.com. August 10, 2017. Archived from the original on April 3, 2012.\n- Patel, Sonal (March 1, 2012). \"High-Temperature Superconductor Technology Stepped Up\". POWER Magazine.\n- \"Operation of longest superconducting cable worldwide started\". phys.org.\n- Shiels, Maggie (April 9, 2009). \"Spies 'infiltrate US power grid'. BBC News.\n- \"Hackers reportedly have embedded code in power grid\". CNN. April 9, 2009.\n- Holland, Steve; Mikkelsen, Randall (April 8, 2009). \"UPDATE 2-US concerned power grid vulnerable to cyber-attack\". Reuters. Archived from the original on January 13, 2016.\n- \"US and Russia clash over power grid 'hack attacks\". BBC News. June 18, 2019.\n- Greenberg, Andy (June 18, 2019). \"How Not To Prevent a Cyberwar With Russia\". Wired.\n- \"Development of UHV Transmission and Insulation Technology in China\" (PDF). Archived (PDF) from the original on October 9, 2022.\n- \"准东-皖南±1100千伏特高压直流输电工程竣工投运\". xj.xinhuanet.com. Archived from the original on September 30, 2019.\n- \"India Steps It Up\". Transmission & Distribution World. January 2013.\n- Grigsby, L. L., et al. The Electric Power Engineering Handbook. US: CRC Press. (2001). ISBN 0-8493-8578-4\n- Hughes, Thomas P., Networks of Power: Electrification in Western Society 1880–1930, The Johns Hopkins University Press, Baltimore 1983 ISBN 0-8018-2873-2, an excellent overview of development during the first 50 years of commercial electric power\n- Reilly, Helen (2008). Connecting the Country – New Zealand's National Grid 1886–2007. Wellington: Steele Roberts. pp. 376 pages. ISBN 978-1-877448-40-9.\n- Pansini, Anthony J, E.E., P.E. undergrounding electric lines. US: Hayden Book Co, 1978. ISBN 0-8104-0827-9\n- Westinghouse Electric Corporation, \"Electric power transmission patents; Tesla polyphase system\". (Transmission of power; polyphase system; Tesla patents)",
    "travel industry": "Tourism is travel for pleasure, and the commercial activity of providing and supporting such travel.[1] UN Tourism defines tourism more generally, in terms which go \"beyond the common perception of tourism as being limited to holiday activity only\", as people \"travelling to and staying in places outside their usual environment for not more than one consecutive year for leisure and not less than 24 hours, business and other purposes\".[2] Tourism can be domestic (within the traveller's own country) or international. International tourism has both incoming and outgoing implications on a country's balance of payments.\nBetween the second half of 2008 and the end of 2009, tourism numbers declined due to a severe economic slowdown (see Great Recession) and the outbreak of the 2009 H1N1 influenza virus.[3][4] These numbers, however, recovered until the COVID-19 pandemic put an abrupt end to the growth.[5] The United Nations World Tourism Organization has estimated that global international tourist arrivals might have decreased by 58% to 78% in 2020, leading to a potential loss of US$0.9–1.2 trillion in international tourism receipts.[6]\nGlobally, international tourism receipts (the travel item in the balance of payments) grew to US$1.03 trillion (€740 billion) in 2005, corresponding to an increase in real terms of 3.8% from 2010.[7] International tourist arrivals surpassed the milestone of 1 billion tourists globally for the first time in 2012.[8] Emerging source markets such as China, Russia, and Brazil had significantly increased their spending over the previous decade.[9]\nGlobal tourism accounts for c. 8% of global greenhouse-gas emissions.[10] Emissions as well as other significant environmental and social impacts are not always beneficial to local communities and their economies. Many tourist development organizations are shifting focus to sustainable tourism to minimize the negative effects of growing tourism. This approach aims to balance economic benefits with environmental and social responsibility. The United Nations World Tourism Organization emphasized these practices by promoting tourism as part of the Sustainable Development Goals, through programs such as the International Year for Sustainable Tourism for Development in 2017.[11]\nThe English-language word tourist was used in 1772[12] and tourism in 1811.[13][14] These words derive from the word tour, which comes from Old English turian, from Old French torner, from Latin tornare, \"to turn on a lathe\", which is itself from Ancient Greek tornos (τόρνος), \"lathe\".[15]\nIn 1936, the League of Nations defined a foreign tourist as \"someone traveling abroad for at least twenty-four hours\". Its successor, the United Nations, amended this definition in 1945, by including a maximum stay of six months.[16]\nIn 1941, Hunziker and Kraft defined tourism as \"the sum of the phenomena and relationships arising from the travel and stay of non-residents, insofar as they do not lead to permanent residence and are not connected with any earning activity.\"[17][18] In 1976, the Tourism Society of England's definition was: \"Tourism is the temporary, short-term movement of people to destinations outside the places where they normally live and work and their activities during the stay at each destination. It includes movements for all purposes.\"[19] In 1981, the International Association of Scientific Experts in Tourism defined tourism in terms of particular activities chosen and undertaken outside the home.[20]\nIn 1994, the United Nations identified three forms of tourism in its Recommendations on Tourism Statistics:[21]\n- Domestic tourism, involving residents of the given country traveling only within this country\n- Inbound tourism,[22] involving non-residents traveling into the given country\n- Outbound tourism, involving residents traveling to another country\nOther groupings derived from the above grouping:[23]\n- National tourism, a combination of domestic and outbound tourism\n- Regional tourism, a combination of domestic and inbound tourism\n- International tourism, a combination of inbound and outbound tourism\nTourism has reached new dimensions with the emerging industry of space tourism, as well as the transoceanic cruise ship industry.\nThe terms tourism and travel are sometimes used interchangeably. In this context, travel has a similar definition to tourism but implies a more purposeful journey. The terms tourism and tourist are sometimes used pejoratively, to imply a shallow interest in the cultures or locations visited. By contrast, traveller is often used as a sign of distinction. The sociology of tourism has studied the cultural values underpinning these distinctions and their implications for class relations.[24]\nThere are many varieties of tourism. Of those types, there are multiple forms of outdoor-oriented tourism. Outdoor tourism is generally categorized into nature, eco, and adventure tourism (NEAT). These categories share many similarities but also possess definite and unique characteristics. Nature tourism generally encompasses tourism activities that would take place outside. Nature tourism appeals to a large audience of tourists and many may not know they are participating in this form of tourism. This type of tourism has a low barrier to entry and is accessible to a large population. Ecotourism focuses on education, maintaining a social responsibility for the community and the environment, as well as centering economic growth around the local economy. Weaver describes ecotourism as sustainable nature-based tourism.[25] Ecotourism is more specific than nature tourism and works toward accomplishing a specific goal through the outdoors. Finally, we have adventure tourism. Adventure tourism is the most extreme of the categories and includes participation in activities and sports that require a level of skill or experience, risk, and physical exertion.[25] Adventure tourism often appeals less to the general public than nature and ecotourism and tends to draw in individuals who partake in such activities with limited marketing.\nIt is important to understand that these definitions may vary. Perceived risk in adventure tourism is subjective and may change for each individual.\nExamples of these tourism types include...\nNature tourism\nEcotourism\n- Guided tours focusing on educating, summer camps, outdoor classes\nAdventure tourism\nAccording to the World Tourism Organization, a tourism product is:[26]\n\"a combination of tangible and intangible elements, such as natural, cultural, and man-made resources, attractions, facilities, services and activities around a specific center of interest which represents the core of the destination marketing mix and creates an overall visitor experience including emotional aspects for the potential customers. A tourism product is priced and sold through distribution channels and it has a life-cycle.\"\nA tourist map shows the functional zones of a city.[27] Tourism products cover a wide variety of services including:[28]\n- Accommodation services from low-cost homestays to five-star hotels\n- Hospitality services including food and beverage serving centers\n- Health care services like massages\n- All modes of transport, its booking and rental\n- Travel agencies, guided tours and tourist guides\n- Cultural services such as religious monuments, museums, and historical places\n- Shopping\n- Additional travel services like airport parking, airport hotels and travel insurance\nInternational tourism is tourism that crosses national borders. Globalization has made tourism a popular global leisure activity. The World Tourism Organization defines tourists as people \"traveling to and staying in places outside their usual environment for not more than one consecutive year for leisure, business and other purposes\".[29] The World Health Organization (WHO) estimates that up to 500,000 people are in flight at any one time.[30]\nIn 2010, international tourism reached US$919B, growing 6.5% over 2009, corresponding to an increase in real terms of 4.7%.[31] In 2010, there were over 940 million international tourist arrivals worldwide.[32] By 2016 that number had risen to 1,235 million, producing $1.22 trillion USD in destination spending.[33] The COVID-19 crisis had significant negative effects on international tourism significantly slowing the overall increasing trend.\nInternational tourism has significant impacts on the environment, exacerbated in part by the problems created by air travel but also by other issues, including wealthy tourists bringing lifestyles that stress local infrastructure, water and trash systems among others. In many countries, there have been protests against Air bnb tourism raising rents.\nTourism typically requires the tourist to feel engaged in a genuine experience of the location they are visiting. According to Dean MacCannell, tourism requires that the tourist can view the toured area as both authentic and different from their own lived experience.[34][35]: 113 [better source needed] By viewing the \"exotic,\" tourists learn what they themselves are not: that is, they are \"un-exotic,\" or normal.[35][better source needed]\nAccording to MacCannell, all modern tourism experiences the \"authentic\" and \"exotic\" as \"developmentally inferior\" to the modern—that is, to the lived experience of the tourist.[35]: 114 [better source needed]\nTravel outside a person's local area for leisure was largely confined to wealthy classes, who at times travelled to distant parts of the world, to see great buildings and works of art, learn new languages, experience new cultures, enjoy pristine nature and to taste different cuisines. As early as Shulgi, however, kings praised themselves for protecting roads and building way stations for travellers. Travelling for pleasure can be seen in Egypt as early on as 1500 BC. Ancient Roman tourists during the Republic would visit spas and coastal resorts such as Baiae. The Roman upper class used to spend their free time on land or at sea and travelled to their villa urbana or villa maritima. Numerous villas were located in Campania, around Rome and in the northern part of the Adriatic as in Barcola near Trieste. Pausanias wrote his Description of Greece in the second century AD. In ancient China, nobles sometimes made a point of visiting Mount Tai and, on occasion, all five Sacred Mountains.\nBy the post-classical era, many religions, including Christianity, Buddhism, and Islam had developed traditions of pilgrimage. The Canterbury Tales (c. 1390s), which uses a pilgrimage as a framing device, remains a classic of English literature, and Journey to the West (c. 1592), which holds a seminal place in Chinese literature, has a Buddhist pilgrimage at the center of its narrative.\nIn medieval Italy, Petrarch wrote an allegorical account of his 1336 ascent of Mont Ventoux that praised the act of travelling and criticized frigida incuriositas (a 'cold lack of curiosity'); this account is regarded as one of the first known instances of travel being undertaken for its own sake.[36][37] The Burgundian poet Michault Taillevent later composed his own horrified recollections of a 1430 trip through the Jura Mountains.[38]\nIn China, 'travel record literature' (遊記文學; yóujì wénxué) became popular during the Song Dynasty (960–1279).[39] Travel writers such as Fan Chengda (1126–1193) and Xu Xiake (1587–1641) incorporated a wealth of geographical and topographical information into their writing, while the 'daytrip essay' Record of Stone Bell Mountain by the noted poet and statesman Su Shi (1037–1101) presented a philosophical and moral argument as its central purpose. [40]\nModern tourism can be traced to what was known as the Grand Tour, which was a traditional trip around Europe (especially Germany and Italy), undertaken by mainly upper-class European young men of means, mainly from Western and Northern European countries. In 1624, the young Prince of Poland, Ladislaus Sigismund Vasa, the eldest son of Sigismund III, embarked on a journey across Europe, as was in custom among Polish nobility.[41] He travelled through territories of today's Germany, Belgium, the Netherlands, where he admired the siege of Breda by Spanish forces, France, Switzerland to Italy, Austria, and the Czech Republic.[41] It was an educational journey[42] and one of the outcomes was introduction of Italian opera in the Polish–Lithuanian Commonwealth.[43]\nThe custom flourished from about 1660 until the advent of large-scale rail transit in the 1840s and generally followed a standard itinerary. It was an educational opportunity and rite of passage. Though primarily associated with the British nobility and wealthy landed gentry, similar trips were made by wealthy young men of Protestant Northern European nations on the Continent, and from the second half of the 18th century some South American, US, and other overseas youth joined in. The tradition was extended to include more of the middle class after rail and steamship travel made the journey easier, and Thomas Cook made the \"Cook's Tour\" a byword.\nThe Grand Tour became a status symbol for upper-class students in the 18th and 19th centuries. In this period, Johann Joachim Winckelmann's theories about the supremacy of classic culture became very popular and appreciated in the European academic world. Artists, writers, and travellers (such as Goethe) affirmed the supremacy of classic art of which Italy, France, and Greece provide excellent examples. For these reasons, the Grand Tour's main destinations were to those centers, where upper-class students could find rare examples of classic art and history.\nThe New York Times recently described the Grand Tour in this way:\nThree hundred years ago, wealthy young Englishmen began taking a post-Oxbridge trek through France and Italy in search of art, culture and the roots of Western civilization. With nearly unlimited funds, aristocratic connections and months (or years) to roam, they commissioned paintings, perfected their language skills and mingled with the upper crust of the Continent.\nThe primary value of the Grand Tour, it was believed, laid in the exposure both to the cultural legacy of classical antiquity and the Renaissance, and to the aristocratic and fashionably polite society of the European continent.\nLeisure travel was associated with the Industrial Revolution in the United Kingdom – the first European country to promote leisure time to the increasing industrial population.[44] Initially, this applied to the owners of the machinery of production, the economic oligarchy, factory owners and traders. These comprised the new middle class.[44] Cox & Kings was the first official travel company to be formed in 1758.[45]\nThe British origin of this new industry is reflected in many place names. In Nice, France, one of the first and best-established holiday resorts on the French Riviera, the long esplanade along the seafront is known to this day as the Promenade des Anglais; in many other historic resorts in continental Europe, old, well-established palace hotels have names like the Hotel Bristol, Hotel Carlton, or Hotel Majestic – reflecting the dominance of English customers.\nA pioneer of the travel agency business, Thomas Cook's idea to offer excursions came to him while waiting for the stagecoach on the London Road at Kibworth. With the opening of the extended Midland Counties Railway, he arranged to take a group of 540 temperance campaigners from Leicester Campbell Street station to a rally in Loughborough, eleven miles (18 km) away. On 5 July 1841, Thomas Cook arranged for the rail company to charge one shilling per person; this included rail tickets and food for the journey. Cook was paid a share of the fares charged to the passengers, as the railway tickets, being legal contracts between company and passenger, could not have been issued at his own price.[clarification needed] This was the first privately chartered excursion train to be advertised to the general public; Cook himself acknowledged that there had been previous, unadvertised, private excursion trains.[46] During the following three summers he planned and conducted outings for temperance societies and Sunday school children. In 1844, the Midland Counties Railway Company agreed to make a permanent arrangement with him, provided he found the passengers. This success led him to start his own business running rail excursions for pleasure, taking a percentage of the railway fares.[47]\nIn 1855, he planned his first excursion abroad, when he took a group from Leicester to Calais to coincide with the Paris Exhibition. The following year he started his \"grand circular tours\" of Europe.[48] During the 1860s he took parties to Switzerland, Italy, Egypt, and the United States. Cook established \"inclusive independent travel\", whereby the traveller went independently but his agency charged for travel, food, and accommodation for a fixed period over any chosen route. Such was his success that the Scottish railway companies withdrew their support between 1862 and 1863 to try the excursion business for themselves.\nAlthough tourism is more often associated with cultural appreciation and leisure, it is also directly connected with power dynamics, cultural representations, and conflicts.[49] As a matter of fact, tourism developed alongside violent colonial domination in many regions of the world.[50] Colonial authorities often developed transportation infrastructure that facilitated the growth of tourism, while simultaneously promoting racialized and demeaning representations of native populations.[51]\nThe violence of the colonial powers was justified by labelling European culture as superior and civilized, while labeling others as inferior, uncivilized and in-need of domestication.[52] European people often depicted non-European peoples and cultures as fundamentally different and inferior, establishing hierarchical representations of societies in various kinds of media such as academic books, travel journals, and travel guidebooks.[53] [54] [55] By portraying colonized societies as inferior on the hierarchy of cultural value, they \"othered\" these populations.[55] The concept of \"othering\" refers to the representation of individuals and cultures in a way that simultaneously romanticizes and devalues them, with the goal of establishing dominance.[55] \"Othering\" also refers to representing peoples while ignoring their own self-representations.[55]\nIn the 19th century, in order to foster the development of tourism in the colonies, touristic enterprises used tourist media to present them as attractive destinations for European travelers.[54] Consequently, tourism media not only promoted the colonies as touristic destinations and helped shape popular conceptions about them, but also helped consolidate ideas of Western cultural superiority.[56][57] One notable example is Thomas Cook's travel enterprise established in the United Kingdom in 1841 and his travel newspaper called “The Excursionist”.[58][59] Thomas Cook enterprise promoted touristic excursions and package tours all over the world. In the case of the tour to Egypt, Thomas Cook & Son’s promotional materials aimed to portray it as an “out-of-the-ordinary”, wild, yet safe and domesticated destination, appealing to European tourists’ desire for both familiarity and adventure.[60] Thomas Cook & Son collaboration with the British Empire during the occupation of Egypt facilitated European access to the Middle East through the construction of transportation networks such as steamships on the River Nile.[61][50] At the same time, it reinforced Eurocentric and imperial politics.[62][50]\nThese narratives, as reflected in travel guidebooks present in the Orientalist collection, often reveal more about the symbolic authority of European powers over colonized regions than they do about the actual cultures depicted.[63] The process of othering and categorizing societies into simplistic binary oppositions—such as civilized/primitive and superior/inferior — contributes to the perpetuation of imperialist ideologies because it silences the voices of local communities and obscures their cultural complexity.[64]\nIn the period following World War II, an increasing number of individuals from diverse backgrounds were able to participate in tourism.[65]\nPrior to the Civil Rights Act, Black travellers encountered specific challenges when travelling within the United States.[66] Jim Crow legislation enforced racial segregation in numerous public spaces, including public transport, accommodation, and tourist sites in general.[67][66]\nThe Negro Motorist Green Book was a travel guide published from 1936 to 1967 by Victor and Alma Duke Green. It was aimed at Black travellers in the United States during the era of segregation and listed places where Black travellers were welcome.[68] Several major companies collaborated with the Green Book. For instance, the Esso Standard Oil Company placed advertisements in the Green Book and sold it at their nationwide gas stations.[68]\nCultural and natural heritage are in many cases the absolute basis for worldwide tourism. Cultural tourism is one of the mega-trends that is reflected in massive numbers of overnight stays and sales. As UNESCO is increasingly observing, the cultural heritage is needed for tourism, but also endangered by it. The \"ICOMOS - International Cultural Tourism Charter\" from 1999 is already dealing with all of these problems. As a result of the tourist hazard, for example, the Lascaux cave was rebuilt for tourists. Overtourism is an important buzzword in this area. Furthermore, the focus of UNESCO in war zones is to ensure the protection of cultural heritage in order to maintain this future important economic basis for the local population. And there is intensive cooperation between UNESCO, the United Nations, the United Nations peacekeeping and Blue Shield International. There are extensive international and national considerations, studies and programs to protect cultural assets from the effects of tourism and those from war. In particular, it is also about training civilian and military personnel. But the involvement of the locals is particularly important. The founding president of Blue Shield International Karl von Habsburg summed it up with the words: \"Without the local community and without the local participants, that would be completely impossible'.[69][70][71][72]\nMass tourism and its tourist attractions have emerged as among the most iconic demonstration of western consumer societies.[73] Academics have defined mass tourism as travel by groups on pre-scheduled tours, usually under the organization of tourism professionals. This form of tourism developed during the second half of the 19th century in the United Kingdom and was pioneered by Thomas Cook. Cook took advantage of Europe's rapidly expanding railway network and established a company that offered affordable day trip excursions to the masses, in addition to longer holidays to Continental Europe, India, Asia and the Western Hemisphere which attracted wealthier customers. By the 1890s over 20,000 tourists per year used Thomas Cook & Son.\nThe relationship between tourism companies, transportation operators and hotels is a central feature of mass tourism. Cook was able to offer prices that were below the publicly advertised price because his company purchased large numbers of tickets from railroads. One contemporary form of mass tourism, package tourism, still incorporates the partnership between these three groups.\nTravel developed during the early 20th century and was facilitated by the development of the automobiles and later by airplanes. Improvements in transport allowed many people to travel quickly to places of leisure interest so that more people could begin to enjoy the benefits of leisure time.\nIn Continental Europe, early seaside resorts included: Heiligendamm, founded in 1793 at the Baltic Sea, being the first seaside resort; Ostend, popularized by the people of Brussels; Boulogne-sur-Mer and Deauville for the Parisians; Taormina in Sicily. In the United States, the first seaside resorts in the European style were at Atlantic City, New Jersey and Long Island, New York.\nBy the mid-20th century, the Mediterranean Coast became the principal mass tourism destination. The 1960s and 1970s saw mass tourism play a major role in the Spanish economic \"miracle\".[74]\nIn the 1960s and 1970s, scientists discussed negative socio-cultural impacts of tourism on host communities. Since the 1980s the positive aspects of tourism began to be recognized as well.[75]\nIn more recent times, mass tourism is something which has become a negative experience for local residents of cities and destinations that experience heavy tourism, especially in summer months. In July 2024 for example, protests by local residents in Barcelona, Spain were held in the city, where ″thousands of people joined an anti-tourism protest amid rising housing costs.″[76]\nNiche tourism refers to the specialty forms of tourism that have emerged over the years, each with its own adjective. Many of these terms have come into common use by the tourism industry and academics.[77] Others are emerging concepts that may or may not gain popular usage. Examples of the more common niche tourism markets are:\n- Agritourism\n- Birth tourism\n- Coastal island tourism\n- Culinary tourism\n- Cultural tourism\n- Dark tourism (also called \"black tourism\" or \"grief tourism\")\n- Eco tourism\n- Extreme tourism\n- Film tourism\n- Geotourism\n- Heritage tourism\n- LGBT tourism\n- Medical tourism\n- Nautical tourism\n- Pop-culture tourism\n- Religious tourism\n- Sex tourism\n- Slum tourism\n- Sports tourism\n- Tallest buildings tourism\n- Trains tourism (e.g., steam and model railways)\n- Virtual tourism\n- War tourism\n- Wellness tourism\n- Wildlife tourism\nOther terms used for niche or specialty travel forms include the term \"destination\" in the descriptions, such as destination weddings, and terms such as location vacation.\nThere has been a limited amount of orbital space tourism, with only the Russian Space Agency providing transport to date. A 2010 report into space tourism anticipated that it could become a billion-dollar market by 2030.[78][79] The space market has been around since 1979, however, there has been a limited amount of orbital space tourism, with only the Russian Space Agency providing transport on its Soyuz and the Chinese Shenzhou being the only two spacecrafts suitable for human travel . In April 2001, Dennis Tito, a customer of the Russian Soyuz became the first tourist to visit space. In May 2011, Virgin Galactic launched its SpaceShipTwo plane that allows people to travel 2 hours space at the advertised price of $200,000 per seat. A challenge that the commercial space tourism industry faces is to be able to have fundings from private investments needed to lower the cost of access to space in addition to being able to encourage both private and public sector support to increase capacity to allow commercial passengers. With space tourism still being new concept, there are many factors that needs to be considered for the industry. From its actual demand to its risk factor to its liabilities and insurance issues, there are still a lot of research that needs to be conducted. A 2010 report into space tourism anticipated that the industry is expected to grow by 18% - 26% per year during 2020 to 2030.\nSports tourism that attracts spectators is associated with negative impacts such as traffic congestion, vandalism, and anti-social behaviour. Sports tourist destinations may therefore be subject public displays of resentment and antagonism even though the host community benefits substantially. Sports tourism growth and decline can be subject to international commercial sporting events. For example, the irreversible environmental damage caused by the 1992 Winter Olympics is cited as a reason for stagnating ski tourism.[80]\nCruising is a popular form of water tourism. Leisure cruise ships were introduced by the P&O in 1844, sailing from Southampton to destinations such as Gibraltar, Malta and Athens.[81] In 1891, German businessman Albert Ballin sailed the ship Augusta Victoria from Hamburg into the Mediterranean Sea. 29 June 1900 saw the launching of the first purpose-built cruise ship was Prinzessin Victoria Luise, built in Hamburg for the Hamburg America Line.[82][83]\nSt. Moritz, Switzerland became the cradle of the developing winter tourism in the 1860s: hotel manager Johannes Badrutt invited some summer guests from England to return in the winter to see the snowy landscape, thereby inaugurating a popular trend.[85][86] It was, however, only in the 1970s when winter tourism took over the lead from summer tourism in many of the Swiss ski resorts. Even in winter, up to one third of all guests (depending on the location) consist of non-skiers.[87]\nMajor ski resorts are located mostly in the various European countries (e.g. Andorra, Austria, Bulgaria, Bosnia and Herzegovina, Croatia, Czech Republic, Cyprus, Finland, France, Germany, Greece, Iceland, Italy, Norway, Latvia, Lithuania, Poland, Romania, Serbia, Sweden, Slovakia, Slovenia, Spain, Switzerland, Turkey), Canada, the United States (e.g. Montana, Utah, Colorado, California, Wyoming, Vermont, New Hampshire, New York) Argentina, New Zealand, Japan, South Korea, Chile, and Lebanon.\nThere has been an up-trend in tourism over the last few decades,[vague] especially in Europe, where international travel for short breaks is common. Tourists have a wide range of budgets and tastes, and a wide variety of resorts and hotels have developed to cater for them. For example, some people prefer simple beach vacations, while others want more specialized holidays, quieter resorts, family-oriented holidays, or niche market-targeted destination hotels.\nThe developments in air transport infrastructure, such as jumbo jets, low-cost airlines, and more accessible airports have made many types of tourism more affordable. A major factor in the relatively low cost of air travel is the tax exemption for aviation fuels. The WHO estimated in 2009 that there are around half a million people on board aircraft at any given time.[30] There have also been changes in lifestyle, for example, some retirement-age people sustain year-round tourism. This is facilitated by internet sales of tourist services. Some sites have now started to offer dynamic packaging, in which an inclusive price is quoted for a tailor-made package requested by the customer upon impulse.\nThere have been a few setbacks in tourism, such as the September 11 attacks and terrorist threats to tourist destinations, such as in Bali and several European cities. Also, on 26 December 2004, a tsunami, caused by the 2004 Indian Ocean earthquake, hit the Asian countries on the Indian Ocean, including the Maldives. Thousands of people died including many tourists. This, together with the vast clean-up operations, stopped or severely hampered tourism in the area for a time.[88]\nIndividual low-price or even zero-price overnight stays have become more popular in the 2000s, especially with a strong growth in the hostel market and services like CouchSurfing and airbnb being established.[89] There has also been examples of jurisdictions wherein a significant portion of GDP is being spent on altering the primary sources of revenue towards tourism, as has occurred for instance in Dubai.[90]\nSustainable tourism is a concept that covers the complete tourism experience, including concern for economic, social, and environmental issues as well as attention to improving tourists' experiences and addressing the needs of host communities.[91] Sustainable tourism should embrace concerns for environmental protection, social equity, and the quality of life, cultural diversity, and a dynamic, viable economy delivering jobs and prosperity for all.[92] It has its roots in sustainable development and there can be some confusion as to what \"sustainable tourism\" means.[93]: 23 There is now broad consensus that tourism should be sustainable.[94][95] In fact, all forms of tourism have the potential to be sustainable if planned, developed and managed properly.[93] Tourist development organizations are promoting sustainable tourism practices in order to mitigate negative effects caused by the growing impact of tourism, for example its environmental impacts.\nThe United Nations World Tourism Organization emphasized these practices by promoting sustainable tourism as part of the Sustainable Development Goals, through programs like the International Year for Sustainable Tourism for Development in 2017.[96] There is a direct link between sustainable tourism and several of the 17 Sustainable Development Goals (SDGs).[93]: 26 Tourism for SDGs focuses on how SDG 8 (\"decent work and economic growth\"), SDG 12 (\"responsible consumption and production\") and SDG 14 (\"life below water\") implicate tourism in creating a sustainable economy.[97]Ecotourism, also known as ecological tourism, is responsible travel to fragile, pristine, and usually protected areas that strives to be low-impact and (often) small-scale. It helps educate the traveller; provides funds for conservation; directly benefits the economic development and political empowerment of local communities, and fosters respect for different cultures and for human rights. Take only memories and leave only footprints is a very common slogan in protected areas.[98] Tourist destinations are shifting to low carbon emissions following the trend of visitors more focused in being environmentally responsible adopting a sustainable behavior.[99]\nVolunteer tourism (or voluntourism) is growing as a largely Western phenomenon, with volunteers travelling to aid those less fortunate than themselves to counter global inequalities. Volunteer tourism is defined as applying \"to those tourists who, for various reasons, volunteer in an organised way to undertake holidays that might involve aiding or alleviating the material poverty of some groups in society\" (Wearing 2001). VSO founded in 1958 in the UK and the US Peace Corps founded in 1958 were the first large-scale voluntary organisations sending groups, initially arising to modernise less economically developed countries, which it was hoped would curb the influence of communism.\nThis form of tourism is largely praised for being a more sustainable approach to travel, with tourists attempting to assimilate into local cultures and avoiding the criticism of consumptive, exploitative mass tourism. However, increasingly, voluntourism is being criticised by scholars who suggest that volunteer tourism may have negative effects as it begins to undermine local labour and force unwilling host communities to adopt Western initiatives. While host communities without a strong heritage fail to retain volunteers who become dissatisfied with their experiences, volunteer shortages persist. Increasingly, organisations such as VSO have been concerned with community-centric volunteer programmes where power to control the future of the community is in the hands of local people.\nPro-poor tourism, which seeks to help the poorest people in developing countries, has been receiving increasing attention by those involved in development; the issue has been addressed through small-scale projects in local communities and through attempts by Ministries of Tourism to attract large numbers of tourists.[100] Research by the Overseas Development Institute suggests that neither is the best way to encourage tourists' money to reach the poorest as only 25% or less (far less in some cases) ever reaches the poor; successful examples of money reaching the poor include mountain-climbing in Tanzania and cultural tourism in Luang Prabang, Laos.[101] There is also the possibility of pro-poor tourism principles being adopted in centre sites of regeneration in the developed world.[102]\nRecession tourism is a travel trend which evolved by way of the world economic crisis. Recession tourism is defined by low-cost and high-value experiences taking place at once-popular generic retreats. Various recession tourism hotspots have seen business boom during the recession thanks to comparatively low costs of living and a slow world job market suggesting travellers are elongating trips where their money travels further. This concept is not widely used in tourism research. It is related to the short-lived phenomenon that is more widely known as staycation. In general, studies have primarily focused on the short-term effects of the crisis on tourism demand, often overlooking the long-term implications for the competitive positioning of the impacted destinations.[103]\nWhen there is a significant price difference between countries for a given medical procedure, particularly in Southeast Asia, India, Sri Lanka, Eastern Europe, Cuba[104] and Canada[105] where there are different regulatory regimes, in relation to particular medical procedures (e.g. dentistry), travelling to take advantage of the price or regulatory differences is often referred to as \"medical tourism\".\nEducational tourism is developed because of the growing popularity of teaching and learning of knowledge and the enhancing of technical competency outside of the classroom environment. Brent W. Ritchie, publisher of Managing Educational Tourism, created a study of a geographic subdivision to demonstrate how tourism educated high school students participating in foreign exchange programs over the last 15 years.[106] In educational tourism, the main focus of the tour or leisure activity includes visiting another country to learn about the culture, study tours, or to work and apply skills learned inside the classroom in a different environment, such as in the International Practicum Training Program.[107] In 2018, one impact was many exchange students traveled to America to assist students financially in order to maintain their secondary education.[108]\nThis type of tourism is focused on tourists coming into a region to either participate in an event or to see an organized event put on by the city/region.[109] This type of tourism can also fall under sustainable tourism as well and companies that create a sustainable event to attend open up a chance to not only the consumer but their workers to learn and develop from the experience. Creating a sustainable atmosphere creates a chance to inform and encourage sustainable practices. An example of event tourism would be the music festival South by Southwest that is hosted in Austin, Texas annually. Every year people from all over the world flock to the city for one week to sit in on technology talks and see bands perform. People are drawn here to experience something that they are not able to experience in their hometown, which defines event tourism.\nCreative tourism has existed as a form of cultural tourism, since the early beginnings of tourism itself. Its European roots date back to the time of the Grand Tour, which saw the sons of aristocratic families travelling for the purpose of mostly interactive, educational experiences. More recently, creative tourism has been given its own name by Crispin Raymond and Greg Richards,[110] who as members of the Association for Tourism and Leisure Education (ATLAS), have directed a number of projects for the European Commission, including cultural and crafts tourism, known as sustainable tourism. They have defined \"creative tourism\" as tourism related to the active participation of travellers in the culture of the host community, through interactive workshops and informal learning experiences.[110]\nMeanwhile, the concept of creative tourism has been picked up by high-profile organizations such as UNESCO, who through the Creative Cities Network, have endorsed creative tourism as an engaged, authentic experience that promotes an active understanding of the specific cultural features of a place. UNESCO wrote in one of its documents: \"'Creative Tourism' involves more interaction, in which the visitor has an educational, emotional, social, and participative interaction with the place, its living culture, and the people who live there. They feel like a citizen.\"[111] Saying so, the tourist will have the opportunity to take part in workshops, classes and activities related to the culture of the destination.\nMore recently, creative tourism has gained popularity as a form of cultural tourism, drawing on active participation by travellers in the culture of the host communities they visit. Several countries offer examples of this type of tourism development, including the United Kingdom, Austria, France, the Bahamas, Jamaica, Spain, Italy, New Zealand and South Korea.[112][113]\nThe growing interest of tourists[114] in this new way to discover a culture regards particularly the operators and branding managers, attentive to the possibility of attracting a quality tourism, highlighting the intangible heritage (craft workshops, cooking classes, etc.) and optimizing the use of existing infrastructure (for example, through the rent of halls and auditoriums).\nExperiential travel (or \"immersion travel\") is one of the major market trends in the modern tourism industry. It is an approach to travelling which focuses on experiencing a country, city or particular place by connecting to its history, people, food and culture.[115]\nThe term \"experiential travel\" has been mentioned in publications since 1985,[116] but it was not discovered as a meaningful market trend until much later.\nOne emerging area of special interest has been identified by Lennon and Foley (2000)[117][118] as \"dark\" tourism. This type of tourism involves visits to \"dark\" sites, such as battlegrounds, scenes of horrific crimes or acts of genocide, for example concentration camps. Its origins are rooted in fairgrounds and medieval fairs.[119]\nSocial tourism is making tourism available to poor people who otherwise could not afford to travel for their education or recreation. It includes youth hostels and low-priced holiday accommodation run by church and voluntary organisations, trade unions, or in Communist times publicly owned enterprises. In May 1959, at the second Congress of Social Tourism in Austria, Walter Hunziker proposed the following definition: \"Social tourism is a type of tourism practiced by low-income groups, and which is rendered possible and facilitated by entirely separate and therefore easily recognizable services\".[120]\nAlso known as \"tourism of doom,\" or \"last chance tourism\", involves travelling to places that are environmentally or otherwise threatened (such as the ice caps of Mount Kilimanjaro, the melting glaciers of Patagonia, or the coral of the Great Barrier Reef) before it is too late. The trend emerged in the 21st century, identified in 2007 by travel trade magazine in 2007[121] and explored in The New York Times,[122] This type of tourism has been on the rise. Some see the trend as related to sustainable tourism or ecotourism due to the fact that a number of these tourist destinations are considered threatened by environmental factors such as global warming, overpopulation or climate change. Others worry that travel to many of these threatened locations increases an individual's carbon footprint and only hastens problems threatened locations are already facing.[123][124][125] As of 2024, climate change has been making Last Chance Tourism more popular, and riskier. In August 2024, an American was killed visiting an ice cave at the foot of the Breidamerkurjokull glacier.[126]\nReligious tourism, in particular pilgrimage, can serve to strengthen faith and to demonstrate devotion.[127] Religious tourists may seek destinations whose image encourages them to believe that they can strengthen the religious elements of their self-identity in a positive manner. Given this, the perceived image of a destination may be positively influenced by whether it conforms to the requirements of their religious self-identity or not.[128]\nDNA tourism, also called \"ancestry tourism\" or \"heritage travel\", is tourism based on DNA testing. These tourists visit their remote relatives or places where their ancestors came from, or where their relatives reside, based on the results of DNA tests. DNA tourism became a growing trend in 2019.[129][130]\nSleep tourism focuses on medical treatments or other approaches, and may focus on people who have difficulty falling asleep, people who experience interrupted sleep, people who don't feel rested after sleeping, snoring, breathing difficulties, and dreaming.[131]\nTourism has a significant impact on destinations, influencing their economy, culture, environment, and communities. Tourism positively affects many parties in society but can also be detrimental in certain situations.\nIn general, tourism positively affects the economy of its destination. The purchasing of commodities, and the usage of hotels and transport by tourists all contribute to economic activity within the country.\nThe sociocultural impacts of tourism are less straightforward, bringing both benefits and challenges to the destination. The interactions between tourists and locals foster a cultural exchange, particularly exposing tourists to a different culture through direct interactions and overall immersion. However, differing expectations in the societal and moral values of the tourists and those from the host location can cause friction between the two parties.\nWhile tourism may have positive impacts environmentally, through an increase in awareness of certain environmental issues, tourism overall negatively impacts the environment. Tourist destinations and attractions located in the wild may neglect environmental concerns to satisfy the demands of tourists, creating issues such as pollution and deforestation.\nTourism also has positive and negative health outcomes for local people.[132] The short-term negative impacts of tourism on residents' health are related to the density of tourist arrivals, the risk of disease transmission, road accidents, higher crime levels, as well as traffic congestion, crowding, and other stressful factors.[133] In addition, residents can experience anxiety and depression related to their risk perceptions about mortality rates, food insecurity, contact with infected tourists, etc.[134] At the same time, there are positive long-term impacts of tourism on residents' health and well-being outcomes through improving healthcare access, positive emotions, novelty, and social interactions.The tourism industry, as part of the service sector,[135] has become an important source of income for many regions and even for entire countries. The Manila Declaration on World Tourism of 1980 recognized its importance as \"an activity essential to the life of nations because of its direct effects on the social, cultural, educational, and economic sectors of national societies, and on their international relations.\"[2][136]\nTourism brings large amounts of income into a local economy in the form of payment for goods and services needed by tourists, accounting as of 2011[update] for 30% of the world's trade in services, and, as an invisible export, for 6% of overall exports of goods and services.[7] It also generates opportunities for employment in the service sector of the economy associated with tourism.[137] It is also claimed that travel broadens the mind.[138][139]\nThe hospitality industries which benefit from tourism include transportation services (such as airlines, cruise ships, transits, trains and taxicabs); lodging (including hotels, hostels, homestays, resorts and renting out rooms); and entertainment venues (such as amusement parks, restaurants, casinos, festivals, shopping malls, music venues, and theatres). This is in addition to goods bought by tourists, including souvenirs.\nOn the flip-side, tourism can degrade people[140] and sour relationships between host and guest.[141] Tourism frequently also puts additional pressure on the local environment.[142]\nThe economic foundations of tourism are essentially the cultural assets, the cultural property and the nature of the travel location. The World Heritage Sites are particularly worth mentioning today because they are real tourism magnets. But even a country's current or former form of government can be decisive for tourism. For example, the fascination of the British royal family brings millions of tourists to Great Britain every year and thus the economy around £550 million a year. The Habsburg family can be mentioned in Central Europe. According to estimates, the Habsburg brand should generate tourism sales of 60 million euros per year for Vienna alone. The tourist principle \"Habsburg sells\" applies.[143][144]\nIn 2004 the World Tourism Organization (UNWTO) forecasts that international tourism will continue growing at the average annual rate of 4 percent.[145] With the advent of e-commerce, tourism products have become prominent traded items on the internet.[146][147] Tourism products and services have been made available through intermediaries, although tourism providers (hotels, airlines, etc.), including small-scale operators, can sell their services directly.[148][149]\nAs a result of the late-2000s recession, international arrivals experienced a strong slowdown beginning in June 2008. Growth from 2007 to 2008 was only 3.7 percent during the first eight months of 2008. This slowdown on international tourism demand was also reflected in the air transport industry, with negative growth in September 2008 and a 3.3% growth in passenger traffic through September. The hotel industry also reported a slowdown, with room occupancy declining. In 2009 worldwide tourism arrivals decreased by 3.8 percent.[150] By the first quarter of 2009, real travel demand in the United States had fallen 6 percent over six quarters. While this was considerably milder than what occurred after the September 11 attacks, the decline was at twice the rate, as real GDP has fallen.[151][152] However, evidence suggests that tourism as a global phenomenon shows no signs of substantially abating in the long term.[153] The UNWTO has noted, that tourists increasingly view vacations and travel as a necessity rather than a luxury, and that this shift in attitudes may explain tourist numbers recovering globally in 2009.[150]\nIt has been suggested there is a strong correlation between tourism expenditure per capita and the degree to which countries play in the global context.[154] Not only as a result of the important economic contribution of the tourism industry, but also as an indicator of the degree of confidence with which global citizens leverage the resources of the globe for the benefit of their local economies. This is why any projections of growth in tourism may serve as an indication of the relative influence that each country will exercise in the future.\nAfter the September 11 attacks the tourism industry operators had to consider the health and safety of tourists because it became increasingly difficult to obtain liability insurance. The organisations willing to provide insurance to tourism industry operators required, that operators put in place best practice risk management structures. This included, that whatever was promised in the contract about the holiday was really delivered by the operator.[155]\nSecurity in Tourism is a sub-discipline of tourist studies that explores the factors that affect the ontological security of tourists. Risks are evaluated by their impact and nature.[156] Tourism security includes methodologies, theories and techniques oriented to protect the organic image of tourist destinations.[157] Three academic waves are significant in tourism security: risk perception theory, disaster management, and post-disaster consumption.[158]\nAndrew Spencer & Peter Tarlow argue that tourism security is not an easy concept to define. It includes a set of sub-disciplines, and global risks different in nature which cause different effects in the tourism industry. The rise of tourism security and safety as a consolidated discipline coincides with the globalization and ultimate maturation of the industry worldwide. Some threats include, for example, terrorist groups looking to destabilize governments affecting not only the local economies but killing foreign tourists to cause geopolitical tensions between delivery-country and receiving-tourist countries. Today, island destinations are more affected by terrorism and other global risks than other continent destinations [159][160]\nIn 2020 the COVID-19 pandemic travel bans and a substantial reduction in passenger travel by air and sea contributed to a sharp decline in tourism activity.[161] The World Tourism Organization (WTO) reported a 70% decrease in international travel in 2020, where 165 of 217 worldwide destinations completely stopped international tourism by April 2020. Since every country imposes different travel restrictions, it makes traveling plans complicated and often too difficult to figure out, thus the willingness to travel for the general population decreases. It is estimated that the United States lost 147 billion U.S. dollars in revenue from tourism between January and October 2020. Spain had the next highest loss of revenue at around 46.7 billion U.S dollars, and countries in Africa collectively lost about 55 billion dollars during April and June 2020.[citation needed]\n- Business tourism – Type of tourism\n- Cultural travel – Style of tourism\n- Environmental effects of aviation – Effect of emissions from aircraft engines\n- International tourism advertising\n- Medical tourism – People traveling abroad to obtain medical treatment\n- Noctourism\n- Outline of tourism – Overview and topical guide of tourism\n- Overtourism – Excessive number of tourists\n- Science tourism – Travel to notable science locations\n- Scuba diving tourism – Industry based on recreational diver travel\n- Sex tourism – Travel to engage in sexual activity\n- Snorkeling – Swimming while inhaling through a snorkel\n- Terminal tourism\n- Tombstone tourist – Person who visits grave sites\n- Tour guide – Person who provides cultural heritage interpretation to tourists\n- Tourist attraction – Place of interest where tourists visit\n- Touron – Pejorative for irresponsible tourists\n- Travel agency – Retailer that provides tourism-related services\n- Travel visa – Authority to enter, stay in, or exit a territory\n- World Tourism rankings – List compiled by the UN World Tourism Organization\n- Tourismphobia – Negative attitudes towards tourists\n- \"tourism\". Oxford English Dictionary (Online ed.). Oxford University Press.(Subscription or participating institution membership required.)\n- \"UNWTO technical manual: Collection of Tourism Expenditure Statistics\" (PDF). World Tourism Organization. 1995. p. 10. Archived from the original (PDF) on 22 September 2010. Retrieved 26 March 2009.\n- \"International tourism challenged by deteriorating global economy\" (PDF). UNWTO World Tourism Barometer. 7 (1). January 2009. Archived from the original (PDF) on 17 October 2013. Retrieved 17 November 2011.\n- \"UNWTO World Tourism Barometer Interim Update\" (PDF). UNWTO World Tourism Barometer. August 2010. Archived from the original (PDF) on 17 October 2013. Retrieved 17 November 2011.\n- \"International Tourist Arrivals Reach 1.4 billion Two Years Ahead of Forecasts | UN Tourism\". www.unwto.org. Retrieved 1 May 2025.\n- \"International Tourist Numbers Could Fall 60-80% in 2020\". www.unwto.org. Retrieved 16 September 2020.\n- Magalhães, Bianca dos Santos (1 July 2017). UNWTO Tourism Highlights: 2017 Edition. World Tourism Organization (UNWTO). doi:10.18111/9789284419029. ISBN 978-92-844-1902-9.\n- \"UNWTO World Tourism Barometer\" (PDF). UNWTO World Tourism Barometer. 11 (1). January 2013. Archived from the original (PDF) on 28 February 2013. Retrieved 9 April 2013.\n- \"China – the new number one tourism source market in the world\". World Tourism Organization. 4 April 2013. Archived from the original on 8 April 2013. Retrieved 9 April 2013.\n-\nLenzen, Manfred; Sun, Ya-Yen; Faturay, Futu; Ting, Yuan-Peng; Geschke, Arne; Malik, Arunima (7 May 2018). \"The carbon footprint of global tourism\". Nature Climate Change. 8 (6). Springer Nature Limited: 522–528. Bibcode:2018NatCC...8..522L. doi:10.1038/s41558-018-0141-x. ISSN 1758-6798. S2CID 90810502.\n[...] between 2009 and 2013, tourism's global carbon footprint has increased from 3.9 to 4.5 GtCO2e, four times more than previously estimated, accounting for about 8% of global greenhouse gas emissions. Transport, shopping and food are significant contributors. The majority of this footprint is exerted by and in high-income countries.\n- Tourism and the Sustainable Development Goals – Journey to 2030, Highlights. World Tourism Organization (UNWTO). 18 December 2017. doi:10.18111/9789284419340. ISBN 978-92-844-1934-0.\n- Griffiths, Ralph; Griffiths, G.E. (1772). \"Pennant's Tour in Scotland in 1769\". The Monthly Review, Or, Literary Journal. 46: 150. Retrieved 23 December 2011.\n- Harper, Douglas. \"tour (n.)\". Online Etymology Dictionary. Retrieved 23 December 2011.\n- \"tourism\". Oxford English Dictionary (Online ed.). Oxford University Press.(Subscription or participating institution membership required.)\n- \"Online Etymology Dictionary\". etymonline.com. Retrieved 3 June 2016.\n- Theobald, William F. (1998). Global Tourism (2nd ed.). Oxford [England]: Butterworth–Heinemann. pp. 6–7. ISBN 978-0-7506-4022-0. OCLC 40330075.\n- Hunziker, W; Krapf, K (1942). Grundriß Der Allgemeinen Fremdenverkehrslehre (in German). Zurich: Polygr. Verl. OCLC 180109383.\n- Spode, Hasso (1998). \"Geschichte der Tourismuswissenschaft\". In Haedrich, Günther (ed.). Tourismus-management: Tourismus-marketing Und Fremdenverkehrsplanung (in German). Berlin: [u.a.] de Gruyter. ISBN 978-3-11-015185-5. OCLC 243881885.\n- Beaver, Allan (2002). A Dictionary of Travel and Tourism Terminology. Wallingford: CAB International. p. 313. ISBN 978-0-85199-582-3. OCLC 301675778.\n- International Association of Scientific Experts in Tourism. \"The AIEST, its character and aims\". Archived from the original on 26 November 2011. Retrieved 29 March 2008.\n- \"Recommendations on Tourism Statistics\" (PDF). Statistical Papers (83): 5. 1994. Retrieved 12 July 2010.\n- \"ww.oicstatcom.org\" (PDF). Archived from the original (PDF) on 12 December 2019. Retrieved 19 June 2019.\n- \"Glossary:Tourism - Statistics Explained\". ec.europa.eu. 30 October 2020. Archived from the original on 30 October 2020. Retrieved 17 December 2020.\n- Edensor, Tim (1998). Tourists at the Taj: Performance and Meaning at a Symbolic Site. Psychology Press. ISBN 978-0-415-16712-3.\n- Weaver, David B. (2008). Ecotourism. Wiley Australia tourism series (2nd ed.). Milton, Qld: Wiley. ISBN 978-0-470-81304-1.\n- \"Product Development\". unwto.org. 21 November 2020. Archived from the original on 21 November 2020.\n- Erin H. Fouberg; Alexander B. Murphy (2020). Human Geography: People, Place, and Culture. Wiley. p. 268. ISBN 9781119577607.\n- \"Introduction to tourism\". visitbritain.org. 11 April 2020. Archived from the original on 11 April 2020.\n- \"UNWTO technical manual: Collection of Tourism Expenditure Statistics\" (PDF). World Tourism Organization. 1995. p. 14. Archived from the original (PDF) on 22 September 2010. Retrieved 26 March 2009.\n- Swine flu prompts EU warning on travel to US. The Guardian. 28 April 2009.\n- \"UNWTO World Tourism Barometer June 2009\" (PDF). UNWTO World Tourism Barometer. 7 (2). World Tourism Organization. June 2011. Archived from the original (PDF) on 19 November 2011. Retrieved 3 August 2009.\n- \"2011 Highlights\" (PDF). UNWTO World Tourism Highlights. UNWTO. June 2011. Archived from the original (PDF) on 13 January 2012. Retrieved 9 January 2012.\n- World Tourism Organization (UNWTO) (1 July 2017). UNWTO Tourism Highlights: 2017 Edition. World Tourism Organization (UNWTO). doi:10.18111/9789284419029. ISBN 978-92-844-1902-9.\n- Maccannell, Dean (1999). The Tourist: A New Theory of the Leisure Class (2nd ed.). University of California Press. p. 12. ISBN 9780520218925.\n- Nolt, Steven (2016). The Amish and the Media | Johns Hopkins University Press Books. jhupbooks.press.jhu.edu. doi:10.1353/book.44948. ISBN 9781421419572. Retrieved 30 November 2021.\n- Cassirer, Ernst (January 1943). \"Some Remarks on the Question of the Originality of the Renaissance\". Journal of the History of Ideas. 4 (1). University of Pennsylvania Press: 49–74. doi:10.2307/2707236. ISSN 0022-5037. JSTOR 2707236.\n- Halsall, Paul (August 1998). \"Petrarch: The Ascent of Mount Ventoux\". fordham.edu. Fordham University. Retrieved 5 March 2014.\n- Deschaux, Robert; Taillevent, Michault (1975). Un poète bourguignon du XVe siècle, Michault Taillevent: édition et étude. Librairie Droz. pp. 31–32. ISBN 978-2-600-02831-8.\n- Hargett 1985, p. 67.\n- Hargett, James M. (1985). \"Some Preliminary Remarks on the Travel Records of the Song Dynasty (960-1279)\". Chinese Literature: Essays, Articles, Reviews. 7 (1/2): 67–93. doi:10.2307/495194. JSTOR 495194.\n- Tomasz Bohun, Podróże po Europie, Władysław IV Wasa, Władcy Polski, p. 12\n- Adam Kucharski. \"Dyplomacja i turystyka – królewicz Władysław Waza w posiadłościach hiszpańskich (1624–1625)\". Silva Rerum. Archived from the original on 14 August 2019. Retrieved 7 June 2017.\n- The Oxford Illustrated History of Opera, ed. Roger Parker (1994): a chapter on Central and Eastern European opera by John Warrack, p. 240; The Viking Opera Guide, ed. Amanda Holden (1993): articles on Polish composers, p. 174\n- Singh, L.K. (2008). \"Issues in Tourism Industry\". Fundamental of Tourism and Travel. Delhi: Isha Books. p. 189. ISBN 978-81-8205-478-3.\n- \"History: Centuries of Experience\". Cox & Kings. Archived from the original on 25 May 2011. Retrieved 23 December 2011.\n- Ingle, R., 1991 Thomas Cook of Leicester, Bangor, Headstart History\n- \"Thomas Cook History\". Thomas Cook. Archived from the original on 19 September 2018. Retrieved 12 May 2017.\n- \"Key Dates 1841–2014\". Thomas Cook. Archived from the original on 5 August 2017. Retrieved 12 May 2017.\n- Hunter, F. Robert (2004). \"Tourism and Empire: The Thomas Cook & Son Enterprise on the Nile, 1868–1914\". Middle Eastern Studies. 40 (5): 28. doi:10.1080/0026320042000265666.\n- Baranowski, Shelley; Endy, Christopher; Hazbun, Waleed; Hom, Stephanie M.; Pirie, Gordon; Simmons, Tony; Zuelow, Eric G. E. (2015). \"Tourism and Empire\". Journal of Tourism History. 7 (1–2): 101. doi:10.1080/1755182X.2015.1063709.\n- Hunter, F. Robert (2004). \"Tourism and Empire: The Thomas Cook & Son Enterprise on the Nile, 1868–1914\". Middle Eastern Studies. 40 (5): 28–29. doi:10.1080/0026320042000265666.\n- Hunter, F. Robert (2004). \"Tourism and Empire: The Thomas Cook & Son Enterprise on the Nile, 1868–1914\". Middle Eastern Studies. 40 (5): 29. doi:10.1080/0026320042000265666.\n- Zuelow, Eric G. E. (2016). \"Chapter 5. Guidebooks and the importance of seeing the sights\". A History of Modern Tourism. London: Palgrave Macmillan. pp. 76–90. ISBN 9780230369641.\n- MacKenzie, John M. (2005). \"Chapter 1. Empires of Travel: British Guide Books and Cultural Imperialism in the 19th and 20th Centuries\". In John K. Walton (ed.). Histories of Tourism: Representation, Identity and Conflict. Bristol, Blue Ridge Summit: Channel View Publications. p. 31. doi:10.21832/9781845410339-003. ISBN 978-1-84541-033-9.\n- Said, Edward W. (1979). Orientalism. New York: Vintage Books. p. 20. ISBN 9780394740676.\n- Hunter, F. Robert (2004). \"Tourism and Empire: The Thomas Cook & Son Enterprise on the Nile, 1868–1914\". Middle Eastern Studies. 40 (5): 28–29. doi:10.1080/0026320042000265666.\n- MacKenzie, John M. (2005). \"Chapter 1. Empires of Travel: British Guide Books and Cultural Imperialism in the 19th and 20th Centuries\". In John K. Walton (ed.). Histories of Tourism: Representation, Identity and Conflict. Bristol, Blue Ridge Summit: Channel View Publications. p. 21. doi:10.21832/9781845410339-003. ISBN 978-1-84541-033-9.\n- Hunter, F. Robert (2004). \"Tourism and Empire: The Thomas Cook & Son Enterprise on the Nile, 1868–1914\". Middle Eastern Studies. 40 (5): 30. doi:10.1080/0026320042000265666.\n- Zuelow, Eric G. E. (2016). \"Chapter 5\". A History of Modern Tourism. London: Palgrave Macmillan. pp. 76–90. ISBN 9780230369641.\n- MacKenzie, John M. (2005). \"Chapter 1. Empires of Travel: British Guide Books and Cultural Imperialism in the 19th and 20th Centuries\". In John K. Walton (ed.). Histories of Tourism: Representation, Identity and Conflict. Bristol, Blue Ridge Summit: Channel View Publications. p. 20. doi:10.21832/9781845410339-003. ISBN 978-1-84541-033-9.\n- Hunter, F. Robert (2004). \"Tourism and Empire: The Thomas Cook & Son Enterprise on the Nile, 1868–1914\". Middle Eastern Studies. 40 (5): 31–32. doi:10.1080/0026320042000265666.\n- MacKenzie, John M. (2005). \"Chapter 1. Empires of Travel: British Guide Books and Cultural Imperialism in the 19th and 20th Centuries\". In John K. Walton (ed.). Histories of Tourism: Representation, Identity and Conflict. Bristol, Blue Ridge Summit: Channel View Publications. p. 25. doi:10.21832/9781845410339-003. ISBN 978-1-84541-033-9.\n- Said, Edward W. (1979). Orientalism. New York: Vintage Books. p. 6. ISBN 9780394740676.\n- Said, Edward W. (1979). Orientalism. New York: Vintage Books. p. 33. ISBN 9780394740676.\n- Zuelow, Eric (2016). A History of Modern Tourism. Palgrave. pp. 149–164. ISBN 978-0-230-36965-8.\n- Zuelow, Eric (2016). A History of Modern Tourism. Palgrave. p. 171. ISBN 978-0-230-36965-8.\n- Jackson, Antoinette T. (2020). Heritage, Tourism, and Race: The Other Side of Leisure. Taylor & Francis. p. 12. ISBN 978-1-00-004806-3.\n- Jackson, Antoinette T. (2020). Heritage, Tourism, and Race: The Other Side of Leisure. Taylor & Francis. p. 13. ISBN 978-1-00-004806-3. Retrieved 2 May 2025.\n- Rick Szostak: The Causes of Economic Growth: Interdisciplinary Perspectives. Springer Science & Business Media, 2009, ISBN 9783540922827; Markus Tauschek \"Kulturerbe\" (2013), p 166; Laurajane Smith \"Uses of Heritage\" (2006).\n- \"UNESCO Legal Instruments: Second Protocol to the Hague Convention of 1954 for the Protection of Cultural Property in the Event of Armed Conflict 1999\".Action plan to preserve heritage sites during conflict - UNITED NATIONS, 12 Apr 2019\n- \"Austrian Armed Forces Mission in Lebanon\" (in German). 28 April 2019.Culture: at the heart of SDGs. UNESCO-Kurier, April-Juni 2017.\n- Simon Osborne (27 September 2016). \"Don't look now, Venice tourists – the locals are sick of you\". The Guardian. Retrieved 10 May 2018.\n- Pau Obrador Pons; Mike Crang; Penny Travlou, eds. (2016). Cultures of Mass Tourism: Doing the Mediterranean in the Age of Banal Mobilities. Taylor & Francis. p. 2. ISBN 9781317155652.\n- S. Pack (2006). Tourism and Dictatorship Europe's Peaceful Invasion of Franco's Spain. Palgrave Macmillan US. p. 141. ISBN 9780230601161.\n- Putova, Barbora (2018). \"Anthropology of Tourism: Researching Interactions between Hosts and Guests\" (PDF). Czech Journal of Tourism. 7 (1): 71–92. doi:10.1515/cjot-2018-0004. S2CID 159280794. Archived from the original (PDF) on 10 July 2023. Retrieved 25 September 2022.\n- Al Jazeera Staff. \". Al Jazeera. Retrieved 10 July 2024.\n- Lew, Alan A. (2008). \"Long Tail Tourism: New geographies for marketing niche tourism products\" (PDF). Journal of Travel & Tourism Marketing. 25 (3–4): 409–19. CiteSeerX 10.1.1.467.6320. doi:10.1080/10548400802508515. S2CID 16085592. Archived from the original (PDF) on 14 June 2010. Retrieved 22 December 2011.\n- \"The Economic Impact of Commercial Space Transportation on the U. S Economy in 2009\" (PDF). Federal Aviation Administration. September 2010. p. 11. Retrieved 5 May 2012.\n- Cohen, E. (2017). The paradoxes of space tourism. Tourism Recreation Research, 42(1), 22-31.\n- James Higham (2007). Sport Tourism Destinations. Taylor & Francis. p. 225. ISBN 9781136364617.\n- \"Cruise News\". June 2012. Retrieved 17 December 2012.\n- \"The Prinzessin Victoria Luise – world's first cruise ship\". Cruising the Past. Retrieved 12 August 2018.\n- Russell, Mark A. (2020). Steamship nationalism: ocean liners and national identity in Imperial Germany and Atlantic world. Routledge studies in modern European history. Abingdon, Oxon; New York, NY: Routledge. ISBN 978-0-429-02771-0.\n- \"Rovaniemi Lapland Holidays – Discovering Finland\".\n- \"Birthplace of winter tourism\". Archived from the original on 17 October 2013.\n- \"Early Winter Tourism\". Tradition & History. St. Moritz: Kulm Hotel. Archived from the original on 19 December 2011. Retrieved 23 December 2011.\n- \"Winter hiking in Switzerland-Graubünden\". graubuenden.ch. Archived from the original on 29 January 2012. Retrieved 23 December 2011.\n- \"India Top Tourist Destinations & Attractions\". TravelCupio. Archived from the original on 8 June 2017. Retrieved 9 April 2017.\n- Marx, Patricia. \"Couch-surfing the globe\". The New Yorker. Retrieved 15 March 2014.\n- Cadene, Philippe (2013). Atlas of the Gulf States. p. 29.\n- \"Sustainable development | UNWTO\". www.unwto.org. Retrieved 25 September 2020.\n- Zeng, L. Economic Development and Mountain Tourism Research from 2010 to 2020: Bibliometric Analysis and Science Mapping Approach. Sustainability 2022, 14, 562. https://doi.org/10.3390/su14010562.\n- Fennell, David A.; Cooper, Chris (2020). Sustainable Tourism: Principles, Contexts and Practices. Bristol, Blue Ridge Summit: Multilingual Matters. pp. 198, 234. doi:10.21832/9781845417673. ISBN 978-1-84541-767-3. S2CID 228913882.\n- Peeters P., Gössling S., Ceron J.P., Dubois G., Patterson T., Richardson R.B., Studies E. (2004). The Eco-efficiency of Tourism.\n- Bramwell, B., & Lane, B. (1993). Sustainable tourism: An evolving global approach. Journal of sustainable tourism, 1(1), 1-5.\n- Tourism and the Sustainable Development Goals – Journey to 2030, Highlights. World Tourism Organization. 18 December 2017. doi:10.18111/9789284419340. ISBN 978-92-844-1934-0.\n- \"Tourism & Sustainable Development Goals – Tourism for SDGs\". Retrieved 10 January 2021.\n- \"Morgan Gamble\". Pinterest. Retrieved 9 June 2015.\n- Entrepreneuring Sustainable Tourism, Jack Soifer Editor, Lisboa, 2008, ISBN 978-989-95976-0-0\n- Freire-Medeiros, B. (2014). Touring poverty. Routledge.\n- Jonathan Mitchel (2009). \"Value chain analysis and poverty reduction at scale\". Overseas Development Institute. Archived from the original on 26 August 2010. Retrieved 3 October 2010.\n- Butler, Richard; Curran, Ross; O'Gorman, Kevin D. (1 September 2013). \"Pro-Poor Tourism in a First World Urban Setting: Case Study of Glasgow Govan\". International Journal of Tourism Research. 15 (5): 443–57. doi:10.1002/jtr.1888. ISSN 1522-1970.\n- Ramón, Ana (1 January 2014). \"The effects of economic crises on tourism success: an integrated model\". Tourism Economics.\n- Neuman, William (17 February 2015). \"Americans May See Appeal of Medical Tourism in Cuba\". The New York Times. ISSN 0362-4331. Retrieved 12 September 2016.\n- \"Evolving medical tourism in Canada | Deloitte Canada\". Deloitte Canada. Retrieved 12 September 2016.\n- McGladdery, Christine A.; Lubbe, Berendien A. (1 January 2017). \"Rethinking educational tourism: proposing a new model and future directions\". Tourism Review. 72 (3): 319–329. doi:10.1108/TR-03-2017-0055. hdl:2263/62536. ISSN 1660-5373.\n- Seraphin, H., Bah, M., Fyall, A., & Gowreesunkar, V. (2021). Tourism education in France and sustainable development goal 4 (quality education). Worldwide Hospitality and Tourism Themes.\n- Shulman, Robyn D. \"5 Ways Student Exchange Programs Affect The American Economy\". Forbes. Retrieved 17 February 2022.\n- Clare., Inkson (2012). Tourism management : an introduction. Minnaert, Lynn. Los Angeles: Sage. ISBN 978-1-84860-869-6. OCLC 760291882.\n- Wurzburger, Rebecca; et al. (2009). Creative Tourism: A Global Conversation: How to Provide Unique Creative Experiences for Travelers Worldwide: As Presented at the 2008 Santa Fe & UNESCO International Conference on Creative Tourism in Santa Fe, New Mexico, USA. Santa Fe: Sunstone Press. ISBN 978-0-86534-724-3. OCLC 370387178.\n- \"Towards Sustainable Strategies for Creative Tourism: discussion report of the planning meeting for the 2008 International Conference on Creative Tourism\". UNESCO Digital Library. 2006.\n- Lau, Samantha (14 November 2016). \"Creative tourism\". Legislative Council of the Hong Kong Special Administrative Region. Archived from the original on 5 March 2024.\n- \"Creative Friendly Destinations\". Creative Tourism Network. Retrieved 20 February 2022.\n- Charlie Mansfield Lecturer in Tourism Management and French. \"JTCaP Tourism Consumption Online Journal\". Tourismconsumption.org. Archived from the original on 15 April 2013. Retrieved 10 August 2013.\n- Bellafante, Ginia (6 July 2012). \"Your Home, the New Frontier for Tourists in New York City\". The New York Times.\n- Gattorna, John (1985). Insights in Strategic Retail Management. MCB University Press. ISBN 9780861762378. Retrieved 9 June 2015.\n- Quinion, Michael (26 November 2005). \"Dark Tourism\". World Wide Words. Retrieved 9 April 2010.\n- Lennon, J. John; Foley, Malcolm (2000). Dark Tourism. London: Continuum. ISBN 978-0-8264-5063-0. OCLC 44603703.\n- Cooper, Chris; et al. (2005). Tourism: Principles and Practice (3rd ed.). Harlow: Pearson Education. ISBN 978-0-273-68406-0. OCLC 466952897.\n- R., Goeldner, Charles (2009). Tourism : principles, practices, philosophies. Ritchie, J.R. Brent. (Eleventh ed.). Hoboken, N.J.: John Wiley. ISBN 978-0-470-38213-4. OCLC 261135450.\n{{cite book}}\n: CS1 maint: multiple names: authors list (link) - Shapiro, Kenneth (11 May 2007). \"The Tourism of Doom\". TravelAge West.\n- Salkin, Allen (16 December 2007). \". The New York Times. Retrieved 30 October 2012.\n- Lemelin, H., Dawson, J., & Stewart, E.J. (Eds.). (2013). Last chance tourism: adapting tourism opportunities in a changing world. Routledge.\n- Frew, E. (2008). Climate change and doom tourism: Advertising destinations 'before they disappear'. In J. Fountain & K. Moore (Chair), Symposium conducted at the meeting of the New Zealand Tourism & Hospitality Research Conference.\n- Hall, C.M. (2010). Crisis events in tourism: subjects of crisis in tourism. Current Issues in Tourism, 13(5), 401–17.\n- \"Climate Change Is Making 'Last Chance Tourism' More Popular, and Riskier\". NYT. 4 September 2024.\n- Jafari, Jafar; Scott, Noel (1 January 2014). \"Muslim world and its tourisms\" (PDF). Annals of Tourism Research. 44: 1–19. doi:10.1016/j.annals.2013.08.011. hdl:10072/63617.\n- Compare:\nGannon, Martin Joseph; Baxter, Ian W.F.; Collinson, Elaine; Curran, Ross; Farrington, Thomas; Glasgow, Steven; Godsman, Elliot M.; Gori, Keith; Jack, Gordon R.A. (11 June 2017). \"Travelling for Umrah: destination attributes, destination image, and post-travel intentions\" (PDF). The Service Industries Journal. 37 (7–8): 448–65. doi:10.1080/02642069.2017.1333601. ISSN 0264-2069. S2CID 54745153.\nThe result from the structural model suggests that destination attributes influence perceived destination image. Further, such tourists are likely to revisit or recommend Islamic destinations if their experience matches their perceived image of the destination. This implies that, while the religious characteristics of the destination remain important, destination managers cannot disregard the tangential, non-religious attributes of a destination which are crucial in order to satisfy more conventional tourist desires.\n- \"Why DNA tourism may be the big travel trend of 2019\". NBC News. Retrieved 7 October 2019.\n- Okona, Nneka M. (18 September 2019). \". Vox. Retrieved 7 October 2019.\n- Bennett, Elizabeth (15 March 2025). \"What is sleep tourism and why is it on the rise?\". National Geographic. Retrieved 15 March 2025.\n- Godovykh, Maksim; Ridderstaat, Jorge (1 September 2020). \"Health outcomes of tourism development: A longitudinal study of the impact of tourism arrivals on residents' health\". Journal of Destination Marketing & Management. 17 100462. doi:10.1016/j.jdmm.2020.100462. ISSN 2212-571X. PMC 7376339. S2CID 220688162.\n- Gursoy, Dogan; Ouyang, Zhe; Nunkoo, Robin; Wei, Wei (17 September 2018). \"Residents' impact perceptions of and attitudes towards tourism development: a meta-analysis\". Journal of Hospitality Marketing & Management. 28 (3): 306–333. doi:10.1080/19368623.2018.1516589. ISSN 1936-8623. S2CID 149483878.\n- Zhang, Yingfei; Ma, Zheng Feei (20 August 2020). \"Psychological responses and lifestyle changes among pregnant women with respect to the early stages of COVID-19 pandemic\". International Journal of Social Psychiatry. 67 (4): 344–350. doi:10.1177/0020764020952116. ISSN 0020-7640. PMC 8191160. PMID 32815434.\n- Tassiopoulos, Dimitri (2008). Tassiopoulos, Dimitri (ed.). New Tourism Ventures: An Entrepreneurial and Managerial Approach. Cape Town: Juta and Company Ltd. p. 10. ISBN 9780702177262.\n- Manila Declaration on World Tourism (PDF). World Tourism Conference. Manila, Philippines. 10 October 1980. pp. 1–4. Archived from the original (PDF) on 20 November 2012.\n- \"2012 Tourism Highlights\" (PDF). UNWTO. June 2012. Archived from the original (PDF) on 9 July 2012. Retrieved 17 June 2012.\n- \"Travel broadens the mind, but can it alter the brain?\". theguardian.com. 18 January 2016.\n- Rebanks, James (2019). \"James Rebanks: One shepherd and his beloved Herdwick sheep\". bbc.co.uk.\n-\nO'Grady, Alison, ed. (1990). The Challenge of Tourism: Learning Resources for Study and Action. Ecumenical Coalition on Third World Tourism. p. 19. ISBN 9789748555706. Retrieved 20 September 2019.\n[...] the products to be sold to international tourists are not only natural resources such as sea, sand and sun, but also the subservience of people in receiving countries.\n-\nSmith, Melanie K. (2003). Issues in Cultural Tourism Studies. Tourism / Routledge. London: Routledge. p. 50. ISBN 978-0-415-25638-4. Retrieved 30 May 2018.\nThe globalisation of tourism has partially exacerbated the relationships of inequality and subservience that are so commonplace in host-guest encounters. It is not simply enough for local people to accept their role as servants, guides or companions to a range of ever-changing tourists. They are also confronted increasingly by the luxurious global products of Western indulgence which remain far from their reach, rather like the thirsty Tantalus in his elusive pool of water.\n- Gössling, Stefan; Hansson, Carina Borgström; Hörstmeier, Oliver; Saggel, Stefan (1 December 2002). \"Ecological footprint analysis as a tool to assess tourism sustainability\". Ecological Economics. 43 (2): 199–211. Bibcode:2002EcoEc..43..199G. doi:10.1016/S0921-8009(02)00211-2. ISSN 0921-8009.\n- Laurajane Smith \"Uses of Heritage\" (2006); Regina Bendix, Vladimir Hafstein \"Culture and Property. An Introduction\" (2009) in Ethnologia Europaea 39/2\n- Gerhard Bitzan, Christine Imlinger \"Die Millionen-Marke Habsburg\" (German), in Die Presse, 15 July 2011.\n- \"Long-term Prospects: Tourism 2020 Vision\". World Tourism. 2004. Archived from the original on 19 June 2004.\n- Lock, S. (3 July 2018). \"Online travel market - Statistics & Facts\". Statista.\n- Statista Research Department (23 July 2019). \"Digital travel sales worldwide from 2014 to 2020\". Statista.\n- Lu, Jie; Lu, Zi (1 July 2004). \"Development, Distribution and Evaluation of Online Tourism Services in China\". Electronic Commerce Research. 4 (3): 221–39. doi:10.1023/B:ELEC.0000027981.81945.2a. ISSN 1389-5753. S2CID 6473875.\n- Karanasios, Stan; Burgess, Stephen (1 March 2008). \"Tourism and internet adoption: a developing world perspective\". International Journal of Tourism Research. 10 (2): 169–82. doi:10.1002/jtr.649. ISSN 1522-1970.\n- UNWTO. \"UNWTO Tourism Highlights\" (PDF). UNWTO. Archived from the original (PDF) on 5 January 2012. Retrieved 2 May 2012.\n- \"Impacts of the World Recession and Economic Crisis on Tourism: North America\".\n- Ritchie, J.R. Brent; Amaya Molinar, Carlos Mario; Frechtling, Douglas C. (2011). \"Impacts of the World Recession and Economic Crisis on Tourism: North America\". Journal of Travel Research. 49 (1): 5–15. doi:10.1177/0047287509353193. S2CID 154854770.\n- Spencer, A., Tarlow, P. E., Gowreesunkar, V. G., Maingi, S. W., Roy, H., Micera, R., ... & Lane, W. (2021). Tourism Destination Management in a Post-Pandemic Context, New York, Emerald.\n- \"airports & tourists\". Global Culture. 2007. Archived from the original on 5 June 2009. Retrieved 1 May 2007.\n- Jeff Wilks; Stephen J Stephen, eds. (2013). Managing Tourist Health and Safety in the New Millennium. Taylor & Francis. ISBN 9781136381348.\n- Mansfeld, Y., & Pizam, A. (Eds.). (2006). Tourism, security and safety. Routledge.\n- Tarlow, P. (2014). Tourism security: strategies for effectively managing travel risk and safety. Elsevier.\n- Vanessa GB Gowreesunkar et al. 2020. Tourism Destination Management in a Post-Pandemic Context: Global Issues and Destination Management Solutions, Emerald\n- Tourism Security. 2014. doi:10.1016/c2012-0-06812-3. ISBN 9780124115705.\n- Spencer, Andrew; Tarlow, Peter (22 February 2021), \"Introduction\", Tourism Safety and Security for the Caribbean, Emerald Publishing Limited, pp. 1–14, doi:10.1108/978-1-80071-318-520211003, ISBN 978-1-80071-319-2, S2CID 240831742, retrieved 30 November 2021\n- Tate, Curtis. \"International tourism won't come back until late 2021, UN panel predicts\". USA TODAY. Retrieved 24 November 2020.\n- Costa, P (1991). \"Managing tourism carrying capacity of art cities\". The Tourist Review. 46 (4): 8–11. doi:10.1108/eb058076.\n- Garlick, S (2002). \"Revealing the unseen: Tourism, art and photography\". Cultural Studies. 16 (2): 289–305. doi:10.1080/09502380110107599. S2CID 143902911.\n- Gartner, W.C. (1993). \"Image formation process\". Journal of Travel & Tourism Marketing. 2 (2–3): 191–216. doi:10.1300/j073v02n02_12.\n- Hughes, H.L. (1989). \"Tourism and the arts\". Tourism Management. 10 (2): 97–99. doi:10.1016/0261-5177(89)90050-2.\n- Phelps, A (1986). \"Holiday destination image: The problem of assessment—an example developed in Minorca\". Tourism Management. 7 (3): 168–80. doi:10.1016/0261-5177(86)90003-8.\n- Richardson, S.; Crompton, J. (1988). \"Cultural variations in perceptions of vacation attributes\". Tourism Management. 9 (2): 128–36. doi:10.1016/0261-5177(88)90022-2.\n- Holder IV, Floyd William (2009). An Empirical Analysis of the State's Monopolization of the Legitimate Means of Movement: Evaluating the Effects of Required Passport use on International Travel (M.P.A. thesis). Texas State University-San Marcos. OCLC 564144593. Docket Applied Research Projects. Paper 308.\n- Wilkerson, Chad (2003). \"Travel and Tourism: An Overlooked Industry in the U.S. and Tenth District\" (PDF). Economic Review. 88 (Third Quarter): 45–72. ISSN 0161-2387. OCLC 295437935. Archived from the original (PDF) on 9 January 2011. Retrieved 31 October 2007.\n- Antje Monshausen, Sustainable and development friendly In: D+C Vol.42.2015:4",
    "video game industry": "Appearance\n| Part of a series on the |\n| Video game industry |\n|---|\nThe video game industry is a significant segment of the leisure sector, straddling the tertiary sector, which provides services to people, and the quaternary sector, which focuses on knowledge-intensive activities such as research and technological development. This industry includes the development, marketing, distribution, monetization, and consumer feedback processes related to video games. The industry encompasses dozens of job disciplines and thousands of jobs worldwide.[1] The professions involved range from game designers and software engineers to sound designers, testers, marketers, and customer support staff. Video games have gradually gained increasing relevance as a widespread cultural phenomenon, exerting significant influence on many areas of contemporary society: from the economy and the labor market to education, from consumption patterns and daily habits to architecture and urban planning, passing through sectors such as healthcare, the automotive industry, cinema and television, fashion, and sports.[2]\nThe video game industry has grown from niche to mainstream.[3] As of July 2018[update], video games generated US$134.9 billion annually in global sales.[4] In the US, the industry earned about $9.5 billion in 2007, $11.7 billion in 2008, and US$25.1 billion in[update] 2010,[5] as per the ESA annual report. Research from Ampere Analysis indicated three points: the sector has consistently grown since at least 2015 and expanded 26% from 2019 to 2021, to a record $191 billion; the global games and services market is forecast to shrink 1.2% annually to $188 billion in 2022.[6] Video games now compete with movies, music, and television in terms of both popularity and revenue.\nThe video game industry has played an important role in improvement of computer hardware. Many parts of modern personal computers were originally improved to meet the needs of video games. The industry has influenced the technological advancement of personal computers through sound cards, graphics cards and 3D graphic accelerators, CPUs, and co-processors like PhysX.[citation needed] Sound cards, for example, were originally developed for games and then improved for adoption by the music industry.[7]\nIn 2017 in the United States, which represented about a third of the global video game market, the Entertainment Software Association estimated that there were over 2,300 development companies and over 525 publishing companies, including in hardware and software manufacturing, service providers, and distributors. These companies in total have nearly 66,000 direct employees. If including indirect employment, such as a developer using the services of a graphics design package from a different firm, the total number of employees involved in the video game industry rises above 220,000.[8]\nTraditionally, the video game industry has had six connected layers in its value chain based on the retail distribution of games:\n- Game development, representing programmers, designers, and artists, and their leadership, with support of middleware and other development tools.\n- Publishing, which typically includes both the source of funding the development of a video game, as well as providing the marketing and advertising for a game.\n- Distribution, whether through retail or digital channels. Distribution typically includes manufacturing and duplication of game media and packaging for retail games.\n- Retailer, storefront where the game is sold.\n- Consumers, the purchasers and players of video games\n- Hardware platform manufacturers, which can own and place limitations for content on the platform they have made, charging license fees to developers or publishers.\nAs games have transitioned from the retail to more digital market, parts of this value chain have become redundant. For example, the distributor may be redundant as a function of either the publisher or the retailer, or even in some cases as the case of indie games, the function of the developer themselves.[9]\nBen Sawyer of Digitalmill observes that the development side of the industry is made up of six connected and distinctive layers:\n- Capital and publishing layer: involved in paying for development of new games and seeking returns through licensing of the properties.\n- Product and talent layer: includes developers, designers and artists, who may be working under individual contracts or as part of in-house development teams.\n- Production and tools layer: generates content production tools, game development middleware, customizable game engines, and production management tools.\n- Distribution layer: or the \"publishing\" industry, involved in generating and marketing catalogs of games for retail and online distribution.\n- Hardware (or Virtual Machine or Software Platform) layer: or the providers of the underlying platform, which may be console-based, accessed through online media, or accessed through mobile devices such as smartphones. This layer includes network infrastructure and non-hardware platforms such as virtual machines (such as Java or Flash), or software platforms such as browsers or Facebook.\n- End-users layer: or the players of the games.[10]\nThe game industry employs those experienced in other traditional businesses, but some have experience tailored to the game industry. Some of the disciplines specific to the game industry include: game programmer, game designer, level designer, game producer, game artist, and game tester. Most of these professionals are employed by video game developers or video game publishers. However, many hobbyists also produce computer games and sell them commercially.[citation needed] Game developers and publishers sometimes employ those with extensive or long-term experience within the modding communities.[11]\nThis section may need to be rewritten to comply with Wikipedia's quality standards, as Section should focus on the history of segments of the industry (developers, publishers, etc.) and major events, which may be tied to hardware and software, but this should be less about reiterating the hardware and generations.. (March 2021) |\nPrior to the 1970s, there was no significant commercial aspect of the video game industry, but many advances in computing would set the stage for the birth of the industry.\nMany early publicly available interactive computer-based game machines used or other mechanisms to mimic a display; while technically not \"video games\", they had elements of interactivity between the player and the machine. Some examples of these included the 1940 \"Nimatron\", an electromagnetic relay-based Nim-playing device designed by Edward Condon and built by Westinghouse Electric for the New York World's Fair,[12] Bertie the Brain, an arcade game of tic-tac-toe, built by Josef Kates for the 1950 Canadian National Exhibition,[13] and Nimrod created by engineering firm Ferranti for the 1951 Festival of Britain.[14]\nThe development of cathode-ray tube, the core technology inside televisions, created several of the first true video games. In 1947, Thomas T. Goldsmith Jr. and Estle Ray Mann filed a patent for a \"cathode ray tube amusement device\". Their game, which uses a cathode-ray tube hooked to an oscilloscope display, challenges players to fire a gun at target.[15]\nBetween the 1950s and 1960s, with mainframe computers becoming available to campus colleges, students and others started to develop games that could be played at terminals that accessed the mainframe. One of the first known examples is Spacewar!, developed by Harvard and MIT employees Martin Graetz, Steve Russell, and Wayne Wiitanen.[16] The introduction of easy-to-program languages like BASIC for mainframes allowed for more simplistic games to be developed.\nThe arcade video game industry grew out of the pre-existing arcade game industry, which was previously dominated by electro-mechanical games (EM games). Following the arrival of Sega's EM game Periscope (1966), the arcade industry was experiencing a \"technological renaissance\" driven by \"audio-visual\" EM novelty games, establishing the arcades as a healthy environment for the introduction of commercial video games in the early 1970s.[17] In the late 1960s, a college student named Nolan Bushnell had a part-time job at an arcade where he became familiar with EM games such as Chicago Coin's racing game Speedway (1969), watching customers play and helping to maintain the machinery, while learning how it worked and developing his understanding of how the game business operates.[18]\nIn 1971, the first commercial arcade video game, Computer Space, was released.[19] The following year, Atari, Inc. released the first commercially successful video game, Pong, and 19,000 arcade cabinets of the original arcade version were sold.[20] In that year, video games were introduced to the home market with the release of the early video game console, the Magnavox Odyssey. However, both the arcade and home markets would be dominated by Pong clones, which flooded the market and led to the video game crash of 1977. The crash eventually came to an end with the success of Taito's Space Invaders, released in 1978, inspiring the golden age of video arcade games.[21] The game's success prompted the prevalence of arcade machines in mainstream locations such as shopping malls, traditional storefronts, restaurants, and convenience stores during the golden age.[22] More than 360,000 Space Invaders arcade cabinets were sold worldwide,[23] and by 1982, generated a revenue of $2 billion (equivalent to $6.52 billion in 2024) in quarters.[24][25]\nSpace Invaders was soon licensed for the Atari VCS (later known as Atari 2600), becoming the first \"killer app\" and quadrupling the console's sales.[26] The success of the Atari 2600 in turn revived the home video game market during the second generation of consoles, until the video game crash of 1983.[27] By the end of the 1970s, the personal computer game industry began forming from a hobby culture.\nIn the early 1980s, the golden age of video arcade games reached its zenith. The total sales of arcade video game machines in North America increased significantly during this period, from $50 million in 1978 to $900 million by 1981,[28] with the arcade video game industry's revenue in North America tripling to $2.8 billion in 1980.[29] By 1981, the arcade video game industry was generating an annual North American revenue of $5 billion[21][30] (equivalent to $17.3 billion in 2024). In 1982, the arcade video game industry reached its peak, generating $8 billion in quarters,[31] surpassing the annual gross revenue of both pop music ($4 billion) and Hollywood films ($3 billion) combined.[31] This was also nearly twice as much as the $3.8 billion generated by the home video game industry that year; both the arcade and home video game markets combined in 1982 total of $11.8 billion[31] (equivalent to $38.4 billion in 2024). The arcade video game industry would continue to generate an annual revenue of $5 billion in quarters through to 1985.[32] The most successful game of this era was Namco's Pac-Man, released in 1980, of which more than 350,000 cabinets were eventually sold,[33] and within a year, collected more than $1 billion in quarters;[34] in total, Pac-Man is estimated to have grossed over 10 billion quarters ($2.5 billion) during the 20th century.[34][35]\nIn the early 1980s, 8-bit home computing and home-made games boomed. This was especially in Europe (with the ZX Spectrum and Commodore 64) and in Asia (with the NEC PC-88 and MSX). Video game journalism arose at that time, which was later expanded to include covermounted cassettes and CDs. In 1983, the North American industry crashed due to the production of too many badly developed games (quantity over quality), resulting in the fall of the North American industry. The industry would eventually be revitalized by the release of the Nintendo Entertainment System, which resulted in the home console market being dominated by Japanese companies such as Nintendo,[10] while a professional European video game industry also began taking shape with companies such as Ocean Software and Gremlin Interactive.[36] In 1987, Nintendo lost a legal challenge against Blockbuster Entertainment, which continued game rentals in the same way as movies. In 1989, the Game Boy handheld system was launched.\nVideo games transitioned from having been showcased at general trade shows like Consumer Electronics Show, to dedicated shows like Nintendo Space World and Electronic Entertainment Expo.\nGame related technology advances of the 1990s include these:\n- The \"3D Revolution\" where 3D polygon graphics became the de facto standard for video game visual presentation, initially in the arcades during the early 1990s,[37] and then on home systems with 3D consoles and PC graphics cards in the mid-1990s.\n- The widespread adoption of CD-based storage and software distribution\n- Continuing advancement of CPU speed and sophistication\n- Widespread adoption of GUI-based operating systems, such as the series of Amiga OS, Microsoft Windows and Mac OS\n- Shrinking of hardware, with handheld game consoles and mobile phones, which enabled mobile gaming\n- The emergence of the Internet, which in the late 1990s enabled online cooperative play and competitive gaming\nAside from technology, in the early part of the decade, licensed games became more popular,[38][39] as did video game sequels.[40]\nThe arcades experienced a renaissance in the early 1990s following the release of Street Fighter II (1991), which led to a number of other popular fighting games such as Fatal Fury (1991) and Mortal Kombat (1992).[41][42] The arcade resurgence was further driven by increasing realism,[43] with the \"3D Revolution\" from 2D and pseudo-3D graphics to true real-time 3D polygon graphics, following the release of games such as Virtua Racing (1992) and Virtua Fighter (1993).[37][44] In the late 1990s, there was a transition away from arcades to home systems. Until about 1996–1997, arcade video games represented the largest sector of the global video game industry, before arcades declined and the console market surpassed arcade video games for the first time around 1997–1998.[45] Arcade systems such as the Sega Model 3 remained more technologically advanced than home systems in the late 1990s,[46][47] but the gap between arcade and home systems began narrowing in the late 1990s.\nThe video game industry generated worldwide sales of $19.8 billion in 1993[48] (equivalent to $43.1 billion in 2024), $20.8 billion in 1994[48] (equivalent to $44.1 billion in 2024), and an estimated $30 billion in 1998[49] (equivalent to $57.9 billion in 2024). In the United States alone, in 1994, arcades generated $7 billion[50] in quarters while home console game sales generated $6 billion[50] Combined, this was nearly two and a half times the $5 billion revenue generated by movies in the United States at the time.[50]\nIn 2000s, the video game industry was in heavy development; profit still drove technological advancement used by other industry sectors. Technologies such as Smartphones, virtual reality, and augmented reality were major drivers for game hardware and gameplay development. Though maturing, the video game industry was still very volatile, with third-party video game developers quickly cropping up, and just as quickly, going out of business.[citation needed] Nevertheless, many casual games and indie games became successful, such as Braid and Limbo. Game development for mobile phones (such as iOS and Android devices) and social networking sites emerged. For example, a Facebook game developer, Zynga, raised more than $300 million.[clarification needed][51]\nIndie games are not the main driver but significantly impact the industry, such as Spelunky, Fez, Don't Starve, Castle Crashers, and Minecraft, with millions of dollars and users.[52][unreliable source?] In the 2010s, the shift increased to casual and mobile gaming, and in 2016, the mobile video game market was estimated at $38 billion in revenues, compared to $6 billion for the console market and $33 billion for personal computing gaming.[53] Virtual reality and augmented reality games arose during this decade. As of 2014, newer game companies arose that vertically integrate live operations and publishing such as crowdfunding and other direct-to-consumer efforts, rather than relying on a traditional publishers, and some of these grew substantially.[54] Spurred by some initial events in the late 2000s, eSports centered around professional players in organized competitions and leagues for prize money, grew greatly over this decade, drawing hundreds of millions of viewers and reaching nearly $500 million in revenue by 2016 and expected to break $1 billion by 2019.[55]\nThe next generations of Xbox Series X/S and PlayStation 5 were planned for 2020, but the video game industry was affected by the COVID-19 pandemic that had a worldwide impact starting in March 2020 due to forced stay-at-home orders by governmental regulations. There were similar impacts to the video game industry as with other industries, such as cancellation of in-person trade shows, conventions and esports events, and the delay of many games into late 2020, 2021, or beyond, and the industry was one of the few to actually thrive from a home-bound population using video games to cope. The market had a 20% year-to-year growth from 2019, reaching over $179 billion in global revenue in both hardware and software for 2020.[56] Easily learned games with high social interactions were popular, including Animal Crossing: New Horizons,[57] Fall Guys, and Among Us.[58][59][60][61]\nAs the pandemic wore on from 2020 into 2021, a secondary effect was the impact of the global semiconductor chip shortage on hardware manufacturing. The three major console vendors, Nintendo, Microsoft, and Sony, were impacted by availability of supply of core components, and for the latter two, limited the launch of their new consoles. The chip supply shortage also affected personal computer gamers, coupled with demand for computer parts to be used in cryptocurrency mining, which artificially raised prices and made it difficult to purchase newer components.[62] However, after cryptocurrency mining started paying out less during and following the 2021–2022 cryptocurrency crash, computer parts such as GPUs have become more affordable as of August 2022.[63]\nEarly development costs were minimal, and video games could be quite profitable. Games developed by a single programmer, or by a small team of programmers and artists, could sell hundreds of thousands of copies each. Many of these games only took a few months to create, so developers could release multiple games per year. Thus, publishers could often be generous with benefits, such as royalties on the games sold. Many early game publishers started from this economic climate, such as Origin Systems, Sierra Entertainment, Capcom, Activision and Electronic Arts.\nAs computing and graphics power increased, so too did the size of development teams, as larger staffs were needed to address the ever-increasing technical and design complexities. The larger teams consist of programmers, artists, game designers, and producers. Their salaries can range anywhere from $50,000 to $120,000 generating large labor costs for firms producing video games[64] which can often take between one and three years to develop. Modern budgets typically reach millions of dollars and use middleware and pre-built game engines. In addition to growing development costs, marketing budgets have grown dramatically, sometimes two to three times of the cost of development.[65]\nTraditionally, the video game monetization method is to sell hard copies in retail store. Cheaper production and distribution methods include online distribution.[66]\nIn the 2010s, the video game industry had a major impact on the economy through the sales of major systems and games such as Call of Duty: Black Ops, which had over $650 million of sales in the game's first five days and which set a five-day global record for a movie, book or video game.[67] The game's income was more than the opening weekend of Spider-Man 3 and the previous title holder for a video game Halo 3.[68] Many individuals have also benefited from the economic success of video games including the former chairman of Nintendo and Japan's third richest man: Hiroshi Yamauchi.[69] By 2014, the global video game market was valued at over $93 billion.[70]\nThe industry wide adoption of high-definition graphics during the seventh generation of consoles greatly increased development teams' sizes and reduced the number of high-budget, high-quality games under development. In 2013 Richard Hilleman of Electronic Arts estimated that only 25 developers were working on such games for the eighth console generation, compared to 125 at the same point in the seventh generation-console cycle seven or eight years earlier.[71]\nBy 2018, the United States video game industry had matched that of the United States film industry on basis of revenue, with both having made around US$43 billion that year.[72][73]\nSince 2000, the video game industry was considered recession-proof, having thrived compared to other industries during the 2008 Great Recession, and as one of the more profitable industries during the COVID-19 pandemic in 2020 and 2021. Video games are seen as a low-cost vice and entertainment for consumers when approaching recession.[74][75] However, in 2022, atop pandemic economic fallout including chip shortages, supply chain disruption, and consumers preferring outdoor activities, the industry started to indicate recession with global revenues falling for the first time in twenty years.[76]\nThe industry's shift from brick and mortar retail to digital downloads led to a severe sales decline at video game retailers such as GameStop, following other media retailers superseded by Internet delivery, such as Blockbuster, Tower Records, and Virgin Megastores. GameStop diversified its services by purchasing chains that repair wireless devices and expanding its trade-in program through which customers trade used games for credit towards new games.[77] The company began to produce its own merchandise and games. In Britain, the games retailer Game revamped its stores so customers would spend time playing games there. It built a gaming arena for events and tournaments.[78] The shift to digital marketplaces, especially for smartphones, led to an influx of inexpensive and disposable games,[79] and lower engagement among gamers who otherwise purchased new games from retail.[80] Customers also shifted away from the tradition of buying games on their first day of release.[81]\nPublishers often funded trade-in deals to encourage consumers to purchase new games. Trade-in customers at the Australian retailer Game would purchase twice the games per year as non-trade-in customers. The sale of pre-owned games kept retailers in business, and composed about a third of Game's revenue. Retailers also saved on the UK's value-added tax, which only taxed the retailer's profit on pre-owned games, rather than the full sale on regular games. The former trade-in retail executives behind the trade-in price comparison site Trade In Detectives estimated that the United Kingdom's trade-in industry was about a third of the size of its new games business.[82] They figured that sites such as eBay, which convert used games into cash, compose about a quarter of the UK's trade-in market,[83] but do not keep the credit within the industry. While consumers might appear to receive better offers on these sites, they also take about 15 percent of the selling price in fees. Alternatively, some retailers will match the trade-in values offered by their competitors. Microsoft's original plan for the Xbox One attempted to translate trade-in deals for the digital marketplace, with a database of product licenses that shops would be able to resell with publisher permission, though the plan was poorly received or poorly sold.[82]\nVideo game industry practices are similar to those of other entertainment industries (e.g., the music recording industry), but the video game industry in particular has been accused of treating its development talent poorly. This promotes independent development, as developers leave to form new companies and projects. In some notable cases, these new companies grow large and impersonal, having adopted the business practices of their forebears, and ultimately perpetuate the cycle.\nHowever, unlike the music industry, where modern technology has allowed a fully professional product to be created extremely inexpensively by an independent musician, modern games require increasing amounts of manpower and equipment. This dynamic makes publishers, who fund the developers, much more important than in the music industry.\nIn the video game industry, it is common for developers to leave their current studio and start their own. A particularly famous case is the \"original\" independent developer Activision, founded by former Atari developers. Activision grew to become the world's second largest game publisher.[84] In the meantime, many of the original developers left to work on other projects. For example, founder Alan Miller left Activision to start another video game development company, Accolade (now Atari née Infogrames).\nActivision was popular among developers for giving them credit in the packaging and title screens for their games, while Atari disallowed this practice. As the video game industry took off in the mid-1980s, many developers faced the more distressing problem of working with fly-by-night or unscrupulous publishers that would either fold unexpectedly or run off with the game profits.\nThe industry claims software piracy to be a big problem, and takes measures to counter this.[85] Digital rights management have proved to be the most unpopular with gamers, as a measure to counter piracy.[86] The most popular and effective strategy to counter piracy is to change the business model to freemium, where gamers pay for their in-game needs or service. Strong server-side security is required for this, to properly distinguish authentic transactions from hacked transactions.\nOn various Internet forums, some gamers have expressed disapproval of publishers having creative control since publishers are more apt to follow short-term market trends rather than invest in risky but potentially lucrative ideas. On the other hand, publishers may know better than developers what consumers want. The relationship between video game developers and publishers parallels the relationship between recording artists and record labels in many ways. But unlike the music industry, which has seen flat or declining sales in the early 2000s,[87][88][89] the video game industry continues to grow.[90]\nIn the computer games industry, it is easier to create a startup, resulting in many successful companies. The console industry is more closed, and a game developer must have up to three licenses from the console manufacturer:\n- A license to develop games for the console\n- The publisher must have a license to publish games for the console\n- A separate license for each game\nIn addition, the developer must usually buy development systems from the console manufacturer in order to develop a game for consideration, as well as obtain concept approval for the game from the console manufacturer. Therefore, the developer normally has to have a publishing deal in place before starting development on a game project, but in order to secure a publishing deal, the developer must have a track record of console development, something which few startups will have.\nThere are some alternative methods for publishing video games, such as self-publish using the shareware or open source model over the Internet and Cloud gaming.\nCloud gaming is a gaming method based on cloud computing. The main technologies used in cloud gaming include cloud computing technology, which completes game operation and screen rendering in the cloud, and streaming media transmission technology between the player's terminal and the cloud.[91]\nCloud gaming is also known as on-demand gaming, is a new technology based on cloud computing. Obviously, on-demand gaming means that if you want it, you can get it; it's a service that can improve game performance.[92]\nCloud computing technology includes two categories: narrow and broad. Narrow cloud computing refers to the delivery and usage model of IT infrastructure, which means obtaining the required resources in an on-demand and easily scalable manner through the network; broad cloud computing refers to the delivery and usage model of services, which means obtaining the required services in an on-demand and easily scalable manner through the network. Such services can be IT and software, Internet-related, or other services.[91]\nCloud gaming is similar to video on demand. Many providers offer this technology, but it only requires a certain network speed and a monthly rental fee.[93]\nPeople are becoming increasingly familiar with the term \"cloud computing\" lately, and many are paying attention to its various applications, such as cloud IoT, cloud identity, cloud storage, and cloud security. The \"cloud\" has changed people's perception of the internet. It's worth noting that in this era of booming gaming, people are often limited by low-spec devices, which is very disappointing for gamers. Therefore, game developers are turning their attention to cloud gaming, which combines cloud computing with gaming.[92]\nIn the cloud gaming model, all game logic and rendering run on the server side, and then the compressed video is transmitted from the server to the user.[91] This way, players don't need a computer with a high-end CPU and GPU; the only requirements are basic video decompression software and a reliable network. However, if the network is unstable, cloud gaming can be unreliable.[94]\nloud gaming eliminates the dependence on hardware. For servers, it is only necessary to improve server performance without developing new host machines; for users, they can get higher image quality without buying high-performance computers. In other words, they can spend a small amount of money to rent a better computer to play various games, just like watching TV with a set-top box. This means that a lot of money can be saved on computer hardware, especially GPUs.[91]\nBy performing computation and rendering on remote servers, cloud gaming users can enjoy advanced games on low-cost devices via network connection without high-performance hardware.[91][93] This technology is increasingly seen as a natural extension of cloud services and is considered one of the key trends for the future development of the gaming industry.[91]\nWith the development of 5G technology and advancements in video compression, the network latency and stability requirements of cloud gaming are becoming easier to meet.[94] In 2024, the global cloud gaming industry reached $2.27 billion, and it is projected to exceed $21 billion by 2030, representing a compound annual growth rate of over 44%.[95] However, Although network and cloud rendering technologies developed significantly, user experience remains highly dependent on low network latency and high network stability. Poor network connectivity will continue to impact game performance and the player's gaming experience.[94]\nCompared with traditional game modes, cloud gaming can greatly reduce the equipment costs for players to play games. For many high-quality games that require long-term updates, cloud gaming can also reduce the cost for game developers to release and update and maintain games.\nHowever, in terms of ensuring the player's gaming experience, cloud gaming has certain gaps compared with traditional games, mainly including:\n- The game interaction latency depends on the network communication latency. Compared with traditional online games, which only need to transmit game state data, cloud gaming's multimedia transmission is more sensitive to network latency. When the network communication quality is poor, players will directly feel the high latency between command input and screen update, thus significantly reducing the quality of the player's gaming experience.[91][94]\n- The quality of the multimedia stream rendering of the game scene depends on the network communication bandwidth. Compared with traditional online games, cloud gaming's multimedia stream requires more bandwidth, and the higher the quality of the multimedia stream, the higher the bandwidth resources it consumes.[91][93]\nGaming conventions are an important showcase of the industry. The major annual video game conventions include Gamescom in Cologne (Germany) Penny Arcade Expo, Summer Games Fest, Tokyo Game Show(TGS), Brazil Game Show(BGS), and prior to its cancellation, E3 in Los Angeles (US),[96] etc.\nAs with other forms of media, video games have often been released in different world regions at different times.[97] The practice has been used where localization is not done in parallel with the rest of development[98] or where the game must be encoded differently, as in PAL vs. NTSC.[99] It has also been used to provide price discrimination in different markets or to focus limited marketing resources.[97] Developers may also stagger digital releases so as not to overwhelm the servers hosting the game.[100]\nThe video game industry had its primary roots in the United States following the introduction of arcade games and console systems, with Japan soon following. With the introduction of the personal computer, Western Europe also became a major center for video game development. Since then, the industry is primarily led by companies in North America, Europe, and Japan, but other regions, including Australia/New Zealand, and other East Asian countries including China and South Korea, have become significant sectors for the industry.\nInternational video game revenue was over $142B in 2022.[101] This is almost double the revenue of the international film industry in 2023.[102]\nThe gaming industry saw strong growth in 2020, the first year of the pandemic, and this trend continued into 2021.[103]\nAccording to market research firm Newzoo, the following countries are the largest video game markets by annual revenue, as of 2023[update]:[104]\n| Rank | Country | Revenue (billion US$) |\n|---|---|---|\n| 1 | China | 49.8 |\n| 2 | United States | 49.6 |\n| 3 | Japan | 16.8 |\n| 4 | South Korea | 7.3 |\n| 5 | Germany | 6.6 |\n| 6 | United Kingdom | 6.3 |\n| 7 | France | 4.0 |\n| 8 | Canada | 3.1 |\n| 9 | Brazil | 2.7 |\n| 10 | Mexico | 2.6 |\nAccording to market research firm Newzoo, the following countries are the largest video game markets by number of players in the top 10 richest video game markets, as of 2025[update]:[105]\n| Rank | Country | Number of players (million) |\n|---|---|---|\n| 1 | China | 723 million |\n| 2 | United States | 225 million |\n| 3 | Brazil | 123 million |\n| 4 | Mexico | 78 million |\n| 5 | Japan | 74 million |\n| 6 | Germany | 53 million |\n| 7 | France | 45 million |\n| 8 | United Kingdom | 43 million |\n| 9 | South Korea | 34 million |\n| 10 | Canada | 24 million |\nIn general, spending on gaming tends to increase with increase in nominal GDP. However, gaming is relatively more popular in East Asia, and relatively less popular in India.\nCanada has the third largest video game industry in terms of employment numbers.[106] The video game industry has also been booming in Montreal since 1997, coinciding with the opening of Ubisoft Montreal.[107] Recently, the city has attracted world leading game developers and publishers studios such as Ubisoft, EA, Eidos Interactive, Artificial Mind and Movement, BioWare, Warner Bros. Interactive Entertainment, and Strategy First, mainly because video games jobs have been heavily subsidized by the provincial government. Every year, this industry generates billions of dollars and thousands of jobs in the Montreal area.[108] Vancouver has also developed a particularly large cluster of video game developers, the largest of which, Electronic Arts, employs over two thousand people. The Assassin's Creed series, along with the Tom Clancy series have all been produced in Canada and have achieved worldwide success. For consumers, the largest video games convention in Canada is the Enthusiast Gaming Live Expo (EGLX).[109]\nThe video game industry got its start in the United States in the 1970s and early 1980s with the creation of arcade games like Pong and the first home console, the Magnavox Odyssey. Several factors, including loss of publishing control, a flooded market, and competition from personal computers, led to the 1983 video game crash in the U.S., affecting both arcades and home game systems. Nintendo's introduction of the Nintendo Entertainment System helped to revitalize the industry, but until Microsoft's introduction of the Xbox in the early 2000s, the hardware side was dominated by mostly Japanese-developed systems. Instead, much of the industry's growth in the U.S. was on game development, implementing new game technologies and gameplay concepts, as well as creating the large-scale publisher model used by companies like Electronic Arts to support marketing and distribution of games.\nThe United States has the largest video games presence in the world in terms of total industry employees.[106][110] In 2017, the U.S. game industry as a whole was worth US$18.4 billion and consisted of roughly 2457 companies that had a rough total of 220,000 people employed.[111][112] U.S. video game revenue is forecast to reach $230 billion by 2022,[113] making it the largest video game market in the world.[114] Over 150 million Americans play video games, with an average age of 35 and a gender breakdown of 59 percent male and 41 percent female.[115] American gamers are more likely to vote than non-gamers, feel that the economy is the most important political issue, and lean conservative, however party demographics are split evenly with 38% identifying as Democrats, 38% identifying as Republicans, and 24% identifying as Independents.[116]\nGermany has the largest video games market in Europe, with revenues of $4.1 billion forecast for 2017.[117] The annual Gamescom in Cologne is Europe's largest video game expo.\nOne of the earliest internationally successful video game companies was Gütersloh-based Rainbow Arts (founded in 1984) who were responsible for publishing the popular Turrican series of games. The Anno series and The Settlers series are globally popular strategy game franchises since the 1990s. The Gothic series, SpellForce and Risen are established RPG franchises. The X series by Egosoft is the best-selling space simulation. The FIFA Manager series was also developed in Germany. The German action game Spec Ops: The Line (2012) was successful in the markets and received largely positive reviews. One of the most famed games from Germany is Far Cry (2004) by Frankfurt-based Crytek, who also produced the topseller Crysis and its sequels later.\nOther well-known current and former developers from Germany include Ascaron, Blue Byte, Deck13, EA Phenomic, Piranha Bytes, Radon Labs, Related Designs, Spellbound Entertainment and Yager Development. Publishers include Deep Silver (Plaion), dtp entertainment, Kalypso Media and Nintendo Europe. Bigpoint Games, Gameforge, Goodgame Studios and Wooga are among the world's leading browser game and social network game developers/distributors.\nThe United Kingdom's video game industry is the third largest in the world in terms of developer success and sales of hardware and software by country alone but fourth behind Canada in terms of people employed.[106] The size of the UK game industry is comparable to its film or music industries.[118]\nLike most European countries, the UK entered the video game industry through personal computers rather than video game consoles. Low-cost computers like the ZX Spectrum and Amiga 500 led to numerous \"bedroom coders\" that would make and sell games through mail-order or to distributors that helped to mass-produce them.[119] Coupled with quirky british humour, the \"Britsoft\" wave of popular games led to a number of influential people and studios in the 1990s.[120] As game programming became more complex and costly in the early 2000s, more traditional studio structures arose to support both personal computers and consoles, with several studios that, in some form or another, remain highly regarded and influential in the present.[121]\nSome of the studios have become defunct or been purchased by larger companies such as LittleBigPlanet developer Media Molecule,[122] and Codemasters.[123] The country is home to some of the world's most successful video game franchises, such as Tomb Raider, Grand Theft Auto, Fable, Colin McRae Dirt, and Total War.\nThe country also went without tax relief until March 21, 2012[124] when the British government changed its mind on tax relief for UK developers, which without, meant most of the talented development within the UK may move overseas for more profit, along with parents of certain video game developers which would pay for having games developed in the UK. The industry trade body TIGA estimates that it will increase the games development sector's contribution to UK GDP by £283 million, generate £172 million in new and protected tax receipts to HM Treasury, and could cost just £96 million over five years.[125] Before the tax relief was introduced there was a fear that the UK game industry could fall behind other leading game industries around the world such as France and Canada, of which Canada overtook the UK in terms of job numbers in the industry in 2010.[126]\nThe video game industry is still in its infancy throughout the African continent, but due to the continent's young population and increasing technological literacy, the sector is growing rapidly. African countries such as South Africa, Nigeria, and Kenya have been making rapid advances in mobile game development, both within their country and internationally,[127] but due to limited funding and a market overcrowded with Western games, success has thus far been minimal.[128]\nVideo gaming is a relatively new sector in Bangladesh. Games have been developed since 2002, mostly independently. However, from 2014, some IT companies have started to develop video games commercially. Some research has been carried out at various universities to improve the video game development sector.[129] In 2020, the first person shooter Zero Hour was released on Steam in Early Access with the version 1.0 being released on September 9, 2024, and has received positive reviews from gamers. It is the first game from Bangladesh to be released on the platform.[130]\nChina had not been a major factor in the global video game market early on due to economic factors, governmental oversight, and a black market for foreign products. The government initiated a ban on video game consoles in 2000 that lasted through 2014, during which China's video game market grew for personal computer games, particularly subscription-based and microtransaction-based ones that were amenable to use in PC cafes, and later into mobile games. Media publishers like Tencent and NetEase focused on these types of games, growing successfully during the 2010s to become leading international companies. As of 2015, China's video game market revenue exceeds that of the United States, and is the largest country by both revenue and number of players.[132][133] China is also the largest contributor towards esports in both revenue and in the number of professional players from the country.[134] The industry, like most media in China, is tightly controlled by the government, with strong restrictions on what content may be in games,[135] and incorporation of anti-addiction measures to limit playtime.[136] It is home to Asia Game Show, the largest game convention in the world by attendance.[137]\nThe Japanese video game industry is markedly different from the industry in North America, Europe and Australia. Japan initially trailed the United States in entering the video game sector as its companies followed trends set by their American partners, but started to pioneer their own ideas soon after. Several Japanese-developed arcade games, such as Space Invaders, helped to usher in the golden age of arcade video games from 1978 to 1982. The 1983 video game crash that affected the North American market did have small but short-term effects in Japan, as most companies involved in the business were well-established and could weather the disruption. Nintendo took the opportunity to push the Nintendo Entertainment System, a rebranding of its Famicom system, into the Western markets after the crash, implementing technical and business practices to avoid the factors that created the 1983 crash but also secured its control on what games were published for the system. Japan became the dominant home for consoles and console games through the early 2000s, challenged only by the incorporation of large publishers in the West and the Xbox line of consoles from Microsoft. Nintendo along with companies like Sega, Sony Interactive Entertainment, and Capcom are dominant leaders in the Japanese video game industry.\nNintendo themselves are recognized for having created some of the most positively-reviewed and best-selling video game series such as Mario, Donkey Kong, The Legend of Zelda, Metroid and Pokémon.\nIn recent years, consoles and arcade games have both been overtaken by downloadable free-to-play games on the PC and mobile platforms.[138][139]\nVideo gaming in India is an emerging market since India is experiencing strong growth in online gaming, making it one of the top gaming markets in the world. Over the past few decades, the Indian gaming industry has gone from close to nonexistent in the 1990s to one of the top markets globally in the late 2010s. In 2019, the online gaming market in India was estimated at ₹6,200 crore (US$730 million) with an estimated 300 million gamers, a 41.6% increase from 2018.[140] As of 2021, it is one of the top five mobile gaming markets in the world. The industry is projected to reach 510 million gamers by 2022.[citation needed]\nThe video game industry in South Korea generally followed the same early trends as the Japanese market, but players started focusing on massively-multiplayer online games (MMO) and other games that could be played at PC bangs (Internet cafes). South Korea was one of the first major regions involved in esports in the 1990s and 2000s, and today a large number of professional esports players originate from South Korea.\nThe video game industry in Taiwan developed along a markedly different path from that of North America, Europe, and Japan. In the 1980s, limited copyright awareness and the high cost of legitimate software led many Taiwanese companies to focus on distributing and modifying imported titles.[141]\nBy the early 1990s, however, Taiwan began to cultivate its own game development scene, with companies like Softstar Entertainment producing influential role-playing titles such as The Legend of Sword and Fairy and the Xuan-Yuan Sword series, both of which became cultural touchstones across the Sinophone world.[142] The release of and transition to Windows 95 initially disrupted Taiwan's PC game development, but studios adapted quickly, and by the late 1990s a wave of domestic games achieved notable commercial success.\nIn the 2000s, the rapid rise of broadband Internet and online gaming reshaped the market. Many studios shifted toward online games and licensed publishing, though the domestic single‑player market declined under pressure from piracy and growing development costs.[143] The era also marked the rise of Taiwan's first professional esports events. In 2003, the Taipei Game Show started attracting international developers and audiences, further embedding online games into Taiwan's youth culture.[144]\nToday, Taiwan's game industry is characterized by a mix of smaller independent studios and established publishers, as well as its vibrant esports scene, with tournaments drawing large audiences and significant sponsorships. For example, a Taiwanese gamer – named Chen Yin-hung – won the Apex Legends championship at 2025's Esports World Cup held in Saudi Arabia, earning the championship and the tournament's most valuable player title, becoming the first Taiwanese player to achieve both distinctions.[145] In 2022, with an estimated total of 17.1 million gamers, the value of Taiwan's digital gaming market exceeded US$2.2 billion, with mobile gaming accounting for the largest share of 63.8%.[146] According to Taiwan's Ministry of Culture, the nation is both a significant consumer and a producer of online and mobile games, with a growing number of developers and art studios contributing to international projects.[147]\nAustralia and New Zealand have an active video game industry, with several standalone developers as well as additional studios from other major developers across the globe.\nGaming conventions are an important showcase of the industry. These typically provide the means for developers and publishers to demonstrate their games directly to video game players and consumers and obtain feedback. New games are frequently introduced during these events. Some examples of each conventions include the annual Gamescom in Cologne, and numerous PAX events. Some publishers, developers and technology producers also have their own regular conventions, with BlizzCon, QuakeCon, Nvision and the X shows being prominent examples.\nNational trade groups that support their local video game industry often will hold trade shows aimed for developers and publishers to interact more directly with the video game media, and with retailers and distributors for planning future sales of products. The largest such trade show was E3 in Los Angeles, California is held by the Entertainment Software Association. Other similar trade shows include Tokyo Game Show (Japan), Brasil Game Show (Brazil), EB Games Expo (Australia), KRI (Russia), ChinaJoy (China) and the annual Game Developers Conference.\nThe development of video games is also a topic of academic and professional interest, leading to a number of conferences for developers to share their knowledge with others. Two of the major professional conferences include the Game Developers Conference (GDC), which holds multiple events through the year but with its main annual conference held in March in San Francisco, and the D.I.C.E. Summit run by the Academy of Interactive Arts & Sciences in February of each year in Las Vegas, Nevada.\nThe coverage of the video game industry started off with several magazines covering the topic, but as the Internet became widely available to support new media, much of the dedicated coverage of the video game industry has transitioned to detected websites, including Gamasutra, IGN, Eurogamer, Polygon and GameSpot. More recently, the effect of social media influencers, video game players that create online videos or stream themselves playing games through services like Twitch, have also become a significant source for coverage of video game news from the consumer point of view.\nAnother facet of tracking the history of the video game industry is video game preservation, a process that is complicated due to game hardware technology that can become obsolete, dependencies on decommissioned online servers, and issues over intellectual property that legally restricts preservation efforts. Much of the industry's history prior to the 1983 crash has been lost, as companies affected by the crash simply threw material away, leaving little to recover today. There is better awareness of video game preservation into the 21st century, and several groups and museums have been established to collect and preserve hardware and software for the industry.[148]\nThe video game industry has a number of annual award ceremonies, commonly associated with the above conventions, trade shows, and conferences, as well as standalone award shows. Many of the dedicated video game journalism websites also have their own set of awards. Most commonly, these ceremonies are capped by the top prize, the \"Game of the Year\".\nThis article needs to be updated.(April 2024) |\nPlayers become fourth-party developers, allowing for more open source models of game design, development and engineering. Players also create modifications (mods), which in some cases become just as popular as the original game for which they were created. An example of this is the game Counter-Strike, which began as a mod of the video game Half-Life and eventually became a very successful, published game in its own right.\nWhile this \"community of modifiers\" may only add up to approximately 1% of a particular game's user base, the number of those involved will grow as more games offer modifying opportunities (such as, by releasing source code) and the video user base swells. According to Ben Sawyer, as many as 600,000 established online game community developers existed as of 2012. This effectively added a new component to the game industry value chain and if it continues to mature, it will integrate itself into the overall industry.[10]\nThe industry has seen a shift towards games with multiplayer facilities. A larger percentage of games on all types of platforms include some type of competitive online multiplayer capability.\nIn addition, the industry is experiencing further significant change driven by convergence, with technology and player comfort being the two primary reasons for this wave of industry convergence. Video games and related content can now be accessed and played on a variety of media, including: cable television, dedicated consoles, handheld devices and smartphones, through social networking sites or through an ISP, through a game developer's website, and online through a game console and/or home or office personal computer. In fact, 12% of U.S. households already make regular use of game consoles for accessing video content provided by online services such as Hulu and Netflix. In 2012, for the first time, entertainment usage passed multiplayer game usage on Xbox, meaning that users spent more time with online video and music services and applications than playing multiplayer games. This rapid type of industry convergence has caused the distinction between video game console and personal computers to disappear. A game console with high-speed microprocessors attached to a television set is, for all intents and purposes, a computer and monitor.[149]\nAs this distinction has been diminished, players' willingness to play and access content on different platforms has increased. The growing video gamer demographic accounts for this trend, as former president of the Entertainment Software Association Douglas Lowenstein explained at the 10th E3 expo, \"Looking ahead, a child born in 1995, E3's inaugural year, will be 19 years old in 2014. And according to Census Bureau data, by the year 2020, there will be 174 million Americans between the ages of 5 and 44. That's 174 million Americans who will have grown up with PlayStations, Xboxes, and GameCubes from their early childhood and teenage years...What this means is that the average gamer will be both older and, given their lifetime familiarity with playing interactive games, more sophisticated and discriminating about the games they play.\"[150]\nEvidence of the increasing player willingness to play video games across a variety of media and different platforms can be seen in the rise of casual gaming on smartphones, tablets, and social networking sites as 92% of all smartphone and tablet owners play games at least once a week, 45% play daily, and industry estimates predict that, by 2016, one-third of all global mobile video game revenue will come from tablets alone.[outdated statistic] Apple's App Store alone has more than 90,000 game apps, a growth of 1,400% since it went online. In addition, game revenues for iOS and Android mobile devices now exceed those of both Nintendo and Sony handheld video game systems combined.[151]\n- Zackariasson, P. and Wilson, T.L. eds. (2012). The Video Game Industry: Formation, Present State, and Future. New York: Routledge.\n- Yodovich, Neta; Bagnall, Gaynor; Crawford, Garry; Gislam, Charlotte; Stukoff, Maria (2025). \"Video Games in/as Culture: The Evolving Cultural Significance of Video Games\". International Journal of the Sociology of Leisure. doi:10.1007/s41978-025-00184-6.\n- \"New ESA Report Shows Gaming Is No Longer A Niche Market\". TheGamer. July 25, 2020. Archived from the original on January 12, 2021. Retrieved December 16, 2020.\n- \"Key Numbers\". newzoo.com. Archived from the original on May 9, 2019. Retrieved August 21, 2021.\n- \"ESA: Facts and figures about the gaming industry in 2010\". TechSpot. June 9, 2011. Archived from the original on June 12, 2021. Retrieved December 16, 2020.\n- Browne, Ryan (July 7, 2022). \"Video game sales set to fall for first time in years as industry braces for recession\". CNBC. Archived from the original on August 9, 2022. Retrieved August 9, 2022.\n- Gain, Bruce. \"Doom 3 Like You've Never Seen\". Wired.\n- Siwek, Stephen E. (2017). \"Video Games in the 21st Century\" (PDF) (Report). Entertainment Software Association. Archived from the original (PDF) on March 10, 2021. Retrieved January 22, 2020.\n- Kelly, Stephen; Klézl, Vojtech; Israilidis, John; Malone, Neil; Butler, Stuart (2020). \"Digital Supply Chain Management in the Videogames Industry: A Systematic Literature Review\" (PDF). The Computer Games Journal. 10 (1–4): 19–40. doi:10.1007/s40869-020-00118-0.\n- Flew, Terry; Humphreys, Sal (2005). \"Games: Technology, Industry, Culture\". New Media: an Introduction (Second ed.). Oxford University Press. pp. 101–114. ISBN 0-19-555149-4.\n- Scacchi, Walt (2010). \"Computer game mods, modders, modding and the mod scene\". First Monday. 15 (5). University of Chicago. doi:10.5210/fm.v15i5.2965.\n- Smith, Alexander (January 22, 2014). \"The Priesthood At Play: Computer Games in the 1950s\". They Create Worlds. Archived from the original on December 22, 2015. Retrieved December 18, 2015.\n- Simmons, Marlene (October 9, 1975). \"Bertie the Brain programmer heads science council\". Ottawa Citizen. p. 17. Archived from the original on March 8, 2021. Retrieved December 18, 2015.\n- Donovan, Tristan (April 20, 2010). Replay: The History of Video Games. Yellow Ant. pp. 1–9. ISBN 978-0-9565072-0-4.\n- \"Video Game History Timeline | The Strong\". Museumofplay.org. Archived from the original on September 6, 2021. Retrieved June 5, 2018.\n- Smith, Alexander (August 7, 2014). \"One, Two, Three, Four I Declare a Space War\". They Create Worlds. Archived from the original on December 22, 2015. Retrieved December 18, 2015.\n- Smith, Alexander (November 19, 2019). They Create Worlds: The Story of the People and Companies That Shaped the Video Game Industry, Vol. I: 1971-1982. CRC Press. pp. 119–20, 188–91. ISBN 978-0-429-75261-2. Archived from the original on January 17, 2023. Retrieved May 21, 2021.\n- \"The Great Videogame Swindle?\". Next Generation. No. 23. Imagine Media. November 1996. pp. 211–229.\n- \"The Gaming Industry – An Introduction\". Cleverism. April 17, 2015. Archived from the original on January 5, 2016. Retrieved December 27, 2015.\n- Ashley S. Lipson & Robert D. Brain (2009). Computer and Video Game Law: Cases and Materials. Carolina Academic Press. p. 9. ISBN 978-1-59460-488-1. Archived from the original on January 17, 2023. Retrieved April 11, 2011.\nAtari eventually sold more than 19,000 Pong machines, giving rise to many imitations. Pong made its first appearance in 1972 at \"Andy Capp's,\" a small bar in Sunnyvale, California, where the video game was literally \"overplayed\" as eager customers tried to cram quarters into an already heavily overloaded coin slot.\n- Jason Whittaker (2004). The cyberspace handbook. Routledge. p. 122. ISBN 0-415-16835-X.\n- Edge Staff (August 13, 2007). \"The 30 Defining Moments in Gaming\". Edge. Future plc. Archived from the original on October 29, 2011. Retrieved September 18, 2008.\n- Jiji Gaho Sha, inc. (2003). \"Asia Pacific Perspectives, Japan\". Asia-Pacific Perspectives, Japan. 1. University of Virginia: 57. Retrieved April 9, 2011.\nAt that time, a game for use in entertainment arcades was considered a hit if it sold 1000 units; sales of Space Invaders topped 300,000 units in Japan and 60,000 units overseas.\n- \"Making millions, 25 cents at a time\". The Fifth Estate. Canadian Broadcasting Corporation. November 23, 1982. Archived from the original on January 28, 2013. Retrieved June 6, 2012.\n- \"Space Invaders vs. Star Wars\". Executive. Vol. 24. Southam Business Publications. 1982. p. 9. Retrieved April 30, 2011.\nAccording to TEC, Atari's arcade game Space Invaders has taken in $2 billion, with net receipts of $450 million.\n- \"The Definitive Space Invaders\". Retro Gamer. No. 41. Imagine Publishing. September 2007. pp. 24–33. Retrieved April 20, 2011.\n- Whittaker, Jason (2004). The cyberspace handbook. Routledge. pp. 122–3. ISBN 0-415-16835-X.\n- Mark J. P. Wolf (2008). The video game explosion: a history from PONG to Playstation and beyond. ABC-CLIO. p. 105. ISBN 978-0-313-33868-7. Retrieved April 19, 2011.\n- \"Electronic Education\". Electronic Education. Vol. 2, no. 5–8. Electronic Communications. 1983. p. 41. Retrieved April 23, 2011.\nIn 1980 alone, according to Time, $2.8 billion in quarters, triple the amount of the previous years, were fed into video games.\n- Mark J. P. Wolf (2008). The video game explosion: a history from PONG to Playstation and beyond. ABC-CLIO. p. 103. ISBN 978-0-313-33868-7. Retrieved April 19, 2011.\n- Everett M. Rogers & Judith K. Larsen (1984). Silicon Valley fever: growth of high-technology culture. Basic Books. p. 263. ISBN 0-465-07821-4. Retrieved April 19, 2025.\nVideo game machines have an average weekly take of $109 per machine. The video arcade industry took in $8 billion in quarters in 1982, surpassing pop music (at $4 billion in sales per year) and Hollywood films ($3 billion, $10 billion if cassette sales and rentals are included). Those 32 billion arcade games played translate to 143 games for every man, woman, and child in America. A recent Atari survey showed that 86 percent of the US population from 13 to 20 has played some kind of video game and an estimated 8 million US homes have video games hooked up to the television set. Sales of home video games were $3.8 billion in 1982, approximately half that of video game arcades.\n- Ellen Goodman (1985). Keeping in touch. Summit Books. p. 38. ISBN 0-671-55376-3. Retrieved April 23, 2011.\nThere are 95,000 others like him spread across the country, getting fed a fat share of the $5 billion in videogame quarters every year.\n- Kevin \"Fragmaster\" Bowen (2001). \"Game of the Week: Pac-Man\". GameSpy. Archived from the original on October 1, 2011. Retrieved April 9, 2011.\nReleased in 1980, Pac-Man was an immediate success. It sold over 350,000 units, and probably would of sold more if not for the numerous illegal pirate and bootleg machines that were also sold.\n- Mark J. P. Wolf (2008). \"Video Game Stars: Pac-Man\". The video game explosion: a history from PONG to Playstation and beyond. ABC-CLIO. p. 73. ISBN 978-0-313-33868-7. Retrieved April 10, 2011.\nIt would go on to become arguably the most famous video game of all time, with the arcade game alone taking in more than a billion dollars, and one study estimated that it had been played more than 10 billion times during the twentieth century.\n- Chris Morris (May 10, 2005). \"Pac Man turns 25: A pizza dinner yields a cultural phenomenon - and millions of dollars in quarters\". CNN. Archived from the original on May 15, 2011. Retrieved April 23, 2011.\nIn the late 1990s, Twin Galaxies, which tracks video game world record scores, visited used game auctions and counted how many times the average Pac Man machine had been played. Based on those findings and the total number of machines that were manufactured, the organization said it believed the game had been played more than 10 billion times in the 20th century.\n- \"World of Spectrum - Archive - YS Top 100\". worldofspectrum.org. Archived from the original on October 30, 2015. Retrieved November 8, 2010.\n- Williams, Andrew (March 16, 2017). History of Digital Games: Developments in Art, Design and Interaction. CRC Press. pp. 143–6, 152–4. ISBN 978-1-317-50381-1.\n- Fahs, Travis (August 8, 2008). \"IGN Presents the History of Madden\". IGN. Archived from the original on October 1, 2012. Retrieved November 9, 2010.\n- Hurby, Patrick. \"The Franchise\". ESPN. Archived from the original on June 25, 2020. Retrieved November 9, 2010.\n- McLaughlin, Rus (July 7, 2010). \"IGN Presents the History of Street Fighter\". IGN. Archived from the original on November 9, 2020. Retrieved November 9, 2010.\n- Compton, Shanna (2004). Gamers: writers, artists & programmers on the pleasures of pixels. Soft Skull Press. p. 119. ISBN 1-932360-57-3.\n- Carter, Jay (July 1993). \"Insert Coin Here: Getting a Fighting Chance\". Electronic Games.\n- Perry, Dave (November 1994). \"Arcades: Ready for a Renaissance?\". Games World. No. 7 (January 1995). Paragon Publishing. p. 6.\n- Spencer, Spanner (February 12, 2008). \"The Tao of Beat-'em-ups (part 2)\". Eurogamer. Archived from the original on July 15, 2011. Retrieved March 18, 2009.\n- Nakamura, Yuki (January 23, 2019). \"Peak Video Game? Top Analyst Sees Industry Slumping in 2019\". Bloomberg L.P. Archived from the original on January 30, 2019. Retrieved January 29, 2019.\n- \"News: Virtua Fighter 3\". Computer and Video Games. No. 174. May 1996. pp. 10–1.\n- \"Second Hand Smoke – One up, two down\". Tom's Hardware Guide. October 22, 1999. Archived from the original on February 22, 2015. Retrieved January 8, 2018.\n- Statistical yearbook: cinema, television, video, and new media in Europe, Volume 1999. Council of Europe. 1996. p. 123. ISBN 9789287129048.\n- Statistical yearbook: cinema, television, video, and new media in Europe, Volume 1999. Council of Europe. 1996. p. 123. ISBN 9789287129048.\n- \"Business Week\". Business Week. No. 3392–3405. Bloomberg. 1994. p. 58. Retrieved January 25, 2012.\nHollywood's aim, of course, is to tap into the $7 billion that Americans pour into arcade games each year — and the $6 billion they spend on home versions for Nintendo and Sega game machines. Combined, it's a market nearly 2 ½ times the size of the $5 billion movie box office.\n- \"Zynga Takes $180 Million Venture Round From DST, Others (Cue Russian Mafia Jokes)\". TechCrunch. December 15, 2009. Archived from the original on February 13, 2013. Retrieved February 11, 2014.\n- \"The Gaming Industry – An Introduction\". Entrepreneurial Insights. April 17, 2015. Archived from the original on October 6, 2015. Retrieved October 5, 2015.\n- van Dreunen, Joost (October 24, 2016). \"Welcome to the New Era: Games as Media\". GamesIndustry.biz. Archived from the original on November 1, 2016. Retrieved October 31, 2016.\n- Radoff, Jon (February 10, 2014). \"The Future of Games and How to Stop It\". medium.com. Archived from the original on February 22, 2014. Retrieved February 11, 2014.\n- Riddell, Don (May 29, 2016). \"ESports: Global revenue expected to smash $1 billion by 2019\". CNN. Archived from the original on January 22, 2018. Retrieved January 16, 2018.\n- Witkowski, Wallace (December 26, 2020). \"Videogames are a bigger industry than movies and North American sports combined, thanks to the pandemic\". Market Watch. Archived from the original on July 16, 2022. Retrieved December 27, 2020.\n- Zhu, Lin (2021). \"The psychology behind video games during COVID-19 pandemic: A case study of Animal Crossing: New Horizons\". Human Behavior and Emerging Technologies. 3: 157–159. doi:10.1002/hbe2.221. ISSN 2578-1863.\n- Grayson, Nathan (September 8, 2020). \"Among Us' Improbable Rise To The Top Of Twitch\". Kotaku Australia. Archived from the original on September 9, 2020. Retrieved September 8, 2020.\n- Grimm, Peter (September 7, 2020). \"Among Us Hits Impressive Concurrent Player Milestone\". Game Rant. Archived from the original on September 9, 2020. Retrieved September 8, 2020.\n- Baird, Scott (September 7, 2020). \"Fall Guys Is Number One On Steam's Bestselling List For Fifth Week In A Row\". TheGamer. Archived from the original on September 9, 2020. Retrieved September 8, 2020.\n- Matthews, Emma (August 25, 2020). \"Why Among Us is the best game to watch on Twitch right now\". PC Gamer. Archived from the original on September 9, 2020. Retrieved September 8, 2020.\n- Antonovici, Anatol (March 23, 2021). \"Bitcoin Mining Adds to Existing Shortage in Semiconductor Market, Chip Prices Surge\". Yahoo News. Archived from the original on April 20, 2021. Retrieved April 20, 2021.\n- Jarred Walton (August 1, 2022). \"Most GPUs Now Start Below MSRP: Graphics Card Prices, August 2022\". Tom's Hardware. Archived from the original on August 10, 2022. Retrieved August 10, 2022.\n- \"Top Gaming Studios, Schools & Salaries\". Big Fish Games. Archived from the original on July 19, 2013. Retrieved August 20, 2013.\n- Superannuation (January 15, 2014). \"How Much Does It Cost To Make A Big Video Game?\". Kotaku. Gawker Media. Archived from the original on January 17, 2014. Retrieved October 30, 2014.\n- Kain, Erik. \"Why Digital Distribution Is The Future And GameStop Is Not: Taking The Long View On Used Games\". Forbes. Archived from the original on October 30, 2014. Retrieved October 30, 2014.\n- \"Call of Duty: Black Ops\" sets record for Activision\" Archived January 25, 2011, at the Wayback Machine. Yahoo Games Plugged In. December 21, 2010. Retrieved on May 19, 2011.\n- \"Variety: GTA IV Launch Bigger Than Halo 3 (And Then Some)\" Archived March 17, 2009, at the Wayback Machine, Kotaku, April 15, 2008. Retrieved on April 15, 2008.\n- \"Japan's Richest Man Is...Yes, Hiroshi Yamauchi\". Forbes. May 7, 2008. Archived from the original on March 30, 2009. Retrieved March 30, 2009.\n- van der Meulen, Rob. \"Gartner Says Worldwide Video Game Market to Total $93 Billion in 2013\". Gartner. Archived from the original on October 31, 2013. Retrieved October 30, 2014.\n- \"Only 25 triple-A console studios left, claims EA\". MCV/Develop. July 5, 2013. Retrieved December 24, 2019.\n- Minoitti, Mike (January 22, 2019). \"NPD: U.S. game sales hit a record $43.4 billion in 2018\". Venture Beat. Archived from the original on January 2, 2020. Retrieved January 22, 2019.\n- Robb, David (July 13, 2018). \"U.S. Film Industry Topped $43 Billion In Revenue Last Year, Study Finds, But It's Not All Good News\". Deadline Hollywood. Archived from the original on January 23, 2019. Retrieved January 22, 2019.\n- \"Is the video game industry recession-proof?\". NBC News. March 6, 2008.\n- Wen, Howard (April 9, 2008). \"Analyze This: Is the Video Game Industry Recession-Proof?\". Archived from the original on September 15, 2022. Retrieved September 14, 2022.\n- \"Even 'recession-proof' video game industry is feeling an economic chill\". The Washington Post. August 22, 2022. Archived from the original on August 24, 2022. Retrieved September 3, 2022.\n- Wingfield, Nick (December 20, 2015). \"As Downloads Take Over, a Turning Point for the Video Game Industry\". The New York Times. ISSN 0362-4331. Archived from the original on July 2, 2018. Retrieved June 30, 2017.\n- Dring, Christopher (December 16, 2016). \"GAME launches Belong - is this the future of video games retail?\". GamesIndustry.biz. Archived from the original on June 15, 2017. Retrieved June 30, 2017.\n- Suellentrop, Chris; Totilo, Stephen (October 3, 2012). \"Video Game Retail Sales Decline Despite New Hits\". The New York Times. ISSN 0362-4331. Archived from the original on January 31, 2018. Retrieved June 30, 2017.\n- Dring, Christopher (November 21, 2016). \"What's going wrong at UK games retail?\". GamesIndustry.biz. Archived from the original on June 22, 2017. Retrieved June 30, 2017.\n- Dring, Christopher (November 8, 2016). \"Is the industry's obsession with Day One coming to an end?\". GamesIndustry.biz. Archived from the original on November 27, 2016. Retrieved June 30, 2017.\n- Purchese, Robert (December 18, 2013). \"Myth-busting the murky world of video game trade-ins\". Eurogamer. Archived from the original on June 22, 2017. Retrieved June 30, 2017.\n- Parfitt, Ben (August 7, 2013). \"Pre-owned price comparison site Trade In Detectives goes live\". MCV. Archived from the original on September 7, 2016. Retrieved June 30, 2017.\n- Wolverton, Troy (May 24, 2005). \"Activision Aims for Sweet Spot\". TheStreet.com. Archived from the original on June 6, 2011. Retrieved March 30, 2009.\n- Valjalo, David (October 4, 2010). \"3DS Will Fight Piracy With Firmware | Edge Magazine\". Next-gen.biz. Archived from the original on April 3, 2013. Retrieved November 9, 2010.\n- \"Technology | EA 'dumps DRM' for next Sims game\". BBC News. March 31, 2009. Archived from the original on December 2, 2012. Retrieved November 9, 2010.\n- \"Global sales of recorded music down 9.2% in the first half of 2002 from IFPI\". ifpi.org. Archived from the original on August 10, 2012. Retrieved July 28, 2010.\n- \"Global sales of recorded music down 10.9% in the first half of 2003 from IFPI\". ifpi.org. Archived from the original on February 6, 2011. Retrieved July 28, 2010.\n- \"Digital sales triple to 6% of industry retail revenues as global music market falls 1.9% (2005) from IFPI\". ifpi.org. Archived from the original on March 3, 2013. Retrieved July 28, 2010.\n- Szalai, Georg (June 21, 2007). \"Video game industry growth still strong: study\". Reuters. Archived from the original on March 8, 2021. Retrieved July 3, 2017.\n- Cai, Wei; Shea, Ryan; Huang, Chun-Ying; Chen, Kuan-Ta; Liu, Jiangchuan; Leung, Victor C. M.; Hsu, Cheng-Hsin (2016). \"A Survey on Cloud Gaming: Future of Computer Games\" (PDF). IEEE Access. 4: 7605. Bibcode:2016IEEEA...4.7605C. doi:10.1109/ACCESS.2016.2590500.\n- Wortham, J. (2009, March 24). OnLive’s “Cloud Gaming” could be a game-changer. Wired. https://www.wired.com/2009/03/cloud-gaming/\n- Shea, R.; Liu, J.; Ngai, E. C.-H.; & Cui, Y. (2012). Cloud Gaming: Architecture and Performance. Simon Fraser University. https://www.sfu.ca/~rws1/papers/Cloud-Gaming-Architecture-and-Performance.pdf\n- Ericsson ConsumerLab. (2024, January). Cloud Gaming Report: Tracing the Consumer Journey. Ericsson. https://www.ericsson.com/en/blog/2024/1/cloud-gaming-report-consumer-research\n- \"Cloud Gaming Market Size & Share | Industry Report, 2030\". www.grandviewresearch.com. Retrieved October 30, 2025.\n- \"E3 is Obsolete, But it Doesn't Matter\". Forbes. June 8, 2012. Retrieved October 18, 2012.\n- Josh Butler (August 11, 2010). \"The irritation of staggered release dates\". Den of Geek. Archived from the original on June 8, 2018. Retrieved June 5, 2018.\n- Elliman, Sarah (November 8, 2017). \"East to West: The Major Differences in Game Releases Based on Geographic Locations\". Gameskinny.com. Archived from the original on August 3, 2020. Retrieved June 5, 2018.\n- \"Region Lock and Video Games\". Dungeoncrawl.com.au. Archived from the original on April 7, 2018. Retrieved June 5, 2018.\n- Jason Rodriguez (August 31, 2017). \"Destiny 2 will have a staggered worldwide release, Australia and Japan get it first\". Destructoid.com. Archived from the original on September 3, 2017. Retrieved June 5, 2018.\n- \"Top Countries/Markets by Game Revenues\". newzoo.com. newzoo. Archived from the original on June 27, 2023. Retrieved June 27, 2023.\n- \"Key data on the movie production and distribution industry worldwide in 2022\". Statistica. Retrieved June 27, 2022.\n- \"A SURVEY OF THE VIDEO GAME MARKET IN 2021\". allcorrectgames.com. April 1, 2022. Archived from the original on April 7, 2023. Retrieved April 7, 2023.\n- \"Top countries and markets by video game revenues\". Newzoo. Archived from the original on March 26, 2023. Retrieved October 6, 2023.\n- \"Top countries and markets by video game revenues\". Newzoo. Archived from the original on March 26, 2023. Retrieved October 6, 2023.\n- \"Canada boasts the third-largest video game industry\". Networkworld.com. April 6, 2010. Archived from the original on April 12, 2010. Retrieved November 9, 2010.\n- \"Immigration Services For Canada, USA, Australia, UK, Australia & New Zealand !\". siiscanada.com. Archived from the original on October 7, 2015.\n- \"What are the leading business sectors in Montréal? We're glad you asked\". Meetings à la Montréal. January 20, 2015. Archived from the original on October 6, 2015. Retrieved October 5, 2015.\n- Kevin Carignan (January 30, 2018). \"Dtoid is hosting Canada's largest gaming event! EGLX returns, March 9-11, 2018\". Destructoid.com. Archived from the original on November 5, 2017. Retrieved June 5, 2018.\n- \"US still the gaming super power | GamesIndustry International\". Gamesindustry.biz. December 11, 2012. Archived from the original on March 31, 2014. Retrieved February 11, 2014.\n- Takahashi, Dean (February 14, 2017). \"The U.S. game industry has 2,457 companies supporting 220,000 jobs\". VentureBeat. Archived from the original on April 7, 2020. Retrieved April 7, 2020.\n- Gough, Christina (August 12, 2019). \"Video Game Industry - Statistics & Facts\". Statista. Archived from the original on September 9, 2019. Retrieved August 23, 2019.\n- \"Games software/hardware $165B+ in 2018, $230B+ in 5 years, record $2B+ investment last year | Digi Capital\". Archived from the original on August 24, 2019. Retrieved August 24, 2019.\n- \"Top 100 Countries by Game Revenue\". newzoo.com. newzoo. January 2017. Archived from the original on March 30, 2016. Retrieved June 3, 2016.\n- \"Industry Facts\". Entertainment Software Association. Archived from the original on May 23, 2019. Retrieved September 23, 2016.\n- \"New Study Finds Video Game Players Are Highly Engaged Politically\". The Entertainment Software Association. Entertainment Software Association. Archived from the original on September 23, 2016. Retrieved September 23, 2016.\n- \"Top 100 Countries By Game Revenues\". newzoo.com. January 2017. Archived from the original on March 30, 2016. Retrieved October 1, 2014.\n- \"The View From the Tower\". gamesindustry.biz. April 5, 2016. Archived from the original on April 8, 2016. Retrieved April 6, 2016.\n- Mardsen, Rhordi (January 25, 2015). \"Geeks Who Rocked The World: Documentary Looks Back At Origins Of The Computer-games Industry\". The Independent. Archived from the original on November 9, 2019. Retrieved October 3, 2019.\n- Stuart, Keith (January 27, 2010). \"Back to the bedroom: how indie gaming is reviving the Britsoft spirit\". The Guardian. Archived from the original on April 5, 2019. Retrieved October 3, 2019.\n- \"How British video games became a billion pound industry\". BBC. December 2014. Archived from the original on September 20, 2019. Retrieved September 30, 2019.\n- \"Media Molecule Officially Joins The PlayStation Family – PlayStation.Blog.Europe\". Blog.eu.playstation.com. March 2, 2010. Archived from the original on March 21, 2015. Retrieved January 27, 2011.\n- Hinkle, David (April 5, 2010). \"Reliance Big Entertainment acquires 50% stake in Codemasters\". Joystiq. Archived from the original on November 7, 2010. Retrieved November 9, 2010.\n- Henderson, Rik (March 21, 2012). \"UK tax relief break\". Archived from the original on March 24, 2012. Retrieved March 31, 2012.\n- \"Game industry tax relief plans are shelved\". Wired.co.uk. June 22, 2010. Archived from the original on June 25, 2010. Retrieved November 9, 2010.\n- \"Canada overtakes UK\". March 31, 2012. Archived from the original on May 9, 2012. Retrieved March 31, 2012.\n- Fripp, Charlie (October 15, 2013). \"Top 10 African game developers\". IT News Africa. Archived from the original on August 3, 2015. Retrieved August 18, 2015.\n- Spooner, Samantha (January 5, 2015). \"Africa 2030, the next 25 years: From video games, eco-buildings, robotics, and cycling\". Mail & Guardian Africa. Archived from the original on September 15, 2015. Retrieved August 18, 2015.\n- \". Daily Observer. Retrieved 21 June 2014.\n- \". Dhaka Tribune. August 9, 2020. Retrieved May 27, 2023.\n- \"Game Revenues of Top 25 Companies up 17%, Totaling $25Bn\". Newzoo. September 30, 2014. Archived from the original on October 4, 2014. Retrieved October 2, 2014.\n- \"The Global Games Market Reaches $99.6 Billion in 2016, Mobile Generating 37%\". newzoo.com. April 21, 2016. Archived from the original on April 7, 2022. Retrieved June 3, 2016.\n- \"Xbox One Hits China Today Following 14-Year Console Ban\". GameSpot. Archived from the original on October 2, 2014. Retrieved October 2, 2014.\n- Valentine, Rebekah (February 12, 2019). \"Newzoo: Global esports market will exceed $1 billion in 2019\". GamesIndustry.biz. Archived from the original on January 17, 2023. Retrieved September 24, 2019.\n- \"China Freezes Game Approvals Amid Agency Shakeup\". Bloomberg L.P. August 14, 2018. Archived from the original on August 16, 2018. Retrieved August 15, 2018.\n- \"China targets video gaming to tackle myopia in children\". BBC. August 31, 2018. Archived from the original on December 10, 2019. Retrieved November 6, 2019.\n- \"The World's Biggest Games Show Isn't In Germany. Not Any More\". Kotaku. December 29, 2011. Archived from the original on August 6, 2018. Retrieved October 2, 2014.\n- \"Japan fights back\". The Economist. November 17, 2012. Archived from the original on July 1, 2017. Retrieved September 17, 2017.\n- \"Market Data\". Capcom. Archived from the original on November 18, 2015. Retrieved October 5, 2012.\n- \"KPMG in India's Media and Entertainment report 2019\" (PDF). KPMG. Archived (PDF) from the original on December 31, 2019.\n- \"1982: Eyeing global leadership\". CommonWealth Magazine (Taiwan). January 22, 2021. Retrieved June 4, 2025.\n- 蘇晟彥 (September 12, 2024). \"大宇賣雙劍震驚老粉 董事長吐心聲：處理閒置IP對大家都好\" (in Chinese (Taiwan)). ETtoday. Retrieved June 4, 2025.\n- MrSun (September 1, 2022). \"你都玩過嗎？盤點那些年熱門的5款「懷舊線上FPS」\" (in Chinese (Taiwan)). Yahoo! News. Retrieved June 4, 2025.\n- \"About TGS\". tgs.tca.org.tw. Retrieved June 4, 2025.\n- \"Gamer 'QQ' wins Apex, MVP title\". Taipei Times. July 15, 2025. Retrieved June 4, 2025.\n- \"The Gaming Market in Taiwan\". allcorrectgames.com. November 16, 2023. Retrieved June 4, 2025.\n- \"Taiwan survey finds nearly half mobile gamers spend NT$300 to NT$1000 monthly\". Taiwan News. July 22, 2024. Retrieved June 4, 2025.\n- Whan, Christopher (August 12, 2018). \"Retro game preservation in limbo after Nintendo files lawsuit\". Global News. Archived from the original on August 13, 2018. Retrieved August 14, 2018.\n- Baran, Stanley J. (2014). Introduction to Mass Communication : Media Literacy and Culture (Eighth ed.). New York: McGraw-Hill. pp. 220–221. ISBN 978-0-07-352621-8.\n- Baran, Stanley J. (2014). Introduction to Mass Communication : Media Literacy and Culture (Eighth ed.). New York: McGraw-Hill. p. 221. ISBN 978-0-07-352621-8.\n- Baran, Stanley J. (2014). Introduction to Mass Communication : Media Literacy and Culture (Eighth ed.). New York: McGraw-Hill. p. 222. ISBN 978-0-07-352621-8.",
    "weapons industry": "| Part of a series on |\n| War (outline) |\n|---|\nThe arms industry, also known as the defense (or defence) industry, military industry, or the arms trade, is a global industry which manufactures and sells weapons and other military technology to a variety of customers, including the armed forces of states and civilian individuals and organizations. Products of the arms industry include weapons, munitions, weapons platforms, communications systems, and other electronics, and related equipment. The arms industry also provides defense-related services, such as logistical and operational support. As a matter of policy, many governments of industrialized countries maintain or support a network of organizations, facilities, and resources to produce weapons and equipment for their military forces (and sometimes those of other countries). This is often referred to as a defense industrial base. Entities involved in arms production for military purposes vary widely, and include private sector commercial firms, state-owned enterprises and public sector organizations, and scientific and academic institutions.[1] Such entities perform a wide variety of functions, including research and development, engineering, production, and servicing of military material, equipment, and facilities. The weapons they produce are often made, maintained, and stored in arsenals.\nIn some regions of the world, there is a substantial legal trade in firearms for use by individuals (commonly cited purposes include self-defense and hunting/sporting). Illegal small arms trade occurs in many countries and regions affected by political instability.\nDuring the early modern period, England, France, Sweden, and the Netherlands became self-sufficient in arms production, with diffusion and migration of skilled workers to more peripheral countries such as Portugal and Russia.[citation needed]\nThe modern arms industry emerged in the second half of the nineteenth century as a product of the creation and expansion of the first large military–industrial companies. As smaller countries and even newly industrializing countries like Russia and Japan could no longer produce cutting-edge military equipment with their Indigenous capacity-based resources, they increasingly began to contract the manufacturers of military equipment, such as battleships, artillery pieces and rifles to foreign government military entities.[citation needed] In 1854, the British government awarded a contract to the Elswick Ordnance Company to supply the latest loading artillery pieces. This galvanized the private sector into weapons production, with the surplus increasingly exported to foreign countries. William Armstrong became one of the first international arms dealers, selling his systems to governments across the world from Brazil to Japan.[2][non-primary source needed] In 1884, he opened a shipyard at Elswick to specialize in warship production – at the time, it was the only factory in the world that could build a battleship and arm it completely.[3] The factory produced warships for foreign naval forces, including the Imperial Japanese Navy. Several Armstrong cruisers played an important role in defeating the Russian fleet at the Battle of Tsushima in 1905.[citation needed] In the American Civil War in 1861 the North had about ten times the manufacturing capacity of the economy of the Confederate States of America. This advantage over the South included the ability to produce (in relatively small numbers) breech-loading rifles for use against the muzzle-loading rifled muskets of the South. This began the transition to industrially produced mechanized weapons such as the Gatling gun.[4]\nThis industrial innovation in the defense industry was adopted by Prussia in its 1864, 1866, and 1870–71 defeats of Denmark, Austria, and, France respectively. By this time the machine gun had begun entering arsenals. The first examples of its effectiveness were in 1899 during the Boer War and in 1905 during the Russo-Japanese War. However, Germany led the innovation of weapons and this advantage in the weapons of World War I nearly defeated the allies.[citation needed]\nIn 1885, France decided to capitalize on this increasingly lucrative trade and repealed its ban on weapon exports. The regulatory framework for the period up to the First World War was characterized by a laissez-faire policy that placed little obstruction in the way of weapons exports. Due to the carnage of World War I, arms traders began to be regarded with odium as \"merchants of death\" and were accused of having instigated and perpetuated the war for earning their profits from weapons sales. An inquiry into these allegations in Britain failed to find evidence to support them. However, the sea change in attitude about war more generally meant that governments began to control and regulate the trade themselves.[citation needed] The volume of the arms trade greatly increased during the 20th century, and it began to be used as a political tool, especially during the Cold War when the United States and the USSR supplied weapons to their proxies across the world, particularly third world countries (see Nixon Doctrine).[5]\nThis category includes everything from light arms to heavy artillery, and the majority of producers are small. Many are located in third-world countries. International trade in handguns, machine guns, tanks, armored personnel carriers, and other relatively inexpensive weapons is substantial. There is relatively little regulation at the international level, and as a result, many weapons fall into the hands of organized crime, rebel forces, terrorists, or regimes under sanctions.[6]\nOne billion firearms were in global circulation in 2017; of those, 857 million (85%) were possessed by civilians, 133 million (13%) were possessed by national militaries, and 23 million (2%) belonged to law enforcement agencies.[7] 1,135 companies based in more than 98 countries manufactured small arms as well as their various components and ammunition as of 2003.[8]\nOne billion firearms were in global circulation in 2017; of those, 857 million (85%) were possessed by civilians, 133 million (13%) were possessed by national militaries, and 23 million (2%) belonged to law enforcement agencies.[9]\nEncompassing military aircraft (both land-based and naval aviation), conventional missiles, and military satellites, this is the most technologically advanced sector of the market. It is also the least competitive from an economic standpoint, with a handful of companies dominating the entire market. The top clients and major producers are virtually all located in the western world and Russia, with the United States easily in the first place. Prominent aerospace firms include Rolls-Royce, BAE Systems, Saab AB, Dassault Aviation, Sukhoi, Mikoyan, EADS, Leonardo, Thales Group, Lockheed Martin, Northrop Grumman, RTX Corporation, and Boeing. There are also several multinational consortia mostly involved in the manufacturing of fighter jets, such as the Eurofighter. The largest military contract in history, signed in October 2001, involved the development of the Joint Strike Fighter.[6]\nSeveral of the world's great powers maintain substantial naval forces to provide a global presence, with the largest nations possessing aircraft carriers, nuclear submarines and advanced anti-air defense systems. The vast majority of military ships are conventionally powered, but some are nuclear-powered. There is also a large global market in second-hand naval vessels, generally purchased by developing countries from Western governments.[6]\nThe cybersecurity industry is expected to be of increasing importance to defense, intelligence, and homeland security agencies.[10][11][better source needed]\nAccording to research institute SIPRI, the volume of international transfers of major weapons in 2010–14 was 16 percent higher than in 2005–2009. The five biggest exporters in 2010–2014 were the United States, Russia, China, Germany, and France, and the five biggest importers were India, Saudi Arabia, China, the United Arab Emirates, and Pakistan. The flow of arms to the Middle East increased by 87 percent between 2009–13 and 2014–18, while there was a decrease in flows to all other regions: Africa, the Americas, Asia and Oceania, and Europe.[13]\nSIPRI has identified 67 countries as exporters of major weapons in 2014–18. The top 5 exporters during the period were responsible for 75 percent of all arms exports. The composition of the five largest exporters of arms changed between 2014 and 2018 and remained unchanged compared to 2009–13, although their combined total exports of major arms were 10 percent higher. In 2014–18, significant increases in arms exports from the US, France and Germany were seen, while Chinese exports rose marginally and Russian exports decreased.[13]\nIn 2014–18, 155 countries (about three-quarters of all countries) imported major weapons. The top 5 recipients accounted for 33 percent of the total arms imports during the period. The top five arms importers – Saudi Arabia, India, Egypt, Australia, and Algeria – accounted for 35 percent of total arms imports in 2014–18. Of these, Saudi Arabia and India were among the top five importers in both 2009–13 and 2014–18.\nIn 2014–18, the volume of major arms international transfers was 7.8 percent higher than in 2009–13 and 23 percent higher than that in 2004–08. The largest arms importer was Saudi Arabia, importing arms primarily from the United States, United Kingdom, and France. Between 2009–13 and 2014–18, the flow of arms to the Middle East increased by 87 percent. Also including India, Egypt, Australia, and Algeria, the top five importers received 35 percent of the total arms imports, during 2014–18. The five largest exporters were the United States, Russia, France, Germany and China.[13]\nImports of major arms by states in Europe increased by 155 per cent between 2015–19 and 2020–24, while the global volume of international arms transfers decreased marginally, by 0.6 per cent. The five largest arms importers in 2020–24 were Ukraine, India, Qatar, Saudi Arabia and Pakistan, while the five largest arms exporters were the United States, France, Russia, China and Germany.[14]\nThe following are estimates from the Stockholm International Peace Research Institute's Arms Transfers Database.[16]\n| 2020-2024 rank |\nExporter | Share of global arms exports (%) |\n|---|---|---|\n| 1 | United States | 43 |\n| 2 | France | 9.6 |\n| 3 | Russia | 7.8 |\n| 4 | China | 5.9 |\n| 5 | Germany | 5.6 |\n| 6 | Italy | 4.8 |\n| 7 | United Kingdom | 3.6 |\n| 8 | Israel | 3.1 |\n| 9 | Spain | 3.0 |\n| 10 | Republic of Korea | 2.2 |\nWhile Russian, Chinese and German arms exports fell from 2015-2019, US and French arms exports rose. The top 25 arms exporters accounted for 98 per cent of the world’s arms exports in 2020–24. States in North America and Europe together accounted for 87 per cent of all arms exports in the period. The five largest exporters in Western Europe supplied around one quarter of total global arms exports in 2020–24.[17]\nSIPRI uses the \"trend-indicator values\" (TIV). These are based on the known unit production costs of weapons and represent the transfer of military resources rather than the financial value of the transfer.[18]\n| 1950–2022 rank |\nSupplier | Arms export (in billion TIV) |\n|---|---|---|\n| 1 | United States | 729,161 |\n| 2 | Soviet Union (1950-1991) | 450,786 |\n| 3 | Russia (1992-present) | 155,926 |\n| 4 | United Kingdom | 144,569 |\n| 5 | France | 136,347 |\n| 6 | Germany | 90,701 |\n| 7 | China | 61,283 |\n| 8 | Italy | 37,328 |\n| 9 | Czechoslovakia (1950-1992) | 31,066 |\n| 10 | Netherlands | 25,632 |\nArms import rankings fluctuate heavily as countries enter and exit wars. Accordingly, 5-year moving averages present a much more accurate picture of import volume, free from yearly fluctuations.[19]\n| 2020-2024 rank |\nImporter | Share of global arms imports (in %) |\n|---|---|---|\n| 1 | Ukraine | 8.8 |\n| 2 | India | 8.3 |\n| 3 | Qatar | 6.8 |\n| 4 | Saudi Arabia | 6.8 |\n| 5 | Pakistan | 4.6 |\n| 6 | Japan | 3.9 |\n| 7 | Australia | 3.5 |\n| 8 | Egypt | 3.3 |\n| 9 | United States | 3.1 |\n| 10 | Kuwait | 2.9 |\nIn the period from 2020 to 2024, the top five arms importers together received 35.3 per cent of all arms imports. States in Asia and Oceania accounted for 33 per cent of all arms imports in 2020–24, followed by Europe (28 per cent), the Middle East (27 per cent), the Americas (6.2 per cent) and Africa (4.5 per cent).[20]\nThis is a list of the world's largest arms manufacturers and other military service companies who profit the most from the war economy, their origin is shown as well. The information is based on a list published by the Stockholm International Peace Research Institute for 2023.[21]\n| 2023 rank | Company name | Arms revenue (US$ billions) |\n% of total revenue from arms |\n|---|---|---|---|\n| 1 | Lockheed Martin | 60.81 | 90 |\n| 2 | RTX Corporation | 40.66 | 59 |\n| 3 | Northrop Grumman | 35.57 | 90.5 |\n| 4 | Boeing | 31.10 | 40 |\n| 5 | General Dynamics | 30.20 | 71.4 |\n| 6 | BAE Systems | 29.81 | 98.2 |\n| 7 | Rostec | 21.73 | 65 |\n| 8 | Aviation Industry Corporation of China | 20.85 | 25 |\n| 9 | NORINCO | 20.56 | 26.8 |\n| 10 | China Electronics Technology Group Corporation | 16.05 | 28.7 |\n| 11 | L3Harris Technologies | 14.76 | 76 |\n| 12 | Airbus | 12.89 | 18.2 |\n| 13 | Leonardo | 12.39 | 75 |\n| 14 | China Aerospace Science and Industry Corporation | 12.35 | 30 |\n| 15 | China State Shipbuilding Corporation | 11.48 | 23.5 |\n... in all countries, markets for military goods work poorly. This is to a large extent independent of the constitution of the state and the social and economic system. In all countries, whether ownership is private or collective, and whether rulers are democratic or authoritarian, the agents on each side of the defense market are powerful and well connected. On one side a senior minister manages a government monopsony: there is only one significant customer for such items as heavy artillery, aircraft, and battleships. On the other side is a charmed circle of big defense contractors. A few large-scale corporations supply such weapons; their ability to squeeze money out of government is augmented by the fact that they are too important for production, employment, and national security for the government to let them fail. As a direct result, defense markets everywhere are notorious for cost overruns, delayed deliveries, quality shortfalls, subsidies, and kickbacks. It would be a mistake, however, to conclude that defense markets everywhere are uniformly the same.\nA free market for weapons cannot exist within a state because the market is necessarily a monopsony where there is a single buyer and a small number of suppliers.[23]: 5, 30–31, 69 The high cost of weapons together with the lack of a free market makes pricing controversial and allegations of corruption and inefficiency common.[23]: 1 Furthermore, the complexity and specialization involved in weapons together with barriers to entry created by the government procurement process frequently result in monopolistic situations where suppliers are able to charge high prices and dictate long delivery times.[23]: 6 The cyclic nature of the business has driven consolidation which further impedes pricing.[23]: 11\nWhile profiteering by the arms industry is frequently blamed for the costs of defense procurement, a comparison between commercial and defense companies found little difference in profitability. Rather, cost overruns appear to be caused by a variety of complicated factors inherent in the structure of military procurement including needless levels of technological sophistication, a bidding process that rewards underbidding, a profit formula that rewards inefficiency by paying contractors a percentage of the total cost, procurement organization structure that hampers decision-making, and concurrent engineering that requires rework of already produced equipment.[24]: 18–19 Technological determinism may arise where competition between weapons systems drives relentless development of new weapons, not because they are needed, but because they are possible.[25]: 32–33 Pressure on the US government has resulted in an inefficient procurement system where the government negotiates with the objective of low contractor profit rather than low overall cost.[23]\nPoorly managed procurement during the American Civil War resulted in generals and states competing against each other when buying arms which resulted in a seller’s market where prices were ten times higher than before the war and the goods were sometimes unusable.[26]: 178 Similar problems occurred at the start of WWII before procurement was centralized to the War Production Board to prevent useless competition.[27]: 119\nBids for government contracts may involve collusion among the bidders to extract exorbitant profits.[28]: 94 High profitability of companies involved in the manufacture of armor plate for ships resulting from their anti-competitive tactics around the year 1900 lead to much public controversy. This culminated in the Budget and Accounting Act of 1921 to limit the sort of abuses perpetrated by the nickel-steel cartel.[29]: 56 The period leading up to WWI saw Navy Department funds being used as a source of federal patronage.[30]: 60\nA continuing community of interests between the military and industry creates the potential for an old boy network in control of weapons procurement that threatens the public interest.[31]: 256–257 This may involve a revolving door dynamic were personnel frequently change their employment between government and private industry, thus making their allegiance unclear.[26]: 179\nMultinational corporations form a global network stitched together by reciprocal agreements and interlocking ownership that may pursue objectives contrary to that of the nations whose resources they employ.[28]: 94 [32]: 43 For example, the English arms maker Vickers supplied field guns to Germany prior to 1914. These guns were then used against British troops during WWI.[28]: 95\nFurthermore, a tradeoff exists between procuring the best specialized parts and materials from international businesses, or attempting to achieve autarky by developing purely domestic substitutes. During the Gulf War, a shortage of advanced ceramic components for Tomahawk missiles occurred. This was caused by a ceramics manufacturer located in the US being pressured by its Japanese parent company, which was in turn pressured by Socialist members of the National Diet to withhold support for the war.[32]: 43–44\nArms control refers to international restrictions upon the development, production, stockpiling, proliferation, and usage of small arms, conventional weapons, and weapons of mass destruction.[33] It is typically exercised through the use of diplomacy, which seeks to persuade governments to accept such limitations through agreements and treaties, although it may also be forced upon non-consenting governments.\n- Arms Trade Treaty, concluded in 2013, entered into force on 24 December 2014.[34]\n- Biological Weapons Convention, signed in 1972, entered into force during 1975\n- Chemical Weapons Convention, signed in 1993, entered into force during 1997\n- Geneva Protocol on biological and chemical weapons during 1925\n- Missile Technology Control Regime (MTCR), 1987\n- Ottawa Treaty on anti-personnel land mines, signed in 1997, entered into force during 1999\n- Outer Space Treaty, signed and entered into force during 1967\n- New START Treaty, signed by Russia and the United States in April 2010, entered into force in February 2011\n- Wassenaar Arrangement, established on 12 July 1996\n- Nicastro, Luke. The U.S. Defense Industrial Base: Background and Issues for Congress. Congressional Research Service. October 12, 2023. https://crsreports.congress.gov/product/pdf/R/R47751\n- \"William Armstrong | About the Man\". williamarmstrong.info. Archived from the original on September 30, 2019. Retrieved July 6, 2021.\n- Dougan, David (1970). The Great Gun-Maker: The Story of Lord Armstrong. Sandhill Press Ltd. ISBN 0-946098-23-9.\n- \"Defense Industries – Military History\". Oxford Bibliographies. Archived from the original on December 7, 2019. Retrieved November 3, 2015.\n- Stohl, Rachel; Grillot, Suzette (2013). The International Arms Trade. Wiley Press. ISBN 9780745654188. Archived from the original on January 21, 2023. Retrieved February 7, 2013.\n- \"International Defense Industry\". Foreign Policy Association (Newsletter). Archived from the original on July 26, 2011. Retrieved May 20, 2007.\n- \"Global Firearms Holdings\". www.smallarmssurvey.org. Retrieved August 21, 2024.\n- Debbie Hillier; Brian Wood (2003). \"Shattered Lives – the case for tough international arms control\" (PDF). Control Arms Campaign. p. 19. Archived from the original (PDF) on July 23, 2011. Retrieved March 28, 2009.\n- \"Global Firearms Holdings\". www.smallarmssurvey.org. Retrieved August 21, 2024.\n- \"The defence industry – a changing game?\". NATO Review. Archived from the original on September 14, 2016. Retrieved July 25, 2021.\n- \"Cyber security for the defence industry\". Cybersecurity Review. May 5, 2015. Archived from the original on December 8, 2015. Retrieved November 2, 2015.\n- Wezeman, Pieter D. (December 7, 2020). \"Arms production\". SIPRI. Archived from the original on December 17, 2014. Retrieved July 25, 2021.\n- Fleurant, Aude; Wezeman, Pieter D.; Wezeman, Siemon T.; Tian, Nan; Kuimova, Alexandra (March 2019). \"TRENDS IN INTERNATIONAL ARMS TRANSFERS, 2018\" (PDF). sipri.org. Archived (PDF) from the original on March 15, 2019. Retrieved July 25, 2021.\n- Trends in International Arms Transfers, 2024 (Report). SIPRI. March 2025.\n- \"US Arms Exports Hit Record High in Fiscal 2023\". Voice of America News. January 29, 2024.\n- Trends in International Arms Transfers, 2024 (Report). SIPRI. March 2025.\n- Wezeman, Simon T.; Djokic, Katarina; George, Mathew; Hussain, Zain; Wezeman, Pieter D. (May 2024). \"6. International Arms Transfers\". SIPRI.\n- \"SIPRI Arms Transfers Database\". SIPRI. February 12, 2024.\n- Trends in International Arms Transfers, 2024 (Report). SIPRI. March 2025.\n- Wezeman, Simon T.; Djokic, Katarina; George, Mathew; Hussain, Zain; Wezeman, Pieter D. (May 2024). \"6. International Arms Transfers\". SIPRI.\n- \"The SIPRI Top 100 arms-producing and military services companies in the world, 2023\". SIPRI. Retrieved January 21, 2025.\n- Harrison, Mark; Markevich, Andrei (2008). \"Chapter 6: The Soviet Market for Weapons\". In Harrison, Mark (ed.). Guns and Rubles: The Defense Industry in the Stalinist State. Yale University Press. pp. 156–179. ISBN 978-0-300-12524-5.\n- Gansler, Jacques (1980). The Defense Industry. The MIT Press. ISBN 0-262-07078-2.\n- Rosen, Steven (1973). \"Chapter 1: Testing the Theory of the Military-Industrial Complex\". In Rosen, Steven (ed.). Testing the Theory of the Military-Industrial Complex. Lexington Books. pp. 1–26. ISBN 0-669-84871-9.\n- Roland, Alex (2021). Delta of Power: The Military-Industrial Complex. Baltimore: Johns Hopkins University Press. ISBN 9781421441818.\n- Molander, Earl (1977). \"Chapter 12: Historical Antecedents of Military-Industrial Criticism\". In Cooling, Benjamin (ed.). War, Business, and American Society. Kennikat Press. pp. 171–187. ISBN 0-8046-9156-8.\n- Beaumont, Roger (1977). \"Chapter 8: Quantum Increase; The MIC in the Second World War\". In Cooling, Benjamin (ed.). War, Business, and American Society. Kennikat Press. pp. 118–132. ISBN 0-8046-9156-8.\n- Trotter, Anne (1977). \"Chapter 6: Development of the \"Merchants of Death Theory\"War, Business, and American Society. Kennikat Press. pp. 93–104. ISBN 0-8046-9156-8.\n- Lischka, Johannes (1977). \"Chapter 3: Armor Plate: Nickel and Steel, Monopoly and Profit\". In Cooling, Benjamin (ed.). War, Business, and American Society. Kennikat Press. pp. 43–58. ISBN 0-8046-9156-8.\n- Ferrell, Henry (1977). \"Chapter 4: Regional Rivalries, Congress, and MIC; The Norfolk and Charlestown Navy Yards, 1913-1920\". In Cooling, Benjamin (ed.). War, Business, and American Society. Kennikat Press. pp. 59–72. ISBN 0-8046-9156-8.\n- Proxmire, William (1972). \"Chapter 17: Retired High-Ranking Military Officers\". In Pursell, Carroll (ed.). The Military-Industrial Complex. Harper & Rowe. pp. 253–263. SBN 06-045296-X.\n- Gansler, Jacques (1995). Defense Conversion: Transforming the Arsenal of Democracy. The MIT Press. ISBN 0-262-07166-5.\n- Kolodkin, Barry. \"What Is Arms Control?\". About. com. The New York Times Company. Archived from the original (Article) on September 3, 2016. Retrieved May 13, 2012.\n- Delgado, Andrea (February 23, 2015). \"Explainer: what is the Arms Trade Treaty?\". The Conversation. Archived from the original on April 29, 2021. Retrieved July 25, 2021.",
    "web hosting service": "| Part of a series on |\n| Internet hosting service |\n|---|\n| Full-featured hosting |\n| Web hosting |\n| Application-specific web hosting |\n| By content format |\n| Other types |\nA web hosting service is a type of Internet hosting service that hosts websites for clients, i.e. it offers the facilities required for them to create and maintain a site and makes it accessible on the World Wide Web. Companies providing web hosting services are sometimes called web hosts.\nTypically, web hosting requires the following:\n- one or more servers to act as the host(s) for the sites; servers may be physical or virtual;\n- colocation for the server(s), providing physical space, electricity, and Internet connectivity;\n- Domain Name System configuration to define name(s) for the sites and point them to the hosting server(s);\n- a web server running on the host;\n- for each site hosted on the server:\n- space on the server(s) to hold the files making up the site;\n- site-specific configuration;\n- often, a database;\n- software and credentials allowing the client to access these, enabling them to create, configure, and modify the site;\n- email connectivity allowing the host and site to send email to the client.\nHistory\nUntil 1991, the Internet was restricted to use only \"... for research and education in the sciences and engineering ...\"[1][2] and was used for email, telnet, FTP and USENET traffic—but only a tiny number of web pages. The World Wide Web protocols had only just been written,[3] and there wouldn't be a graphical web browser for Mac or Windows computers until the end of 1993.[4] Even after there was some opening up of Internet access, the situation was confused[clarification needed] until 1995.[5]\nTo host a website on the internet, an individual or company would need their own computer or server.[2] As not all companies had the budget or expertise to do this, web hosting services began to offer to host users' websites on their own servers, without the client needing to own the necessary infrastructure required to operate the website. The owners of the websites, also called webmasters, would be able to create a website that would be hosted on the web hosting service's server and published to the web by the web hosting service.\nAs the number of users on the World Wide Web grew, the pressure for companies, both large and small, to have an online presence grew. By 1995, companies such as GeoCities, Angelfire and Tripod were offering free hosting.[6]\nClassification\nStatic page hosting\nStatic web page files can be uploaded via File Transfer Protocol (FTP) or a web interface. The files are usually delivered to the Web \"as is\" or with minimal processing. Many Internet service providers (ISPs) offer this service free to subscribers. Individuals and organizations may also obtain web page hosting from alternative service providers.\nFree web hosting service is offered by different companies with limited services, sometimes supported by advertisements,[needs update?] and often limited when compared to paid hosting.\nSingle page hosting is generally sufficient for personal web pages. Personal website hosting is typically free, advertisement-sponsored, or inexpensive. Business website hosting often has a higher expense depending upon the size and type of the site.\nCommercial services that provide static page hosting include GitHub Pages, where the website version control is tracked using Git.\nPeer-to-peer hosting\nLarger hosting services\nA complex site calls for a more comprehensive package that provides database support and application development platforms (e.g. ASP.NET, ColdFusion, Java EE, Perl/Plack, PHP or Ruby on Rails). These facilities allow customers to write or install scripts for applications like forums and content management. Web hosting packages often include a web content management system, so the end-user does not have to worry about the more technical aspects. Secure Sockets Layer (SSL) is used for websites that wish to encrypt the transmitted data.\nTypes of hosting\nInternet hosting services can run web servers. The scope of web hosting services varies greatly.\n- Shared web hosting service\n- One's website is placed on the same server as many other sites, ranging from a few sites to hundreds of websites. Typically, all domains may share a common pool of server resources, such as RAM and the CPU. The features available with this type of service can be quite basic and not flexible in terms of software and updates. Resellers often sell shared web hosting and web companies often have reseller accounts to provide hosting for clients.\n- Reseller web hosting\n- Allows clients to become web hosts themselves. Resellers could function, for individual domains, under any combination of these listed types of hosting, depending on who they are affiliated with as a reseller. Resellers' accounts may vary tremendously in size: they may have their own virtual dedicated server to a colocated server. Many resellers provide a nearly identical service to their provider's shared hosting plan and provide the technical support themselves.\n- Virtual Dedicated Server\n- Also known as a Virtual Private Server (VPS), divides server resources into virtual servers, where resources can be allocated in a way that does not directly reflect the underlying hardware. VPS will often be allocated resources based on a one server to many VPSs relationship, however virtualisation may be done for a number of reasons, including the ability to move a VPS container between servers. The users may have root access to their own virtual space. Customers are sometimes responsible for patching and maintaining the server (unmanaged server) or the VPS provider may provide server admin tasks for the customer (managed server).\n- Dedicated hosting service\n- The user gets their own web server and gains full control over it (user has root access for Linux/administrator access for Windows); however, the user typically does not own the server. One type of dedicated hosting is self-managed or unmanaged. This is usually the least expensive for dedicated plans. The user has full administrative access to the server, which means the client is responsible for the security and maintenance of their own dedicated server.\n- Managed hosting service\n- The user gets their own web server but is not allowed full control over it (user is denied root access for Linux/administrator access for Windows); however, they are allowed to manage their data via FTP or other remote management tools. The user is disallowed full control so that the provider can guarantee quality of service by not allowing the user to modify the server or potentially create configuration problems. The user typically does not own the server. The server is leased to the client.\n- Colocation web hosting service\n- Similar to the dedicated web hosting service, but the user owns the colo server; the hosting company provides physical space that the server takes up and takes care of the server. This is the most powerful and expensive type of web hosting service. In most cases, the colocation provider may provide little to no support directly for their client's machine, providing only the electrical, Internet access, and storage facilities for the server. In most cases for colo, the client would have their own administrator visit the data center on site to do any hardware upgrades or changes. Formerly, many colocation providers would accept any system configuration for hosting, even ones housed in desktop-style minitower cases, but most hosts now require rack mount enclosures and standard system configurations.\n- Cloud hosting\n- Hosting based on clustered load-balanced servers. A cloud hosted website may be more reliable than alternatives since other computers in the cloud can compensate when a single piece of hardware goes down. Also, local power disruptions or even natural disasters are less problematic for cloud hosted sites, as cloud hosting is decentralized. Cloud hosting also allows providers to charge users only for resources consumed by the user, rather than a flat fee for the amount the user expects they will use, or a fixed cost upfront hardware investment. Alternatively, the lack of centralization may give users less control on where their data is located which could be a problem for users with data security or privacy concerns as per GDPR guidelines. Cloud hosting users can request additional resources on-demand such as only during periods of peak traffic, while offloading IT management to the cloud hosting service.\n- Clustered hosting\n- Having multiple servers hosting the same content for better resource utilization. Clustered servers are a perfect solution for high-availability dedicated hosting, or creating a scalable web hosting solution. A cluster may separate web serving from database hosting capability. (Usually web hosts use clustered hosting for their shared hosting plans, as there are multiple benefits to the mass managing of clients).[8]\n- Grid hosting\n- This form of distributed hosting is when a server cluster acts like a grid and is composed of multiple nodes.[citation needed]\n- Home server\n- A private server can be used to host one or more websites from a usually consumer-grade broadband connection. These can be purpose-built machines or more commonly old PCs. Some ISPs block home servers by disallowing incoming requests to TCP port 80 of the user's connection and by refusing to provide static IP addresses. A common way to attain a reliable DNS host name is by creating an account with a dynamic DNS service. A dynamic DNS service will automatically change the IP address that a URL points to when the IP address changes.[9]\nSome specific types of hosting provided by web host service providers:\n- File hosting service: hosts files, not web pages\n- Image hosting service\n- Video hosting service\n- Blog hosting service\n- Paste bin\n- Shopping cart software\n- E-mail hosting service\nHost management\nThe host may also provide an interface or control panel for managing the web server and installing scripts, as well as other modules and service applications like e-mail. A web server that does not use a control panel for managing the hosting account, is often referred to as a \"headless\" server. Some hosts specialize in certain software or services (e.g. e-commerce, blogs, etc.).\nReliability and uptime\nThe availability of a website is measured by the percentage of a year in which the website is publicly accessible and reachable via the Internet. This is different from measuring the uptime of a system. Uptime refers to the system itself being online. Uptime does not take into account being able to reach it as in the event of a network outage.[citation needed] A hosting provider's Service Level Agreement (SLA) may include a certain amount of scheduled downtime per year in order to perform maintenance on the systems. This scheduled downtime is often excluded from the SLA timeframe, and needs to be subtracted from the Total Time when availability is calculated. Depending on the wording of an SLA, if the availability of a system drops below that in the signed SLA, a hosting provider often will provide a partial refund for time lost. How downtime is determined changes from provider to provider, therefore reading the SLA is imperative.[10] Not all providers release uptime statistics.\nSecurity\nBecause web hosting services host websites belonging to their customers, online security is an important concern. When a customer agrees to use a web hosting service, they are relinquishing control of the security of their site to the company that is hosting the site. The level of security that a web hosting service offers is extremely important to a prospective customer and can be a major factor when considering which provider a customer may choose.[11]\nWeb hosting servers can be attacked by malicious users in different ways, including uploading malware or malicious code onto a hosted website. These attacks may be done for different reasons, including stealing credit card data, launching a Distributed Denial of Service Attack (DDoS) or spamming.[12]\nSee also\nReferences\n- March 16, 1992, memo from Mariam Leder, NSF Assistant General Counsel to Steven Wolff, Division Director, NSF DNCRI (included at page 128 of Management of NSFNET, a transcript of the March 12, 1992, hearing before the Subcommittee on Science of the Committee on Science, Space, and Technology, U.S. House of Representatives, One Hundred Second Congress, Second Session, Hon. Rick Boucher, subcommittee chairman, presiding)\n- \"The history of web hosting\". www.tibus.com. Retrieved 2016-12-11.\n- Ward, Mark (3 August 2006). \"How the web went world wide\". BBC News. Retrieved 24 January 2011.\n- Raggett, Dave; Jenny Lam; Ian Alexander (1996). HTML 3: Electronic Publishing on the World Wide Web. Harlow, England; Reading, Mass: Addison-Wesley. p. 21. ISBN 9780201876932.\n- \"Retiring the NSFNET Backbone Service: Chronicling the End of an Era\", Susan R. Harris and Elise Gerich, ConneXions, Vol. 10, No. 4, April 1996\n- \"A History of Web Hosting [Infographic]\". BizTech. 2012-02-24. Retrieved 2016-11-04.\n- \"Peer-To-Peer File Sharing\". Active Web Hosting. Archived from the original on 19 February 2020. Retrieved 3 November 2013.\n- Buyya, Rajkumar; Yeo, Chee Shin; Venugopal, Srikumar (2008). \"Market-Oriented Cloud Computing: Vision, Hype, and Reality for Delivering IT Services as Computing Utilities\". 2008 10th IEEE International Conference on High Performance Computing and Communications. pp. 5–13. arXiv:0808.3558. doi:10.1109/HPCC.2008.172. ISBN 978-0-7695-3352-0. S2CID 16882678.\n- Intark Han; Hong-Shik Park; Youn-Kwae Jeong; Kwang-Roh Park (2006). \"An integrated home server for communication, broadcast reception, and home automation\". IEEE Transactions on Consumer Electronics. 52 (1): 104–109. Bibcode:2006ITCE...52..104H. doi:10.1109/TCE.2006.1605033. S2CID 22145496.\n- Dawson, Christian. \"Why Uptime Guarantees are Ridiculous\". Servint. Retrieved 7 October 2014.\na good SLA will clearly state how uptime is defined and what you'll receive if the \"uptime promise\" is not met.\n- Schultz, Eugene (2003). \"Attackers hit Web hosting servers\". Computers & Security. 22 (4): 273–283. doi:10.1016/s0167-4048(03)00402-4.\n- InstantShift (11 February 2011). \"A Guide to Web Hosting Security Issues and Prevention\". InstantShift - Web Designers and Developers Daily Resource. Retrieved 2016-10-31.",
    "web service": "A web service (WS) is either:\n- a service offered by an electronic device to another electronic device, communicating with each other via the Internet, or\n- a server running on a computer device, listening for requests at a particular port over a network, serving web documents (HTML, JSON, XML, images).[citation needed]\nIn a web service, a web technology such as HTTP is used for transferring machine-readable file formats such as XML and JSON.\nIn practice, a web service commonly provides an object-oriented web-based interface to a database server, utilized for example by another web server, or by a mobile app, that provides a user interface to the end-user. Many organizations that provide data in formatted HTML pages will also provide that data on their server as XML or JSON, often through a Web service to allow syndication. Another application offered to the end-user may be a mashup, where a Web server consumes several Web services at different machines and compiles the content into one user interface.\nAsynchronous JavaScript and XML (AJAX) is a dominant technology for Web services. Developing from the combination of HTTP servers, JavaScript clients and Plain Old XML (as distinct from SOAP and W3C Web Services), now it is frequently used with JSON as well as, or instead of, XML.\nRepresentational State Transfer (REST) is an architecture for well-behaved Web services that can function at Internet scale.\nIn a 2004 document, the W3C sets following REST as a key distinguishing feature of Web services:\nWe can identify two major classes of Web services:\n- REST-compliant Web services, in which the primary purpose of the service is to manipulate XML representations of Web resources using a uniform set of stateless operations; and\n- arbitrary Web services, in which the service may expose an arbitrary set of operations.\nThere are a number of Web services that use markup languages:\n- JSON-RPC.\n- JSON-WSP\n- Representational state transfer (REST) versus remote procedure call (RPC)\n- Simple Object Access Protocol (SOAP)\n- Web Services Conversation Language (WSCL)\n- Web Services Description Language (WSDL), developed by the W3C\n- Web Services Flow Language (WSFL), superseded by BPEL\n- Web template\n- WS-MetadataExchange\n- XML Interface for Network Services (XINS), provides a POX-style web service specification format\nA Web API is a development in Web services where emphasis has been moving to simpler representational state transfer (REST) based communications.[2] Restful APIs do not require XML-based Web service protocols (SOAP and WSDL) to support their interfaces.\nIn relation to W3C Web services, the W3C defined a Web service as:\nA web service is a software system designed to support interoperable machine-to-machine interaction over a network. It has an interface described in a machine-processable format (specifically WSDL). Other systems interact with the web service in a manner prescribed by its description using SOAP-messages, typically conveyed using HTTP with an XML serialization in conjunction with other web-related standards.\nW3C Web Services may use SOAP over HTTP protocol, allowing less costly (more efficient) interactions over the Internet than via proprietary solutions like EDI/B2B. Besides SOAP over HTTP, Web services can also be implemented on other reliable transport mechanisms like FTP. In a 2002 document, the Web Services Architecture Working Group defined a Web services architecture, requiring a standardized implementation of a \"Web service.\"\nThe term \"Web service\" describes a standardized way of integrating Web-based applications using the XML, SOAP, WSDL and UDDI open standards over an Internet Protocol backbone. XML is the data format used to contain the data and provide metadata around it, SOAP is used to transfer the data, WSDL is used for describing the services available and UDDI lists what services are available.\nA Web service is a method of communication between two electronic devices over a network. It is a software function provided at a network address over the Web with the service always-on as in the concept of utility computing.\nMany organizations use multiple software systems for management.[citation needed] Different software systems often need to exchange data with each other, and a Web service is a method of communication that allows two software systems to exchange this data over the Internet. The software system that requests data is called a service requester, whereas the software system that would process the request and provide the data is called a service provider.\nDifferent software may use different programming languages, and hence there is a need for a method of data exchange that doesn't depend upon a particular programming language. Most types of software can, however, interpret XML tags. Thus, Web services can use XML files for data exchange.\nRules for communication with different systems need to be defined, such as:\n- How one system can request data from another system.\n- Which specific parameters are needed in the data request.\n- What would be the structure of the data produced. (Normally, data is exchanged in XML files, and the structure of the XML file is validated against a .xsd file.)\n- What error messages to display when a certain rule for communication is not observed, to make troubleshooting easier.\nAll of these rules for communication are defined in a file called WSDL (Web Services Description Language), which has a .wsdl\nextension. (Proposals for Autonomous Web Services (AWS) seek to develop more flexible Web services that do not rely on strict rules.[a])\nA directory called UDDI (Universal Description, Discovery, and Integration) defines which software system should be contacted for which type of data. So when one software system needs one particular report/data, it would go to the UDDI and find out which other systems it can contact for receiving that data. Once the software system finds out which other systems it should contact, it would then contact that system using a special protocol called SOAP (Simple Object Access Protocol). The service provider system would first validate the data request by referring to the WSDL file, and then process the request and send the data under the SOAP protocol.\nAutomated tools can aid in the creation of a Web service. For services using WSDL, it is possible to either automatically generate WSDL for existing classes (a bottom-up model) or to generate a class skeleton given existing WSDL (a top-down model).\n- A developer using a bottom-up model writes implementing classes first (in some programming language) and then uses a WSDL generating tool to expose methods from these classes as a Web service. This is simpler to develop but may be harder to maintain if the original classes are subject to frequent change.[5]\n- A developer using a top-down model writes the WSDL document first and then uses a code generating tool to produce the class skeleton, to be completed as necessary. This model is generally considered more difficult but can produce cleaner designs and is generally more resistant to change. As long as the message formats between the sender and receiver do not change, changes in the sender and receiver themselves do not affect the Web service. The technique is also referred to as contract first since the WSDL (or contract between sender and receiver) is the starting point.[6]\n- A developer using a Subset WSDL (SWSDL)[7] (i.e. a WSDL with the subset operation in the original WSDL) can perform Web service testing and top-down development.\nCritics of non-RESTful Web services often complain that they are too complex[8] and based upon large software vendors or integrators, rather than typical open source implementations.\nThere are also concerns about performance due to Web services' use of XML as a message format and SOAP/HTTP in enveloping and transporting.[9]\nFunctional and non-functional testing of Web services is done with the help of WSDL parsing. Regression testing is performed by identifying the changes made to upgrade software. Web service regression testing needs can be categorized in three different ways, namely, changes in WSDL, changes in the code, and selective re-testing of operations. We can capture the above three needs in three intermediate forms of Subset WSDL,[7] namely, Difference WSDL (DWSDL), Unit WSDL (UWSDL), and Reduced WSDL (RWSDL), respectively. These three Subset WSDLs are then combined to form Combined WSDL (CWSDL) that is further used for regression testing of the Web service. This will help in Automated Web Service Change Management (AWSCM),[10] by performing the selection of the relevant test cases to construct a reduced test suite from the old test suite. [11]\nWeb services testing can also be automated using several test automation tools like SoapUI, Oracle Application Testing Suite (OATS),[12][13] Unified Functional Testing, Selenium, etc.\nWork-related to the capture and visualization of changes made to a Web service. Visualization and computation of changes can be done in the form of intermediate artifacts (Subset WSDL).[7] The insight on the computation of change impact is helpful in testing, top-down development and reduce regression testing. AWSCM[10] is a tool that can identify subset operations in a WSDL file to construct a subset WSDL.\nWhile UDDI was intended to serve as a service directory and become the means to discovering web services, many vendors discontinued their UDDI solutions or repositories between 2005 and 2008, including Microsoft, SAP, IBM, among others.[14][15] A key study published in WWW2008 Conference (Beijing, China)[16] presented the state of SOAP-based web services and concluded that only 63% of the available SOAP-based web services at the time of the study were actually active or can be invoked. The study also found that search engines were becoming an ideal source for searching for web services compared to that of service registries like the UDDI due its design complexity.[17]\n- List of web service frameworks\n- List of web service protocols\n- List of web service specifications\n- Middleware\n- Service-oriented architecture (SOA)\n- Web Map Service\n- Web API\n- Compare: Oya 2008, \"Under the current Web Services, […] stakeholder systems must follow the predefined rules for a particular business service including those about business protocols to send/receive messages and about system operation. […] More flexible mechanism is desired where freely built and autonomously running systems can exchange business messages without pre-agreed strict rules. We call it Autonomous Web Services (AWS) and proposed the framework called Dynamic Model Harmonization (DMH) with its algorithm, which dynamically adjusts different business process models between systems […].\"[4]\n- \"Web Services Architecture § Relationship to the World Wide Web and REST Architectures\". W3C. Retrieved 11 November 2017.\n- Benslimane, D.; Dustdar, S.; Sheth, A. (2008). \"Services Mashups: The New Generation of Web Applications\". IEEE Internet Computing. 10 (5): 13–15. doi:10.1109/MIC.2008.110. S2CID 8124905.\n- \"Web Services Glossary § Web service\". W3C. 11 February 2004. Retrieved 24 January 2017.\n- Oya, Makoto (2008-09-02). \"Autonomous Web Services Based on Dynamic Model Harmonization\". In Oya, Makoto; Uda, Ryuya; Yasunobu, Chizuko (eds.). Towards Sustainable Society on Ubiquitous Networks: The 8th IFIP Conference on E-Business, E-Services, and E-Society (I3E 2008), September 24 – 26, 2008, Tokyo, Japan. IFIP Advances in Information and Communication Technology. Vol. 286. Springer Science & Business Media (published 2008). p. 139. ISBN 9780387856902. Retrieved 2015-08-19.\n- \"Creating bottom-up Web services\". Eclipse. Retrieved 11 November 2017.\n- \"Creating top-down Web services\". Eclipse. Retrieved 11 November 2017.\n- Chaturvedi, Animesh (2014). Subset WSDL to Access Subset Service for Analysis. 2014 IEEE 6th International Conference on Cloud Computing Technology and Science. p. 688. doi:10.1109/CloudCom.2014.149. ISBN 978-1-4799-4093-6.\n- Bray, Tim (2004-10-28). \"WS-Pagecount\". TBray.org. Retrieved 2011-04-22.\n- Gray, N. A. B. (2005). \"Performance of Java Middleware – Java RMI, JAX-RPC, and CORBA\". University of Wollongong: 31–39.\nThe results presented in this paper show that the nature of response data has a greater impact on relative performance than has been allowed for in most previous studies.\n- Chaturvedi, Animesh (2014). Automated Web Service Change Management AWSCM - A Tool. 2014 IEEE 6th International Conference on Cloud Computing Technology and Science. p. 715. doi:10.1109/CloudCom.2014.144. ISBN 978-1-4799-4093-6.\n- Chaturvedi, Animesh; Gupta, Atul (2013). A tool-supported approach to perform efficient regression testing of Web services. 2013 IEEE 7th International Symposium on the Maintenance and Evolution of Service-Oriented and Cloud-Based Systems. p. 50. doi:10.1109/MESOCA.2013.6632734. ISBN 978-1-4673-4889-8.\n- Oracle Application Testing Suite\n- Web Services Testing using Oracle Application Testing Suite\n- Krill, Paul (2005-12-16). \"Microsoft, IBM, SAP discontinue UDDI registry effort\". InfoWorld. Retrieved 2022-05-28.\n- QuinnRadich (27 April 2021). \"Removal of UDDI Services from Server Operating System – Win32 apps\". docs.microsoft.com. Retrieved 2022-05-28.\n- \"WWW2008 – WWW 2008: 17th International World Wide Web Conference (Welcome)\". Archived from the original on 2022-10-04. Retrieved 2022-05-28.\n- Al-Masri, Eyhab; Mahmoud, Qusay H. (2008-04-21). \"Investigating web services on the world wide web\". Proceedings of the 17th international conference on World Wide Web. WWW '08. New York, NY, USA: Association for Computing Machinery. pp. 795–804. doi:10.1145/1367497.1367605. ISBN 978-1-60558-085-2. S2CID 12570844.\n- Messaging Design Pattern Archived 2018-10-09 at the Wayback Machine documentation at SOA Patterns\n- The Web Services Activity page at W3C\n- Web Services Architecture, the W3C Working Group Note (11 February 2004)\n- Investigating Web Services on the World Wide Web, the analysis presented at the WWW2008 conference\n- Guide to Secure Web Services (SP 800-95) at NIST"
}